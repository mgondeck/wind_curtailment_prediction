{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9mAVew5fDd6i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import load_model\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import joblib\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, f1_score\n",
        "from sklearn.model_selection import TimeSeriesSplit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrDePMGSDvbu",
        "outputId": "d5269607-ce2a-4183-df83-d1f25519b4c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Deep learning model and the Extra trees classifier model"
      ],
      "metadata": {
        "id": "fnkjXBaJEFY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load deep learning model\n",
        "# deep_learning_model = load_model('deep_learning_model.h5')\n",
        "\n",
        "# Load XGBoost classifier\n",
        "xgboost_class = joblib.load('/content/drive/My Drive/ms_wind_curtailment_prediction/xgboost_class.pkl')\n",
        "\n",
        "# Load Extra Trees classifier\n",
        "extra_trees_clf = joblib.load('/content/drive/My Drive/ms_wind_curtailment_prediction/extra_trees_classifier.pkl')\n"
      ],
      "metadata": {
        "id": "v9Ef1Ac5EFMT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/ms_wind_curtailment_prediction/lagged_curtailment_target_features.csv', sep = ';', index_col=0)"
      ],
      "metadata": {
        "id": "0_1UwYdczRm0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get desired df size\n",
        "start_date = '2021-01-01'\n",
        "end_date = '2023-06-30'\n",
        "df = df.loc[start_date:end_date]"
      ],
      "metadata": {
        "id": "lWBWpP7YzMrE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impute, scale pipeline and smote (for class imbalance)\n",
        "preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "smote = SMOTE(random_state=13)\n",
        "\n",
        "# define features X and target y\n",
        "X = df.drop(['redispatch', 'level'], axis = 1)\n",
        "y = df['redispatch']"
      ],
      "metadata": {
        "id": "X0Xr3R7q3IhS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voting use a soft vote"
      ],
      "metadata": {
        "id": "qLFnGmabEKJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a voting classifier with soft voting\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgboost', xgboost_class),\n",
        "        ('extra_trees', extra_trees_clf)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# define features X and target y\n",
        "X = df.drop(['redispatch', 'level'], axis = 1)\n",
        "y = df['redispatch']\n",
        "\n",
        "# cross-validation\n",
        "n_splits = 70\n",
        "test_size = 48 #(48 - 12h with 15 min intervalls)\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=test_size, gap = 10)\n",
        "\n",
        "precision_scores = []\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "precision_train_scores = []\n",
        "f1_train_scores = []\n",
        "conf_train_matrices = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(tscv.split(X), 1):\n",
        "    print(f\"Training on fold {fold}/{n_splits}\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # having at least one instance of redispatch 1 and 0 in test\n",
        "    if y_test.sum() == 0 or y_test.sum() == test_size:\n",
        "        continue\n",
        "\n",
        "    # preprocess train and test data\n",
        "    X_train_scaled = preprocessor.fit_transform(X_train)\n",
        "    X_train_preprocessed, y_train_preprocessed = smote.fit_resample(X_train_scaled, y_train)\n",
        "    X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "    # fit the model\n",
        "    voting_classifier.fit(X_train_preprocessed, y_train_preprocessed)\n",
        "\n",
        "    # Make predictions using the voting classifier\n",
        "    threshold = 0.7\n",
        "    y_prob_voting = voting_classifier.predict_proba(X_test_preprocessed)\n",
        "    y_pred_voting = (y_prob_voting[:, 1] >= threshold).astype(int)\n",
        "    y_train_prob_voting = voting_classifier.predict_proba(X_train_preprocessed)\n",
        "    y_pred_train_voting = (y_train_prob_voting[:, 1] >= threshold).astype(int)\n",
        "\n",
        "    # evaluate\n",
        "    print(\"Calculating evaluation metrics for test set...\")\n",
        "    precision_scores.append(precision_score(y_test, y_pred_voting))\n",
        "    f1_scores.append(f1_score(y_test, y_pred_voting))\n",
        "    conf_matrices.append(confusion_matrix(y_test, y_pred_voting))\n",
        "\n",
        "    print(\"Calculating evaluation metrics for train set...\")\n",
        "    precision_train_scores.append(precision_score(y_train_preprocessed, y_pred_train_voting))\n",
        "    f1_train_scores.append(f1_score(y_train_preprocessed, y_pred_train_voting))\n",
        "    conf_train_matrices.append(confusion_matrix(y_train_preprocessed, y_pred_train_voting))\n",
        "\n",
        "# print evaluation results\n",
        "print(\"Average Scores:\")\n",
        "print(\"Precision:\", np.array(precision_scores).mean())\n",
        "print(\"F1-Scores:\", np.array(f1_scores).mean())\n",
        "print(\"Confusion Matrix:\", sum(conf_matrices)/len(conf_matrices))\n",
        "print(\"Precision (Train):\", np.array(precision_train_scores).mean())\n",
        "print(\"F1-Scores (Train):\", np.array(f1_train_scores).mean())\n",
        "print(\"Confusion Matrix (Train):\", sum(conf_train_matrices)/len(conf_train_matrices))"
      ],
      "metadata": {
        "id": "xgm29_ksEKa2",
        "outputId": "287d254d-c642-4a89-b2dd-603bd1aaad33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1/70\n",
            "Training on fold 2/70\n",
            "Training on fold 3/70\n",
            "Training on fold 4/70\n",
            "Training on fold 5/70\n",
            "Training on fold 6/70\n",
            "Training on fold 7/70\n",
            "Training on fold 8/70\n",
            "Training on fold 9/70\n",
            "Training on fold 10/70\n",
            "Training on fold 11/70\n",
            "Training on fold 12/70\n",
            "Training on fold 13/70\n",
            "Training on fold 14/70\n",
            "Calculating evaluation metrics for test set...\n",
            "Calculating evaluation metrics for train set...\n",
            "Training on fold 15/70\n",
            "Training on fold 16/70\n",
            "Training on fold 17/70\n",
            "Training on fold 18/70\n",
            "Training on fold 19/70\n",
            "Training on fold 20/70\n",
            "Training on fold 21/70\n",
            "Training on fold 22/70\n",
            "Training on fold 23/70\n",
            "Training on fold 24/70\n",
            "Training on fold 25/70\n",
            "Training on fold 26/70\n",
            "Training on fold 27/70\n",
            "Training on fold 28/70\n",
            "Training on fold 29/70\n",
            "Training on fold 30/70\n",
            "Training on fold 31/70\n",
            "Training on fold 32/70\n",
            "Calculating evaluation metrics for test set...\n",
            "Calculating evaluation metrics for train set...\n",
            "Training on fold 33/70\n",
            "Training on fold 34/70\n",
            "Training on fold 35/70\n",
            "Training on fold 36/70\n",
            "Training on fold 37/70\n",
            "Training on fold 38/70\n",
            "Training on fold 39/70\n",
            "Training on fold 40/70\n",
            "Training on fold 41/70\n",
            "Training on fold 42/70\n",
            "Training on fold 43/70\n",
            "Training on fold 44/70\n",
            "Training on fold 45/70\n",
            "Training on fold 46/70\n",
            "Training on fold 47/70\n",
            "Training on fold 48/70\n",
            "Training on fold 49/70\n",
            "Training on fold 50/70\n",
            "Training on fold 51/70\n",
            "Training on fold 52/70\n",
            "Training on fold 53/70\n",
            "Calculating evaluation metrics for test set...\n",
            "Calculating evaluation metrics for train set...\n",
            "Training on fold 54/70\n",
            "Calculating evaluation metrics for test set...\n",
            "Calculating evaluation metrics for train set...\n",
            "Training on fold 55/70\n",
            "Training on fold 56/70\n",
            "Training on fold 57/70\n",
            "Training on fold 58/70\n",
            "Training on fold 59/70\n",
            "Training on fold 60/70\n",
            "Training on fold 61/70\n",
            "Training on fold 62/70\n",
            "Training on fold 63/70\n",
            "Training on fold 64/70\n",
            "Calculating evaluation metrics for test set...\n",
            "Calculating evaluation metrics for train set...\n",
            "Training on fold 65/70\n",
            "Calculating evaluation metrics for test set...\n",
            "Calculating evaluation metrics for train set...\n",
            "Training on fold 66/70\n",
            "Calculating evaluation metrics for test set...\n",
            "Calculating evaluation metrics for train set...\n",
            "Training on fold 67/70\n",
            "Training on fold 68/70\n",
            "Training on fold 69/70\n",
            "Training on fold 70/70\n",
            "Average Scores:\n",
            "Precision: 0.5930541680541681\n",
            "F1-Scores: 0.5506038244215541\n",
            "Confusion Matrix: [[27.          9.        ]\n",
            " [ 1.57142857 10.42857143]]\n",
            "Precision (Train): 0.8710206518273825\n",
            "F1-Scores (Train): 0.3426674706506356\n",
            "Confusion Matrix (Train): [[76626.28571429  2498.42857143]\n",
            " [62245.28571429 16879.42857143]]\n"
          ]
        }
      ]
    }
  ]
}