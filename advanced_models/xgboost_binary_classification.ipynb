{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBTmJiudskN8xZRVVWYzAa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification with XGBoost\n",
        "\n",
        "xgboost tbd."
      ],
      "metadata": {
        "id": "EvVyUtGZ8WdJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cAUnjqGq8e0I"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_score, f1_score\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDLSLy76-MS8",
        "outputId": "8700003d-7e91-48f5-97e7-1be7cee06ac6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# searching for files, load data and convert index to datetime type\n",
        "\n",
        "def search_file(directory, filename):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    return None\n",
        "\n",
        "search_directory = '/content/drive/My Drive'\n",
        "file_name = 'lagged_curtailment_target_features_extended.csv'\n",
        "file_path = search_file(search_directory, file_name)\n",
        "\n",
        "df_lagged = pd.read_csv(file_path, sep = ';', index_col=0)\n",
        "df_lagged.index = pd.to_datetime(df_lagged.index)"
      ],
      "metadata": {
        "id": "6FPmhU2Sxj3d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get desired df size\n",
        "start_date = '2021-07-01'\n",
        "end_date = '2023-11-30'\n",
        "df_lagged = df_lagged.loc[start_date:end_date]"
      ],
      "metadata": {
        "id": "H4kgvp2Q6oTW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impute, scale pipeline and smote (for class imbalance)\n",
        "preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "smote = SMOTE(random_state=13, k_neighbors=3)\n",
        "\n",
        "X = df_lagged.drop(['redispatch', 'level'], axis = 1)\n",
        "y = df_lagged['redispatch']"
      ],
      "metadata": {
        "id": "is0ckOao15OY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "share_minority = y.value_counts().get(1, 0)/len(y)\n",
        "print(share_minority)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgN1sIY5zd-k",
        "outputId": "8de0f4ff-b0e1-41c0-e219-a74aeeafd09f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1367589837491417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-fold cross-validation smoting train and test**"
      ],
      "metadata": {
        "id": "wCnSJnWHTiK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model instance\n",
        "xgboost_class = XGBClassifier(booster='gbtree', reg_alpha=4, reg_lambda=4, eval_metric='logloss',\n",
        "                              n_estimators=300, max_depth=2, learning_rate=0.1, objective='binary:logistic', random_state = 13)\n",
        "# cross-validation\n",
        "n_splits = 10\n",
        "test_size = 96 #(24 - 6h; 48 - 12h; 96 - 24h with 15 min intervalls)\n",
        "\n",
        "# Preprocess data outside the loop\n",
        "X_scaled = preprocessor.fit_transform(X)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "precision_scores = []\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "precision_train_scores = []\n",
        "f1_train_scores = []\n",
        "conf_train_matrices = []\n",
        "\n",
        "total_folds = 0\n",
        "for _ in range(n_splits):\n",
        "    total_folds += 1\n",
        "    print(f\"Fold {total_folds}\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=test_size, random_state=13)\n",
        "\n",
        "    xgboost_class.fit(X_train, y_train)\n",
        "\n",
        "    threshold = 0.5\n",
        "    y_pred_proba = xgboost_class.predict_proba(X_test)[:, 1]\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "    y_train_proba = xgboost_class.predict_proba(X_train)[:, 1]\n",
        "    y_pred_train = (y_train_proba >= threshold).astype(int)\n",
        "\n",
        "    # evaluate\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "    conf_matrices.append(confusion_matrix(y_test, y_pred))\n",
        "    precision_train_scores.append(precision_score(y_train, y_pred_train))\n",
        "    f1_train_scores.append(f1_score(y_train, y_pred_train))\n",
        "    conf_train_matrices.append(confusion_matrix(y_train, y_pred_train))\n",
        "\n",
        "\n",
        "# print evaluation\n",
        "print(\"Average Scores:\")\n",
        "print(\"Precision (Test):\", np.array(precision_scores).mean())\n",
        "print(\"F1-Scores (Test):\", np.array(f1_scores).mean())\n",
        "\n",
        "confusion_matrix_test = False\n",
        "if confusion_matrix_test:\n",
        "  average_conf_matrix = np.round(sum(conf_matrices) / len(conf_matrices)).astype(int)\n",
        "  print(\"Average Confusion Matrix:\")\n",
        "  print(f\"{'True Negative':<20} {'False Positive':<20}\")\n",
        "  print(f\"{average_conf_matrix[0][0]:<20} {average_conf_matrix[0][1]:<20}\")\n",
        "  print(f\"{'False Negative':<20} {'True Positive':<20}\")\n",
        "  print(f\"{average_conf_matrix[1][0]:<20} {average_conf_matrix[1][1]:<20}\")\n",
        "\n",
        "print(\"Precision (Train):\", np.array(precision_train_scores).mean())\n",
        "print(\"F1-Scores (Train):\", np.array(f1_train_scores).mean())\n",
        "\n",
        "confusion_matrix_train = False\n",
        "if confusion_matrix_train:\n",
        "  average_conf_matrix_train = np.round(sum(conf_train_matrices) / len(conf_train_matrices)).astype(int)\n",
        "  print(\"Average Confusion Matrix (Train):\")\n",
        "  print(f\"{'True Negative':<20} {'False Positive':<20}\")\n",
        "  print(f\"{average_conf_matrix_train[0][0]:<20} {average_conf_matrix_train[0][1]:<20}\")\n",
        "  print(f\"{'False Negative':<20} {'True Positive':<20}\")\n",
        "  print(f\"{average_conf_matrix_train[1][0]:<20} {average_conf_matrix_train[1][1]:<20}\")"
      ],
      "metadata": {
        "id": "0zT1aiddThyx",
        "outputId": "83434574-5a37-4092-9b26-701455e0987b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n",
            "Fold 5\n",
            "Fold 6\n",
            "Fold 7\n",
            "Fold 8\n",
            "Fold 9\n",
            "Fold 10\n",
            "Average Scores:\n",
            "Precision (Test): 0.8541666666666666\n",
            "F1-Scores (Test): 0.8723404255319149\n",
            "Precision (Train): 0.8578753473942736\n",
            "F1-Scores (Train): 0.8691571445721333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/wind_curtailment_prediction'\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    print(\"Folder created successfully.\")\n",
        "else:\n",
        "    print(\"Folder already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wY4uWTDzvi4",
        "outputId": "502910e7-bbdf-43fa-943b-d56015a755fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# safe XGBoost classifier\n",
        "joblib.dump(xgboost_class, '/content/drive/My Drive/wind_curtailment_prediction/xgboost_class.pkl')"
      ],
      "metadata": {
        "id": "JmeAc6Yn1icc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c1c2f0-2b0f-43e8-b56b-ce5c600e0b57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/wind_curtailment_prediction/xgboost_class.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra: Grid Search**\n"
      ],
      "metadata": {
        "id": "TOgqejrOtZO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "X_scaled = preprocessor.fit_transform(X)\n",
        "X_preprocessed, y_preprocessed = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [250, 300, 350],\n",
        "    'max_depth': [None, 1, 2],\n",
        "    'reg_alpha': [1, 2, 3],\n",
        "    'reg_lambda': [1, 2, 3],\n",
        "    'scale_pos_weight': [1, 2, 3]\n",
        "}\n",
        "\n",
        "# timeseries split\n",
        "test_size = 96\n",
        "tscv = TimeSeriesSplit(test_size=test_size)\n",
        "\n",
        "# XGBClassifier and GridSearchCV\n",
        "xgboost_class = XGBClassifier(booster='gbtree', eval_metric='logloss', objective='binary:logistic', random_state=13)\n",
        "grid_search = GridSearchCV(estimator=xgboost_class, param_grid=param_grid, cv=tscv, scoring='precision', n_jobs=-1)\n",
        "\n",
        "# fit\n",
        "grid_search.fit(X_preprocessed, y_preprocessed)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "outputId": "e014508c-d260-490e-9fca-5eada422fcc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53pqOnqZYg89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'n_estimators': 250, 'reg_alpha': 1, 'reg_lambda': 1, 'scale_pos_weight': 1}\n",
            "Best Score: 1.0\n"
          ]
        }
      ]
    }
  ]
}