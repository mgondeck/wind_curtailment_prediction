{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlywET4ZRXnI5/dpe9M6hw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Binary Classification with XGBoost**\n",
        "\n"
      ],
      "metadata": {
        "id": "EvVyUtGZ8WdJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cAUnjqGq8e0I"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_score, f1_score\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDLSLy76-MS8",
        "outputId": "a626b98f-7c24-4855-d4b5-fc1007e7c119"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# searching for files, load data and convert index to datetime type\n",
        "def search_file(directory, filename):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    return None\n",
        "\n",
        "search_directory = '/content/drive/My Drive'\n",
        "file_name = 'lagged_curtailment_target_features_extended.csv'\n",
        "file_path = search_file(search_directory, file_name)\n",
        "\n",
        "df_lagged = pd.read_csv(file_path, sep = ';', index_col=0)\n",
        "df_lagged.index = pd.to_datetime(df_lagged.index)"
      ],
      "metadata": {
        "id": "6FPmhU2Sxj3d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get desired df size\n",
        "start_date = '2021-07-01'\n",
        "end_date = '2023-11-30'\n",
        "df_lagged = df_lagged.loc[start_date:end_date]"
      ],
      "metadata": {
        "id": "H4kgvp2Q6oTW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impute, scale pipeline and smote (for class imbalance)\n",
        "preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "smote = SMOTE(k_neighbors=1, random_state=42)\n",
        "\n",
        "X = df_lagged.drop(['redispatch', 'level'], axis = 1)\n",
        "y = df_lagged['redispatch']"
      ],
      "metadata": {
        "id": "is0ckOao15OY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "share_minority = y.value_counts().get(1, 0)/len(y)\n",
        "print(share_minority)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgN1sIY5zd-k",
        "outputId": "71973fef-ab53-45ee-f8b5-d8c61ac3549e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09733031460780152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-fold cross-validation smoting train data**"
      ],
      "metadata": {
        "id": "wCnSJnWHTiK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "params = {\n",
        "    'max_depth': 5,\n",
        "    'min_child_weight': 10,\n",
        "    'gamma': 0.2,\n",
        "    'subsample': 0.5,\n",
        "    'colsample_bytree': 0.5,\n",
        "    'booster': 'gbtree',\n",
        "    'reg_alpha': 4,\n",
        "    'reg_lambda': 4,\n",
        "    'n_estimators': 100,\n",
        "    'learning_rate': 0.1,\n",
        "    'objective': 'binary:logistic',\n",
        "    'random_state': 42,\n",
        "    'verbosity': 0\n",
        "}\n",
        "\n",
        "# cross-validation\n",
        "n_splits = 10\n",
        "gap = 48  # 12 hour difference between train and test sets\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits, gap=gap)\n",
        "\n",
        "precision_scores = []\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "precision_train_scores = []\n",
        "f1_train_scores = []\n",
        "conf_train_matrices = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(tscv.split(X), 1):\n",
        "    print(f\"Training on fold {fold}/{n_splits}\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    xgboost_class = XGBClassifier(**params)\n",
        "    xgboost_class.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    threshold = 0.5\n",
        "    y_pred_proba = xgboost_class.predict_proba(X_test)[:, 1]\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "    y_train_proba = xgboost_class.predict_proba(X_train)[:, 1]\n",
        "    y_pred_train = (y_train_proba >= threshold).astype(int)\n",
        "\n",
        "    # evaluate\n",
        "    precision_scores.append(precision_score(y_test, y_pred, average='binary', zero_division=1))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average='binary', zero_division=1))\n",
        "    conf_matrices.append(confusion_matrix(y_test, y_pred))\n",
        "    precision_train_scores.append(precision_score(y_train, y_pred_train, average='binary', zero_division=1))\n",
        "    f1_train_scores.append(f1_score(y_train, y_pred_train, average='binary', zero_division=1))\n",
        "    conf_train_matrices.append(confusion_matrix(y_train, y_pred_train))\n",
        "\n",
        "\n",
        "# print evaluation\n",
        "print(\"Average Scores:\")\n",
        "print(\"Precision (Test):\", np.array(precision_scores).mean())\n",
        "print(\"F1-Scores (Test):\", np.array(f1_scores).mean())\n",
        "\n",
        "confusion_matrix_test = False\n",
        "if confusion_matrix_test:\n",
        "  average_conf_matrix = np.round(sum(conf_matrices) / len(conf_matrices)).astype(int)\n",
        "  print(\"Average Confusion Matrix:\")\n",
        "  print(f\"{'True Negative':<20} {'False Positive':<20}\")\n",
        "  print(f\"{average_conf_matrix[0][0]:<20} {average_conf_matrix[0][1]:<20}\")\n",
        "  print(f\"{'False Negative':<20} {'True Positive':<20}\")\n",
        "  print(f\"{average_conf_matrix[1][0]:<20} {average_conf_matrix[1][1]:<20}\")\n",
        "\n",
        "print(\"Precision (Train):\", np.array(precision_train_scores).mean())\n",
        "print(\"F1-Scores (Train):\", np.array(f1_train_scores).mean())\n",
        "\n",
        "confusion_matrix_train = False\n",
        "if confusion_matrix_train:\n",
        "  average_conf_matrix_train = np.round(sum(conf_train_matrices) / len(conf_train_matrices)).astype(int)\n",
        "  print(\"Average Confusion Matrix (Train):\")\n",
        "  print(f\"{'True Negative':<20} {'False Positive':<20}\")\n",
        "  print(f\"{average_conf_matrix_train[0][0]:<20} {average_conf_matrix_train[0][1]:<20}\")\n",
        "  print(f\"{'False Negative':<20} {'True Positive':<20}\")\n",
        "  print(f\"{average_conf_matrix_train[1][0]:<20} {average_conf_matrix_train[1][1]:<20}\")"
      ],
      "metadata": {
        "id": "0zT1aiddThyx",
        "outputId": "920ae4cb-c3be-4859-c7e5-0125862b0942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1/10\n",
            "Training on fold 2/10\n",
            "Training on fold 3/10\n",
            "Training on fold 4/10\n",
            "Training on fold 5/10\n",
            "Training on fold 6/10\n",
            "Training on fold 7/10\n",
            "Training on fold 8/10\n",
            "Training on fold 9/10\n",
            "Training on fold 10/10\n",
            "Average Scores:\n",
            "Precision (Test): 0.3970896215290381\n",
            "F1-Scores (Test): 0.28592101936868686\n",
            "Precision (Train): 0.5979080512717131\n",
            "F1-Scores (Train): 0.7043845042387452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/wind_curtailment_prediction'\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    print(\"Folder created successfully.\")\n",
        "else:\n",
        "    print(\"Folder already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wY4uWTDzvi4",
        "outputId": "af6453c1-128d-4ea1-86cf-51d103458d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# safe XGBoost classifier\n",
        "joblib.dump(xgboost_class, '/content/drive/My Drive/wind_curtailment_prediction/xgboost_class.pkl')"
      ],
      "metadata": {
        "id": "JmeAc6Yn1icc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec16f354-d93c-4db0-c591-d91e044eace9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/wind_curtailment_prediction/xgboost_class.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra: Grid Search**\n"
      ],
      "metadata": {
        "id": "TOgqejrOtZO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "X_scaled = preprocessor.fit_transform(X)\n",
        "X_preprocessed, y_preprocessed = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [250, 300, 350],\n",
        "    'max_depth': [None, 1, 2],\n",
        "    'reg_alpha': [1, 2, 3],\n",
        "    'reg_lambda': [1, 2, 3],\n",
        "    'scale_pos_weight': [1, 2, 3]\n",
        "}\n",
        "\n",
        "# timeseries split\n",
        "test_size = 96\n",
        "tscv = TimeSeriesSplit(test_size=test_size)\n",
        "\n",
        "# XGBClassifier and GridSearchCV\n",
        "xgboost_class = XGBClassifier(booster='gbtree', eval_metric='logloss', objective='binary:logistic', random_state=13)\n",
        "grid_search = GridSearchCV(estimator=xgboost_class, param_grid=param_grid, cv=tscv, scoring='precision', n_jobs=-1)\n",
        "\n",
        "# fit\n",
        "grid_search.fit(X_preprocessed, y_preprocessed)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "outputId": "e014508c-d260-490e-9fca-5eada422fcc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53pqOnqZYg89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'n_estimators': 250, 'reg_alpha': 1, 'reg_lambda': 1, 'scale_pos_weight': 1}\n",
            "Best Score: 1.0\n"
          ]
        }
      ]
    }
  ]
}