{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Extra Trees Classifier**"
      ],
      "metadata": {
        "id": "XVQa5EOftYPU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cKboLpcTwXq1"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, f1_score\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from matplotlib import pyplot as plt\n",
        "from statsmodels.graphics.tsaplots import plot_acf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2m0GmJ8wgSM",
        "outputId": "53a99a47-df8f-4fda-f826-39ce7e2c33a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# searching for files, load data and convert index to datetime type\n",
        "def search_file(directory, filename):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    return None\n",
        "\n",
        "search_directory = '/content/drive/My Drive'\n",
        "file_name = 'lagged_curtailment_target_features_etc.csv'\n",
        "file_path = search_file(search_directory, file_name)\n",
        "\n",
        "df_lagged = pd.read_csv(file_path, sep = ';', index_col=0)\n",
        "df_lagged.index = pd.to_datetime(df_lagged.index)"
      ],
      "metadata": {
        "id": "1Ck24BrB2Oov"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get desired df size\n",
        "start_date = '2022-01-01'\n",
        "end_date = '2023-06-30'\n",
        "df_lagged = df_lagged.loc[start_date:end_date]"
      ],
      "metadata": {
        "id": "X7W8rJDE200O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(k_neighbors=1, random_state=42)\n",
        "\n",
        "# define features X and target y\n",
        "X = df_lagged.drop(['redispatch', 'level'], axis = 1)\n",
        "y = df_lagged['redispatch']\n",
        "\n",
        "# hyperparameters\n",
        "params = {\n",
        "    'max_depth': 10,\n",
        "    'min_samples_split': 5,\n",
        "    'min_samples_leaf': 5,\n",
        "    'max_features': 'log2',\n",
        "    'n_estimators': 500,\n",
        "    'random_state': 42,\n",
        "    'class_weight': 'balanced',\n",
        "    'bootstrap': True\n",
        "}\n",
        "\n",
        "# time series cross-validation\n",
        "n_splits = 10\n",
        "gap = 48  # 12 hour difference between train and test sets\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits, gap=gap)\n",
        "threshold = 0.5\n",
        "\n",
        "train_f1_scores = []\n",
        "train_precision_scores = []\n",
        "test_f1_scores = []\n",
        "test_precision_scores = []\n",
        "\n",
        "# iterate over each fold\n",
        "for fold, (train_index, test_index) in enumerate(tscv.split(X), 1):\n",
        "    print(f\"Training on fold {fold}/{n_splits}\")\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    model = ExtraTreesClassifier(**params)\n",
        "    model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # evaluation\n",
        "    train_f1 = f1_score(y_train, y_train_pred, average='binary', zero_division=1)\n",
        "    train_precision = precision_score(y_train, y_train_pred, average='binary', zero_division=1)\n",
        "    test_f1 = f1_score(y_test, y_test_pred, average='binary', zero_division=1)\n",
        "    test_precision = precision_score(y_test, y_test_pred, average='binary', zero_division=1)\n",
        "\n",
        "    train_f1_scores.append(train_f1)\n",
        "    train_precision_scores.append(train_precision)\n",
        "    test_f1_scores.append(test_f1)\n",
        "    test_precision_scores.append(test_precision)\n",
        "\n",
        "    confusion_matrix = False\n",
        "    if confusion_matrix:\n",
        "      cm = confusion_matrix(y_test, y_test_pred)\n",
        "      print(f\"Confusion Matrix (Fold {fold}):\")\n",
        "      print(cm)\n",
        "      print(\"\\n\")\n",
        "\n",
        "avg_train_f1 = np.mean(train_f1_scores)\n",
        "avg_train_precision = np.mean(train_precision_scores)\n",
        "avg_test_f1 = np.mean(test_f1_scores)\n",
        "avg_test_precision = np.mean(test_precision_scores)\n",
        "\n",
        "# Print the results\n",
        "print(\"Average Train F1 Score:\", avg_train_f1)\n",
        "print(\"Average Train Precision:\", avg_train_precision)\n",
        "print(\"\\nAverage Test F1 Score:\", avg_test_f1)\n",
        "print(\"Average Test Precision:\", avg_test_precision)"
      ],
      "metadata": {
        "id": "7qq3Q38f20qs",
        "outputId": "543b7154-520c-4a3b-8e7f-f15741352b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1/10\n",
            "Training on fold 2/10\n",
            "Training on fold 3/10\n",
            "Training on fold 4/10\n",
            "Training on fold 5/10\n",
            "Training on fold 6/10\n",
            "Training on fold 7/10\n",
            "Training on fold 8/10\n",
            "Training on fold 9/10\n",
            "Training on fold 10/10\n",
            "Average Train F1 Score: 0.6811096847995011\n",
            "Average Train Precision: 0.5594604793765078\n",
            "\n",
            "Average Test F1 Score: 0.3739929844817952\n",
            "Average Test Precision: 0.3512463757589768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/wind_curtailment_prediction'\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    print(\"Folder created successfully.\")\n",
        "else:\n",
        "    print(\"Folder already exists.\")"
      ],
      "metadata": {
        "id": "QGhFdqd09MOU",
        "outputId": "94f5e016-e480-49c3-a498-c58ac9c80c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# safe XGBoost classifier\n",
        "joblib.dump(model, '/content/drive/My Drive/wind_curtailment_prediction/extra_trees_classifier.pkl')"
      ],
      "metadata": {
        "id": "5SbnL_u023Dv",
        "outputId": "cc450ddd-04d5-4f13-82fe-e2a045aa976b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/wind_curtailment_prediction/extra_trees_classifier.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra: Grid Search**"
      ],
      "metadata": {
        "id": "wWMIVx0bq_3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "X_scaled = preprocessor.fit_transform(X)\n",
        "X_preprocessed, y_preprocessed = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [200, 250, 300],\n",
        "    'max_depth': [None, 1, 2],\n",
        "    'min_samples_leaf': [2, 3, 4],\n",
        "    'min_samples_split': [1, 2, 3]\n",
        "}\n",
        "\n",
        "# timeseries split\n",
        "test_size = 96\n",
        "tscv = TimeSeriesSplit(test_size=test_size)\n",
        "\n",
        "# XGBClassifier and GridSearchCV\n",
        "extra_trees_clf = ExtraTreesClassifier(max_features='sqrt', random_state=42)\n",
        "grid_search = GridSearchCV(estimator=extra_trees_clf, param_grid=param_grid, cv=tscv, scoring='precision', n_jobs=-1)\n",
        "\n",
        "# fit\n",
        "grid_search.fit(X_preprocessed, y_preprocessed)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "oRYFu6wbq_kV",
        "outputId": "a6701d65-ddc2-4102-eb97-10d427a53462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "135 fits failed out of a total of 405.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "135 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of ExtraTreesClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan  1.  1.  1.  1.  1.  1. nan nan nan  1.  1.  1.  1.  1.  1.\n",
            " nan nan nan  1.  1.  1.  1.  1.  1. nan nan nan  1.  1.  1.  1.  1.  1.\n",
            " nan nan nan  1.  1.  1.  1.  1.  1. nan nan nan  1.  1.  1.  1.  1.  1.\n",
            " nan nan nan  1.  1.  1.  1.  1.  1. nan nan nan  1.  1.  1.  1.  1.  1.\n",
            " nan nan nan  1.  1.  1.  1.  1.  1.]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best Score: 1.0\n"
          ]
        }
      ]
    }
  ]
}