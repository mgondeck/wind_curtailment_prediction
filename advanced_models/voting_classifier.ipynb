{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Soft Voting Classifier**"
      ],
      "metadata": {
        "id": "S-QrVkvGoOvx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9mAVew5fDd6i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.base import is_classifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, f1_score, recall_score\n",
        "\n",
        "from keras.models import load_model\n",
        "import joblib\n",
        "from sklearn.model_selection import TimeSeriesSplit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrDePMGSDvbu",
        "outputId": "5564c9a4-143a-4ddb-faee-b3d6acb4861b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# searching for files, load data and convert index to datetime type\n",
        "def search_file(directory, filename):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    return None\n",
        "\n",
        "search_directory = '/content/drive/My Drive'\n",
        "file_name = 'lagged_curtailment_target_features.csv'\n",
        "file_path = search_file(search_directory, file_name)\n",
        "\n",
        "df_lagged = pd.read_csv(file_path, sep = ';', index_col=0)\n",
        "df_lagged.index = pd.to_datetime(df_lagged.index)"
      ],
      "metadata": {
        "id": "rFzsb_1GnrFp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load XGBoost classifier\n",
        "xgboost_class = joblib.load('/content/drive/My Drive/wind_curtailment_prediction/xgboost_class.pkl')\n",
        "\n",
        "# load Extra Trees classifier\n",
        "extra_trees_clf = joblib.load('/content/drive/My Drive/wind_curtailment_prediction/extra_trees_classifier.pkl')"
      ],
      "metadata": {
        "id": "v9Ef1Ac5EFMT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impute, scale pipeline and smote (for class imbalance)\n",
        "preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "smote = SMOTE(k_neighbors=1, random_state=42)\n",
        "\n",
        "# voting classifier with soft voting\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgboost', xgboost_class),\n",
        "        ('extra_trees', extra_trees_clf)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=[1, 1]\n",
        ")"
      ],
      "metadata": {
        "id": "ufUYpL8TMKni"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get desired df size\n",
        "start_date = '2022-01-01'\n",
        "end_date = '2023-06-30'\n",
        "df_lagged = df_lagged.loc[start_date:end_date]\n",
        "\n",
        "X = df_lagged.drop(['redispatch', 'level'], axis = 1)\n",
        "y = df_lagged['redispatch']"
      ],
      "metadata": {
        "id": "nFDwscXyoAOH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time series cross-validation\n",
        "n_splits = 10\n",
        "gap = 48\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits, gap=gap)\n",
        "train_f1_scores = []\n",
        "train_precision_scores = []\n",
        "test_f1_scores = []\n",
        "test_precision_scores = []\n",
        "\n",
        "# Iterate over each fold\n",
        "for fold, (train_index, test_index) in enumerate(tscv.split(X), 1):\n",
        "    print(f\"Training on fold {fold}/{n_splits}\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "    X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)\n",
        "\n",
        "    voting_classifier.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    y_train_pred = voting_classifier.predict(X_train_preprocessed)\n",
        "    y_test_pred = voting_classifier.predict(X_test_preprocessed)\n",
        "\n",
        "    # evaluate\n",
        "    train_f1 = f1_score(y_train, y_train_pred, average='binary', zero_division=1)\n",
        "    train_precision = precision_score(y_train, y_train_pred, average='binary', zero_division=1)\n",
        "    test_f1 = f1_score(y_test, y_test_pred, average='binary', zero_division=1)\n",
        "    test_precision = precision_score(y_test, y_test_pred, average='binary', zero_division=1)\n",
        "\n",
        "    train_f1_scores.append(train_f1)\n",
        "    train_precision_scores.append(train_precision)\n",
        "    test_f1_scores.append(test_f1)\n",
        "    test_precision_scores.append(test_precision)\n",
        "\n",
        "avg_train_f1 = np.mean(train_f1_scores)\n",
        "avg_train_precision = np.mean(train_precision_scores)\n",
        "avg_test_f1 = np.mean(test_f1_scores)\n",
        "avg_test_precision = np.mean(test_precision_scores)\n",
        "\n",
        "# Print the results\n",
        "print(\"Average Train F1 Score:\", avg_train_f1)\n",
        "print(\"Average Train Precision:\", avg_train_precision)\n",
        "print(\"\\nAverage Test F1 Score:\", avg_test_f1)\n",
        "print(\"Average Test Precision:\", avg_test_precision)"
      ],
      "metadata": {
        "id": "R65sVbsnMa6P",
        "outputId": "874ecd55-3df0-41b1-d9cd-3264b788bf59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1/10\n",
            "Training on fold 2/10\n",
            "Training on fold 3/10\n",
            "Training on fold 4/10\n",
            "Training on fold 5/10\n",
            "Training on fold 6/10\n",
            "Training on fold 7/10\n",
            "Training on fold 8/10\n",
            "Training on fold 9/10\n",
            "Training on fold 10/10\n",
            "Average Train F1 Score: 0.7008136203835795\n",
            "Average Train Precision: 0.5690254824963213\n",
            "\n",
            "Average Test F1 Score: 0.3635277784308423\n",
            "Average Test Precision: 0.43367400359549013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3hkud-vQYutV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}