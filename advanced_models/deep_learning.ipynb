{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Binary Classification with a Deepl Learning Model**"
      ],
      "metadata": {
        "id": "k-dmUa6w-eqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ijerM10CgCXa"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, f1_score\n",
        "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
        "from matplotlib import pyplot as plt\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv1D, BatchNormalization, ReLU, GlobalAveragePooling1D, Dense\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmFcTXOro9wR",
        "outputId": "cec6a1cc-1a7a-47e1-b1fc-800d3fff1bbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load lagged data"
      ],
      "metadata": {
        "id": "s3DA17qi-a_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/ms_wind_curtailment_prediction/lagged_curtailment_target_features.csv', sep = ';', index_col=0)"
      ],
      "metadata": {
        "id": "nMsDoQL7pF5r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert index to datetime type\n",
        "df.index = pd.to_datetime(df.index)\n",
        "# drop wind speed to reduce multicollinearity\n",
        "df.drop(['wind_speed_m/s', 'wind_speed_m/s_lag1', 'wind_speed_m/s_lag2', 'wind_speed_m/s_lag3'], inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "u_LM2zJthu0J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding weekday and season cols"
      ],
      "metadata": {
        "id": "qpVmmx5G_5Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Assuming df_lagged is your DataFrame with a datetime index\n",
        "# Create a new column for weekday/weekend\n",
        "df_lagged['weekday'] = df_lagged.index.weekday < 5\n",
        "\n",
        "# Create a new column for season based on month\n",
        "df_lagged['season'] = (df_lagged.index.month % 12 + 3) // 3\n",
        "\n",
        "# Perform one-hot encoding for the 'season' column\n",
        "df_lagged = pd.get_dummies(df_lagged, columns=['season'], drop_first=True)\n",
        "\n",
        "# Perform one-hot encoding for the 'weekday' column\n",
        "df_lagged = pd.get_dummies(df_lagged, columns=['weekday'], drop_first=True)\n",
        "\n",
        "# Convert the 'weekday' and 'season' columns to numerical\n",
        "df_lagged['weekday'] = df_lagged['weekday_True'].astype(int)\n",
        "df_lagged['season'] = df_lagged[['season_2', 'season_3', 'season_4']].idxmax(axis=1).str.extract(r'(\\d)').astype(int)\n",
        "\n",
        "# Drop the intermediate columns created during one-hot encoding\n",
        "df_lagged.drop(columns=['weekday_True', 'season_2', 'season_3', 'season_4'], inplace=True)\n",
        "\n",
        "# Now df_lagged contains the original data with the new weekday and season columns encoded numerically\n",
        "'''"
      ],
      "metadata": {
        "id": "dzrgWKDf_8Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning model with 3 hidden layers consisting of 100, 50 and 25 neurons"
      ],
      "metadata": {
        "id": "wAckLmg1A4Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get desired df size\n",
        "start_date = '2022-01-01'\n",
        "end_date = '2023-12-31'\n",
        "df = df.loc[start_date:end_date]"
      ],
      "metadata": {
        "id": "YCm1uf7FB4Xz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# impute, scale pipeline and smote (for class imbalance)\n",
        "preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "smote = SMOTE(random_state=13)\n",
        "\n",
        "# define features X and target y\n",
        "X = df.drop(['redispatch', 'level'], axis = 1)\n",
        "y = df['redispatch']"
      ],
      "metadata": {
        "id": "SboRqIGv-mbQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "def make_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        InputLayer(input_shape),\n",
        "        #Dense(100, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)), # add l2 regularization\n",
        "        Dense(100, activation='relu'),\n",
        "        Dense(50, activation='relu'),\n",
        "        #tf.keras.layers.Dropout(0.5), #add dropout layers to reduce overfitting\n",
        "        Dense(25, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape = X.shape[1:]\n",
        "num_classes = 1  # binary classification\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\"),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]"
      ],
      "metadata": {
        "id": "EPwsz3vJ-r_C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross-testidation\n",
        "n_splits = 50 #500\n",
        "test_size = 48 #(48 - 12h with 15 min intervals)\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=test_size, gap = 10)\n",
        "\n",
        "# Initialize lists to store etestuation metrics for each fold\n",
        "f1_scores_train = []\n",
        "precision_scores_train = []\n",
        "f1_scores_test = []\n",
        "precision_scores_test = []\n",
        "\n",
        "# Iterate over each fold\n",
        "for fold, (train_index, test_index) in enumerate(tscv.split(X), 1):\n",
        "    print(f\"Training on fold {fold}/{n_splits}\")\n",
        "\n",
        "    # Get the data for this fold\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # preprocess train data\n",
        "    X_train_balanced = preprocessor.fit_transform(X_train_fold)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_balanced, y_train_fold)\n",
        "\n",
        "    # Define validation and train data for this fold (but test seperate to keep it the same as other models)\n",
        "    val_split = int(len(X_train_fold) * 0.2)  # Adjust validation split as needed\n",
        "    X_val_fold, y_val_fold = X_train_fold[:val_split], y_train_fold[:val_split]\n",
        "    X_train_fold, y_train_fold = X_train_fold[val_split:], y_train_fold[val_split:]\n",
        "\n",
        "    # Create model instance\n",
        "    model = make_model(input_shape, num_classes)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\", tf.keras.metrics.Precision()])\n",
        "\n",
        "    # to address the class imbalance further\n",
        "    class_weights = ...\n",
        "\n",
        "    # Train the model\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      model.fit(\n",
        "          X_train_fold, y_train_fold,\n",
        "          validation_data=(X_val_fold, y_val_fold),\n",
        "          epochs=100,\n",
        "          batch_size=500,\n",
        "          #class_weight=class_weights,\n",
        "          callbacks=callbacks,\n",
        "          verbose=1\n",
        "      )\n",
        "\n",
        "    # preprocess testidation/test data\n",
        "    X_test_fold = preprocessor.transform(X_test_fold)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_test = model.predict(X_test_fold)\n",
        "    y_pred_test_classes = (y_pred_test > 0.5).astype(int)\n",
        "    f1_test = f1_score(y_test_fold, y_pred_test_classes)\n",
        "    precision_test = precision_score(y_test_fold, y_pred_test_classes)\n",
        "\n",
        "    if precision_test != 0 and f1_test != 0:\n",
        "        precision_scores_test.append(precision_test)\n",
        "        f1_scores_test.append(f1_test)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    # Predict on the train set\n",
        "    y_pred_train = model.predict(X_train_fold)\n",
        "    y_pred_train_classes = (y_pred_train > 0.5).astype(int)\n",
        "    f1_train = f1_score(y_train_fold, y_pred_train_classes)\n",
        "    precision_train = precision_score(y_train_fold, y_pred_train_classes)\n",
        "    f1_scores_train.append(f1_train)\n",
        "    precision_scores_train.append(precision_train)\n",
        "\n",
        "    # Print etestuation metrics for fold\n",
        "    print(f\"Fold {fold} - Test F1 score: {f1_test}, Test Precision: {precision_test}\")\n",
        "    print(f\"Fold {fold} - Train F1 score: {f1_train}, Train Precision: {precision_train}\")\n",
        "\n",
        "# Print average scores across all folds\n",
        "print(\"Average F1 score (test):\", np.mean(f1_scores_test))\n",
        "print(\"Average Precision score (test):\", np.mean(precision_scores_test))\n",
        "print(\"Average F1 score (Train):\", np.mean(f1_scores_train))\n",
        "print(\"Average Precision score (Train):\", np.mean(precision_scores_train))\n"
      ],
      "metadata": {
        "id": "zAhpKo9QA39c",
        "outputId": "e577e02a-51c6-47ac-8952-63458622c28a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1/50\n",
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 118.1387 - accuracy: 0.7730 - precision_7: 0.1618 - val_loss: 11.0445 - val_accuracy: 0.8634 - val_precision_7: 0.0218 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 40.0189 - accuracy: 0.7809 - precision_7: 0.1928 - val_loss: 14.7693 - val_accuracy: 0.9397 - val_precision_7: 0.0043 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.0509 - accuracy: 0.7855 - precision_7: 0.1972 - val_loss: 12.6697 - val_accuracy: 0.9391 - val_precision_7: 0.0126 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 46.5257 - accuracy: 0.7889 - precision_7: 0.2064 - val_loss: 134.6392 - val_accuracy: 0.4428 - val_precision_7: 0.0382 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 57.1776 - accuracy: 0.7873 - precision_7: 0.2155 - val_loss: 27.9500 - val_accuracy: 0.9091 - val_precision_7: 0.0166 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 41.5901 - accuracy: 0.7935 - precision_7: 0.2152 - val_loss: 11.7148 - val_accuracy: 0.9234 - val_precision_7: 0.0029 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.0125 - accuracy: 0.7966 - precision_7: 0.2355 - val_loss: 4.4208 - val_accuracy: 0.8689 - val_precision_7: 0.0144 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 16.9614 - accuracy: 0.7963 - precision_7: 0.2321 - val_loss: 4.1713 - val_accuracy: 0.9326 - val_precision_7: 0.0036 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.2774 - accuracy: 0.7987 - precision_7: 0.2391 - val_loss: 59.4665 - val_accuracy: 0.4784 - val_precision_7: 0.0391 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.6757 - accuracy: 0.7941 - precision_7: 0.2312 - val_loss: 4.0553 - val_accuracy: 0.7670 - val_precision_7: 0.0180 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.0494 - accuracy: 0.7990 - precision_7: 0.2389 - val_loss: 4.1974 - val_accuracy: 0.8895 - val_precision_7: 0.0178 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 14.7261 - accuracy: 0.7986 - precision_7: 0.2391 - val_loss: 3.2492 - val_accuracy: 0.8799 - val_precision_7: 0.0093 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.0189 - accuracy: 0.7997 - precision_7: 0.2436 - val_loss: 8.6255 - val_accuracy: 0.8616 - val_precision_7: 0.0257 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.6491 - accuracy: 0.7985 - precision_7: 0.2343 - val_loss: 9.8204 - val_accuracy: 0.8862 - val_precision_7: 0.0164 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.9568 - accuracy: 0.7960 - precision_7: 0.2371 - val_loss: 6.6772 - val_accuracy: 0.8202 - val_precision_7: 0.0234 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 14.0689 - accuracy: 0.7990 - precision_7: 0.2365 - val_loss: 3.1520 - val_accuracy: 0.8597 - val_precision_7: 0.0145 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 10.2960 - accuracy: 0.8011 - precision_7: 0.2500 - val_loss: 2.7321 - val_accuracy: 0.7582 - val_precision_7: 0.0375 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.3383 - accuracy: 0.7995 - precision_7: 0.2468 - val_loss: 11.1959 - val_accuracy: 0.9496 - val_precision_7: 0.0091 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.7514 - accuracy: 0.7982 - precision_7: 0.2378 - val_loss: 10.1629 - val_accuracy: 0.8990 - val_precision_7: 0.0245 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.2166 - accuracy: 0.8001 - precision_7: 0.2353 - val_loss: 3.4301 - val_accuracy: 0.8084 - val_precision_7: 0.0299 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 10.9832 - accuracy: 0.7999 - precision_7: 0.2381 - val_loss: 2.1491 - val_accuracy: 0.8549 - val_precision_7: 0.0104 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.9986 - accuracy: 0.8006 - precision_7: 0.2467 - val_loss: 2.4731 - val_accuracy: 0.9007 - val_precision_7: 0.0138 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.6920 - accuracy: 0.8013 - precision_7: 0.2440 - val_loss: 2.6716 - val_accuracy: 0.7907 - val_precision_7: 0.0290 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 8.7954 - accuracy: 0.7990 - precision_7: 0.2461 - val_loss: 1.7266 - val_accuracy: 0.9041 - val_precision_7: 0.0135 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.0696 - accuracy: 0.8065 - precision_7: 0.2554 - val_loss: 23.9767 - val_accuracy: 0.4693 - val_precision_7: 0.0407 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.7981 - accuracy: 0.8027 - precision_7: 0.2522 - val_loss: 2.6924 - val_accuracy: 0.8919 - val_precision_7: 0.0217 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.3751 - accuracy: 0.8053 - precision_7: 0.2521 - val_loss: 3.6617 - val_accuracy: 0.8540 - val_precision_7: 0.0291 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 6.4389 - accuracy: 0.8053 - precision_7: 0.2676 - val_loss: 1.1637 - val_accuracy: 0.8356 - val_precision_7: 0.0264 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.3579 - accuracy: 0.8066 - precision_7: 0.2579 - val_loss: 1.7237 - val_accuracy: 0.8569 - val_precision_7: 0.0087 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.0245 - accuracy: 0.8064 - precision_7: 0.2599 - val_loss: 1.2818 - val_accuracy: 0.8275 - val_precision_7: 0.0304 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.1424 - accuracy: 0.8000 - precision_7: 0.2410 - val_loss: 7.6955 - val_accuracy: 0.9148 - val_precision_7: 0.0296 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 6.9669 - accuracy: 0.8039 - precision_7: 0.2495 - val_loss: 2.0314 - val_accuracy: 0.8768 - val_precision_7: 0.0191 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 6.8669 - accuracy: 0.8039 - precision_7: 0.2536 - val_loss: 1.2733 - val_accuracy: 0.8832 - val_precision_7: 0.0159 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 4.7596 - accuracy: 0.8063 - precision_7: 0.2603 - val_loss: 2.9076 - val_accuracy: 0.6606 - val_precision_7: 0.0325 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.4925 - accuracy: 0.8082 - precision_7: 0.2672 - val_loss: 2.9305 - val_accuracy: 0.8973 - val_precision_7: 0.0240 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.7124 - accuracy: 0.8038 - precision_7: 0.2547 - val_loss: 1.9620 - val_accuracy: 0.7867 - val_precision_7: 0.0230 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.3417 - accuracy: 0.8069 - precision_7: 0.2628 - val_loss: 1.4814 - val_accuracy: 0.8080 - val_precision_7: 0.0266 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.4935 - accuracy: 0.8076 - precision_7: 0.2624 - val_loss: 8.4783 - val_accuracy: 0.4961 - val_precision_7: 0.0412 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 3.4159 - accuracy: 0.8097 - precision_7: 0.2785 - val_loss: 0.8614 - val_accuracy: 0.8959 - val_precision_7: 0.0066 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.6234 - accuracy: 0.8038 - precision_7: 0.2545 - val_loss: 1.3386 - val_accuracy: 0.8581 - val_precision_7: 0.0094 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.3567 - accuracy: 0.8094 - precision_7: 0.2692 - val_loss: 6.5289 - val_accuracy: 0.6090 - val_precision_7: 0.0423 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.2844 - accuracy: 0.8095 - precision_7: 0.2726 - val_loss: 0.9753 - val_accuracy: 0.8466 - val_precision_7: 0.0142 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.8583 - accuracy: 0.8081 - precision_7: 0.2729 - val_loss: 1.3209 - val_accuracy: 0.9113 - val_precision_7: 0.0139 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.2915 - accuracy: 0.8086 - precision_7: 0.2683 - val_loss: 1.8628 - val_accuracy: 0.9123 - val_precision_7: 0.0036 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.8811 - accuracy: 0.8102 - precision_7: 0.2756 - val_loss: 1.5864 - val_accuracy: 0.9167 - val_precision_7: 0.0064 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.2039 - accuracy: 0.8087 - precision_7: 0.2642 - val_loss: 1.8058 - val_accuracy: 0.6793 - val_precision_7: 0.0387 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.7259 - accuracy: 0.8057 - precision_7: 0.2563 - val_loss: 2.0292 - val_accuracy: 0.8888 - val_precision_7: 0.0327 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.5918 - accuracy: 0.8074 - precision_7: 0.2668 - val_loss: 0.8807 - val_accuracy: 0.9123 - val_precision_7: 0.0024 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.1190 - accuracy: 0.8117 - precision_7: 0.2745 - val_loss: 3.7075 - val_accuracy: 0.5822 - val_precision_7: 0.0424 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.9703 - accuracy: 0.8086 - precision_7: 0.2656 - val_loss: 1.1279 - val_accuracy: 0.9062 - val_precision_7: 0.0011 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.5667 - accuracy: 0.8098 - precision_7: 0.2700 - val_loss: 0.9557 - val_accuracy: 0.9172 - val_precision_7: 0.0052 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.4315 - accuracy: 0.8097 - precision_7: 0.2748 - val_loss: 1.0512 - val_accuracy: 0.9210 - val_precision_7: 0.0069 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.8343 - accuracy: 0.8119 - precision_7: 0.2734 - val_loss: 1.2968 - val_accuracy: 0.9342 - val_precision_7: 0.0284 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.7302 - accuracy: 0.8142 - precision_7: 0.2825 - val_loss: 3.6682 - val_accuracy: 0.6293 - val_precision_7: 0.0441 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.7968 - accuracy: 0.8133 - precision_7: 0.2820 - val_loss: 0.6583 - val_accuracy: 0.9052 - val_precision_7: 0.0116 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.5487 - accuracy: 0.8143 - precision_7: 0.2827 - val_loss: 0.6799 - val_accuracy: 0.8028 - val_precision_7: 0.0235 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.5483 - accuracy: 0.8139 - precision_7: 0.2816 - val_loss: 0.5511 - val_accuracy: 0.7879 - val_precision_7: 0.0348 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.3464 - accuracy: 0.8187 - precision_7: 0.2963 - val_loss: 0.8522 - val_accuracy: 0.9192 - val_precision_7: 0.0093 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.6008 - accuracy: 0.8145 - precision_7: 0.2828 - val_loss: 0.5239 - val_accuracy: 0.9322 - val_precision_7: 0.0018 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4926 - accuracy: 0.8148 - precision_7: 0.2806 - val_loss: 0.6085 - val_accuracy: 0.8038 - val_precision_7: 0.0241 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.4270 - accuracy: 0.8128 - precision_7: 0.2818 - val_loss: 0.4972 - val_accuracy: 0.8903 - val_precision_7: 0.0087 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.2665 - accuracy: 0.8176 - precision_7: 0.2935 - val_loss: 0.7719 - val_accuracy: 0.7586 - val_precision_7: 0.0358 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.2405 - accuracy: 0.8174 - precision_7: 0.2940 - val_loss: 0.9612 - val_accuracy: 0.9311 - val_precision_7: 0.0233 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 1.2457 - accuracy: 0.8175 - precision_7: 0.2964 - val_loss: 0.4266 - val_accuracy: 0.8857 - val_precision_7: 0.0187 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9683 - accuracy: 0.8201 - precision_7: 0.2985 - val_loss: 0.4687 - val_accuracy: 0.9400 - val_precision_7: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0567 - accuracy: 0.8207 - precision_7: 0.3010 - val_loss: 0.4315 - val_accuracy: 0.8608 - val_precision_7: 0.0404 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 1.3517 - accuracy: 0.8126 - precision_7: 0.2744 - val_loss: 0.3668 - val_accuracy: 0.8975 - val_precision_7: 0.0105 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8850 - accuracy: 0.8230 - precision_7: 0.3072 - val_loss: 0.3792 - val_accuracy: 0.8702 - val_precision_7: 0.0132 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9255 - accuracy: 0.8230 - precision_7: 0.3064 - val_loss: 0.5484 - val_accuracy: 0.7848 - val_precision_7: 0.0217 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.2232 - accuracy: 0.8188 - precision_7: 0.2923 - val_loss: 0.4655 - val_accuracy: 0.8339 - val_precision_7: 0.0395 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8764 - accuracy: 0.8204 - precision_7: 0.2990 - val_loss: 0.4210 - val_accuracy: 0.8826 - val_precision_7: 0.0142 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9260 - accuracy: 0.8205 - precision_7: 0.2994 - val_loss: 0.3392 - val_accuracy: 0.9200 - val_precision_7: 0.0121 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.8276 - precision_7: 0.3228 - val_loss: 0.2834 - val_accuracy: 0.9355 - val_precision_7: 0.0039 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9308 - accuracy: 0.8197 - precision_7: 0.2913 - val_loss: 0.8864 - val_accuracy: 0.6796 - val_precision_7: 0.0375 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.8253 - precision_7: 0.3068 - val_loss: 1.3200 - val_accuracy: 0.5861 - val_precision_7: 0.0428 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7847 - accuracy: 0.8249 - precision_7: 0.3132 - val_loss: 0.3068 - val_accuracy: 0.9109 - val_precision_7: 0.0115 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7036 - accuracy: 0.8286 - precision_7: 0.3231 - val_loss: 0.4031 - val_accuracy: 0.9328 - val_precision_7: 0.0158 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9346 - accuracy: 0.8202 - precision_7: 0.2921 - val_loss: 0.4074 - val_accuracy: 0.9045 - val_precision_7: 0.0196 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.8268 - precision_7: 0.3169 - val_loss: 0.3376 - val_accuracy: 0.8785 - val_precision_7: 0.0341 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6662 - accuracy: 0.8299 - precision_7: 0.3293 - val_loss: 0.6097 - val_accuracy: 0.7484 - val_precision_7: 0.0430 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.8305 - precision_7: 0.3279 - val_loss: 0.3216 - val_accuracy: 0.9293 - val_precision_7: 0.0193 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6612 - accuracy: 0.8296 - precision_7: 0.3191 - val_loss: 0.4643 - val_accuracy: 0.8157 - val_precision_7: 0.0547 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5902 - accuracy: 0.8345 - precision_7: 0.3471 - val_loss: 0.2712 - val_accuracy: 0.9273 - val_precision_7: 0.0079 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.8325 - precision_7: 0.3388 - val_loss: 0.3792 - val_accuracy: 0.9293 - val_precision_7: 0.0284 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.8350 - precision_7: 0.3488 - val_loss: 0.2365 - val_accuracy: 0.9515 - val_precision_7: 0.0099 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.8337 - precision_7: 0.3466 - val_loss: 0.2780 - val_accuracy: 0.9655 - val_precision_7: 0.0090 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.8303 - precision_7: 0.3172 - val_loss: 0.2422 - val_accuracy: 0.9461 - val_precision_7: 0.0106 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.8367 - precision_7: 0.3584 - val_loss: 0.9498 - val_accuracy: 0.6200 - val_precision_7: 0.0465 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.8364 - precision_7: 0.3585 - val_loss: 0.2813 - val_accuracy: 0.9322 - val_precision_7: 0.0139 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.8389 - precision_7: 0.3722 - val_loss: 0.2875 - val_accuracy: 0.9393 - val_precision_7: 0.0085 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.8333 - precision_7: 0.3344 - val_loss: 0.2877 - val_accuracy: 0.9192 - val_precision_7: 0.0401 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.8413 - precision_7: 0.3791 - val_loss: 0.5047 - val_accuracy: 0.7935 - val_precision_7: 0.0619 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.8361 - precision_7: 0.3503 - val_loss: 0.2881 - val_accuracy: 0.9422 - val_precision_7: 0.0182 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.8386 - precision_7: 0.3617 - val_loss: 0.7784 - val_accuracy: 0.7009 - val_precision_7: 0.0518 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.8397 - precision_7: 0.3696 - val_loss: 0.2375 - val_accuracy: 0.9442 - val_precision_7: 0.0580 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8467 - precision_7: 0.4104 - val_loss: 0.2241 - val_accuracy: 0.9567 - val_precision_7: 0.0367 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8486 - precision_7: 0.4270 - val_loss: 0.2759 - val_accuracy: 0.9242 - val_precision_7: 0.0045 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8458 - precision_7: 0.4091 - val_loss: 0.3257 - val_accuracy: 0.8943 - val_precision_7: 0.0240 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8474 - precision_7: 0.4205 - val_loss: 0.2427 - val_accuracy: 0.9539 - val_precision_7: 0.0074 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7570 - accuracy: 0.8341 - precision_7: 0.3429 - val_loss: 0.6238 - val_accuracy: 0.7850 - val_precision_7: 0.0505 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d42b7577be0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 2/50\n",
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 285.1668 - accuracy: 0.7510 - precision_8: 0.1466 - val_loss: 57.5443 - val_accuracy: 0.8898 - val_precision_8: 0.0162 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 82.4272 - accuracy: 0.7582 - precision_8: 0.1657 - val_loss: 33.1272 - val_accuracy: 0.9630 - val_precision_8: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 81.2329 - accuracy: 0.7648 - precision_8: 0.1818 - val_loss: 108.6396 - val_accuracy: 0.4055 - val_precision_8: 0.0340 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 62.2980 - accuracy: 0.7697 - precision_8: 0.1868 - val_loss: 13.4291 - val_accuracy: 0.9415 - val_precision_8: 0.0135 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 61.9862 - accuracy: 0.7782 - precision_8: 0.2040 - val_loss: 52.3848 - val_accuracy: 0.5067 - val_precision_8: 0.0350 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 63.4087 - accuracy: 0.7709 - precision_8: 0.1977 - val_loss: 22.6094 - val_accuracy: 0.9645 - val_precision_8: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 56.1282 - accuracy: 0.7793 - precision_8: 0.2090 - val_loss: 10.6474 - val_accuracy: 0.7821 - val_precision_8: 0.0411 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 78.7517 - accuracy: 0.7669 - precision_8: 0.1928 - val_loss: 31.3318 - val_accuracy: 0.9223 - val_precision_8: 0.0207 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 100.0837 - accuracy: 0.7704 - precision_8: 0.1927 - val_loss: 16.0660 - val_accuracy: 0.9236 - val_precision_8: 0.0213 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.9624 - accuracy: 0.7786 - precision_8: 0.2142 - val_loss: 44.0025 - val_accuracy: 0.9723 - val_precision_8: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 47.3132 - accuracy: 0.7758 - precision_8: 0.2098 - val_loss: 7.9692 - val_accuracy: 0.9218 - val_precision_8: 0.0112 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 62.1127 - accuracy: 0.7787 - precision_8: 0.2200 - val_loss: 18.4327 - val_accuracy: 0.9687 - val_precision_8: 0.0147 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 38.3863 - accuracy: 0.7870 - precision_8: 0.2207 - val_loss: 15.9423 - val_accuracy: 0.9198 - val_precision_8: 0.0273 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 62.1092 - accuracy: 0.7818 - precision_8: 0.2158 - val_loss: 13.4824 - val_accuracy: 0.7434 - val_precision_8: 0.0259 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.1287 - accuracy: 0.7895 - precision_8: 0.2281 - val_loss: 8.8397 - val_accuracy: 0.7486 - val_precision_8: 0.0385 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 31.9973 - accuracy: 0.7942 - precision_8: 0.2438 - val_loss: 17.2873 - val_accuracy: 0.9604 - val_precision_8: 0.0163 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.7893 - accuracy: 0.7900 - precision_8: 0.2271 - val_loss: 34.4430 - val_accuracy: 0.5048 - val_precision_8: 0.0391 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 51.3052 - accuracy: 0.7881 - precision_8: 0.2265 - val_loss: 97.7950 - val_accuracy: 0.3450 - val_precision_8: 0.0346 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.2353 - accuracy: 0.7851 - precision_8: 0.2224 - val_loss: 13.2244 - val_accuracy: 0.9289 - val_precision_8: 0.0311 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.2595 - accuracy: 0.7917 - precision_8: 0.2307 - val_loss: 5.3522 - val_accuracy: 0.8887 - val_precision_8: 0.0152 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.9427 - accuracy: 0.7929 - precision_8: 0.2425 - val_loss: 7.4347 - val_accuracy: 0.8642 - val_precision_8: 0.0157 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.0612 - accuracy: 0.7963 - precision_8: 0.2435 - val_loss: 37.8107 - val_accuracy: 0.5712 - val_precision_8: 0.0436 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.0333 - accuracy: 0.7963 - precision_8: 0.2453 - val_loss: 6.3700 - val_accuracy: 0.9037 - val_precision_8: 0.0222 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.4599 - accuracy: 0.7981 - precision_8: 0.2368 - val_loss: 18.3648 - val_accuracy: 0.5862 - val_precision_8: 0.0400 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.6188 - accuracy: 0.7895 - precision_8: 0.2273 - val_loss: 11.8826 - val_accuracy: 0.8802 - val_precision_8: 0.0234 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.5737 - accuracy: 0.7983 - precision_8: 0.2432 - val_loss: 39.6922 - val_accuracy: 0.5281 - val_precision_8: 0.0410 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 21.0912 - accuracy: 0.7934 - precision_8: 0.2345 - val_loss: 10.5178 - val_accuracy: 0.9407 - val_precision_8: 0.0469 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.3575 - accuracy: 0.8000 - precision_8: 0.2420 - val_loss: 3.0301 - val_accuracy: 0.8446 - val_precision_8: 0.0286 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 21.0651 - accuracy: 0.7918 - precision_8: 0.2326 - val_loss: 4.7764 - val_accuracy: 0.8783 - val_precision_8: 0.0208 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 23.1677 - accuracy: 0.7950 - precision_8: 0.2342 - val_loss: 23.0158 - val_accuracy: 0.9583 - val_precision_8: 0.0813 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 16.2091 - accuracy: 0.7986 - precision_8: 0.2361 - val_loss: 3.8771 - val_accuracy: 0.9142 - val_precision_8: 0.0203 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.2243 - accuracy: 0.8014 - precision_8: 0.2503 - val_loss: 3.6106 - val_accuracy: 0.8431 - val_precision_8: 0.0175 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.0217 - accuracy: 0.7970 - precision_8: 0.2384 - val_loss: 4.5967 - val_accuracy: 0.9389 - val_precision_8: 0.0084 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.3173 - accuracy: 0.8036 - precision_8: 0.2522 - val_loss: 4.3648 - val_accuracy: 0.8964 - val_precision_8: 0.0167 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.6818 - accuracy: 0.8005 - precision_8: 0.2466 - val_loss: 4.6469 - val_accuracy: 0.7760 - val_precision_8: 0.0437 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.3553 - accuracy: 0.8005 - precision_8: 0.2423 - val_loss: 2.0983 - val_accuracy: 0.8274 - val_precision_8: 0.0426 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.9141 - accuracy: 0.8029 - precision_8: 0.2483 - val_loss: 3.4681 - val_accuracy: 0.8630 - val_precision_8: 0.0211 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.1995 - accuracy: 0.8001 - precision_8: 0.2421 - val_loss: 3.6796 - val_accuracy: 0.9053 - val_precision_8: 0.0116 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.5112 - accuracy: 0.8016 - precision_8: 0.2438 - val_loss: 2.7642 - val_accuracy: 0.9006 - val_precision_8: 0.0157 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.7822 - accuracy: 0.8036 - precision_8: 0.2455 - val_loss: 3.3561 - val_accuracy: 0.8566 - val_precision_8: 0.0194 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.7508 - accuracy: 0.8023 - precision_8: 0.2425 - val_loss: 2.8941 - val_accuracy: 0.8908 - val_precision_8: 0.0172 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.9647 - accuracy: 0.8061 - precision_8: 0.2529 - val_loss: 4.2728 - val_accuracy: 0.7186 - val_precision_8: 0.0407 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.0579 - accuracy: 0.7998 - precision_8: 0.2352 - val_loss: 2.6448 - val_accuracy: 0.9271 - val_precision_8: 0.0063 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.0243 - accuracy: 0.8074 - precision_8: 0.2549 - val_loss: 10.4934 - val_accuracy: 0.9662 - val_precision_8: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.3122 - accuracy: 0.8058 - precision_8: 0.2516 - val_loss: 10.9181 - val_accuracy: 0.5721 - val_precision_8: 0.0422 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.5143 - accuracy: 0.8048 - precision_8: 0.2393 - val_loss: 17.9101 - val_accuracy: 0.4391 - val_precision_8: 0.0385 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.5307 - accuracy: 0.8036 - precision_8: 0.2383 - val_loss: 1.3304 - val_accuracy: 0.8421 - val_precision_8: 0.0200 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.7424 - accuracy: 0.8024 - precision_8: 0.2350 - val_loss: 1.3101 - val_accuracy: 0.8374 - val_precision_8: 0.0291 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.0610 - accuracy: 0.8020 - precision_8: 0.2309 - val_loss: 1.9411 - val_accuracy: 0.9187 - val_precision_8: 0.0280 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.5306 - accuracy: 0.8065 - precision_8: 0.2489 - val_loss: 1.6012 - val_accuracy: 0.9413 - val_precision_8: 0.0068 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.8541 - accuracy: 0.8077 - precision_8: 0.2527 - val_loss: 1.1154 - val_accuracy: 0.8120 - val_precision_8: 0.0219 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 3.2302 - accuracy: 0.8078 - precision_8: 0.2564 - val_loss: 1.3668 - val_accuracy: 0.9444 - val_precision_8: 0.0025 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.6810 - accuracy: 0.8075 - precision_8: 0.2456 - val_loss: 0.8900 - val_accuracy: 0.8424 - val_precision_8: 0.0307 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.4989 - accuracy: 0.8097 - precision_8: 0.2558 - val_loss: 1.2224 - val_accuracy: 0.9372 - val_precision_8: 0.0233 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.7117 - accuracy: 0.8051 - precision_8: 0.2384 - val_loss: 1.0742 - val_accuracy: 0.9168 - val_precision_8: 0.0127 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.2795 - accuracy: 0.8083 - precision_8: 0.2443 - val_loss: 0.7412 - val_accuracy: 0.8526 - val_precision_8: 0.0250 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 2.1036 - accuracy: 0.8115 - precision_8: 0.2576 - val_loss: 0.6124 - val_accuracy: 0.8174 - val_precision_8: 0.0356 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.6783 - accuracy: 0.8110 - precision_8: 0.2477 - val_loss: 0.5922 - val_accuracy: 0.9527 - val_precision_8: 0.0035 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.5014 - accuracy: 0.8099 - precision_8: 0.2451 - val_loss: 0.7101 - val_accuracy: 0.9520 - val_precision_8: 0.0068 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.2430 - accuracy: 0.8159 - precision_8: 0.2638 - val_loss: 0.3694 - val_accuracy: 0.9490 - val_precision_8: 0.0089 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9793 - accuracy: 0.8172 - precision_8: 0.2618 - val_loss: 0.4743 - val_accuracy: 0.9604 - val_precision_8: 0.0056 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0228 - accuracy: 0.8140 - precision_8: 0.2399 - val_loss: 0.2790 - val_accuracy: 0.9392 - val_precision_8: 0.0341 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9248 - accuracy: 0.8180 - precision_8: 0.2552 - val_loss: 0.4334 - val_accuracy: 0.9447 - val_precision_8: 0.0444 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0101 - accuracy: 0.8162 - precision_8: 0.2477 - val_loss: 0.4333 - val_accuracy: 0.9579 - val_precision_8: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8122 - accuracy: 0.8267 - precision_8: 0.2746 - val_loss: 0.3670 - val_accuracy: 0.9562 - val_precision_8: 0.0125 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8321 - accuracy: 0.8217 - precision_8: 0.2574 - val_loss: 0.2578 - val_accuracy: 0.9568 - val_precision_8: 0.0087 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.8276 - precision_8: 0.2691 - val_loss: 0.9581 - val_accuracy: 0.6692 - val_precision_8: 0.0516 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.8260 - precision_8: 0.2639 - val_loss: 0.2924 - val_accuracy: 0.9472 - val_precision_8: 0.0436 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.8316 - precision_8: 0.2794 - val_loss: 0.3010 - val_accuracy: 0.9277 - val_precision_8: 0.0303 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.8318 - precision_8: 0.2803 - val_loss: 0.2747 - val_accuracy: 0.9413 - val_precision_8: 0.0622 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.8318 - precision_8: 0.2868 - val_loss: 0.2563 - val_accuracy: 0.9650 - val_precision_8: 0.0611 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.8362 - precision_8: 0.2961 - val_loss: 0.2616 - val_accuracy: 0.9502 - val_precision_8: 0.0659 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.8301 - precision_8: 0.2822 - val_loss: 0.3226 - val_accuracy: 0.9319 - val_precision_8: 0.0607 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.8357 - precision_8: 0.3048 - val_loss: 0.2892 - val_accuracy: 0.9135 - val_precision_8: 0.0499 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.8357 - precision_8: 0.3083 - val_loss: 0.2492 - val_accuracy: 0.9459 - val_precision_8: 0.0483 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6017 - accuracy: 0.8305 - precision_8: 0.2833 - val_loss: 0.1927 - val_accuracy: 0.9687 - val_precision_8: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.8397 - precision_8: 0.3264 - val_loss: 0.5390 - val_accuracy: 0.7741 - val_precision_8: 0.0651 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5306 - accuracy: 0.8362 - precision_8: 0.3128 - val_loss: 0.2578 - val_accuracy: 0.9484 - val_precision_8: 0.0330 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.8391 - precision_8: 0.3220 - val_loss: 0.2839 - val_accuracy: 0.9529 - val_precision_8: 0.0271 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.8320 - precision_8: 0.2911 - val_loss: 0.2653 - val_accuracy: 0.9473 - val_precision_8: 0.0390 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.8360 - precision_8: 0.3073 - val_loss: 0.3008 - val_accuracy: 0.9146 - val_precision_8: 0.0306 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.8397 - precision_8: 0.3227 - val_loss: 0.2846 - val_accuracy: 0.9528 - val_precision_8: 0.0597 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.8396 - precision_8: 0.3173 - val_loss: 0.2151 - val_accuracy: 0.9529 - val_precision_8: 0.0036 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.8419 - precision_8: 0.3409 - val_loss: 0.2638 - val_accuracy: 0.9262 - val_precision_8: 0.0348 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8445 - precision_8: 0.3537 - val_loss: 0.2254 - val_accuracy: 0.9515 - val_precision_8: 0.0373 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0949 - accuracy: 0.8272 - precision_8: 0.2815 - val_loss: 1.8028 - val_accuracy: 0.9392 - val_precision_8: 0.0187 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.4435 - accuracy: 0.8062 - precision_8: 0.2251 - val_loss: 1.2156 - val_accuracy: 0.6780 - val_precision_8: 0.0546 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.8330 - precision_8: 0.2872 - val_loss: 0.2218 - val_accuracy: 0.9668 - val_precision_8: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8431 - precision_8: 0.3284 - val_loss: 0.2354 - val_accuracy: 0.9498 - val_precision_8: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.8306 - precision_8: 0.2910 - val_loss: 0.2852 - val_accuracy: 0.9114 - val_precision_8: 0.0333 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.8458 - precision_8: 0.3708 - val_loss: 1.2926 - val_accuracy: 0.7956 - val_precision_8: 0.0470 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.6150 - accuracy: 0.8293 - precision_8: 0.2401 - val_loss: 0.2882 - val_accuracy: 0.9394 - val_precision_8: 0.0361 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8565 - precision_8: 0.5202 - val_loss: 0.2595 - val_accuracy: 0.9545 - val_precision_8: 0.0361 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8572 - precision_8: 0.5461 - val_loss: 0.2885 - val_accuracy: 0.9212 - val_precision_8: 0.0293 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8573 - precision_8: 0.5402 - val_loss: 0.2530 - val_accuracy: 0.9282 - val_precision_8: 0.0173 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8577 - precision_8: 0.5561 - val_loss: 0.2579 - val_accuracy: 0.9404 - val_precision_8: 0.0589 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8589 - precision_8: 0.5964 - val_loss: 0.2581 - val_accuracy: 0.9211 - val_precision_8: 0.0164 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8594 - precision_8: 0.6015 - val_loss: 0.2474 - val_accuracy: 0.9432 - val_precision_8: 0.0276 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8593 - precision_8: 0.5979 - val_loss: 0.2696 - val_accuracy: 0.9247 - val_precision_8: 0.0325 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8597 - precision_8: 0.6050 - val_loss: 0.2493 - val_accuracy: 0.9352 - val_precision_8: 0.0186 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 263.9955 - accuracy: 0.7626 - precision_9: 0.1652 - val_loss: 21.3589 - val_accuracy: 0.8683 - val_precision_9: 0.0272 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 137.8444 - accuracy: 0.7717 - precision_9: 0.1813 - val_loss: 96.2683 - val_accuracy: 0.7076 - val_precision_9: 0.0461 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 107.7871 - accuracy: 0.7815 - precision_9: 0.2011 - val_loss: 68.3690 - val_accuracy: 0.9402 - val_precision_9: 0.0292 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 77.8728 - accuracy: 0.7879 - precision_9: 0.2083 - val_loss: 137.4582 - val_accuracy: 0.5773 - val_precision_9: 0.0409 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 103.0985 - accuracy: 0.7871 - precision_9: 0.2133 - val_loss: 71.7494 - val_accuracy: 0.9034 - val_precision_9: 0.0163 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 60.6610 - accuracy: 0.7874 - precision_9: 0.2141 - val_loss: 27.5929 - val_accuracy: 0.9146 - val_precision_9: 0.0134 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 73.5437 - accuracy: 0.7853 - precision_9: 0.2161 - val_loss: 14.7235 - val_accuracy: 0.9286 - val_precision_9: 0.0033 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 59.2341 - accuracy: 0.7909 - precision_9: 0.2241 - val_loss: 28.6315 - val_accuracy: 0.9359 - val_precision_9: 0.0039 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 60.4174 - accuracy: 0.7896 - precision_9: 0.2260 - val_loss: 10.7961 - val_accuracy: 0.9060 - val_precision_9: 0.0117 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.7671 - accuracy: 0.7910 - precision_9: 0.2232 - val_loss: 21.8660 - val_accuracy: 0.7771 - val_precision_9: 0.0209 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 87.8671 - accuracy: 0.7924 - precision_9: 0.2218 - val_loss: 55.2260 - val_accuracy: 0.6577 - val_precision_9: 0.0313 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 56.6691 - accuracy: 0.7941 - precision_9: 0.2265 - val_loss: 14.6301 - val_accuracy: 0.8733 - val_precision_9: 0.0143 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 39.8308 - accuracy: 0.7956 - precision_9: 0.2372 - val_loss: 41.0537 - val_accuracy: 0.6675 - val_precision_9: 0.0438 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 49.4646 - accuracy: 0.7908 - precision_9: 0.2226 - val_loss: 19.8657 - val_accuracy: 0.9438 - val_precision_9: 0.0025 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 45.2391 - accuracy: 0.7961 - precision_9: 0.2358 - val_loss: 10.7227 - val_accuracy: 0.8896 - val_precision_9: 0.0103 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.7943 - accuracy: 0.7975 - precision_9: 0.2398 - val_loss: 12.2014 - val_accuracy: 0.8903 - val_precision_9: 0.0146 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 47.1222 - accuracy: 0.7956 - precision_9: 0.2309 - val_loss: 19.6435 - val_accuracy: 0.8551 - val_precision_9: 0.0180 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 36.1637 - accuracy: 0.7959 - precision_9: 0.2384 - val_loss: 18.4779 - val_accuracy: 0.9271 - val_precision_9: 0.0032 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.6417 - accuracy: 0.7968 - precision_9: 0.2369 - val_loss: 17.1061 - val_accuracy: 0.8090 - val_precision_9: 0.0177 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.8922 - accuracy: 0.7961 - precision_9: 0.2398 - val_loss: 8.0090 - val_accuracy: 0.8078 - val_precision_9: 0.0230 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.0668 - accuracy: 0.7989 - precision_9: 0.2434 - val_loss: 9.0437 - val_accuracy: 0.8659 - val_precision_9: 0.0147 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.6997 - accuracy: 0.8020 - precision_9: 0.2522 - val_loss: 16.5808 - val_accuracy: 0.9018 - val_precision_9: 0.0061 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.4016 - accuracy: 0.7966 - precision_9: 0.2412 - val_loss: 7.8272 - val_accuracy: 0.8087 - val_precision_9: 0.0214 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 21.9030 - accuracy: 0.8010 - precision_9: 0.2519 - val_loss: 6.2125 - val_accuracy: 0.8407 - val_precision_9: 0.0125 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 23.8180 - accuracy: 0.7999 - precision_9: 0.2452 - val_loss: 11.8716 - val_accuracy: 0.6867 - val_precision_9: 0.0311 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 23.7083 - accuracy: 0.7979 - precision_9: 0.2496 - val_loss: 6.3506 - val_accuracy: 0.8659 - val_precision_9: 0.0172 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 24.7936 - accuracy: 0.7977 - precision_9: 0.2384 - val_loss: 12.1266 - val_accuracy: 0.9111 - val_precision_9: 0.0182 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.2283 - accuracy: 0.7999 - precision_9: 0.2500 - val_loss: 11.6070 - val_accuracy: 0.9226 - val_precision_9: 0.0099 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.9404 - accuracy: 0.7987 - precision_9: 0.2484 - val_loss: 4.0726 - val_accuracy: 0.8320 - val_precision_9: 0.0299 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.8013 - accuracy: 0.8023 - precision_9: 0.2555 - val_loss: 6.3921 - val_accuracy: 0.7893 - val_precision_9: 0.0196 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.9007 - accuracy: 0.8002 - precision_9: 0.2450 - val_loss: 9.0880 - val_accuracy: 0.6405 - val_precision_9: 0.0366 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.7780 - accuracy: 0.8016 - precision_9: 0.2496 - val_loss: 4.3695 - val_accuracy: 0.7889 - val_precision_9: 0.0163 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.9690 - accuracy: 0.7976 - precision_9: 0.2496 - val_loss: 5.4484 - val_accuracy: 0.8070 - val_precision_9: 0.0188 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.2035 - accuracy: 0.8015 - precision_9: 0.2501 - val_loss: 4.9090 - val_accuracy: 0.8094 - val_precision_9: 0.0119 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.2149 - accuracy: 0.8018 - precision_9: 0.2545 - val_loss: 6.9528 - val_accuracy: 0.9213 - val_precision_9: 0.0151 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.2441 - accuracy: 0.8044 - precision_9: 0.2644 - val_loss: 26.0639 - val_accuracy: 0.5902 - val_precision_9: 0.0417 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.6838 - accuracy: 0.8031 - precision_9: 0.2553 - val_loss: 7.5834 - val_accuracy: 0.6822 - val_precision_9: 0.0458 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.6626 - accuracy: 0.8035 - precision_9: 0.2608 - val_loss: 4.4302 - val_accuracy: 0.8786 - val_precision_9: 0.0061 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.7239 - accuracy: 0.8049 - precision_9: 0.2632 - val_loss: 4.8836 - val_accuracy: 0.9155 - val_precision_9: 0.0075 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.3485 - accuracy: 0.8019 - precision_9: 0.2546 - val_loss: 4.2326 - val_accuracy: 0.8300 - val_precision_9: 0.0125 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.8229 - accuracy: 0.8018 - precision_9: 0.2514 - val_loss: 3.9244 - val_accuracy: 0.6298 - val_precision_9: 0.0226 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.7785 - accuracy: 0.8012 - precision_9: 0.2497 - val_loss: 4.2601 - val_accuracy: 0.9201 - val_precision_9: 0.0068 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.2796 - accuracy: 0.8014 - precision_9: 0.2533 - val_loss: 3.5506 - val_accuracy: 0.8433 - val_precision_9: 0.0149 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.0977 - accuracy: 0.8036 - precision_9: 0.2577 - val_loss: 5.0555 - val_accuracy: 0.8839 - val_precision_9: 0.0190 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.6392 - accuracy: 0.8046 - precision_9: 0.2580 - val_loss: 2.5815 - val_accuracy: 0.8147 - val_precision_9: 0.0149 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.2497 - accuracy: 0.8047 - precision_9: 0.2613 - val_loss: 4.0190 - val_accuracy: 0.9335 - val_precision_9: 0.0161 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.9980 - accuracy: 0.8054 - precision_9: 0.2659 - val_loss: 3.1666 - val_accuracy: 0.7480 - val_precision_9: 0.0290 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.5804 - accuracy: 0.8061 - precision_9: 0.2692 - val_loss: 2.4025 - val_accuracy: 0.8984 - val_precision_9: 0.0261 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.9239 - accuracy: 0.8103 - precision_9: 0.2800 - val_loss: 1.7433 - val_accuracy: 0.8717 - val_precision_9: 0.0155 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 5.7121 - accuracy: 0.8031 - precision_9: 0.2648 - val_loss: 4.2224 - val_accuracy: 0.6615 - val_precision_9: 0.0298 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 4.0388 - accuracy: 0.8077 - precision_9: 0.2730 - val_loss: 1.1642 - val_accuracy: 0.8884 - val_precision_9: 0.0224 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.0404 - accuracy: 0.8088 - precision_9: 0.2747 - val_loss: 6.6270 - val_accuracy: 0.5274 - val_precision_9: 0.0381 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 4.1144 - accuracy: 0.8050 - precision_9: 0.2643 - val_loss: 10.0448 - val_accuracy: 0.5832 - val_precision_9: 0.0423 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.5908 - accuracy: 0.8050 - precision_9: 0.2694 - val_loss: 1.6264 - val_accuracy: 0.7862 - val_precision_9: 0.0399 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.1147 - accuracy: 0.8053 - precision_9: 0.2683 - val_loss: 1.4120 - val_accuracy: 0.8504 - val_precision_9: 0.0134 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.1130 - accuracy: 0.8066 - precision_9: 0.2658 - val_loss: 4.9365 - val_accuracy: 0.6529 - val_precision_9: 0.0472 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.7408 - accuracy: 0.8052 - precision_9: 0.2636 - val_loss: 1.3249 - val_accuracy: 0.8681 - val_precision_9: 0.0156 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.9996 - accuracy: 0.8090 - precision_9: 0.2700 - val_loss: 0.8299 - val_accuracy: 0.8025 - val_precision_9: 0.0223 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.8993 - accuracy: 0.8090 - precision_9: 0.2678 - val_loss: 0.8785 - val_accuracy: 0.7813 - val_precision_9: 0.0238 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.6255 - accuracy: 0.8082 - precision_9: 0.2714 - val_loss: 0.7306 - val_accuracy: 0.8405 - val_precision_9: 0.0146 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1965 - accuracy: 0.8105 - precision_9: 0.2767 - val_loss: 0.4206 - val_accuracy: 0.9182 - val_precision_9: 0.0053 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1825 - accuracy: 0.8118 - precision_9: 0.2727 - val_loss: 0.8316 - val_accuracy: 0.9058 - val_precision_9: 0.0278 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9495 - accuracy: 0.8162 - precision_9: 0.2790 - val_loss: 0.6487 - val_accuracy: 0.7913 - val_precision_9: 0.0247 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0784 - accuracy: 0.8132 - precision_9: 0.2635 - val_loss: 3.2729 - val_accuracy: 0.4330 - val_precision_9: 0.0365 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1896 - accuracy: 0.8117 - precision_9: 0.2631 - val_loss: 0.6574 - val_accuracy: 0.8593 - val_precision_9: 0.0199 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7534 - accuracy: 0.8204 - precision_9: 0.2870 - val_loss: 0.4444 - val_accuracy: 0.9263 - val_precision_9: 0.0349 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7947 - accuracy: 0.8197 - precision_9: 0.2770 - val_loss: 0.4478 - val_accuracy: 0.8725 - val_precision_9: 0.0347 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.8244 - precision_9: 0.2903 - val_loss: 0.5536 - val_accuracy: 0.7707 - val_precision_9: 0.0475 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.8226 - precision_9: 0.2947 - val_loss: 0.4730 - val_accuracy: 0.8744 - val_precision_9: 0.0166 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.8280 - precision_9: 0.3097 - val_loss: 0.3452 - val_accuracy: 0.9041 - val_precision_9: 0.0224 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6118 - accuracy: 0.8282 - precision_9: 0.3003 - val_loss: 0.8304 - val_accuracy: 0.6959 - val_precision_9: 0.0515 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8422 - accuracy: 0.8217 - precision_9: 0.2839 - val_loss: 0.8961 - val_accuracy: 0.7531 - val_precision_9: 0.0470 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.8193 - precision_9: 0.2799 - val_loss: 0.4472 - val_accuracy: 0.8474 - val_precision_9: 0.0404 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.8323 - precision_9: 0.3213 - val_loss: 0.3984 - val_accuracy: 0.8642 - val_precision_9: 0.0605 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.8236 - precision_9: 0.2973 - val_loss: 0.5190 - val_accuracy: 0.8162 - val_precision_9: 0.0254 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.7010 - accuracy: 0.8255 - precision_9: 0.2947 - val_loss: 0.4542 - val_accuracy: 0.8075 - val_precision_9: 0.0241 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.8326 - precision_9: 0.3213 - val_loss: 0.4923 - val_accuracy: 0.8687 - val_precision_9: 0.0518 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.7409 - accuracy: 0.8202 - precision_9: 0.2832 - val_loss: 0.3444 - val_accuracy: 0.8893 - val_precision_9: 0.0234 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.8377 - precision_9: 0.3375 - val_loss: 0.2732 - val_accuracy: 0.9212 - val_precision_9: 0.0177 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.8436 - precision_9: 0.3680 - val_loss: 0.2436 - val_accuracy: 0.9391 - val_precision_9: 0.0084 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8510 - precision_9: 0.4345 - val_loss: 0.4115 - val_accuracy: 0.8500 - val_precision_9: 0.0303 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8506 - precision_9: 0.4268 - val_loss: 0.2742 - val_accuracy: 0.9160 - val_precision_9: 0.0267 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8479 - precision_9: 0.4011 - val_loss: 0.2797 - val_accuracy: 0.9267 - val_precision_9: 0.0197 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8486 - precision_9: 0.4092 - val_loss: 0.2417 - val_accuracy: 0.9386 - val_precision_9: 0.0461 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8468 - precision_9: 0.3916 - val_loss: 0.3287 - val_accuracy: 0.8858 - val_precision_9: 0.0263 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8519 - precision_9: 0.4403 - val_loss: 0.1990 - val_accuracy: 0.9593 - val_precision_9: 0.0199 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8528 - precision_9: 0.4518 - val_loss: 0.3077 - val_accuracy: 0.8882 - val_precision_9: 0.0175 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8507 - precision_9: 0.4289 - val_loss: 0.3255 - val_accuracy: 0.9198 - val_precision_9: 0.0333 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.8382 - precision_9: 0.3419 - val_loss: 0.3217 - val_accuracy: 0.8861 - val_precision_9: 0.0256 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8517 - precision_9: 0.4331 - val_loss: 0.2662 - val_accuracy: 0.9384 - val_precision_9: 0.0405 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8545 - precision_9: 0.4743 - val_loss: 0.4064 - val_accuracy: 0.8334 - val_precision_9: 0.0260 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8542 - precision_9: 0.4729 - val_loss: 0.3423 - val_accuracy: 0.8580 - val_precision_9: 0.0300 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8537 - precision_9: 0.4661 - val_loss: 0.2568 - val_accuracy: 0.9421 - val_precision_9: 0.0409 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8541 - precision_9: 0.4695 - val_loss: 0.2528 - val_accuracy: 0.9362 - val_precision_9: 0.0383 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8569 - precision_9: 0.5149 - val_loss: 0.3215 - val_accuracy: 0.9091 - val_precision_9: 0.0362 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8566 - precision_9: 0.5096 - val_loss: 0.2267 - val_accuracy: 0.9493 - val_precision_9: 0.0707 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8544 - precision_9: 0.4755 - val_loss: 0.3357 - val_accuracy: 0.8737 - val_precision_9: 0.0299 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8578 - precision_9: 0.5314 - val_loss: 0.2061 - val_accuracy: 0.9572 - val_precision_9: 0.0795 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8558 - precision_9: 0.4966 - val_loss: 0.2093 - val_accuracy: 0.9608 - val_precision_9: 0.0564 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8569 - precision_9: 0.5141 - val_loss: 0.2462 - val_accuracy: 0.9392 - val_precision_9: 0.0450 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 176.2368 - accuracy: 0.7689 - precision_10: 0.1783 - val_loss: 125.9419 - val_accuracy: 0.5500 - val_precision_10: 0.0407 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 78.9819 - accuracy: 0.7786 - precision_10: 0.1964 - val_loss: 28.3726 - val_accuracy: 0.8936 - val_precision_10: 0.0117 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 45.8990 - accuracy: 0.7846 - precision_10: 0.2086 - val_loss: 16.6945 - val_accuracy: 0.9477 - val_precision_10: 0.0056 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 59.2299 - accuracy: 0.7875 - precision_10: 0.2025 - val_loss: 10.6802 - val_accuracy: 0.8460 - val_precision_10: 0.0216 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 43.1039 - accuracy: 0.7876 - precision_10: 0.2091 - val_loss: 12.9164 - val_accuracy: 0.7796 - val_precision_10: 0.0324 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.7153 - accuracy: 0.7880 - precision_10: 0.2183 - val_loss: 30.3959 - val_accuracy: 0.9336 - val_precision_10: 0.0126 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 39.2902 - accuracy: 0.7970 - precision_10: 0.2355 - val_loss: 22.5257 - val_accuracy: 0.8729 - val_precision_10: 0.0309 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.0643 - accuracy: 0.7956 - precision_10: 0.2267 - val_loss: 79.8567 - val_accuracy: 0.5496 - val_precision_10: 0.0399 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.7654 - accuracy: 0.7945 - precision_10: 0.2294 - val_loss: 12.3614 - val_accuracy: 0.8500 - val_precision_10: 0.0239 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.4099 - accuracy: 0.7955 - precision_10: 0.2377 - val_loss: 16.1036 - val_accuracy: 0.7268 - val_precision_10: 0.0358 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.2420 - accuracy: 0.7950 - precision_10: 0.2219 - val_loss: 18.3511 - val_accuracy: 0.7930 - val_precision_10: 0.0215 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.0422 - accuracy: 0.7978 - precision_10: 0.2328 - val_loss: 6.9237 - val_accuracy: 0.8074 - val_precision_10: 0.0217 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 37.2346 - accuracy: 0.7949 - precision_10: 0.2284 - val_loss: 50.1716 - val_accuracy: 0.5914 - val_precision_10: 0.0344 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.9670 - accuracy: 0.7952 - precision_10: 0.2266 - val_loss: 6.8888 - val_accuracy: 0.9322 - val_precision_10: 0.0035 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 25.2974 - accuracy: 0.7957 - precision_10: 0.2293 - val_loss: 19.5320 - val_accuracy: 0.8603 - val_precision_10: 0.0271 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.8612 - accuracy: 0.7987 - precision_10: 0.2351 - val_loss: 51.2444 - val_accuracy: 0.6681 - val_precision_10: 0.0451 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.0911 - accuracy: 0.7939 - precision_10: 0.2245 - val_loss: 12.8076 - val_accuracy: 0.9458 - val_precision_10: 0.0053 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.9078 - accuracy: 0.7976 - precision_10: 0.2298 - val_loss: 7.1546 - val_accuracy: 0.9343 - val_precision_10: 0.0056 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.6140 - accuracy: 0.7992 - precision_10: 0.2388 - val_loss: 3.9925 - val_accuracy: 0.7795 - val_precision_10: 0.0204 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.5372 - accuracy: 0.8001 - precision_10: 0.2376 - val_loss: 11.4232 - val_accuracy: 0.7319 - val_precision_10: 0.0450 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.8859 - accuracy: 0.8000 - precision_10: 0.2369 - val_loss: 12.3710 - val_accuracy: 0.8985 - val_precision_10: 0.0243 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 17.7027 - accuracy: 0.8038 - precision_10: 0.2459 - val_loss: 6.1074 - val_accuracy: 0.7074 - val_precision_10: 0.0339 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.5688 - accuracy: 0.8035 - precision_10: 0.2489 - val_loss: 5.9915 - val_accuracy: 0.8587 - val_precision_10: 0.0239 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.9084 - accuracy: 0.8015 - precision_10: 0.2413 - val_loss: 5.7082 - val_accuracy: 0.8443 - val_precision_10: 0.0176 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 13.7560 - accuracy: 0.8029 - precision_10: 0.2459 - val_loss: 5.1606 - val_accuracy: 0.8664 - val_precision_10: 0.0034 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.1979 - accuracy: 0.8020 - precision_10: 0.2485 - val_loss: 5.1142 - val_accuracy: 0.7377 - val_precision_10: 0.0184 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.3856 - accuracy: 0.7997 - precision_10: 0.2391 - val_loss: 9.8626 - val_accuracy: 0.6780 - val_precision_10: 0.0344 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.5282 - accuracy: 0.7986 - precision_10: 0.2385 - val_loss: 21.6213 - val_accuracy: 0.9577 - val_precision_10: 0.0091 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.9179 - accuracy: 0.8008 - precision_10: 0.2370 - val_loss: 3.1103 - val_accuracy: 0.7956 - val_precision_10: 0.0199 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.1067 - accuracy: 0.8034 - precision_10: 0.2460 - val_loss: 4.7996 - val_accuracy: 0.9427 - val_precision_10: 0.0047 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.1782 - accuracy: 0.8060 - precision_10: 0.2499 - val_loss: 16.5286 - val_accuracy: 0.6199 - val_precision_10: 0.0435 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.9423 - accuracy: 0.8021 - precision_10: 0.2421 - val_loss: 2.5644 - val_accuracy: 0.7554 - val_precision_10: 0.0223 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.5040 - accuracy: 0.8024 - precision_10: 0.2502 - val_loss: 2.9947 - val_accuracy: 0.7507 - val_precision_10: 0.0218 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.5521 - accuracy: 0.8050 - precision_10: 0.2546 - val_loss: 2.7198 - val_accuracy: 0.8321 - val_precision_10: 0.0229 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.8502 - accuracy: 0.8059 - precision_10: 0.2558 - val_loss: 3.3289 - val_accuracy: 0.8598 - val_precision_10: 0.0241 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.9244 - accuracy: 0.8038 - precision_10: 0.2441 - val_loss: 3.0194 - val_accuracy: 0.9050 - val_precision_10: 0.0032 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.0912 - accuracy: 0.8065 - precision_10: 0.2586 - val_loss: 8.0438 - val_accuracy: 0.6329 - val_precision_10: 0.0430 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.6578 - accuracy: 0.8036 - precision_10: 0.2472 - val_loss: 2.6615 - val_accuracy: 0.9176 - val_precision_10: 0.0026 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.8360 - accuracy: 0.8036 - precision_10: 0.2500 - val_loss: 3.0221 - val_accuracy: 0.9393 - val_precision_10: 0.0043 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.2658 - accuracy: 0.8058 - precision_10: 0.2501 - val_loss: 2.4886 - val_accuracy: 0.9019 - val_precision_10: 0.0010 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.3513 - accuracy: 0.8063 - precision_10: 0.2579 - val_loss: 1.7417 - val_accuracy: 0.9095 - val_precision_10: 0.0023 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.1169 - accuracy: 0.8071 - precision_10: 0.2561 - val_loss: 1.7734 - val_accuracy: 0.8795 - val_precision_10: 0.0196 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.4758 - accuracy: 0.8048 - precision_10: 0.2518 - val_loss: 2.0210 - val_accuracy: 0.8464 - val_precision_10: 0.0130 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.7197 - accuracy: 0.8091 - precision_10: 0.2628 - val_loss: 3.6387 - val_accuracy: 0.8604 - val_precision_10: 0.0146 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.6834 - accuracy: 0.8065 - precision_10: 0.2625 - val_loss: 1.6035 - val_accuracy: 0.8550 - val_precision_10: 0.0197 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.6869 - accuracy: 0.8032 - precision_10: 0.2513 - val_loss: 2.0161 - val_accuracy: 0.7076 - val_precision_10: 0.0394 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.9691 - accuracy: 0.8067 - precision_10: 0.2556 - val_loss: 1.2168 - val_accuracy: 0.8437 - val_precision_10: 0.0254 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 3.8310 - accuracy: 0.8071 - precision_10: 0.2539 - val_loss: 1.3671 - val_accuracy: 0.8440 - val_precision_10: 0.0117 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.7379 - accuracy: 0.8098 - precision_10: 0.2647 - val_loss: 1.5625 - val_accuracy: 0.7995 - val_precision_10: 0.0269 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 3.2552 - accuracy: 0.8071 - precision_10: 0.2654 - val_loss: 1.3612 - val_accuracy: 0.9215 - val_precision_10: 0.0042 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.9105 - accuracy: 0.8102 - precision_10: 0.2719 - val_loss: 3.6877 - val_accuracy: 0.6579 - val_precision_10: 0.0453 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.7342 - accuracy: 0.8075 - precision_10: 0.2623 - val_loss: 1.4651 - val_accuracy: 0.8104 - val_precision_10: 0.0233 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0050 - accuracy: 0.8123 - precision_10: 0.2805 - val_loss: 1.0549 - val_accuracy: 0.8012 - val_precision_10: 0.0279 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.3781 - accuracy: 0.8105 - precision_10: 0.2736 - val_loss: 1.1342 - val_accuracy: 0.7932 - val_precision_10: 0.0332 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.4922 - accuracy: 0.8104 - precision_10: 0.2718 - val_loss: 0.9477 - val_accuracy: 0.9006 - val_precision_10: 0.0040 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.4031 - accuracy: 0.8086 - precision_10: 0.2615 - val_loss: 0.9922 - val_accuracy: 0.8652 - val_precision_10: 0.0343 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.9670 - accuracy: 0.8107 - precision_10: 0.2736 - val_loss: 0.7399 - val_accuracy: 0.7902 - val_precision_10: 0.0267 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4487 - accuracy: 0.8138 - precision_10: 0.2811 - val_loss: 0.6308 - val_accuracy: 0.9147 - val_precision_10: 0.0074 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4224 - accuracy: 0.8155 - precision_10: 0.2855 - val_loss: 0.6746 - val_accuracy: 0.8429 - val_precision_10: 0.0232 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.3462 - accuracy: 0.8135 - precision_10: 0.2771 - val_loss: 0.4408 - val_accuracy: 0.8979 - val_precision_10: 0.0105 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1398 - accuracy: 0.8155 - precision_10: 0.2792 - val_loss: 0.4442 - val_accuracy: 0.9020 - val_precision_10: 0.0071 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9713 - accuracy: 0.8190 - precision_10: 0.2912 - val_loss: 0.3082 - val_accuracy: 0.9308 - val_precision_10: 0.0051 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8413 - accuracy: 0.8208 - precision_10: 0.2899 - val_loss: 1.5058 - val_accuracy: 0.5908 - val_precision_10: 0.0452 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8419 - accuracy: 0.8200 - precision_10: 0.2801 - val_loss: 0.3592 - val_accuracy: 0.9071 - val_precision_10: 0.0463 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7779 - accuracy: 0.8217 - precision_10: 0.2860 - val_loss: 0.9754 - val_accuracy: 0.6537 - val_precision_10: 0.0474 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.8252 - accuracy: 0.8166 - precision_10: 0.2629 - val_loss: 0.2949 - val_accuracy: 0.9362 - val_precision_10: 0.0297 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7245 - accuracy: 0.8215 - precision_10: 0.2740 - val_loss: 0.3384 - val_accuracy: 0.9064 - val_precision_10: 0.0290 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.8301 - precision_10: 0.3005 - val_loss: 0.3691 - val_accuracy: 0.8899 - val_precision_10: 0.0413 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.8331 - precision_10: 0.3020 - val_loss: 0.3170 - val_accuracy: 0.9392 - val_precision_10: 0.0264 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.8248 - precision_10: 0.2775 - val_loss: 1.1840 - val_accuracy: 0.6747 - val_precision_10: 0.0514 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.5865 - accuracy: 0.8294 - precision_10: 0.2974 - val_loss: 0.2567 - val_accuracy: 0.9553 - val_precision_10: 0.0118 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5615 - accuracy: 0.8297 - precision_10: 0.2951 - val_loss: 0.2755 - val_accuracy: 0.9421 - val_precision_10: 0.0505 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5043 - accuracy: 0.8356 - precision_10: 0.3118 - val_loss: 0.2647 - val_accuracy: 0.9341 - val_precision_10: 0.0282 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6105 - accuracy: 0.8265 - precision_10: 0.2922 - val_loss: 0.2396 - val_accuracy: 0.9562 - val_precision_10: 0.0428 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5295 - accuracy: 0.8359 - precision_10: 0.3223 - val_loss: 0.3601 - val_accuracy: 0.8891 - val_precision_10: 0.0416 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.8390 - precision_10: 0.3336 - val_loss: 0.3490 - val_accuracy: 0.8721 - val_precision_10: 0.0314 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.8342 - precision_10: 0.3197 - val_loss: 0.4682 - val_accuracy: 0.8865 - val_precision_10: 0.0597 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.8295 - precision_10: 0.3095 - val_loss: 0.3297 - val_accuracy: 0.9120 - val_precision_10: 0.0592 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.8445 - precision_10: 0.3682 - val_loss: 0.4010 - val_accuracy: 0.8625 - val_precision_10: 0.0638 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8437 - precision_10: 0.3644 - val_loss: 0.4365 - val_accuracy: 0.8318 - val_precision_10: 0.0584 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.8383 - precision_10: 0.3314 - val_loss: 0.2079 - val_accuracy: 0.9601 - val_precision_10: 0.0107 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.8387 - precision_10: 0.3383 - val_loss: 0.2612 - val_accuracy: 0.9419 - val_precision_10: 0.0736 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.8417 - precision_10: 0.3535 - val_loss: 0.3038 - val_accuracy: 0.9286 - val_precision_10: 0.0753 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 4.8529 - accuracy: 0.8204 - precision_10: 0.2830 - val_loss: 1.0446 - val_accuracy: 0.8584 - val_precision_10: 0.0439 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4886 - accuracy: 0.8136 - precision_10: 0.2645 - val_loss: 0.3504 - val_accuracy: 0.8938 - val_precision_10: 0.0693 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.8366 - precision_10: 0.3344 - val_loss: 0.2709 - val_accuracy: 0.9410 - val_precision_10: 0.0667 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.8379 - precision_10: 0.3410 - val_loss: 0.2572 - val_accuracy: 0.9413 - val_precision_10: 0.0260 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8473 - precision_10: 0.3938 - val_loss: 0.3462 - val_accuracy: 0.8902 - val_precision_10: 0.0429 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8566 - precision_10: 0.5085 - val_loss: 0.2888 - val_accuracy: 0.9299 - val_precision_10: 0.0346 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8578 - precision_10: 0.5331 - val_loss: 0.3128 - val_accuracy: 0.9225 - val_precision_10: 0.0495 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8509 - precision_10: 0.4272 - val_loss: 0.2661 - val_accuracy: 0.9350 - val_precision_10: 0.0663 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8520 - precision_10: 0.4451 - val_loss: 0.3340 - val_accuracy: 0.9054 - val_precision_10: 0.0444 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8530 - precision_10: 0.4555 - val_loss: 0.5758 - val_accuracy: 0.8152 - val_precision_10: 0.0642 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8522 - precision_10: 0.4448 - val_loss: 0.3453 - val_accuracy: 0.9046 - val_precision_10: 0.0492 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.0767 - accuracy: 0.8238 - precision_10: 0.2650 - val_loss: 0.3261 - val_accuracy: 0.9176 - val_precision_10: 0.0355 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8590 - precision_10: 0.5683 - val_loss: 0.3419 - val_accuracy: 0.8827 - val_precision_10: 0.0305 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8598 - precision_10: 0.5824 - val_loss: 0.2121 - val_accuracy: 0.9624 - val_precision_10: 0.0422 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8599 - precision_10: 0.5901 - val_loss: 0.2405 - val_accuracy: 0.9526 - val_precision_10: 0.0644 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8614 - precision_10: 0.6284 - val_loss: 0.2321 - val_accuracy: 0.9411 - val_precision_10: 0.0436 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.8618 - precision_10: 0.6373 - val_loss: 0.2120 - val_accuracy: 0.9579 - val_precision_10: 0.1159 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 206.7224 - accuracy: 0.7496 - precision_11: 0.1432 - val_loss: 64.8891 - val_accuracy: 0.9106 - val_precision_11: 0.0023 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 144.5238 - accuracy: 0.7605 - precision_11: 0.1699 - val_loss: 14.3163 - val_accuracy: 0.8940 - val_precision_11: 0.0170 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 99.3470 - accuracy: 0.7678 - precision_11: 0.1772 - val_loss: 51.1705 - val_accuracy: 0.2962 - val_precision_11: 0.0219 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 79.7314 - accuracy: 0.7569 - precision_11: 0.1763 - val_loss: 33.5048 - val_accuracy: 0.7375 - val_precision_11: 0.0354 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 72.6943 - accuracy: 0.7723 - precision_11: 0.1964 - val_loss: 25.8944 - val_accuracy: 0.9384 - val_precision_11: 0.0062 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 104.6026 - accuracy: 0.7691 - precision_11: 0.1864 - val_loss: 26.6663 - val_accuracy: 0.9590 - val_precision_11: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 98.4878 - accuracy: 0.7753 - precision_11: 0.2077 - val_loss: 22.5459 - val_accuracy: 0.7707 - val_precision_11: 0.0355 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 46.3376 - accuracy: 0.7812 - precision_11: 0.2182 - val_loss: 10.0417 - val_accuracy: 0.6669 - val_precision_11: 0.0143 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 85.1385 - accuracy: 0.7771 - precision_11: 0.2107 - val_loss: 11.4190 - val_accuracy: 0.6384 - val_precision_11: 0.0182 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 67.9418 - accuracy: 0.7782 - precision_11: 0.2097 - val_loss: 24.4612 - val_accuracy: 0.7399 - val_precision_11: 0.0185 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 38.5096 - accuracy: 0.7838 - precision_11: 0.2302 - val_loss: 25.2715 - val_accuracy: 0.9231 - val_precision_11: 0.0072 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 44.1844 - accuracy: 0.7881 - precision_11: 0.2308 - val_loss: 7.4821 - val_accuracy: 0.6269 - val_precision_11: 0.0141 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 42.4846 - accuracy: 0.7837 - precision_11: 0.2307 - val_loss: 10.1467 - val_accuracy: 0.7681 - val_precision_11: 0.0220 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 57.9365 - accuracy: 0.7789 - precision_11: 0.2184 - val_loss: 8.6539 - val_accuracy: 0.9233 - val_precision_11: 0.0086 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.8393 - accuracy: 0.7852 - precision_11: 0.2320 - val_loss: 6.4432 - val_accuracy: 0.7699 - val_precision_11: 0.0267 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.6025 - accuracy: 0.7879 - precision_11: 0.2347 - val_loss: 12.1308 - val_accuracy: 0.7227 - val_precision_11: 0.0291 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.5727 - accuracy: 0.7853 - precision_11: 0.2277 - val_loss: 12.3508 - val_accuracy: 0.9438 - val_precision_11: 0.0121 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 53.1665 - accuracy: 0.7907 - precision_11: 0.2400 - val_loss: 16.2118 - val_accuracy: 0.7708 - val_precision_11: 0.0199 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 61.7558 - accuracy: 0.7828 - precision_11: 0.2272 - val_loss: 6.2190 - val_accuracy: 0.7438 - val_precision_11: 0.0253 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 24.1853 - accuracy: 0.7962 - precision_11: 0.2515 - val_loss: 8.0633 - val_accuracy: 0.9080 - val_precision_11: 0.0099 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 32.9170 - accuracy: 0.7931 - precision_11: 0.2405 - val_loss: 7.8351 - val_accuracy: 0.9034 - val_precision_11: 0.0113 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 32.5467 - accuracy: 0.7883 - precision_11: 0.2389 - val_loss: 16.1156 - val_accuracy: 0.9419 - val_precision_11: 0.0046 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 55.9080 - accuracy: 0.7869 - precision_11: 0.2249 - val_loss: 12.0350 - val_accuracy: 0.8901 - val_precision_11: 0.0137 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.8662 - accuracy: 0.7910 - precision_11: 0.2324 - val_loss: 12.2878 - val_accuracy: 0.9341 - val_precision_11: 0.0162 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.5872 - accuracy: 0.7951 - precision_11: 0.2452 - val_loss: 9.5543 - val_accuracy: 0.8019 - val_precision_11: 0.0222 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.4371 - accuracy: 0.7909 - precision_11: 0.2376 - val_loss: 6.0387 - val_accuracy: 0.7489 - val_precision_11: 0.0232 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.5076 - accuracy: 0.7962 - precision_11: 0.2384 - val_loss: 7.5790 - val_accuracy: 0.9037 - val_precision_11: 0.0124 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 38.0457 - accuracy: 0.7894 - precision_11: 0.2250 - val_loss: 4.9989 - val_accuracy: 0.8386 - val_precision_11: 0.0154 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.8274 - accuracy: 0.7973 - precision_11: 0.2396 - val_loss: 8.1252 - val_accuracy: 0.7791 - val_precision_11: 0.0172 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.9921 - accuracy: 0.7994 - precision_11: 0.2402 - val_loss: 4.6633 - val_accuracy: 0.8229 - val_precision_11: 0.0147 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.3833 - accuracy: 0.7964 - precision_11: 0.2456 - val_loss: 4.7111 - val_accuracy: 0.9413 - val_precision_11: 0.0176 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.5730 - accuracy: 0.7899 - precision_11: 0.2243 - val_loss: 7.9449 - val_accuracy: 0.9226 - val_precision_11: 0.0234 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.0834 - accuracy: 0.8000 - precision_11: 0.2430 - val_loss: 8.9504 - val_accuracy: 0.9188 - val_precision_11: 0.0118 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.1237 - accuracy: 0.8011 - precision_11: 0.2438 - val_loss: 5.0601 - val_accuracy: 0.8182 - val_precision_11: 0.0209 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.4091 - accuracy: 0.7968 - precision_11: 0.2437 - val_loss: 3.5317 - val_accuracy: 0.9388 - val_precision_11: 0.0083 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.5196 - accuracy: 0.8048 - precision_11: 0.2642 - val_loss: 22.0772 - val_accuracy: 0.6284 - val_precision_11: 0.0437 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.2643 - accuracy: 0.7975 - precision_11: 0.2411 - val_loss: 39.1393 - val_accuracy: 0.4572 - val_precision_11: 0.0385 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.6233 - accuracy: 0.7969 - precision_11: 0.2428 - val_loss: 6.0085 - val_accuracy: 0.9130 - val_precision_11: 0.0176 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.1826 - accuracy: 0.8000 - precision_11: 0.2528 - val_loss: 4.4044 - val_accuracy: 0.8804 - val_precision_11: 0.0108 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.2677 - accuracy: 0.7961 - precision_11: 0.2362 - val_loss: 11.4508 - val_accuracy: 0.6501 - val_precision_11: 0.0292 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.2644 - accuracy: 0.7973 - precision_11: 0.2423 - val_loss: 25.2795 - val_accuracy: 0.5731 - val_precision_11: 0.0426 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.8030 - accuracy: 0.7995 - precision_11: 0.2427 - val_loss: 5.6224 - val_accuracy: 0.9323 - val_precision_11: 0.0070 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.5936 - accuracy: 0.8038 - precision_11: 0.2519 - val_loss: 3.8485 - val_accuracy: 0.7555 - val_precision_11: 0.0293 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 12.4024 - accuracy: 0.8035 - precision_11: 0.2593 - val_loss: 4.4116 - val_accuracy: 0.9355 - val_precision_11: 0.0076 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 12.7670 - accuracy: 0.8064 - precision_11: 0.2611 - val_loss: 15.9047 - val_accuracy: 0.5086 - val_precision_11: 0.0407 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 11.3504 - accuracy: 0.8013 - precision_11: 0.2488 - val_loss: 25.8137 - val_accuracy: 0.6041 - val_precision_11: 0.0435 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 13.6472 - accuracy: 0.8026 - precision_11: 0.2625 - val_loss: 4.3529 - val_accuracy: 0.9133 - val_precision_11: 0.0119 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.8631 - accuracy: 0.8039 - precision_11: 0.2531 - val_loss: 3.6973 - val_accuracy: 0.9220 - val_precision_11: 0.0071 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.8544 - accuracy: 0.8049 - precision_11: 0.2601 - val_loss: 6.5224 - val_accuracy: 0.9310 - val_precision_11: 0.0135 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.6370 - accuracy: 0.8044 - precision_11: 0.2483 - val_loss: 5.3298 - val_accuracy: 0.7345 - val_precision_11: 0.0467 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.3684 - accuracy: 0.8024 - precision_11: 0.2475 - val_loss: 5.0837 - val_accuracy: 0.9510 - val_precision_11: 0.0188 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.6666 - accuracy: 0.8006 - precision_11: 0.2514 - val_loss: 3.3032 - val_accuracy: 0.8978 - val_precision_11: 0.0105 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.2370 - accuracy: 0.8027 - precision_11: 0.2556 - val_loss: 4.5800 - val_accuracy: 0.9136 - val_precision_11: 0.0061 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.1578 - accuracy: 0.8091 - precision_11: 0.2682 - val_loss: 4.4443 - val_accuracy: 0.7132 - val_precision_11: 0.0427 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.3795 - accuracy: 0.8068 - precision_11: 0.2556 - val_loss: 4.2639 - val_accuracy: 0.7187 - val_precision_11: 0.0394 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.1339 - accuracy: 0.8089 - precision_11: 0.2662 - val_loss: 7.5078 - val_accuracy: 0.5698 - val_precision_11: 0.0429 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.2648 - accuracy: 0.8075 - precision_11: 0.2673 - val_loss: 1.9459 - val_accuracy: 0.8683 - val_precision_11: 0.0096 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.5715 - accuracy: 0.8071 - precision_11: 0.2564 - val_loss: 2.0644 - val_accuracy: 0.8194 - val_precision_11: 0.0171 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.9239 - accuracy: 0.8051 - precision_11: 0.2590 - val_loss: 1.4725 - val_accuracy: 0.8796 - val_precision_11: 0.0123 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.5338 - accuracy: 0.8108 - precision_11: 0.2781 - val_loss: 19.9702 - val_accuracy: 0.6102 - val_precision_11: 0.0439 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.9209 - accuracy: 0.8042 - precision_11: 0.2585 - val_loss: 14.4344 - val_accuracy: 0.5634 - val_precision_11: 0.0405 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.1457 - accuracy: 0.8066 - precision_11: 0.2609 - val_loss: 4.4983 - val_accuracy: 0.8550 - val_precision_11: 0.0203 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.1871 - accuracy: 0.8065 - precision_11: 0.2704 - val_loss: 1.5054 - val_accuracy: 0.8750 - val_precision_11: 0.0201 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.8329 - accuracy: 0.8090 - precision_11: 0.2778 - val_loss: 1.3783 - val_accuracy: 0.8220 - val_precision_11: 0.0297 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.3397 - accuracy: 0.8111 - precision_11: 0.2813 - val_loss: 4.9469 - val_accuracy: 0.5356 - val_precision_11: 0.0374 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.0694 - accuracy: 0.8084 - precision_11: 0.2752 - val_loss: 1.6141 - val_accuracy: 0.9156 - val_precision_11: 0.0075 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.7058 - accuracy: 0.8098 - precision_11: 0.2740 - val_loss: 1.0449 - val_accuracy: 0.8088 - val_precision_11: 0.0139 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.5170 - accuracy: 0.8101 - precision_11: 0.2660 - val_loss: 1.4598 - val_accuracy: 0.8821 - val_precision_11: 0.0040 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 2.5599 - accuracy: 0.8103 - precision_11: 0.2764 - val_loss: 0.8308 - val_accuracy: 0.8479 - val_precision_11: 0.0120 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.2542 - accuracy: 0.8119 - precision_11: 0.2741 - val_loss: 1.3398 - val_accuracy: 0.7452 - val_precision_11: 0.0219 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.9618 - accuracy: 0.8110 - precision_11: 0.2690 - val_loss: 0.9156 - val_accuracy: 0.8960 - val_precision_11: 0.0084 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 2.0188 - accuracy: 0.8102 - precision_11: 0.2679 - val_loss: 1.8477 - val_accuracy: 0.9266 - val_precision_11: 0.0167 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 1.9999 - accuracy: 0.8119 - precision_11: 0.2673 - val_loss: 0.4947 - val_accuracy: 0.9235 - val_precision_11: 0.0073 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.2328 - accuracy: 0.8143 - precision_11: 0.2690 - val_loss: 0.6070 - val_accuracy: 0.9305 - val_precision_11: 0.0101 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1996 - accuracy: 0.8142 - precision_11: 0.2691 - val_loss: 0.7328 - val_accuracy: 0.9157 - val_precision_11: 0.0124 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1584 - accuracy: 0.8146 - precision_11: 0.2704 - val_loss: 0.5768 - val_accuracy: 0.9453 - val_precision_11: 0.0026 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1973 - accuracy: 0.8129 - precision_11: 0.2689 - val_loss: 0.3925 - val_accuracy: 0.9430 - val_precision_11: 0.0252 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8915 - accuracy: 0.8200 - precision_11: 0.2742 - val_loss: 0.3500 - val_accuracy: 0.9013 - val_precision_11: 0.0243 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0198 - accuracy: 0.8124 - precision_11: 0.2554 - val_loss: 0.3239 - val_accuracy: 0.9427 - val_precision_11: 0.0139 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8121 - accuracy: 0.8171 - precision_11: 0.2763 - val_loss: 0.4357 - val_accuracy: 0.9166 - val_precision_11: 0.0089 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.6791 - accuracy: 0.8106 - precision_11: 0.2572 - val_loss: 0.7920 - val_accuracy: 0.7205 - val_precision_11: 0.0510 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9989 - accuracy: 0.8176 - precision_11: 0.2681 - val_loss: 0.3468 - val_accuracy: 0.9217 - val_precision_11: 0.0138 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7245 - accuracy: 0.8204 - precision_11: 0.2688 - val_loss: 0.7349 - val_accuracy: 0.7303 - val_precision_11: 0.0546 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.8246 - precision_11: 0.2874 - val_loss: 0.4282 - val_accuracy: 0.8703 - val_precision_11: 0.0231 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7500 - accuracy: 0.8242 - precision_11: 0.2773 - val_loss: 3.0082 - val_accuracy: 0.7886 - val_precision_11: 0.0275 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.8001 - accuracy: 0.8062 - precision_11: 0.2469 - val_loss: 0.2920 - val_accuracy: 0.9433 - val_precision_11: 0.0095 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.8217 - precision_11: 0.2715 - val_loss: 0.2874 - val_accuracy: 0.9234 - val_precision_11: 0.0072 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.8322 - precision_11: 0.3124 - val_loss: 0.2768 - val_accuracy: 0.9313 - val_precision_11: 0.0035 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.8340 - precision_11: 0.3203 - val_loss: 0.4095 - val_accuracy: 0.8774 - val_precision_11: 0.0376 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.8290 - precision_11: 0.2985 - val_loss: 0.3858 - val_accuracy: 0.8871 - val_precision_11: 0.0228 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7775 - accuracy: 0.8207 - precision_11: 0.2771 - val_loss: 0.3799 - val_accuracy: 0.9139 - val_precision_11: 0.0061 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7955 - accuracy: 0.8261 - precision_11: 0.2958 - val_loss: 0.5657 - val_accuracy: 0.7717 - val_precision_11: 0.0558 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.8264 - precision_11: 0.2989 - val_loss: 0.3421 - val_accuracy: 0.9070 - val_precision_11: 0.0171 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.8338 - precision_11: 0.3096 - val_loss: 0.2857 - val_accuracy: 0.9216 - val_precision_11: 0.0084 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5920 - accuracy: 0.8319 - precision_11: 0.3089 - val_loss: 0.2797 - val_accuracy: 0.9262 - val_precision_11: 0.0092 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6119 - accuracy: 0.8309 - precision_11: 0.3022 - val_loss: 0.2852 - val_accuracy: 0.9351 - val_precision_11: 0.0038 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.8359 - precision_11: 0.3293 - val_loss: 0.2824 - val_accuracy: 0.9204 - val_precision_11: 0.0336 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6263 - accuracy: 0.8371 - precision_11: 0.3404 - val_loss: 12.6713 - val_accuracy: 0.8147 - val_precision_11: 0.0600 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.2621 - accuracy: 0.8135 - precision_11: 0.2188 - val_loss: 0.3088 - val_accuracy: 0.9283 - val_precision_11: 0.0173 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8548 - precision_11: 0.4521 - val_loss: 0.2732 - val_accuracy: 0.9467 - val_precision_11: 0.0210 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 302.8452 - accuracy: 0.7625 - precision_12: 0.1696 - val_loss: 29.3990 - val_accuracy: 0.8765 - val_precision_12: 0.0273 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 197.6496 - accuracy: 0.7652 - precision_12: 0.1782 - val_loss: 62.4761 - val_accuracy: 0.9671 - val_precision_12: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 119.5359 - accuracy: 0.7733 - precision_12: 0.1999 - val_loss: 64.8475 - val_accuracy: 0.7100 - val_precision_12: 0.0403 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 171.1139 - accuracy: 0.7738 - precision_12: 0.1973 - val_loss: 173.5480 - val_accuracy: 0.3593 - val_precision_12: 0.0269 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 131.7531 - accuracy: 0.7728 - precision_12: 0.1987 - val_loss: 13.8955 - val_accuracy: 0.8608 - val_precision_12: 0.0177 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 98.5255 - accuracy: 0.7791 - precision_12: 0.2086 - val_loss: 20.4400 - val_accuracy: 0.7311 - val_precision_12: 0.0254 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 97.1730 - accuracy: 0.7814 - precision_12: 0.2103 - val_loss: 27.0955 - val_accuracy: 0.6248 - val_precision_12: 0.0268 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 118.6420 - accuracy: 0.7713 - precision_12: 0.1997 - val_loss: 34.1263 - val_accuracy: 0.9683 - val_precision_12: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 83.4126 - accuracy: 0.7797 - precision_12: 0.2079 - val_loss: 31.0696 - val_accuracy: 0.8860 - val_precision_12: 0.0163 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 72.2604 - accuracy: 0.7854 - precision_12: 0.2131 - val_loss: 31.7055 - val_accuracy: 0.7674 - val_precision_12: 0.0212 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 86.2832 - accuracy: 0.7861 - precision_12: 0.2133 - val_loss: 85.5493 - val_accuracy: 0.9675 - val_precision_12: 0.0118 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 136.9956 - accuracy: 0.7776 - precision_12: 0.1975 - val_loss: 185.3610 - val_accuracy: 0.4647 - val_precision_12: 0.0391 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 63.9292 - accuracy: 0.7893 - precision_12: 0.2116 - val_loss: 11.1181 - val_accuracy: 0.8657 - val_precision_12: 0.0139 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 67.7978 - accuracy: 0.7910 - precision_12: 0.2177 - val_loss: 143.6882 - val_accuracy: 0.4301 - val_precision_12: 0.0396 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 52.2405 - accuracy: 0.7906 - precision_12: 0.2231 - val_loss: 34.9776 - val_accuracy: 0.9631 - val_precision_12: 0.0137 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 71.3791 - accuracy: 0.7899 - precision_12: 0.2244 - val_loss: 11.1070 - val_accuracy: 0.7919 - val_precision_12: 0.0326 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 46.8618 - accuracy: 0.7967 - precision_12: 0.2267 - val_loss: 122.5863 - val_accuracy: 0.4641 - val_precision_12: 0.0403 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 62.6410 - accuracy: 0.7822 - precision_12: 0.2118 - val_loss: 12.1897 - val_accuracy: 0.9087 - val_precision_12: 0.0248 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 66.8698 - accuracy: 0.7931 - precision_12: 0.2189 - val_loss: 104.5986 - val_accuracy: 0.5264 - val_precision_12: 0.0436 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 40.8423 - accuracy: 0.7962 - precision_12: 0.2235 - val_loss: 75.7476 - val_accuracy: 0.5580 - val_precision_12: 0.0415 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 45.0970 - accuracy: 0.7950 - precision_12: 0.2283 - val_loss: 27.6561 - val_accuracy: 0.9173 - val_precision_12: 0.0249 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 60.5633 - accuracy: 0.7926 - precision_12: 0.2253 - val_loss: 7.6949 - val_accuracy: 0.7596 - val_precision_12: 0.0252 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 39.4491 - accuracy: 0.7985 - precision_12: 0.2321 - val_loss: 8.7177 - val_accuracy: 0.8566 - val_precision_12: 0.0279 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 51.9109 - accuracy: 0.7951 - precision_12: 0.2189 - val_loss: 23.0835 - val_accuracy: 0.9296 - val_precision_12: 0.0017 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.8836 - accuracy: 0.8007 - precision_12: 0.2385 - val_loss: 6.9699 - val_accuracy: 0.8560 - val_precision_12: 0.0187 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.0544 - accuracy: 0.7983 - precision_12: 0.2264 - val_loss: 6.2034 - val_accuracy: 0.8782 - val_precision_12: 0.0128 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.5655 - accuracy: 0.7969 - precision_12: 0.2270 - val_loss: 24.5689 - val_accuracy: 0.9166 - val_precision_12: 0.0089 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 49.6894 - accuracy: 0.7971 - precision_12: 0.2289 - val_loss: 6.0652 - val_accuracy: 0.8727 - val_precision_12: 0.0128 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.8067 - accuracy: 0.8004 - precision_12: 0.2273 - val_loss: 16.8622 - val_accuracy: 0.9385 - val_precision_12: 0.0123 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.8793 - accuracy: 0.7967 - precision_12: 0.2277 - val_loss: 6.9853 - val_accuracy: 0.8774 - val_precision_12: 0.0170 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.0757 - accuracy: 0.8000 - precision_12: 0.2272 - val_loss: 11.3846 - val_accuracy: 0.8616 - val_precision_12: 0.0196 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 25.9320 - accuracy: 0.7988 - precision_12: 0.2252 - val_loss: 16.4142 - val_accuracy: 0.9460 - val_precision_12: 0.0027 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.7376 - accuracy: 0.7969 - precision_12: 0.2259 - val_loss: 17.9805 - val_accuracy: 0.9586 - val_precision_12: 0.0049 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 44.3127 - accuracy: 0.7976 - precision_12: 0.2227 - val_loss: 6.0761 - val_accuracy: 0.8763 - val_precision_12: 0.0104 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 21.9053 - accuracy: 0.8039 - precision_12: 0.2297 - val_loss: 5.2222 - val_accuracy: 0.8691 - val_precision_12: 0.0164 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.5526 - accuracy: 0.8045 - precision_12: 0.2376 - val_loss: 10.8061 - val_accuracy: 0.8854 - val_precision_12: 0.0122 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.8855 - accuracy: 0.8048 - precision_12: 0.2389 - val_loss: 7.9792 - val_accuracy: 0.8743 - val_precision_12: 0.0073 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.5310 - accuracy: 0.8036 - precision_12: 0.2301 - val_loss: 31.8243 - val_accuracy: 0.5868 - val_precision_12: 0.0419 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 21.7856 - accuracy: 0.8037 - precision_12: 0.2377 - val_loss: 5.3032 - val_accuracy: 0.9183 - val_precision_12: 0.0026 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.3956 - accuracy: 0.8015 - precision_12: 0.2259 - val_loss: 53.5681 - val_accuracy: 0.4730 - val_precision_12: 0.0386 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 19.4245 - accuracy: 0.8018 - precision_12: 0.2266 - val_loss: 7.0850 - val_accuracy: 0.7625 - val_precision_12: 0.0375 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 15.4040 - accuracy: 0.8041 - precision_12: 0.2399 - val_loss: 14.4514 - val_accuracy: 0.9254 - val_precision_12: 0.0119 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 37.8210 - accuracy: 0.7950 - precision_12: 0.2239 - val_loss: 6.6904 - val_accuracy: 0.8470 - val_precision_12: 0.0180 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 14.5840 - accuracy: 0.8043 - precision_12: 0.2304 - val_loss: 3.2273 - val_accuracy: 0.8847 - val_precision_12: 0.0090 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.2829 - accuracy: 0.8011 - precision_12: 0.2227 - val_loss: 8.1721 - val_accuracy: 0.9205 - val_precision_12: 0.0122 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.6322 - accuracy: 0.8052 - precision_12: 0.2329 - val_loss: 6.0537 - val_accuracy: 0.8482 - val_precision_12: 0.0137 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.3690 - accuracy: 0.8049 - precision_12: 0.2358 - val_loss: 3.9528 - val_accuracy: 0.8960 - val_precision_12: 0.0111 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.3894 - accuracy: 0.8061 - precision_12: 0.2428 - val_loss: 31.7650 - val_accuracy: 0.5469 - val_precision_12: 0.0418 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.5277 - accuracy: 0.8059 - precision_12: 0.2440 - val_loss: 3.8831 - val_accuracy: 0.9183 - val_precision_12: 0.0192 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.5899 - accuracy: 0.8034 - precision_12: 0.2324 - val_loss: 2.9705 - val_accuracy: 0.7983 - val_precision_12: 0.0155 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 15.2257 - accuracy: 0.8028 - precision_12: 0.2320 - val_loss: 4.2879 - val_accuracy: 0.9162 - val_precision_12: 0.0088 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.3605 - accuracy: 0.8094 - precision_12: 0.2484 - val_loss: 2.1389 - val_accuracy: 0.8320 - val_precision_12: 0.0132 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.2657 - accuracy: 0.8077 - precision_12: 0.2522 - val_loss: 7.5864 - val_accuracy: 0.6501 - val_precision_12: 0.0440 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.5390 - accuracy: 0.8050 - precision_12: 0.2345 - val_loss: 4.5787 - val_accuracy: 0.8903 - val_precision_12: 0.0187 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.0015 - accuracy: 0.8089 - precision_12: 0.2553 - val_loss: 2.5291 - val_accuracy: 0.8697 - val_precision_12: 0.0056 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.2085 - accuracy: 0.8062 - precision_12: 0.2440 - val_loss: 21.1275 - val_accuracy: 0.5686 - val_precision_12: 0.0388 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.5343 - accuracy: 0.8043 - precision_12: 0.2406 - val_loss: 2.4860 - val_accuracy: 0.8767 - val_precision_12: 0.0190 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.7390 - accuracy: 0.8067 - precision_12: 0.2582 - val_loss: 3.6011 - val_accuracy: 0.9225 - val_precision_12: 0.0286 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.2837 - accuracy: 0.8089 - precision_12: 0.2536 - val_loss: 3.2185 - val_accuracy: 0.8902 - val_precision_12: 0.0137 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.3146 - accuracy: 0.8086 - precision_12: 0.2585 - val_loss: 2.6023 - val_accuracy: 0.9046 - val_precision_12: 0.0155 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.4001 - accuracy: 0.8087 - precision_12: 0.2573 - val_loss: 1.9599 - val_accuracy: 0.8636 - val_precision_12: 0.0130 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.8543 - accuracy: 0.8099 - precision_12: 0.2689 - val_loss: 1.8422 - val_accuracy: 0.8355 - val_precision_12: 0.0115 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.6136 - accuracy: 0.8079 - precision_12: 0.2587 - val_loss: 1.8267 - val_accuracy: 0.8001 - val_precision_12: 0.0204 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.5774 - accuracy: 0.8090 - precision_12: 0.2580 - val_loss: 2.1124 - val_accuracy: 0.8902 - val_precision_12: 0.0179 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.3203 - accuracy: 0.8062 - precision_12: 0.2512 - val_loss: 1.3337 - val_accuracy: 0.8711 - val_precision_12: 0.0160 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.0751 - accuracy: 0.8093 - precision_12: 0.2566 - val_loss: 1.5476 - val_accuracy: 0.8955 - val_precision_12: 0.0019 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.8903 - accuracy: 0.8067 - precision_12: 0.2585 - val_loss: 2.1382 - val_accuracy: 0.9012 - val_precision_12: 0.0129 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.0870 - accuracy: 0.8072 - precision_12: 0.2613 - val_loss: 0.9395 - val_accuracy: 0.8640 - val_precision_12: 0.0156 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.5347 - accuracy: 0.8093 - precision_12: 0.2608 - val_loss: 1.6106 - val_accuracy: 0.8936 - val_precision_12: 0.0082 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.2007 - accuracy: 0.8091 - precision_12: 0.2651 - val_loss: 1.3981 - val_accuracy: 0.9158 - val_precision_12: 0.0050 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.9971 - accuracy: 0.8065 - precision_12: 0.2571 - val_loss: 1.1661 - val_accuracy: 0.8849 - val_precision_12: 0.0137 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.6896 - accuracy: 0.8085 - precision_12: 0.2599 - val_loss: 0.6365 - val_accuracy: 0.8468 - val_precision_12: 0.0190 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.7243 - accuracy: 0.8104 - precision_12: 0.2645 - val_loss: 0.6159 - val_accuracy: 0.9215 - val_precision_12: 0.0190 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0972 - accuracy: 0.8143 - precision_12: 0.2727 - val_loss: 0.4363 - val_accuracy: 0.8872 - val_precision_12: 0.0236 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0001 - accuracy: 0.8174 - precision_12: 0.2837 - val_loss: 0.4416 - val_accuracy: 0.8886 - val_precision_12: 0.0135 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7333 - accuracy: 0.8223 - precision_12: 0.2935 - val_loss: 0.3681 - val_accuracy: 0.8751 - val_precision_12: 0.0222 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.8262 - precision_12: 0.3087 - val_loss: 0.3531 - val_accuracy: 0.9155 - val_precision_12: 0.0112 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.8288 - precision_12: 0.3124 - val_loss: 0.5926 - val_accuracy: 0.7246 - val_precision_12: 0.0543 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.8362 - precision_12: 0.3412 - val_loss: 0.2805 - val_accuracy: 0.9364 - val_precision_12: 0.0039 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.8335 - precision_12: 0.3220 - val_loss: 0.6222 - val_accuracy: 0.7848 - val_precision_12: 0.0454 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.8249 - precision_12: 0.2754 - val_loss: 0.3674 - val_accuracy: 0.8823 - val_precision_12: 0.0360 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8426 - precision_12: 0.3527 - val_loss: 0.4626 - val_accuracy: 0.8077 - val_precision_12: 0.0564 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8453 - precision_12: 0.3717 - val_loss: 0.3101 - val_accuracy: 0.9337 - val_precision_12: 0.0126 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.8322 - precision_12: 0.3071 - val_loss: 0.7356 - val_accuracy: 0.9160 - val_precision_12: 0.0076 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.9297 - accuracy: 0.8034 - precision_12: 0.2296 - val_loss: 0.9358 - val_accuracy: 0.9290 - val_precision_12: 0.0236 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.6858 - accuracy: 0.8053 - precision_12: 0.2246 - val_loss: 0.4080 - val_accuracy: 0.9104 - val_precision_12: 0.0275 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.8294 - precision_12: 0.2776 - val_loss: 0.3241 - val_accuracy: 0.9086 - val_precision_12: 0.0175 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8456 - precision_12: 0.3629 - val_loss: 0.2963 - val_accuracy: 0.9146 - val_precision_12: 0.0260 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8469 - precision_12: 0.3714 - val_loss: 0.2804 - val_accuracy: 0.9439 - val_precision_12: 0.0368 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8430 - precision_12: 0.3426 - val_loss: 0.3096 - val_accuracy: 0.9086 - val_precision_12: 0.0227 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.8381 - precision_12: 0.3142 - val_loss: 0.2800 - val_accuracy: 0.9116 - val_precision_12: 0.0248 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.4290 - accuracy: 0.8159 - precision_12: 0.2610 - val_loss: 0.6176 - val_accuracy: 0.9228 - val_precision_12: 0.0313 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.8300 - precision_12: 0.2937 - val_loss: 0.3003 - val_accuracy: 0.9270 - val_precision_12: 0.0283 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.8404 - precision_12: 0.3310 - val_loss: 0.4328 - val_accuracy: 0.8549 - val_precision_12: 0.0400 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.4446 - accuracy: 0.8443 - precision_12: 0.3605 - val_loss: 0.3030 - val_accuracy: 0.8932 - val_precision_12: 0.0269 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.9364 - accuracy: 0.8319 - precision_12: 0.3034 - val_loss: 2.3369 - val_accuracy: 0.9307 - val_precision_12: 0.0261 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.7496 - accuracy: 0.8085 - precision_12: 0.2322 - val_loss: 0.8837 - val_accuracy: 0.6433 - val_precision_12: 0.0509 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.8280 - precision_12: 0.2844 - val_loss: 0.3309 - val_accuracy: 0.9027 - val_precision_12: 0.0348 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.8367 - precision_12: 0.3191 - val_loss: 0.2838 - val_accuracy: 0.9218 - val_precision_12: 0.0205 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8461 - precision_12: 0.3754 - val_loss: 0.3327 - val_accuracy: 0.8960 - val_precision_12: 0.0278 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 99.8484 - accuracy: 0.7554 - precision_13: 0.1617 - val_loss: 21.4076 - val_accuracy: 0.9579 - val_precision_13: 0.0180 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 57.8189 - accuracy: 0.7654 - precision_13: 0.1732 - val_loss: 7.6507 - val_accuracy: 0.9347 - val_precision_13: 0.0147 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 53.9461 - accuracy: 0.7748 - precision_13: 0.1915 - val_loss: 67.9740 - val_accuracy: 0.9701 - val_precision_13: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 82.4211 - accuracy: 0.7714 - precision_13: 0.1825 - val_loss: 17.4729 - val_accuracy: 0.9574 - val_precision_13: 0.0132 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.8584 - accuracy: 0.7856 - precision_13: 0.1938 - val_loss: 21.0562 - val_accuracy: 0.9658 - val_precision_13: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.5583 - accuracy: 0.7909 - precision_13: 0.1967 - val_loss: 17.7011 - val_accuracy: 0.9361 - val_precision_13: 0.0189 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.3818 - accuracy: 0.7939 - precision_13: 0.2057 - val_loss: 20.4947 - val_accuracy: 0.6425 - val_precision_13: 0.0448 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.2059 - accuracy: 0.7949 - precision_13: 0.2166 - val_loss: 6.7844 - val_accuracy: 0.8377 - val_precision_13: 0.0157 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.3890 - accuracy: 0.7955 - precision_13: 0.2171 - val_loss: 17.6916 - val_accuracy: 0.9483 - val_precision_13: 0.0196 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 51.8640 - accuracy: 0.7951 - precision_13: 0.2194 - val_loss: 11.7014 - val_accuracy: 0.9539 - val_precision_13: 0.0074 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.7512 - accuracy: 0.7971 - precision_13: 0.2177 - val_loss: 7.7129 - val_accuracy: 0.9070 - val_precision_13: 0.0181 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 37.8101 - accuracy: 0.7957 - precision_13: 0.2171 - val_loss: 17.0775 - val_accuracy: 0.9003 - val_precision_13: 0.0137 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 21.2682 - accuracy: 0.8006 - precision_13: 0.2299 - val_loss: 5.9802 - val_accuracy: 0.9179 - val_precision_13: 0.0065 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 27.4807 - accuracy: 0.7993 - precision_13: 0.2243 - val_loss: 8.3195 - val_accuracy: 0.8209 - val_precision_13: 0.0136 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.1910 - accuracy: 0.7973 - precision_13: 0.2189 - val_loss: 10.9436 - val_accuracy: 0.8825 - val_precision_13: 0.0172 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 18.2996 - accuracy: 0.7998 - precision_13: 0.2308 - val_loss: 5.9415 - val_accuracy: 0.7951 - val_precision_13: 0.0243 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.3685 - accuracy: 0.7996 - precision_13: 0.2350 - val_loss: 21.3516 - val_accuracy: 0.8899 - val_precision_13: 0.0274 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.2356 - accuracy: 0.8052 - precision_13: 0.2401 - val_loss: 44.4324 - val_accuracy: 0.4690 - val_precision_13: 0.0360 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.0412 - accuracy: 0.8009 - precision_13: 0.2373 - val_loss: 3.8207 - val_accuracy: 0.8683 - val_precision_13: 0.0162 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.0384 - accuracy: 0.7985 - precision_13: 0.2291 - val_loss: 5.2280 - val_accuracy: 0.8746 - val_precision_13: 0.0274 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.9969 - accuracy: 0.7993 - precision_13: 0.2222 - val_loss: 3.6459 - val_accuracy: 0.8727 - val_precision_13: 0.0169 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.5309 - accuracy: 0.8019 - precision_13: 0.2189 - val_loss: 12.5771 - val_accuracy: 0.5491 - val_precision_13: 0.0402 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.8589 - accuracy: 0.8000 - precision_13: 0.2163 - val_loss: 5.8252 - val_accuracy: 0.9210 - val_precision_13: 0.0202 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.0069 - accuracy: 0.8027 - precision_13: 0.2194 - val_loss: 6.0605 - val_accuracy: 0.8890 - val_precision_13: 0.0192 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.0057 - accuracy: 0.8050 - precision_13: 0.2317 - val_loss: 5.4900 - val_accuracy: 0.9035 - val_precision_13: 0.0221 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.1777 - accuracy: 0.8014 - precision_13: 0.2182 - val_loss: 3.2258 - val_accuracy: 0.9056 - val_precision_13: 0.0237 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.7103 - accuracy: 0.8061 - precision_13: 0.2345 - val_loss: 2.6387 - val_accuracy: 0.8293 - val_precision_13: 0.0177 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.4114 - accuracy: 0.8033 - precision_13: 0.2346 - val_loss: 6.7193 - val_accuracy: 0.9262 - val_precision_13: 0.0031 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.5254 - accuracy: 0.8034 - precision_13: 0.2227 - val_loss: 3.3364 - val_accuracy: 0.8719 - val_precision_13: 0.0228 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.7940 - accuracy: 0.8021 - precision_13: 0.2247 - val_loss: 5.8819 - val_accuracy: 0.9348 - val_precision_13: 0.0129 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.1705 - accuracy: 0.8056 - precision_13: 0.2306 - val_loss: 2.3295 - val_accuracy: 0.8788 - val_precision_13: 0.0187 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.0009 - accuracy: 0.8013 - precision_13: 0.2264 - val_loss: 4.1578 - val_accuracy: 0.8592 - val_precision_13: 0.0180 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.5410 - accuracy: 0.8057 - precision_13: 0.2439 - val_loss: 3.2675 - val_accuracy: 0.8986 - val_precision_13: 0.0189 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.6207 - accuracy: 0.8086 - precision_13: 0.2516 - val_loss: 2.8227 - val_accuracy: 0.9032 - val_precision_13: 0.0210 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.0654 - accuracy: 0.8048 - precision_13: 0.2330 - val_loss: 2.8160 - val_accuracy: 0.8061 - val_precision_13: 0.0470 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.4761 - accuracy: 0.8061 - precision_13: 0.2441 - val_loss: 3.5630 - val_accuracy: 0.9121 - val_precision_13: 0.0282 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.7554 - accuracy: 0.8057 - precision_13: 0.2432 - val_loss: 1.4963 - val_accuracy: 0.7769 - val_precision_13: 0.0326 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.2892 - accuracy: 0.8093 - precision_13: 0.2576 - val_loss: 1.1655 - val_accuracy: 0.8721 - val_precision_13: 0.0208 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.0608 - accuracy: 0.8065 - precision_13: 0.2508 - val_loss: 1.1651 - val_accuracy: 0.9059 - val_precision_13: 0.0248 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.1998 - accuracy: 0.8096 - precision_13: 0.2553 - val_loss: 3.3010 - val_accuracy: 0.9304 - val_precision_13: 0.0349 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 4.5385 - accuracy: 0.8082 - precision_13: 0.2534 - val_loss: 15.8340 - val_accuracy: 0.4806 - val_precision_13: 0.0390 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 7.7438 - accuracy: 0.8025 - precision_13: 0.2269 - val_loss: 1.6391 - val_accuracy: 0.6935 - val_precision_13: 0.0372 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.6160 - accuracy: 0.8069 - precision_13: 0.2472 - val_loss: 1.3424 - val_accuracy: 0.7626 - val_precision_13: 0.0419 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.3065 - accuracy: 0.8030 - precision_13: 0.2320 - val_loss: 1.3482 - val_accuracy: 0.8648 - val_precision_13: 0.0189 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.7917 - accuracy: 0.8081 - precision_13: 0.2554 - val_loss: 1.0892 - val_accuracy: 0.8718 - val_precision_13: 0.0195 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0265 - accuracy: 0.8105 - precision_13: 0.2578 - val_loss: 0.5989 - val_accuracy: 0.8304 - val_precision_13: 0.0207 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0525 - accuracy: 0.8117 - precision_13: 0.2679 - val_loss: 4.1926 - val_accuracy: 0.5389 - val_precision_13: 0.0425 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.9502 - accuracy: 0.8131 - precision_13: 0.2741 - val_loss: 3.6270 - val_accuracy: 0.6034 - val_precision_13: 0.0464 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4738 - accuracy: 0.8115 - precision_13: 0.2692 - val_loss: 0.7008 - val_accuracy: 0.9012 - val_precision_13: 0.0196 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.6750 - accuracy: 0.8148 - precision_13: 0.2719 - val_loss: 0.7478 - val_accuracy: 0.8463 - val_precision_13: 0.0178 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1908 - accuracy: 0.8151 - precision_13: 0.2858 - val_loss: 0.5300 - val_accuracy: 0.9294 - val_precision_13: 0.0161 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0655 - accuracy: 0.8183 - precision_13: 0.2865 - val_loss: 0.4224 - val_accuracy: 0.8849 - val_precision_13: 0.0319 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7909 - accuracy: 0.8250 - precision_13: 0.3070 - val_loss: 0.4322 - val_accuracy: 0.8305 - val_precision_13: 0.0380 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7340 - accuracy: 0.8250 - precision_13: 0.3081 - val_loss: 0.3363 - val_accuracy: 0.9284 - val_precision_13: 0.0158 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7845 - accuracy: 0.8261 - precision_13: 0.3043 - val_loss: 0.7861 - val_accuracy: 0.7119 - val_precision_13: 0.0535 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.8312 - precision_13: 0.3258 - val_loss: 0.4268 - val_accuracy: 0.9051 - val_precision_13: 0.0520 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.8318 - precision_13: 0.3246 - val_loss: 0.4095 - val_accuracy: 0.8469 - val_precision_13: 0.0435 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.8322 - precision_13: 0.3184 - val_loss: 0.6921 - val_accuracy: 0.6862 - val_precision_13: 0.0513 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.8399 - precision_13: 0.3542 - val_loss: 0.2867 - val_accuracy: 0.9111 - val_precision_13: 0.0340 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.8328 - precision_13: 0.3169 - val_loss: 0.3235 - val_accuracy: 0.9038 - val_precision_13: 0.0511 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.8412 - precision_13: 0.3558 - val_loss: 0.2201 - val_accuracy: 0.9533 - val_precision_13: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.8401 - precision_13: 0.3519 - val_loss: 0.5029 - val_accuracy: 0.7785 - val_precision_13: 0.0601 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.8363 - precision_13: 0.3358 - val_loss: 0.5609 - val_accuracy: 0.7878 - val_precision_13: 0.0630 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5969 - accuracy: 0.8303 - precision_13: 0.2971 - val_loss: 1.5878 - val_accuracy: 0.5833 - val_precision_13: 0.0431 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.8374 - precision_13: 0.3346 - val_loss: 0.3361 - val_accuracy: 0.9081 - val_precision_13: 0.0266 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8449 - precision_13: 0.3726 - val_loss: 0.3006 - val_accuracy: 0.9104 - val_precision_13: 0.0377 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.4506 - accuracy: 0.8436 - precision_13: 0.3676 - val_loss: 0.2841 - val_accuracy: 0.9269 - val_precision_13: 0.0047 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8462 - precision_13: 0.3829 - val_loss: 0.3409 - val_accuracy: 0.8940 - val_precision_13: 0.0408 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.8361 - precision_13: 0.3261 - val_loss: 0.2728 - val_accuracy: 0.9489 - val_precision_13: 0.0030 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.8333 - precision_13: 0.3118 - val_loss: 0.2172 - val_accuracy: 0.9577 - val_precision_13: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.4940 - accuracy: 0.8070 - precision_13: 0.2380 - val_loss: 0.3777 - val_accuracy: 0.9071 - val_precision_13: 0.0360 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.8412 - precision_13: 0.3205 - val_loss: 0.2768 - val_accuracy: 0.9227 - val_precision_13: 0.0299 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8438 - precision_13: 0.3487 - val_loss: 0.2743 - val_accuracy: 0.9366 - val_precision_13: 0.0436 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8511 - precision_13: 0.4137 - val_loss: 0.3506 - val_accuracy: 0.8606 - val_precision_13: 0.0795 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8504 - precision_13: 0.4086 - val_loss: 0.3677 - val_accuracy: 0.8741 - val_precision_13: 0.0338 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8518 - precision_13: 0.4290 - val_loss: 0.2432 - val_accuracy: 0.9367 - val_precision_13: 0.0404 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8566 - precision_13: 0.5024 - val_loss: 0.3131 - val_accuracy: 0.9104 - val_precision_13: 0.0595 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8520 - precision_13: 0.4348 - val_loss: 0.2442 - val_accuracy: 0.9290 - val_precision_13: 0.0295 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8493 - precision_13: 0.4117 - val_loss: 0.3316 - val_accuracy: 0.9427 - val_precision_13: 0.0139 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.3095 - accuracy: 0.8091 - precision_13: 0.2558 - val_loss: 1.0563 - val_accuracy: 0.9128 - val_precision_13: 0.0296 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7998 - accuracy: 0.8302 - precision_13: 0.2976 - val_loss: 0.2411 - val_accuracy: 0.9341 - val_precision_13: 0.0363 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8548 - precision_13: 0.4712 - val_loss: 0.2420 - val_accuracy: 0.9518 - val_precision_13: 0.0514 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8576 - precision_13: 0.5238 - val_loss: 0.2544 - val_accuracy: 0.9311 - val_precision_13: 0.0262 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8579 - precision_13: 0.5289 - val_loss: 0.2791 - val_accuracy: 0.9224 - val_precision_13: 0.0372 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.8336 - precision_13: 0.3207 - val_loss: 0.2893 - val_accuracy: 0.9149 - val_precision_13: 0.0414 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.0452 - accuracy: 0.8072 - precision_13: 0.2367 - val_loss: 0.4927 - val_accuracy: 0.9651 - val_precision_13: 0.0735 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9661 - accuracy: 0.8286 - precision_13: 0.2730 - val_loss: 0.2467 - val_accuracy: 0.9596 - val_precision_13: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.8437 - precision_13: 0.3457 - val_loss: 0.2259 - val_accuracy: 0.9568 - val_precision_13: 0.0250 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8577 - precision_13: 0.5304 - val_loss: 0.2772 - val_accuracy: 0.9307 - val_precision_13: 0.0380 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8597 - precision_13: 0.5771 - val_loss: 0.2385 - val_accuracy: 0.9485 - val_precision_13: 0.0617 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8618 - precision_13: 0.6303 - val_loss: 0.2361 - val_accuracy: 0.9476 - val_precision_13: 0.0342 - lr: 5.0000e-04\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.3677 - accuracy: 0.8618 - precision_13: 0.6322 - val_loss: 0.2585 - val_accuracy: 0.9380 - val_precision_13: 0.0382 - lr: 5.0000e-04\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8625 - precision_13: 0.6436 - val_loss: 0.2875 - val_accuracy: 0.9186 - val_precision_13: 0.0349 - lr: 5.0000e-04\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8619 - precision_13: 0.6220 - val_loss: 0.2677 - val_accuracy: 0.9181 - val_precision_13: 0.0380 - lr: 5.0000e-04\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3650 - accuracy: 0.8617 - precision_13: 0.6158 - val_loss: 0.2568 - val_accuracy: 0.9280 - val_precision_13: 0.0345 - lr: 5.0000e-04\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8625 - precision_13: 0.6347 - val_loss: 0.2885 - val_accuracy: 0.9087 - val_precision_13: 0.0309 - lr: 5.0000e-04\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8623 - precision_13: 0.6310 - val_loss: 0.3014 - val_accuracy: 0.9225 - val_precision_13: 0.0323 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.8626 - precision_13: 0.6310 - val_loss: 0.2644 - val_accuracy: 0.9256 - val_precision_13: 0.0316 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8634 - precision_13: 0.6450 - val_loss: 0.2454 - val_accuracy: 0.9395 - val_precision_13: 0.0398 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8631 - precision_13: 0.6478 - val_loss: 0.2978 - val_accuracy: 0.9202 - val_precision_13: 0.0563 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 971.8188 - accuracy: 0.7316 - precision_14: 0.1432 - val_loss: 9.2554 - val_accuracy: 0.8727 - val_precision_14: 0.0176 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 44.0362 - accuracy: 0.7633 - precision_14: 0.1652 - val_loss: 20.5284 - val_accuracy: 0.9667 - val_precision_14: 0.0103 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.2477 - accuracy: 0.7721 - precision_14: 0.1819 - val_loss: 11.2622 - val_accuracy: 0.8152 - val_precision_14: 0.0313 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 37.9608 - accuracy: 0.7779 - precision_14: 0.1905 - val_loss: 9.6276 - val_accuracy: 0.9454 - val_precision_14: 0.0102 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.2836 - accuracy: 0.7789 - precision_14: 0.1976 - val_loss: 10.6581 - val_accuracy: 0.8725 - val_precision_14: 0.0196 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.7302 - accuracy: 0.7830 - precision_14: 0.2009 - val_loss: 11.3599 - val_accuracy: 0.8239 - val_precision_14: 0.0134 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.9449 - accuracy: 0.7857 - precision_14: 0.2102 - val_loss: 12.6795 - val_accuracy: 0.4973 - val_precision_14: 0.0241 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.5509 - accuracy: 0.7795 - precision_14: 0.2030 - val_loss: 6.2746 - val_accuracy: 0.8687 - val_precision_14: 0.0221 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.9524 - accuracy: 0.7793 - precision_14: 0.2054 - val_loss: 4.4577 - val_accuracy: 0.8458 - val_precision_14: 0.0183 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.8805 - accuracy: 0.7913 - precision_14: 0.2255 - val_loss: 11.9875 - val_accuracy: 0.6641 - val_precision_14: 0.0161 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 36.4139 - accuracy: 0.7784 - precision_14: 0.2015 - val_loss: 16.9343 - val_accuracy: 0.9625 - val_precision_14: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.9379 - accuracy: 0.7815 - precision_14: 0.2102 - val_loss: 4.7201 - val_accuracy: 0.8812 - val_precision_14: 0.0199 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 39.1756 - accuracy: 0.7775 - precision_14: 0.2018 - val_loss: 4.5217 - val_accuracy: 0.9265 - val_precision_14: 0.0280 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.8929 - accuracy: 0.7948 - precision_14: 0.2265 - val_loss: 10.6666 - val_accuracy: 0.9396 - val_precision_14: 0.0247 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.5588 - accuracy: 0.7924 - precision_14: 0.2289 - val_loss: 5.7057 - val_accuracy: 0.9555 - val_precision_14: 0.0119 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.5351 - accuracy: 0.7968 - precision_14: 0.2291 - val_loss: 4.6686 - val_accuracy: 0.9368 - val_precision_14: 0.0079 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.0691 - accuracy: 0.7916 - precision_14: 0.2145 - val_loss: 10.7062 - val_accuracy: 0.7948 - val_precision_14: 0.0224 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.3901 - accuracy: 0.7937 - precision_14: 0.2284 - val_loss: 2.2244 - val_accuracy: 0.9026 - val_precision_14: 0.0111 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.3122 - accuracy: 0.7974 - precision_14: 0.2279 - val_loss: 2.5869 - val_accuracy: 0.8286 - val_precision_14: 0.0260 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.2031 - accuracy: 0.7933 - precision_14: 0.2205 - val_loss: 23.7699 - val_accuracy: 0.4409 - val_precision_14: 0.0378 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.3664 - accuracy: 0.7963 - precision_14: 0.2344 - val_loss: 3.3501 - val_accuracy: 0.9311 - val_precision_14: 0.0215 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.3019 - accuracy: 0.8012 - precision_14: 0.2364 - val_loss: 17.0946 - val_accuracy: 0.5156 - val_precision_14: 0.0410 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.3816 - accuracy: 0.7964 - precision_14: 0.2305 - val_loss: 16.0301 - val_accuracy: 0.9249 - val_precision_14: 0.0271 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.8033 - accuracy: 0.7917 - precision_14: 0.2222 - val_loss: 1.3050 - val_accuracy: 0.8865 - val_precision_14: 0.0353 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.4314 - accuracy: 0.7915 - precision_14: 0.2085 - val_loss: 1.6624 - val_accuracy: 0.8906 - val_precision_14: 0.0179 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.7886 - accuracy: 0.7977 - precision_14: 0.2140 - val_loss: 1.3901 - val_accuracy: 0.8354 - val_precision_14: 0.0267 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.2395 - accuracy: 0.7970 - precision_14: 0.2165 - val_loss: 2.9947 - val_accuracy: 0.9572 - val_precision_14: 0.0088 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.5148 - accuracy: 0.8018 - precision_14: 0.2294 - val_loss: 1.7990 - val_accuracy: 0.9231 - val_precision_14: 0.0043 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.6374 - accuracy: 0.7997 - precision_14: 0.2155 - val_loss: 1.0892 - val_accuracy: 0.8817 - val_precision_14: 0.0133 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.7835 - accuracy: 0.7990 - precision_14: 0.2136 - val_loss: 1.3632 - val_accuracy: 0.9186 - val_precision_14: 0.0066 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.3619 - accuracy: 0.8016 - precision_14: 0.2237 - val_loss: 1.7409 - val_accuracy: 0.8836 - val_precision_14: 0.0181 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.5200 - accuracy: 0.8014 - precision_14: 0.2169 - val_loss: 1.9514 - val_accuracy: 0.9430 - val_precision_14: 0.0048 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.3226 - accuracy: 0.8025 - precision_14: 0.2193 - val_loss: 11.8253 - val_accuracy: 0.5186 - val_precision_14: 0.0406 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.3238 - accuracy: 0.8009 - precision_14: 0.2214 - val_loss: 2.0051 - val_accuracy: 0.9324 - val_precision_14: 0.0139 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.0704 - accuracy: 0.8054 - precision_14: 0.2289 - val_loss: 1.2406 - val_accuracy: 0.8925 - val_precision_14: 0.0089 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.5742 - accuracy: 0.8058 - precision_14: 0.2240 - val_loss: 1.0424 - val_accuracy: 0.8673 - val_precision_14: 0.0161 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 3.4815 - accuracy: 0.8024 - precision_14: 0.2206 - val_loss: 0.6962 - val_accuracy: 0.9217 - val_precision_14: 0.0416 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.8610 - accuracy: 0.8067 - precision_14: 0.2281 - val_loss: 0.5471 - val_accuracy: 0.9088 - val_precision_14: 0.0196 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 1.9920 - accuracy: 0.8081 - precision_14: 0.2338 - val_loss: 0.9526 - val_accuracy: 0.9449 - val_precision_14: 0.0051 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.4031 - accuracy: 0.8077 - precision_14: 0.2369 - val_loss: 0.7340 - val_accuracy: 0.9044 - val_precision_14: 0.0094 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.7675 - accuracy: 0.8096 - precision_14: 0.2305 - val_loss: 0.4666 - val_accuracy: 0.8919 - val_precision_14: 0.0182 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.8276 - accuracy: 0.8096 - precision_14: 0.2385 - val_loss: 0.7220 - val_accuracy: 0.9192 - val_precision_14: 0.0182 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4791 - accuracy: 0.8137 - precision_14: 0.2449 - val_loss: 2.0231 - val_accuracy: 0.6211 - val_precision_14: 0.0481 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.3468 - accuracy: 0.8136 - precision_14: 0.2454 - val_loss: 0.4090 - val_accuracy: 0.9174 - val_precision_14: 0.0115 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4953 - accuracy: 0.8115 - precision_14: 0.2317 - val_loss: 0.7766 - val_accuracy: 0.9586 - val_precision_14: 0.0049 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.6018 - accuracy: 0.8116 - precision_14: 0.2365 - val_loss: 0.5240 - val_accuracy: 0.9235 - val_precision_14: 0.0303 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.2010 - accuracy: 0.8153 - precision_14: 0.2415 - val_loss: 1.0056 - val_accuracy: 0.6935 - val_precision_14: 0.0456 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7888 - accuracy: 0.8199 - precision_14: 0.2459 - val_loss: 0.4304 - val_accuracy: 0.8980 - val_precision_14: 0.0250 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9833 - accuracy: 0.8172 - precision_14: 0.2362 - val_loss: 0.3396 - val_accuracy: 0.9193 - val_precision_14: 0.0269 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.8189 - precision_14: 0.2420 - val_loss: 0.4545 - val_accuracy: 0.9279 - val_precision_14: 0.0467 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.8287 - precision_14: 0.2631 - val_loss: 0.2888 - val_accuracy: 0.9597 - val_precision_14: 0.0837 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7498 - accuracy: 0.8247 - precision_14: 0.2584 - val_loss: 0.2884 - val_accuracy: 0.9297 - val_precision_14: 0.0443 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.8232 - precision_14: 0.2526 - val_loss: 0.2479 - val_accuracy: 0.9617 - val_precision_14: 0.1106 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7198 - accuracy: 0.8219 - precision_14: 0.2492 - val_loss: 0.3056 - val_accuracy: 0.9238 - val_precision_14: 0.0407 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8065 - accuracy: 0.8196 - precision_14: 0.2443 - val_loss: 0.4145 - val_accuracy: 0.9005 - val_precision_14: 0.0514 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.8278 - precision_14: 0.2560 - val_loss: 0.2415 - val_accuracy: 0.9657 - val_precision_14: 0.1197 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.8313 - precision_14: 0.2767 - val_loss: 0.2488 - val_accuracy: 0.9609 - val_precision_14: 0.0939 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.8315 - precision_14: 0.2738 - val_loss: 0.2393 - val_accuracy: 0.9603 - val_precision_14: 0.0708 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.8264 - precision_14: 0.2704 - val_loss: 0.4224 - val_accuracy: 0.9642 - val_precision_14: 0.1098 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.9955 - accuracy: 0.8077 - precision_14: 0.2150 - val_loss: 0.8399 - val_accuracy: 0.9674 - val_precision_14: 0.0330 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.5523 - accuracy: 0.8097 - precision_14: 0.1797 - val_loss: 0.2715 - val_accuracy: 0.9681 - val_precision_14: 0.0968 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.5783 - accuracy: 0.8354 - precision_14: 0.2137 - val_loss: 1.4979 - val_accuracy: 0.6385 - val_precision_14: 0.0504 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6941 - accuracy: 0.8205 - precision_14: 0.1783 - val_loss: 0.4667 - val_accuracy: 0.9196 - val_precision_14: 0.0610 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9389 - accuracy: 0.8197 - precision_14: 0.1926 - val_loss: 0.2331 - val_accuracy: 0.9719 - val_precision_14: 0.3182 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.8160 - accuracy: 0.8255 - precision_14: 0.2018 - val_loss: 0.6040 - val_accuracy: 0.9678 - val_precision_14: 0.0238 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0323 - accuracy: 0.8273 - precision_14: 0.1970 - val_loss: 0.2585 - val_accuracy: 0.9590 - val_precision_14: 0.0655 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8436 - precision_14: 0.2971 - val_loss: 0.2828 - val_accuracy: 0.9455 - val_precision_14: 0.0318 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0112 - accuracy: 0.8155 - precision_14: 0.2190 - val_loss: 0.3712 - val_accuracy: 0.9734 - val_precision_14: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 31.1344 - accuracy: 0.7912 - precision_14: 0.1679 - val_loss: 13.3368 - val_accuracy: 0.9296 - val_precision_14: 0.0208 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 2.3806 - accuracy: 0.8062 - precision_14: 0.1651 - val_loss: 0.4008 - val_accuracy: 0.9235 - val_precision_14: 0.0465 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.8437 - precision_14: 0.2014 - val_loss: 0.3234 - val_accuracy: 0.9431 - val_precision_14: 0.0399 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9811 - accuracy: 0.8199 - precision_14: 0.1781 - val_loss: 0.3056 - val_accuracy: 0.9714 - val_precision_14: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.8502 - precision_14: 0.1853 - val_loss: 0.2595 - val_accuracy: 0.9707 - val_precision_14: 0.0238 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8528 - precision_14: 0.1763 - val_loss: 0.2433 - val_accuracy: 0.9706 - val_precision_14: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8540 - precision_14: 0.1810 - val_loss: 0.2523 - val_accuracy: 0.9718 - val_precision_14: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.8432 - precision_14: 0.1847 - val_loss: 0.2408 - val_accuracy: 0.9722 - val_precision_14: 0.0455 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8550 - precision_14: 0.2083 - val_loss: 0.3087 - val_accuracy: 0.9711 - val_precision_14: 0.1569 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8479 - precision_14: 0.2038 - val_loss: 0.2684 - val_accuracy: 0.9728 - val_precision_14: 0.2857 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8538 - precision_14: 0.2008 - val_loss: 0.2366 - val_accuracy: 0.9711 - val_precision_14: 0.1964 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8550 - precision_14: 0.2751 - val_loss: 0.2050 - val_accuracy: 0.9732 - val_precision_14: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8534 - precision_14: 0.2369 - val_loss: 0.2899 - val_accuracy: 0.9605 - val_precision_14: 0.0591 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8555 - precision_14: 0.3187 - val_loss: 0.3086 - val_accuracy: 0.9522 - val_precision_14: 0.0495 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8532 - precision_14: 0.2500 - val_loss: 0.2170 - val_accuracy: 0.9711 - val_precision_14: 0.1136 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.9418 - accuracy: 0.8308 - precision_14: 0.1878 - val_loss: 3.1515 - val_accuracy: 0.9547 - val_precision_14: 0.0150 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0284 - accuracy: 0.8456 - precision_14: 0.1771 - val_loss: 0.2633 - val_accuracy: 0.9698 - val_precision_14: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8560 - precision_14: 0.1053 - val_loss: 0.2353 - val_accuracy: 0.9722 - val_precision_14: 0.0455 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8561 - precision_14: 0.3762 - val_loss: 0.2709 - val_accuracy: 0.9462 - val_precision_14: 0.0053 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8564 - precision_14: 0.4780 - val_loss: 0.2830 - val_accuracy: 0.9351 - val_precision_14: 0.0094 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8566 - precision_14: 0.5022 - val_loss: 0.2543 - val_accuracy: 0.9480 - val_precision_14: 0.0057 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.3806 - accuracy: 0.8571 - precision_14: 0.5625 - val_loss: 0.2387 - val_accuracy: 0.9560 - val_precision_14: 0.0276 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8568 - precision_14: 0.5242 - val_loss: 0.2704 - val_accuracy: 0.9386 - val_precision_14: 0.0296 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8564 - precision_14: 0.4879 - val_loss: 0.2732 - val_accuracy: 0.9264 - val_precision_14: 0.0136 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8568 - precision_14: 0.5217 - val_loss: 0.2310 - val_accuracy: 0.9558 - val_precision_14: 0.0485 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8568 - precision_14: 0.5277 - val_loss: 0.2709 - val_accuracy: 0.9404 - val_precision_14: 0.0292 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8568 - precision_14: 0.5195 - val_loss: 0.2777 - val_accuracy: 0.9340 - val_precision_14: 0.0144 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.8570 - precision_14: 0.5314 - val_loss: 0.2663 - val_accuracy: 0.9440 - val_precision_14: 0.0303 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8567 - precision_14: 0.5094 - val_loss: 0.2939 - val_accuracy: 0.9265 - val_precision_14: 0.0166 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8567 - precision_14: 0.5111 - val_loss: 0.2744 - val_accuracy: 0.9413 - val_precision_14: 0.0280 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8571 - precision_14: 0.5419 - val_loss: 0.2867 - val_accuracy: 0.9336 - val_precision_14: 0.0261 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8571 - precision_14: 0.5460 - val_loss: 0.2941 - val_accuracy: 0.9341 - val_precision_14: 0.0162 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 266.3378 - accuracy: 0.7437 - precision_15: 0.1513 - val_loss: 22.3289 - val_accuracy: 0.9499 - val_precision_15: 0.0208 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 130.7816 - accuracy: 0.7664 - precision_15: 0.1768 - val_loss: 56.3423 - val_accuracy: 0.9698 - val_precision_15: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 149.2258 - accuracy: 0.7663 - precision_15: 0.1792 - val_loss: 23.3430 - val_accuracy: 0.9607 - val_precision_15: 0.0111 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 127.8721 - accuracy: 0.7712 - precision_15: 0.1957 - val_loss: 113.8027 - val_accuracy: 0.9726 - val_precision_15: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 90.3222 - accuracy: 0.7783 - precision_15: 0.2135 - val_loss: 49.8013 - val_accuracy: 0.7904 - val_precision_15: 0.0189 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 95.8437 - accuracy: 0.7748 - precision_15: 0.2085 - val_loss: 15.0798 - val_accuracy: 0.7977 - val_precision_15: 0.0204 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 139.1045 - accuracy: 0.7770 - precision_15: 0.2065 - val_loss: 31.9087 - val_accuracy: 0.7285 - val_precision_15: 0.0185 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 68.8465 - accuracy: 0.7807 - precision_15: 0.2175 - val_loss: 20.7672 - val_accuracy: 0.9147 - val_precision_15: 0.0133 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 73.0473 - accuracy: 0.7859 - precision_15: 0.2237 - val_loss: 52.7278 - val_accuracy: 0.6119 - val_precision_15: 0.0409 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 45.7030 - accuracy: 0.7849 - precision_15: 0.2270 - val_loss: 11.5430 - val_accuracy: 0.8622 - val_precision_15: 0.0160 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 41.1885 - accuracy: 0.7871 - precision_15: 0.2313 - val_loss: 13.2266 - val_accuracy: 0.8185 - val_precision_15: 0.0191 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 49.7699 - accuracy: 0.7830 - precision_15: 0.2186 - val_loss: 8.7827 - val_accuracy: 0.7654 - val_precision_15: 0.0190 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 38.8319 - accuracy: 0.7843 - precision_15: 0.2225 - val_loss: 13.6753 - val_accuracy: 0.9499 - val_precision_15: 0.0031 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 48.6448 - accuracy: 0.7868 - precision_15: 0.2211 - val_loss: 97.4706 - val_accuracy: 0.4146 - val_precision_15: 0.0366 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.0252 - accuracy: 0.7825 - precision_15: 0.2201 - val_loss: 13.5975 - val_accuracy: 0.8526 - val_precision_15: 0.0181 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 56.5990 - accuracy: 0.7804 - precision_15: 0.2097 - val_loss: 14.0382 - val_accuracy: 0.8909 - val_precision_15: 0.0027 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 61.3064 - accuracy: 0.7859 - precision_15: 0.2257 - val_loss: 8.0668 - val_accuracy: 0.8474 - val_precision_15: 0.0174 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.8036 - accuracy: 0.7873 - precision_15: 0.2216 - val_loss: 6.3329 - val_accuracy: 0.7066 - val_precision_15: 0.0254 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.8013 - accuracy: 0.7892 - precision_15: 0.2250 - val_loss: 12.2456 - val_accuracy: 0.6763 - val_precision_15: 0.0450 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.3915 - accuracy: 0.7926 - precision_15: 0.2360 - val_loss: 6.1118 - val_accuracy: 0.9175 - val_precision_15: 0.0077 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 32.3140 - accuracy: 0.7886 - precision_15: 0.2251 - val_loss: 10.8218 - val_accuracy: 0.9434 - val_precision_15: 0.0072 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.5884 - accuracy: 0.7948 - precision_15: 0.2317 - val_loss: 15.3163 - val_accuracy: 0.8929 - val_precision_15: 0.0124 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 38.0398 - accuracy: 0.7886 - precision_15: 0.2223 - val_loss: 22.7440 - val_accuracy: 0.9439 - val_precision_15: 0.0073 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 46.5182 - accuracy: 0.7883 - precision_15: 0.2190 - val_loss: 8.7721 - val_accuracy: 0.7877 - val_precision_15: 0.0208 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.4469 - accuracy: 0.7919 - precision_15: 0.2326 - val_loss: 8.1106 - val_accuracy: 0.9406 - val_precision_15: 0.0087 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 25.9416 - accuracy: 0.7945 - precision_15: 0.2205 - val_loss: 54.8546 - val_accuracy: 0.4709 - val_precision_15: 0.0379 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.0161 - accuracy: 0.7940 - precision_15: 0.2307 - val_loss: 4.9577 - val_accuracy: 0.8176 - val_precision_15: 0.0203 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.5805 - accuracy: 0.8033 - precision_15: 0.2584 - val_loss: 24.9955 - val_accuracy: 0.3891 - val_precision_15: 0.0333 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 20.4068 - accuracy: 0.7965 - precision_15: 0.2359 - val_loss: 5.3612 - val_accuracy: 0.8526 - val_precision_15: 0.0142 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.1173 - accuracy: 0.7976 - precision_15: 0.2353 - val_loss: 5.0101 - val_accuracy: 0.8775 - val_precision_15: 0.0191 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.7117 - accuracy: 0.8014 - precision_15: 0.2442 - val_loss: 21.3295 - val_accuracy: 0.5482 - val_precision_15: 0.0376 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.0549 - accuracy: 0.7950 - precision_15: 0.2355 - val_loss: 25.3273 - val_accuracy: 0.5256 - val_precision_15: 0.0396 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 17.9646 - accuracy: 0.8007 - precision_15: 0.2427 - val_loss: 7.9797 - val_accuracy: 0.9308 - val_precision_15: 0.0166 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 22.2787 - accuracy: 0.7979 - precision_15: 0.2363 - val_loss: 8.0930 - val_accuracy: 0.9082 - val_precision_15: 0.0131 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.7180 - accuracy: 0.8011 - precision_15: 0.2341 - val_loss: 6.4794 - val_accuracy: 0.9299 - val_precision_15: 0.0050 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 14.7742 - accuracy: 0.8046 - precision_15: 0.2503 - val_loss: 4.5531 - val_accuracy: 0.8833 - val_precision_15: 0.0173 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 22.9807 - accuracy: 0.7986 - precision_15: 0.2339 - val_loss: 4.1114 - val_accuracy: 0.7756 - val_precision_15: 0.0172 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.3792 - accuracy: 0.8028 - precision_15: 0.2476 - val_loss: 5.0812 - val_accuracy: 0.6965 - val_precision_15: 0.0369 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.2188 - accuracy: 0.8025 - precision_15: 0.2477 - val_loss: 2.0942 - val_accuracy: 0.8623 - val_precision_15: 0.0203 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.6558 - accuracy: 0.8056 - precision_15: 0.2510 - val_loss: 18.2387 - val_accuracy: 0.5388 - val_precision_15: 0.0423 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.8125 - accuracy: 0.8039 - precision_15: 0.2465 - val_loss: 2.8315 - val_accuracy: 0.7399 - val_precision_15: 0.0299 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.9228 - accuracy: 0.8040 - precision_15: 0.2495 - val_loss: 3.0161 - val_accuracy: 0.9317 - val_precision_15: 0.0120 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.5382 - accuracy: 0.7986 - precision_15: 0.2246 - val_loss: 5.3880 - val_accuracy: 0.7436 - val_precision_15: 0.0337 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.3147 - accuracy: 0.8069 - precision_15: 0.2495 - val_loss: 3.7638 - val_accuracy: 0.9254 - val_precision_15: 0.0148 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.8592 - accuracy: 0.8027 - precision_15: 0.2353 - val_loss: 14.6288 - val_accuracy: 0.5189 - val_precision_15: 0.0408 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.9841 - accuracy: 0.8045 - precision_15: 0.2463 - val_loss: 11.4044 - val_accuracy: 0.5395 - val_precision_15: 0.0396 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.6898 - accuracy: 0.8044 - precision_15: 0.2497 - val_loss: 6.2816 - val_accuracy: 0.9498 - val_precision_15: 0.0371 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.8591 - accuracy: 0.7999 - precision_15: 0.2300 - val_loss: 2.6638 - val_accuracy: 0.8059 - val_precision_15: 0.0250 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.4247 - accuracy: 0.8061 - precision_15: 0.2458 - val_loss: 5.8307 - val_accuracy: 0.9420 - val_precision_15: 0.0023 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.4337 - accuracy: 0.8063 - precision_15: 0.2429 - val_loss: 2.7256 - val_accuracy: 0.8977 - val_precision_15: 0.0114 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.5260 - accuracy: 0.8045 - precision_15: 0.2407 - val_loss: 1.8447 - val_accuracy: 0.7898 - val_precision_15: 0.0163 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.9541 - accuracy: 0.8088 - precision_15: 0.2471 - val_loss: 2.8155 - val_accuracy: 0.8644 - val_precision_15: 0.0099 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.7777 - accuracy: 0.8076 - precision_15: 0.2560 - val_loss: 9.4445 - val_accuracy: 0.5982 - val_precision_15: 0.0435 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.9692 - accuracy: 0.8082 - precision_15: 0.2522 - val_loss: 1.3616 - val_accuracy: 0.8842 - val_precision_15: 0.0073 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.3862 - accuracy: 0.8078 - precision_15: 0.2563 - val_loss: 1.7683 - val_accuracy: 0.8853 - val_precision_15: 0.0106 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.6044 - accuracy: 0.8081 - precision_15: 0.2538 - val_loss: 0.9586 - val_accuracy: 0.8800 - val_precision_15: 0.0145 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.2577 - accuracy: 0.8061 - precision_15: 0.2434 - val_loss: 8.3756 - val_accuracy: 0.5923 - val_precision_15: 0.0419 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 4.3795 - accuracy: 0.8058 - precision_15: 0.2474 - val_loss: 1.1783 - val_accuracy: 0.7918 - val_precision_15: 0.0391 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.2175 - accuracy: 0.8062 - precision_15: 0.2466 - val_loss: 1.1975 - val_accuracy: 0.8971 - val_precision_15: 0.0103 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.2227 - accuracy: 0.8092 - precision_15: 0.2527 - val_loss: 1.2032 - val_accuracy: 0.9050 - val_precision_15: 0.0074 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.7493 - accuracy: 0.8081 - precision_15: 0.2503 - val_loss: 0.7394 - val_accuracy: 0.9150 - val_precision_15: 0.0037 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 2.4123 - accuracy: 0.8107 - precision_15: 0.2599 - val_loss: 3.7411 - val_accuracy: 0.5804 - val_precision_15: 0.0390 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0208 - accuracy: 0.8092 - precision_15: 0.2544 - val_loss: 1.1001 - val_accuracy: 0.8973 - val_precision_15: 0.0221 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.1147 - accuracy: 0.8112 - precision_15: 0.2595 - val_loss: 0.4593 - val_accuracy: 0.8956 - val_precision_15: 0.0137 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0316 - accuracy: 0.8108 - precision_15: 0.2587 - val_loss: 0.7780 - val_accuracy: 0.9024 - val_precision_15: 0.0179 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0426 - accuracy: 0.8100 - precision_15: 0.2502 - val_loss: 0.6904 - val_accuracy: 0.7566 - val_precision_15: 0.0350 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.3426 - accuracy: 0.8138 - precision_15: 0.2615 - val_loss: 0.5841 - val_accuracy: 0.8781 - val_precision_15: 0.0164 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1740 - accuracy: 0.8182 - precision_15: 0.2828 - val_loss: 0.4310 - val_accuracy: 0.9060 - val_precision_15: 0.0054 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.2074 - accuracy: 0.8135 - precision_15: 0.2566 - val_loss: 0.4357 - val_accuracy: 0.8967 - val_precision_15: 0.0166 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8328 - accuracy: 0.8197 - precision_15: 0.2751 - val_loss: 0.5035 - val_accuracy: 0.8857 - val_precision_15: 0.0201 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4806 - accuracy: 0.8128 - precision_15: 0.2599 - val_loss: 1.5360 - val_accuracy: 0.6076 - val_precision_15: 0.0440 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8242 - accuracy: 0.8213 - precision_15: 0.2766 - val_loss: 0.7818 - val_accuracy: 0.7205 - val_precision_15: 0.0425 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9359 - accuracy: 0.8149 - precision_15: 0.2556 - val_loss: 0.4063 - val_accuracy: 0.8555 - val_precision_15: 0.0474 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1772 - accuracy: 0.8102 - precision_15: 0.2457 - val_loss: 0.5227 - val_accuracy: 0.9510 - val_precision_15: 0.0333 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 36.1570 - accuracy: 0.7831 - precision_15: 0.1923 - val_loss: 8.7069 - val_accuracy: 0.9609 - val_precision_15: 0.0374 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.3618 - accuracy: 0.7970 - precision_15: 0.1963 - val_loss: 1.9922 - val_accuracy: 0.8939 - val_precision_15: 0.0406 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.3845 - accuracy: 0.7996 - precision_15: 0.1977 - val_loss: 1.4874 - val_accuracy: 0.7949 - val_precision_15: 0.0456 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.4768 - accuracy: 0.7975 - precision_15: 0.1881 - val_loss: 1.3159 - val_accuracy: 0.9142 - val_precision_15: 0.0133 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1967 - accuracy: 0.8159 - precision_15: 0.1939 - val_loss: 0.4034 - val_accuracy: 0.8776 - val_precision_15: 0.0234 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9064 - accuracy: 0.8198 - precision_15: 0.2082 - val_loss: 0.3800 - val_accuracy: 0.8749 - val_precision_15: 0.0207 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.8323 - precision_15: 0.2311 - val_loss: 0.3112 - val_accuracy: 0.9271 - val_precision_15: 0.0047 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8417 - precision_15: 0.2660 - val_loss: 0.3003 - val_accuracy: 0.9411 - val_precision_15: 0.0433 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8437 - precision_15: 0.2753 - val_loss: 0.3127 - val_accuracy: 0.9543 - val_precision_15: 0.0112 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.8434 - precision_15: 0.2768 - val_loss: 0.5691 - val_accuracy: 0.7584 - val_precision_15: 0.0620 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.8426 - precision_15: 0.2729 - val_loss: 0.3095 - val_accuracy: 0.9476 - val_precision_15: 0.0137 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8458 - precision_15: 0.3014 - val_loss: 0.2807 - val_accuracy: 0.9540 - val_precision_15: 0.0565 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8516 - precision_15: 0.3700 - val_loss: 0.2445 - val_accuracy: 0.9541 - val_precision_15: 0.0317 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.8424 - precision_15: 0.2807 - val_loss: 0.2546 - val_accuracy: 0.9440 - val_precision_15: 0.0121 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8506 - precision_15: 0.3618 - val_loss: 0.2474 - val_accuracy: 0.9583 - val_precision_15: 0.0140 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8501 - precision_15: 0.3608 - val_loss: 0.2844 - val_accuracy: 0.9259 - val_precision_15: 0.0620 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8506 - precision_15: 0.3771 - val_loss: 0.2999 - val_accuracy: 0.9504 - val_precision_15: 0.0707 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8494 - precision_15: 0.3543 - val_loss: 0.2173 - val_accuracy: 0.9530 - val_precision_15: 0.0035 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8506 - precision_15: 0.3670 - val_loss: 0.3032 - val_accuracy: 0.9434 - val_precision_15: 0.0523 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8500 - precision_15: 0.3662 - val_loss: 0.2792 - val_accuracy: 0.9306 - val_precision_15: 0.0436 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8540 - precision_15: 0.4290 - val_loss: 0.2478 - val_accuracy: 0.9431 - val_precision_15: 0.0685 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8471 - precision_15: 0.3494 - val_loss: 0.3351 - val_accuracy: 0.8953 - val_precision_15: 0.0250 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8520 - precision_15: 0.4009 - val_loss: 0.2616 - val_accuracy: 0.9403 - val_precision_15: 0.0405 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8519 - precision_15: 0.3953 - val_loss: 0.2015 - val_accuracy: 0.9600 - val_precision_15: 0.0053 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8443 - precision_15: 0.3266 - val_loss: 0.5671 - val_accuracy: 0.8486 - val_precision_15: 0.0455 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8477 - precision_15: 0.3506 - val_loss: 0.2700 - val_accuracy: 0.9227 - val_precision_15: 0.0447 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 1282.0422 - accuracy: 0.7142 - precision_16: 0.1457 - val_loss: 31.1809 - val_accuracy: 0.7878 - val_precision_16: 0.0460 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 72.5887 - accuracy: 0.7676 - precision_16: 0.1662 - val_loss: 95.3582 - val_accuracy: 0.4815 - val_precision_16: 0.0346 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 67.4134 - accuracy: 0.7760 - precision_16: 0.1740 - val_loss: 36.5264 - val_accuracy: 0.9586 - val_precision_16: 0.0048 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 69.1450 - accuracy: 0.7766 - precision_16: 0.1863 - val_loss: 12.8142 - val_accuracy: 0.9258 - val_precision_16: 0.0030 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 82.8081 - accuracy: 0.7795 - precision_16: 0.1869 - val_loss: 24.4889 - val_accuracy: 0.9640 - val_precision_16: 0.0075 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 46.9277 - accuracy: 0.7875 - precision_16: 0.1995 - val_loss: 19.9903 - val_accuracy: 0.9040 - val_precision_16: 0.0031 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 79.1744 - accuracy: 0.7845 - precision_16: 0.2004 - val_loss: 15.9430 - val_accuracy: 0.8566 - val_precision_16: 0.0170 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 37.1249 - accuracy: 0.7907 - precision_16: 0.2113 - val_loss: 59.3965 - val_accuracy: 0.6595 - val_precision_16: 0.0459 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 49.7534 - accuracy: 0.7851 - precision_16: 0.2062 - val_loss: 102.4062 - val_accuracy: 0.4184 - val_precision_16: 0.0342 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.7909 - accuracy: 0.7923 - precision_16: 0.2258 - val_loss: 7.6602 - val_accuracy: 0.7610 - val_precision_16: 0.0161 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 50.6432 - accuracy: 0.7883 - precision_16: 0.2077 - val_loss: 14.5535 - val_accuracy: 0.7323 - val_precision_16: 0.0179 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 51.7145 - accuracy: 0.7878 - precision_16: 0.2126 - val_loss: 40.2440 - val_accuracy: 0.5870 - val_precision_16: 0.0373 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 29.1040 - accuracy: 0.7963 - precision_16: 0.2235 - val_loss: 8.6691 - val_accuracy: 0.9026 - val_precision_16: 0.0061 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.2896 - accuracy: 0.7968 - precision_16: 0.2273 - val_loss: 25.7984 - val_accuracy: 0.6654 - val_precision_16: 0.0258 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.1577 - accuracy: 0.7978 - precision_16: 0.2278 - val_loss: 49.0405 - val_accuracy: 0.4663 - val_precision_16: 0.0359 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.9049 - accuracy: 0.7954 - precision_16: 0.2266 - val_loss: 9.7123 - val_accuracy: 0.9436 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.4363 - accuracy: 0.7969 - precision_16: 0.2245 - val_loss: 40.3153 - val_accuracy: 0.5034 - val_precision_16: 0.0385 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.7571 - accuracy: 0.7958 - precision_16: 0.2284 - val_loss: 12.4030 - val_accuracy: 0.8989 - val_precision_16: 0.0106 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 21.7268 - accuracy: 0.7987 - precision_16: 0.2378 - val_loss: 8.0969 - val_accuracy: 0.7989 - val_precision_16: 0.0202 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.1854 - accuracy: 0.8021 - precision_16: 0.2447 - val_loss: 11.9119 - val_accuracy: 0.6857 - val_precision_16: 0.0345 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 33.0402 - accuracy: 0.7954 - precision_16: 0.2249 - val_loss: 5.5963 - val_accuracy: 0.9011 - val_precision_16: 0.0040 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.3132 - accuracy: 0.8020 - precision_16: 0.2397 - val_loss: 20.2718 - val_accuracy: 0.6047 - val_precision_16: 0.0386 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.8044 - accuracy: 0.8023 - precision_16: 0.2405 - val_loss: 3.1384 - val_accuracy: 0.8656 - val_precision_16: 0.0145 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.2050 - accuracy: 0.8009 - precision_16: 0.2338 - val_loss: 3.7798 - val_accuracy: 0.8204 - val_precision_16: 0.0237 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.8659 - accuracy: 0.7966 - precision_16: 0.2213 - val_loss: 12.5795 - val_accuracy: 0.6357 - val_precision_16: 0.0367 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.5754 - accuracy: 0.7974 - precision_16: 0.2359 - val_loss: 9.9968 - val_accuracy: 0.9515 - val_precision_16: 0.0065 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.6379 - accuracy: 0.7992 - precision_16: 0.2336 - val_loss: 4.9958 - val_accuracy: 0.9416 - val_precision_16: 0.0112 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.2174 - accuracy: 0.8003 - precision_16: 0.2339 - val_loss: 4.8639 - val_accuracy: 0.8654 - val_precision_16: 0.0139 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.5319 - accuracy: 0.8023 - precision_16: 0.2291 - val_loss: 4.4194 - val_accuracy: 0.7882 - val_precision_16: 0.0312 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 16.8696 - accuracy: 0.7960 - precision_16: 0.2319 - val_loss: 2.9308 - val_accuracy: 0.9255 - val_precision_16: 0.0134 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 11.5040 - accuracy: 0.8031 - precision_16: 0.2338 - val_loss: 3.0050 - val_accuracy: 0.8957 - val_precision_16: 0.0102 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 11.6890 - accuracy: 0.8017 - precision_16: 0.2379 - val_loss: 3.4134 - val_accuracy: 0.7757 - val_precision_16: 0.0440 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 11.1427 - accuracy: 0.8040 - precision_16: 0.2432 - val_loss: 32.1898 - val_accuracy: 0.5041 - val_precision_16: 0.0390 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 11.3850 - accuracy: 0.8023 - precision_16: 0.2389 - val_loss: 34.9537 - val_accuracy: 0.4781 - val_precision_16: 0.0380 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.2792 - accuracy: 0.7999 - precision_16: 0.2306 - val_loss: 4.2425 - val_accuracy: 0.9166 - val_precision_16: 0.0051 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.5466 - accuracy: 0.8034 - precision_16: 0.2379 - val_loss: 2.8670 - val_accuracy: 0.8032 - val_precision_16: 0.0311 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.7769 - accuracy: 0.8037 - precision_16: 0.2435 - val_loss: 8.4585 - val_accuracy: 0.5485 - val_precision_16: 0.0359 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.3635 - accuracy: 0.8011 - precision_16: 0.2462 - val_loss: 2.5154 - val_accuracy: 0.8695 - val_precision_16: 0.0196 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.2675 - accuracy: 0.8055 - precision_16: 0.2430 - val_loss: 4.3058 - val_accuracy: 0.9082 - val_precision_16: 0.0066 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.5302 - accuracy: 0.8049 - precision_16: 0.2424 - val_loss: 1.6795 - val_accuracy: 0.8812 - val_precision_16: 0.0086 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.5193 - accuracy: 0.8064 - precision_16: 0.2483 - val_loss: 1.8877 - val_accuracy: 0.8908 - val_precision_16: 0.0138 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.8671 - accuracy: 0.8064 - precision_16: 0.2469 - val_loss: 2.1106 - val_accuracy: 0.8881 - val_precision_16: 0.0051 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.5219 - accuracy: 0.8055 - precision_16: 0.2428 - val_loss: 2.9854 - val_accuracy: 0.7292 - val_precision_16: 0.0334 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.6907 - accuracy: 0.8060 - precision_16: 0.2541 - val_loss: 1.2654 - val_accuracy: 0.8688 - val_precision_16: 0.0116 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.8868 - accuracy: 0.8105 - precision_16: 0.2657 - val_loss: 8.3311 - val_accuracy: 0.5298 - val_precision_16: 0.0384 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.8063 - accuracy: 0.8022 - precision_16: 0.2464 - val_loss: 2.8627 - val_accuracy: 0.6912 - val_precision_16: 0.0330 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.0727 - accuracy: 0.8097 - precision_16: 0.2602 - val_loss: 4.8278 - val_accuracy: 0.5403 - val_precision_16: 0.0388 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.3166 - accuracy: 0.8072 - precision_16: 0.2598 - val_loss: 1.4891 - val_accuracy: 0.9322 - val_precision_16: 0.0035 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.6576 - accuracy: 0.8093 - precision_16: 0.2700 - val_loss: 0.9827 - val_accuracy: 0.8400 - val_precision_16: 0.0123 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0929 - accuracy: 0.8124 - precision_16: 0.2745 - val_loss: 1.6260 - val_accuracy: 0.7024 - val_precision_16: 0.0453 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.5767 - accuracy: 0.8083 - precision_16: 0.2624 - val_loss: 0.9569 - val_accuracy: 0.8687 - val_precision_16: 0.0149 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.7979 - accuracy: 0.8145 - precision_16: 0.2801 - val_loss: 0.6434 - val_accuracy: 0.8606 - val_precision_16: 0.0139 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.3042 - accuracy: 0.8163 - precision_16: 0.2791 - val_loss: 0.7360 - val_accuracy: 0.7616 - val_precision_16: 0.0212 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0780 - accuracy: 0.8188 - precision_16: 0.2874 - val_loss: 0.5540 - val_accuracy: 0.7999 - val_precision_16: 0.0148 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.1399 - accuracy: 0.8158 - precision_16: 0.2768 - val_loss: 0.5393 - val_accuracy: 0.8623 - val_precision_16: 0.0160 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 1.0602 - accuracy: 0.8193 - precision_16: 0.2849 - val_loss: 0.9139 - val_accuracy: 0.7165 - val_precision_16: 0.0429 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.7820 - accuracy: 0.8246 - precision_16: 0.3086 - val_loss: 0.4410 - val_accuracy: 0.9054 - val_precision_16: 0.0011 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8282 - accuracy: 0.8224 - precision_16: 0.2851 - val_loss: 0.5272 - val_accuracy: 0.7866 - val_precision_16: 0.0408 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.6600 - accuracy: 0.8275 - precision_16: 0.3043 - val_loss: 0.6478 - val_accuracy: 0.7634 - val_precision_16: 0.0454 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.6648 - accuracy: 0.8274 - precision_16: 0.2986 - val_loss: 0.3983 - val_accuracy: 0.9296 - val_precision_16: 0.0017 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.8312 - precision_16: 0.3121 - val_loss: 0.3486 - val_accuracy: 0.8917 - val_precision_16: 0.0131 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.8279 - precision_16: 0.3003 - val_loss: 0.4043 - val_accuracy: 0.8755 - val_precision_16: 0.0201 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.8324 - precision_16: 0.3111 - val_loss: 0.2869 - val_accuracy: 0.9230 - val_precision_16: 0.0071 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.8401 - precision_16: 0.3403 - val_loss: 0.2954 - val_accuracy: 0.9208 - val_precision_16: 0.0443 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.8350 - precision_16: 0.3134 - val_loss: 0.5625 - val_accuracy: 0.7555 - val_precision_16: 0.0607 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.8434 - precision_16: 0.3583 - val_loss: 0.3268 - val_accuracy: 0.9167 - val_precision_16: 0.0292 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.8375 - precision_16: 0.3247 - val_loss: 0.3775 - val_accuracy: 0.8831 - val_precision_16: 0.0180 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7174 - accuracy: 0.8257 - precision_16: 0.2881 - val_loss: 0.5549 - val_accuracy: 0.7872 - val_precision_16: 0.0529 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.8389 - precision_16: 0.3371 - val_loss: 0.3511 - val_accuracy: 0.9104 - val_precision_16: 0.0305 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.8396 - precision_16: 0.3325 - val_loss: 0.2706 - val_accuracy: 0.9295 - val_precision_16: 0.0049 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.8337 - precision_16: 0.3187 - val_loss: 0.2447 - val_accuracy: 0.9436 - val_precision_16: 0.0024 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8297 - accuracy: 0.8223 - precision_16: 0.2751 - val_loss: 0.3984 - val_accuracy: 0.8818 - val_precision_16: 0.0294 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 23.0710 - accuracy: 0.7859 - precision_16: 0.1999 - val_loss: 3.8436 - val_accuracy: 0.9549 - val_precision_16: 0.0430 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.0993 - accuracy: 0.7951 - precision_16: 0.1800 - val_loss: 1.6544 - val_accuracy: 0.9675 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.1368 - accuracy: 0.8010 - precision_16: 0.1971 - val_loss: 1.3943 - val_accuracy: 0.9459 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0761 - accuracy: 0.8182 - precision_16: 0.2296 - val_loss: 0.2807 - val_accuracy: 0.9560 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.8297 - precision_16: 0.2523 - val_loss: 0.2708 - val_accuracy: 0.9530 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8383 - precision_16: 0.2922 - val_loss: 0.3821 - val_accuracy: 0.8683 - val_precision_16: 0.0596 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8499 - precision_16: 0.3597 - val_loss: 0.2146 - val_accuracy: 0.9652 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8449 - precision_16: 0.3221 - val_loss: 0.2412 - val_accuracy: 0.9580 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8510 - precision_16: 0.3724 - val_loss: 0.2604 - val_accuracy: 0.9450 - val_precision_16: 0.0173 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8502 - precision_16: 0.3781 - val_loss: 0.2708 - val_accuracy: 0.9416 - val_precision_16: 0.0068 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.3968 - accuracy: 0.8520 - precision_16: 0.3994 - val_loss: 0.3207 - val_accuracy: 0.9000 - val_precision_16: 0.0274 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.3904 - accuracy: 0.8536 - precision_16: 0.4253 - val_loss: 0.2124 - val_accuracy: 0.9621 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.3898 - accuracy: 0.8533 - precision_16: 0.4238 - val_loss: 0.2613 - val_accuracy: 0.9443 - val_precision_16: 0.0122 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8535 - precision_16: 0.4286 - val_loss: 0.2263 - val_accuracy: 0.9586 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8539 - precision_16: 0.4270 - val_loss: 0.2545 - val_accuracy: 0.9255 - val_precision_16: 0.0191 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8555 - precision_16: 0.4686 - val_loss: 0.2131 - val_accuracy: 0.9582 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8556 - precision_16: 0.4692 - val_loss: 0.2461 - val_accuracy: 0.9627 - val_precision_16: 0.0066 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8559 - precision_16: 0.4753 - val_loss: 0.2367 - val_accuracy: 0.9605 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8486 - precision_16: 0.3583 - val_loss: 0.3349 - val_accuracy: 0.8956 - val_precision_16: 0.0407 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8516 - precision_16: 0.4084 - val_loss: 0.2765 - val_accuracy: 0.9410 - val_precision_16: 0.0067 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8543 - precision_16: 0.4454 - val_loss: 0.2292 - val_accuracy: 0.9472 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8544 - precision_16: 0.4532 - val_loss: 0.5510 - val_accuracy: 0.8794 - val_precision_16: 0.0567 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 9.5585 - accuracy: 0.8119 - precision_16: 0.2320 - val_loss: 8.0259 - val_accuracy: 0.9703 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 16.0365 - accuracy: 0.7920 - precision_16: 0.1796 - val_loss: 1.8583 - val_accuracy: 0.6735 - val_precision_16: 0.0496 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7082 - accuracy: 0.8256 - precision_16: 0.2005 - val_loss: 0.2436 - val_accuracy: 0.9618 - val_precision_16: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.8419 - precision_16: 0.2228 - val_loss: 0.2490 - val_accuracy: 0.9513 - val_precision_16: 0.0280 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8479 - precision_16: 0.2616 - val_loss: 0.2424 - val_accuracy: 0.9505 - val_precision_16: 0.0299 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8491 - precision_16: 0.2834 - val_loss: 0.3028 - val_accuracy: 0.8957 - val_precision_16: 0.0182 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "109/109 [==============================] - 2s 6ms/step - loss: 129.3984 - accuracy: 0.7571 - precision_17: 0.1615 - val_loss: 33.0273 - val_accuracy: 0.9708 - val_precision_17: 0.0238 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 64.5815 - accuracy: 0.7735 - precision_17: 0.1944 - val_loss: 18.9253 - val_accuracy: 0.9324 - val_precision_17: 0.0285 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 56.9485 - accuracy: 0.7738 - precision_17: 0.2010 - val_loss: 35.2818 - val_accuracy: 0.7469 - val_precision_17: 0.0399 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 53.9988 - accuracy: 0.7729 - precision_17: 0.1996 - val_loss: 16.8464 - val_accuracy: 0.7582 - val_precision_17: 0.0215 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 54.9269 - accuracy: 0.7794 - precision_17: 0.1997 - val_loss: 19.8231 - val_accuracy: 0.7562 - val_precision_17: 0.0289 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 58.3294 - accuracy: 0.7769 - precision_17: 0.2035 - val_loss: 15.4445 - val_accuracy: 0.8469 - val_precision_17: 0.0157 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 63.2262 - accuracy: 0.7785 - precision_17: 0.2051 - val_loss: 11.8382 - val_accuracy: 0.8880 - val_precision_17: 0.0166 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 63.0565 - accuracy: 0.7794 - precision_17: 0.2056 - val_loss: 52.3079 - val_accuracy: 0.6722 - val_precision_17: 0.0482 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.3192 - accuracy: 0.7829 - precision_17: 0.2173 - val_loss: 23.3414 - val_accuracy: 0.9353 - val_precision_17: 0.0219 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.3699 - accuracy: 0.7916 - precision_17: 0.2293 - val_loss: 15.1690 - val_accuracy: 0.9518 - val_precision_17: 0.0033 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 34.2191 - accuracy: 0.7899 - precision_17: 0.2183 - val_loss: 33.5732 - val_accuracy: 0.5749 - val_precision_17: 0.0409 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 35.0802 - accuracy: 0.7932 - precision_17: 0.2291 - val_loss: 66.1480 - val_accuracy: 0.2587 - val_precision_17: 0.0307 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 41.7387 - accuracy: 0.7855 - precision_17: 0.2220 - val_loss: 7.8735 - val_accuracy: 0.9018 - val_precision_17: 0.0158 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 36.5996 - accuracy: 0.7896 - precision_17: 0.2293 - val_loss: 11.2512 - val_accuracy: 0.7720 - val_precision_17: 0.0186 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.6945 - accuracy: 0.7934 - precision_17: 0.2341 - val_loss: 11.7537 - val_accuracy: 0.9477 - val_precision_17: 0.0028 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.7740 - accuracy: 0.7988 - precision_17: 0.2429 - val_loss: 4.8872 - val_accuracy: 0.8239 - val_precision_17: 0.0157 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 37.4418 - accuracy: 0.7886 - precision_17: 0.2198 - val_loss: 14.7234 - val_accuracy: 0.8649 - val_precision_17: 0.0163 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 24.3896 - accuracy: 0.7958 - precision_17: 0.2347 - val_loss: 7.0759 - val_accuracy: 0.8710 - val_precision_17: 0.0199 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 21.9831 - accuracy: 0.8007 - precision_17: 0.2496 - val_loss: 5.7704 - val_accuracy: 0.7827 - val_precision_17: 0.0360 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 27.7621 - accuracy: 0.7911 - precision_17: 0.2273 - val_loss: 4.6479 - val_accuracy: 0.7420 - val_precision_17: 0.0259 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 19.2381 - accuracy: 0.7987 - precision_17: 0.2372 - val_loss: 15.4678 - val_accuracy: 0.8903 - val_precision_17: 0.0298 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 28.8208 - accuracy: 0.7972 - precision_17: 0.2305 - val_loss: 15.8209 - val_accuracy: 0.6142 - val_precision_17: 0.0430 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.7877 - accuracy: 0.8020 - precision_17: 0.2443 - val_loss: 6.9549 - val_accuracy: 0.8728 - val_precision_17: 0.0182 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 17.4089 - accuracy: 0.7993 - precision_17: 0.2420 - val_loss: 5.6094 - val_accuracy: 0.8920 - val_precision_17: 0.0097 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 18.8361 - accuracy: 0.8010 - precision_17: 0.2437 - val_loss: 6.7294 - val_accuracy: 0.9354 - val_precision_17: 0.0057 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 26.2382 - accuracy: 0.7968 - precision_17: 0.2307 - val_loss: 6.2768 - val_accuracy: 0.9503 - val_precision_17: 0.0031 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 17.6834 - accuracy: 0.8011 - precision_17: 0.2341 - val_loss: 5.4211 - val_accuracy: 0.9409 - val_precision_17: 0.0022 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 12.0460 - accuracy: 0.8022 - precision_17: 0.2406 - val_loss: 8.3685 - val_accuracy: 0.7082 - val_precision_17: 0.0471 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 12.7295 - accuracy: 0.7997 - precision_17: 0.2337 - val_loss: 4.9521 - val_accuracy: 0.8939 - val_precision_17: 0.0169 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 13.6654 - accuracy: 0.8009 - precision_17: 0.2407 - val_loss: 3.2724 - val_accuracy: 0.8842 - val_precision_17: 0.0120 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 10.2778 - accuracy: 0.8061 - precision_17: 0.2494 - val_loss: 3.6407 - val_accuracy: 0.7363 - val_precision_17: 0.0208 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 14.7225 - accuracy: 0.7933 - precision_17: 0.2273 - val_loss: 2.4635 - val_accuracy: 0.8721 - val_precision_17: 0.0234 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.8995 - accuracy: 0.8049 - precision_17: 0.2512 - val_loss: 2.4192 - val_accuracy: 0.8217 - val_precision_17: 0.0154 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.3284 - accuracy: 0.8039 - precision_17: 0.2582 - val_loss: 2.3363 - val_accuracy: 0.8159 - val_precision_17: 0.0184 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.8164 - accuracy: 0.8043 - precision_17: 0.2523 - val_loss: 4.3018 - val_accuracy: 0.9370 - val_precision_17: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.5707 - accuracy: 0.8036 - precision_17: 0.2462 - val_loss: 2.6208 - val_accuracy: 0.8583 - val_precision_17: 0.0196 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 5.9750 - accuracy: 0.8069 - precision_17: 0.2670 - val_loss: 3.7179 - val_accuracy: 0.9169 - val_precision_17: 0.0234 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 8.1025 - accuracy: 0.8049 - precision_17: 0.2548 - val_loss: 2.7971 - val_accuracy: 0.9296 - val_precision_17: 0.0082 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.0382 - accuracy: 0.8058 - precision_17: 0.2493 - val_loss: 2.5962 - val_accuracy: 0.7629 - val_precision_17: 0.0374 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.9999 - accuracy: 0.8050 - precision_17: 0.2543 - val_loss: 1.8448 - val_accuracy: 0.9202 - val_precision_17: 0.0260 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.6200 - accuracy: 0.8067 - precision_17: 0.2544 - val_loss: 1.6924 - val_accuracy: 0.7354 - val_precision_17: 0.0395 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.8324 - accuracy: 0.8046 - precision_17: 0.2587 - val_loss: 1.3188 - val_accuracy: 0.9287 - val_precision_17: 0.0112 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.5997 - accuracy: 0.8086 - precision_17: 0.2652 - val_loss: 1.2258 - val_accuracy: 0.7644 - val_precision_17: 0.0424 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.1356 - accuracy: 0.8098 - precision_17: 0.2695 - val_loss: 4.7683 - val_accuracy: 0.5542 - val_precision_17: 0.0370 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.4837 - accuracy: 0.8097 - precision_17: 0.2669 - val_loss: 1.0940 - val_accuracy: 0.9118 - val_precision_17: 0.0332 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.5679 - accuracy: 0.8099 - precision_17: 0.2658 - val_loss: 0.8168 - val_accuracy: 0.8465 - val_precision_17: 0.0242 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.2319 - accuracy: 0.8090 - precision_17: 0.2649 - val_loss: 0.6840 - val_accuracy: 0.8188 - val_precision_17: 0.0365 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0043 - accuracy: 0.8121 - precision_17: 0.2744 - val_loss: 0.5760 - val_accuracy: 0.8677 - val_precision_17: 0.0256 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.8157 - accuracy: 0.8105 - precision_17: 0.2733 - val_loss: 0.4746 - val_accuracy: 0.8788 - val_precision_17: 0.0229 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.3805 - accuracy: 0.8139 - precision_17: 0.2763 - val_loss: 0.5894 - val_accuracy: 0.8490 - val_precision_17: 0.0268 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.4587 - accuracy: 0.8115 - precision_17: 0.2665 - val_loss: 1.0219 - val_accuracy: 0.7149 - val_precision_17: 0.0351 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.2542 - accuracy: 0.8154 - precision_17: 0.2811 - val_loss: 0.5561 - val_accuracy: 0.8156 - val_precision_17: 0.0285 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 1.0251 - accuracy: 0.8136 - precision_17: 0.2709 - val_loss: 0.3923 - val_accuracy: 0.9170 - val_precision_17: 0.0163 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 1.0609 - accuracy: 0.8149 - precision_17: 0.2694 - val_loss: 0.3793 - val_accuracy: 0.8804 - val_precision_17: 0.0451 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.0189 - accuracy: 0.8147 - precision_17: 0.2680 - val_loss: 0.4507 - val_accuracy: 0.8833 - val_precision_17: 0.0417 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 1.0281 - accuracy: 0.8137 - precision_17: 0.2610 - val_loss: 0.5016 - val_accuracy: 0.8953 - val_precision_17: 0.0316 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.9378 - accuracy: 0.8129 - precision_17: 0.2559 - val_loss: 0.5231 - val_accuracy: 0.7794 - val_precision_17: 0.0278 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8907 - accuracy: 0.8195 - precision_17: 0.2764 - val_loss: 0.9014 - val_accuracy: 0.6801 - val_precision_17: 0.0453 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.8235 - precision_17: 0.2823 - val_loss: 0.3092 - val_accuracy: 0.9249 - val_precision_17: 0.0324 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.8257 - precision_17: 0.2832 - val_loss: 0.2256 - val_accuracy: 0.9545 - val_precision_17: 0.0075 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.8211 - precision_17: 0.2656 - val_loss: 0.3420 - val_accuracy: 0.9103 - val_precision_17: 0.0375 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 6.6130 - accuracy: 0.8127 - precision_17: 0.2432 - val_loss: 2.1849 - val_accuracy: 0.8934 - val_precision_17: 0.0276 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.6620 - accuracy: 0.8005 - precision_17: 0.2317 - val_loss: 0.6514 - val_accuracy: 0.7971 - val_precision_17: 0.0616 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.9860 - accuracy: 0.8124 - precision_17: 0.2517 - val_loss: 0.2948 - val_accuracy: 0.9333 - val_precision_17: 0.0307 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.7637 - accuracy: 0.8178 - precision_17: 0.2596 - val_loss: 0.2554 - val_accuracy: 0.9510 - val_precision_17: 0.0246 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.8229 - precision_17: 0.2675 - val_loss: 0.2632 - val_accuracy: 0.9429 - val_precision_17: 0.0396 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.8341 - precision_17: 0.2966 - val_loss: 0.4973 - val_accuracy: 0.7791 - val_precision_17: 0.0630 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.8388 - precision_17: 0.3265 - val_loss: 0.2597 - val_accuracy: 0.9264 - val_precision_17: 0.0439 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.8379 - precision_17: 0.3194 - val_loss: 0.2469 - val_accuracy: 0.9479 - val_precision_17: 0.0243 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.8393 - precision_17: 0.3228 - val_loss: 0.3164 - val_accuracy: 0.9263 - val_precision_17: 0.0373 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8501 - precision_17: 0.3980 - val_loss: 0.3065 - val_accuracy: 0.9315 - val_precision_17: 0.0543 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8477 - precision_17: 0.3833 - val_loss: 0.3713 - val_accuracy: 0.8761 - val_precision_17: 0.0330 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.8332 - precision_17: 0.3056 - val_loss: 0.2951 - val_accuracy: 0.9044 - val_precision_17: 0.0318 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.8433 - precision_17: 0.3539 - val_loss: 0.2569 - val_accuracy: 0.9297 - val_precision_17: 0.0469 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8432 - precision_17: 0.3542 - val_loss: 0.2723 - val_accuracy: 0.9371 - val_precision_17: 0.0553 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8450 - precision_17: 0.3638 - val_loss: 0.2532 - val_accuracy: 0.9277 - val_precision_17: 0.0396 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.3226 - accuracy: 0.8179 - precision_17: 0.2638 - val_loss: 0.2623 - val_accuracy: 0.9326 - val_precision_17: 0.0484 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.8327 - precision_17: 0.3119 - val_loss: 0.2954 - val_accuracy: 0.9016 - val_precision_17: 0.0385 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.8377 - precision_17: 0.3307 - val_loss: 0.2361 - val_accuracy: 0.9476 - val_precision_17: 0.0721 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8497 - precision_17: 0.4051 - val_loss: 0.2866 - val_accuracy: 0.9138 - val_precision_17: 0.0332 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8565 - precision_17: 0.4945 - val_loss: 0.2931 - val_accuracy: 0.9026 - val_precision_17: 0.0337 - lr: 5.0000e-04\n",
            "Epoch 82/100\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8589 - precision_17: 0.5408 - val_loss: 0.3160 - val_accuracy: 0.8904 - val_precision_17: 0.0306 - lr: 5.0000e-04\n",
            "Epoch 83/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8604 - precision_17: 0.5778 - val_loss: 0.3024 - val_accuracy: 0.8861 - val_precision_17: 0.0307 - lr: 5.0000e-04\n",
            "Epoch 84/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8583 - precision_17: 0.5260 - val_loss: 0.2845 - val_accuracy: 0.9319 - val_precision_17: 0.0534 - lr: 5.0000e-04\n",
            "Epoch 85/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8600 - precision_17: 0.5698 - val_loss: 0.2386 - val_accuracy: 0.9469 - val_precision_17: 0.0538 - lr: 5.0000e-04\n",
            "Epoch 86/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8576 - precision_17: 0.5130 - val_loss: 0.3027 - val_accuracy: 0.9123 - val_precision_17: 0.0386 - lr: 5.0000e-04\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8516 - precision_17: 0.4298 - val_loss: 0.2754 - val_accuracy: 0.9304 - val_precision_17: 0.0448 - lr: 5.0000e-04\n",
            "Epoch 88/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8588 - precision_17: 0.5378 - val_loss: 0.3530 - val_accuracy: 0.8900 - val_precision_17: 0.0336 - lr: 5.0000e-04\n",
            "Epoch 89/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8593 - precision_17: 0.5468 - val_loss: 0.2304 - val_accuracy: 0.9404 - val_precision_17: 0.0515 - lr: 5.0000e-04\n",
            "Epoch 90/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8602 - precision_17: 0.5691 - val_loss: 0.2345 - val_accuracy: 0.9520 - val_precision_17: 0.0571 - lr: 5.0000e-04\n",
            "Epoch 91/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.8968 - accuracy: 0.8377 - precision_17: 0.3408 - val_loss: 0.4239 - val_accuracy: 0.8215 - val_precision_17: 0.0680 - lr: 5.0000e-04\n",
            "Epoch 92/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8561 - precision_17: 0.4878 - val_loss: 0.2415 - val_accuracy: 0.9443 - val_precision_17: 0.0304 - lr: 5.0000e-04\n",
            "Epoch 93/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8607 - precision_17: 0.5743 - val_loss: 0.3056 - val_accuracy: 0.8959 - val_precision_17: 0.0318 - lr: 5.0000e-04\n",
            "Epoch 94/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8561 - precision_17: 0.4885 - val_loss: 0.2838 - val_accuracy: 0.9136 - val_precision_17: 0.0394 - lr: 5.0000e-04\n",
            "Epoch 95/100\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 0.3780 - accuracy: 0.8581 - precision_17: 0.5206 - val_loss: 0.1859 - val_accuracy: 0.9550 - val_precision_17: 0.0261 - lr: 5.0000e-04\n",
            "Epoch 96/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8593 - precision_17: 0.5451 - val_loss: 0.2448 - val_accuracy: 0.9425 - val_precision_17: 0.0488 - lr: 5.0000e-04\n",
            "Epoch 97/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8585 - precision_17: 0.5264 - val_loss: 0.3354 - val_accuracy: 0.8956 - val_precision_17: 0.0333 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8587 - precision_17: 0.5301 - val_loss: 0.2923 - val_accuracy: 0.9061 - val_precision_17: 0.0344 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8590 - precision_17: 0.5343 - val_loss: 0.2885 - val_accuracy: 0.9077 - val_precision_17: 0.0380 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8499 - precision_17: 0.4231 - val_loss: 0.2740 - val_accuracy: 0.9340 - val_precision_17: 0.0423 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 303.3073 - accuracy: 0.7607 - precision_18: 0.1685 - val_loss: 53.5185 - val_accuracy: 0.8906 - val_precision_18: 0.0052 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 110.8468 - accuracy: 0.7702 - precision_18: 0.1857 - val_loss: 20.2142 - val_accuracy: 0.9441 - val_precision_18: 0.0073 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 109.7654 - accuracy: 0.7679 - precision_18: 0.1883 - val_loss: 19.5648 - val_accuracy: 0.9629 - val_precision_18: 0.0067 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 144.8818 - accuracy: 0.7731 - precision_18: 0.1874 - val_loss: 139.9777 - val_accuracy: 0.5080 - val_precision_18: 0.0136 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 99.4030 - accuracy: 0.7674 - precision_18: 0.1671 - val_loss: 24.7449 - val_accuracy: 0.8641 - val_precision_18: 0.0098 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 97.8717 - accuracy: 0.7873 - precision_18: 0.1951 - val_loss: 86.0741 - val_accuracy: 0.5927 - val_precision_18: 0.0428 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 130.1768 - accuracy: 0.7920 - precision_18: 0.2091 - val_loss: 20.9292 - val_accuracy: 0.9462 - val_precision_18: 0.0053 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 63.2374 - accuracy: 0.7930 - precision_18: 0.2130 - val_loss: 9.5940 - val_accuracy: 0.8661 - val_precision_18: 0.0133 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 76.2620 - accuracy: 0.7937 - precision_18: 0.2053 - val_loss: 10.3359 - val_accuracy: 0.8050 - val_precision_18: 0.0188 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 80.1135 - accuracy: 0.7948 - precision_18: 0.2165 - val_loss: 1447.3585 - val_accuracy: 0.1728 - val_precision_18: 0.0297 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 236.3618 - accuracy: 0.7703 - precision_18: 0.1853 - val_loss: 44.8240 - val_accuracy: 0.3798 - val_precision_18: 0.0274 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 52.9227 - accuracy: 0.7854 - precision_18: 0.1881 - val_loss: 22.1729 - val_accuracy: 0.9531 - val_precision_18: 0.0070 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 47.9726 - accuracy: 0.7979 - precision_18: 0.2068 - val_loss: 234.2559 - val_accuracy: 0.4879 - val_precision_18: 0.0360 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 79.2174 - accuracy: 0.7925 - precision_18: 0.1965 - val_loss: 23.8085 - val_accuracy: 0.9668 - val_precision_18: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 67.3845 - accuracy: 0.7980 - precision_18: 0.2046 - val_loss: 14.3795 - val_accuracy: 0.8815 - val_precision_18: 0.0055 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 49.5151 - accuracy: 0.7994 - precision_18: 0.2021 - val_loss: 37.1649 - val_accuracy: 0.5004 - val_precision_18: 0.0373 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 35.9250 - accuracy: 0.8008 - precision_18: 0.2086 - val_loss: 494.0591 - val_accuracy: 0.4799 - val_precision_18: 0.0365 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 112.6486 - accuracy: 0.7857 - precision_18: 0.1852 - val_loss: 1047.9944 - val_accuracy: 0.4812 - val_precision_18: 0.0376 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 235.9485 - accuracy: 0.7710 - precision_18: 0.1881 - val_loss: 7.5137 - val_accuracy: 0.9295 - val_precision_18: 0.0129 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.0797 - accuracy: 0.7976 - precision_18: 0.1978 - val_loss: 8.0805 - val_accuracy: 0.9248 - val_precision_18: 0.0174 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.2274 - accuracy: 0.8047 - precision_18: 0.2200 - val_loss: 27.5047 - val_accuracy: 0.6017 - val_precision_18: 0.0424 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.0609 - accuracy: 0.8029 - precision_18: 0.2207 - val_loss: 2.7352 - val_accuracy: 0.9030 - val_precision_18: 0.0161 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.1167 - accuracy: 0.8035 - precision_18: 0.2200 - val_loss: 40.5109 - val_accuracy: 0.9489 - val_precision_18: 0.0253 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 102.7441 - accuracy: 0.7935 - precision_18: 0.1950 - val_loss: 8.1189 - val_accuracy: 0.9511 - val_precision_18: 0.0217 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 15.8119 - accuracy: 0.7978 - precision_18: 0.2031 - val_loss: 6.2020 - val_accuracy: 0.9512 - val_precision_18: 0.0096 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.6863 - accuracy: 0.8000 - precision_18: 0.2059 - val_loss: 4.5448 - val_accuracy: 0.9439 - val_precision_18: 0.0189 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.2958 - accuracy: 0.7998 - precision_18: 0.2034 - val_loss: 4.5955 - val_accuracy: 0.9365 - val_precision_18: 0.0116 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.5573 - accuracy: 0.8027 - precision_18: 0.2201 - val_loss: 10.3247 - val_accuracy: 0.9171 - val_precision_18: 0.0151 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.6111 - accuracy: 0.8017 - precision_18: 0.2044 - val_loss: 4.0792 - val_accuracy: 0.8878 - val_precision_18: 0.0205 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.2672 - accuracy: 0.8025 - precision_18: 0.2199 - val_loss: 2.8012 - val_accuracy: 0.8930 - val_precision_18: 0.0234 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.7752 - accuracy: 0.8043 - precision_18: 0.2277 - val_loss: 6.9623 - val_accuracy: 0.7526 - val_precision_18: 0.0469 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.6347 - accuracy: 0.8039 - precision_18: 0.2240 - val_loss: 8.1271 - val_accuracy: 0.6771 - val_precision_18: 0.0363 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.6497 - accuracy: 0.8024 - precision_18: 0.2260 - val_loss: 7.7003 - val_accuracy: 0.9226 - val_precision_18: 0.0098 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 17.9503 - accuracy: 0.8020 - precision_18: 0.2217 - val_loss: 6.6080 - val_accuracy: 0.9570 - val_precision_18: 0.0043 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.6056 - accuracy: 0.8035 - precision_18: 0.2275 - val_loss: 2.3154 - val_accuracy: 0.8548 - val_precision_18: 0.0120 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.8408 - accuracy: 0.8032 - precision_18: 0.2273 - val_loss: 2.9301 - val_accuracy: 0.9391 - val_precision_18: 0.0021 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.3066 - accuracy: 0.7908 - precision_18: 0.2056 - val_loss: 3.7903 - val_accuracy: 0.9545 - val_precision_18: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.7428 - accuracy: 0.8027 - precision_18: 0.2326 - val_loss: 6.9716 - val_accuracy: 0.9585 - val_precision_18: 0.0095 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.8789 - accuracy: 0.8030 - precision_18: 0.2287 - val_loss: 9.1341 - val_accuracy: 0.9525 - val_precision_18: 0.0068 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.9306 - accuracy: 0.8067 - precision_18: 0.2393 - val_loss: 71.5865 - val_accuracy: 0.5669 - val_precision_18: 0.0406 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.6935 - accuracy: 0.8032 - precision_18: 0.2207 - val_loss: 6.4777 - val_accuracy: 0.9319 - val_precision_18: 0.0052 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.8474 - accuracy: 0.8021 - precision_18: 0.2133 - val_loss: 30.1620 - val_accuracy: 0.5914 - val_precision_18: 0.0432 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.4672 - accuracy: 0.8037 - precision_18: 0.2279 - val_loss: 6.3281 - val_accuracy: 0.9625 - val_precision_18: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.2627 - accuracy: 0.8033 - precision_18: 0.2246 - val_loss: 16.8124 - val_accuracy: 0.8644 - val_precision_18: 0.0249 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.4854 - accuracy: 0.8039 - precision_18: 0.2269 - val_loss: 4.3731 - val_accuracy: 0.9612 - val_precision_18: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.2311 - accuracy: 0.7996 - precision_18: 0.2067 - val_loss: 122.0978 - val_accuracy: 0.5002 - val_precision_18: 0.0377 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 26.5566 - accuracy: 0.7933 - precision_18: 0.2031 - val_loss: 2.5895 - val_accuracy: 0.4953 - val_precision_18: 0.0150 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.9836 - accuracy: 0.7960 - precision_18: 0.2064 - val_loss: 2.2151 - val_accuracy: 0.8644 - val_precision_18: 0.0112 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.0650 - accuracy: 0.8084 - precision_18: 0.2334 - val_loss: 1.8369 - val_accuracy: 0.8938 - val_precision_18: 0.0063 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.8076 - accuracy: 0.8048 - precision_18: 0.2278 - val_loss: 9.1489 - val_accuracy: 0.5788 - val_precision_18: 0.0136 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.5312 - accuracy: 0.7925 - precision_18: 0.1947 - val_loss: 5.1979 - val_accuracy: 0.9610 - val_precision_18: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.0970 - accuracy: 0.8035 - precision_18: 0.1976 - val_loss: 13.5294 - val_accuracy: 0.2403 - val_precision_18: 0.0299 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 7.2724 - accuracy: 0.7946 - precision_18: 0.2147 - val_loss: 7.5845 - val_accuracy: 0.9323 - val_precision_18: 0.0053 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.5571 - accuracy: 0.8035 - precision_18: 0.2285 - val_loss: 4.8235 - val_accuracy: 0.9347 - val_precision_18: 0.0019 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.4742 - accuracy: 0.8063 - precision_18: 0.2208 - val_loss: 3.4462 - val_accuracy: 0.7546 - val_precision_18: 0.0221 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.3010 - accuracy: 0.7970 - precision_18: 0.2122 - val_loss: 5.8175 - val_accuracy: 0.9450 - val_precision_18: 0.0025 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.1327 - accuracy: 0.8089 - precision_18: 0.2247 - val_loss: 2.2647 - val_accuracy: 0.8994 - val_precision_18: 0.0116 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.7134 - accuracy: 0.8067 - precision_18: 0.2307 - val_loss: 7.1924 - val_accuracy: 0.9552 - val_precision_18: 0.0039 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.1816 - accuracy: 0.8047 - precision_18: 0.2012 - val_loss: 1.9071 - val_accuracy: 0.8106 - val_precision_18: 0.0228 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.7635 - accuracy: 0.8096 - precision_18: 0.2418 - val_loss: 4.3273 - val_accuracy: 0.6464 - val_precision_18: 0.0432 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.9422 - accuracy: 0.8077 - precision_18: 0.2304 - val_loss: 2.8082 - val_accuracy: 0.9430 - val_precision_18: 0.0094 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.7496 - accuracy: 0.8065 - precision_18: 0.2198 - val_loss: 2.9521 - val_accuracy: 0.9248 - val_precision_18: 0.0045 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.0812 - accuracy: 0.8061 - precision_18: 0.2174 - val_loss: 3.6183 - val_accuracy: 0.9380 - val_precision_18: 0.0081 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.6250 - accuracy: 0.8079 - precision_18: 0.2293 - val_loss: 4.1082 - val_accuracy: 0.4765 - val_precision_18: 0.0138 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.0542 - accuracy: 0.7915 - precision_18: 0.2362 - val_loss: 2.4771 - val_accuracy: 0.9382 - val_precision_18: 0.0081 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.5598 - accuracy: 0.8032 - precision_18: 0.2362 - val_loss: 19.5393 - val_accuracy: 0.2224 - val_precision_18: 0.0299 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.2990 - accuracy: 0.7914 - precision_18: 0.2147 - val_loss: 1.6859 - val_accuracy: 0.8243 - val_precision_18: 0.0115 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.7793 - accuracy: 0.8063 - precision_18: 0.2394 - val_loss: 1.8892 - val_accuracy: 0.8277 - val_precision_18: 0.0089 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.4186 - accuracy: 0.8077 - precision_18: 0.2384 - val_loss: 1.6076 - val_accuracy: 0.8926 - val_precision_18: 0.0045 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.5602 - accuracy: 0.8123 - precision_18: 0.2558 - val_loss: 2.0435 - val_accuracy: 0.9552 - val_precision_18: 0.0039 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.6313 - accuracy: 0.8072 - precision_18: 0.2210 - val_loss: 46.3170 - val_accuracy: 0.5514 - val_precision_18: 0.0404 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.9533 - accuracy: 0.7987 - precision_18: 0.2161 - val_loss: 1.6391 - val_accuracy: 0.9104 - val_precision_18: 0.0023 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.8922 - accuracy: 0.8155 - precision_18: 0.2551 - val_loss: 4.1159 - val_accuracy: 0.6202 - val_precision_18: 0.0438 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.5839 - accuracy: 0.8113 - precision_18: 0.2442 - val_loss: 12.8886 - val_accuracy: 0.5193 - val_precision_18: 0.0371 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.1950 - accuracy: 0.8097 - precision_18: 0.2336 - val_loss: 0.9212 - val_accuracy: 0.8862 - val_precision_18: 0.0115 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.7491 - accuracy: 0.8110 - precision_18: 0.2420 - val_loss: 5.8591 - val_accuracy: 0.3126 - val_precision_18: 0.0323 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.5738 - accuracy: 0.8049 - precision_18: 0.2270 - val_loss: 0.7633 - val_accuracy: 0.8581 - val_precision_18: 0.0093 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.1045 - accuracy: 0.8102 - precision_18: 0.2286 - val_loss: 99.6260 - val_accuracy: 0.5334 - val_precision_18: 0.0387 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.5646 - accuracy: 0.7847 - precision_18: 0.1882 - val_loss: 1.2713 - val_accuracy: 0.9110 - val_precision_18: 0.0137 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.7561 - accuracy: 0.8084 - precision_18: 0.2329 - val_loss: 2.2390 - val_accuracy: 0.9318 - val_precision_18: 0.0052 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.6664 - accuracy: 0.8072 - precision_18: 0.2278 - val_loss: 1.4027 - val_accuracy: 0.9171 - val_precision_18: 0.0114 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7288 - accuracy: 0.8128 - precision_18: 0.2511 - val_loss: 7.5534 - val_accuracy: 0.5510 - val_precision_18: 0.0399 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8752 - accuracy: 0.8082 - precision_18: 0.2421 - val_loss: 1.1280 - val_accuracy: 0.9294 - val_precision_18: 0.0033 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7050 - accuracy: 0.8120 - precision_18: 0.2420 - val_loss: 0.5212 - val_accuracy: 0.8856 - val_precision_18: 0.0098 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3404 - accuracy: 0.8148 - precision_18: 0.2609 - val_loss: 1.1316 - val_accuracy: 0.5930 - val_precision_18: 0.0151 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2591 - accuracy: 0.8106 - precision_18: 0.2426 - val_loss: 0.4641 - val_accuracy: 0.8764 - val_precision_18: 0.0175 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7866 - accuracy: 0.8058 - precision_18: 0.2236 - val_loss: 0.5595 - val_accuracy: 0.9174 - val_precision_18: 0.0102 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0621 - accuracy: 0.7973 - precision_18: 0.2093 - val_loss: 0.8037 - val_accuracy: 0.9483 - val_precision_18: 0.0029 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.8076 - precision_18: 0.2137 - val_loss: 0.4656 - val_accuracy: 0.9057 - val_precision_18: 0.0106 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.8210 - precision_18: 0.2180 - val_loss: 0.7846 - val_accuracy: 0.7941 - val_precision_18: 0.0177 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.8130 - precision_18: 0.2117 - val_loss: 0.4304 - val_accuracy: 0.9020 - val_precision_18: 0.0071 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.8183 - precision_18: 0.2095 - val_loss: 0.3595 - val_accuracy: 0.8926 - val_precision_18: 0.0141 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.8346 - precision_18: 0.2513 - val_loss: 0.6629 - val_accuracy: 0.7265 - val_precision_18: 0.0521 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.8284 - precision_18: 0.2419 - val_loss: 0.5118 - val_accuracy: 0.8057 - val_precision_18: 0.0197 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.8404 - precision_18: 0.2501 - val_loss: 0.4245 - val_accuracy: 0.8876 - val_precision_18: 0.0212 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.8331 - precision_18: 0.2294 - val_loss: 0.3495 - val_accuracy: 0.9155 - val_precision_18: 0.0087 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8422 - precision_18: 0.2467 - val_loss: 0.3042 - val_accuracy: 0.9661 - val_precision_18: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.8375 - precision_18: 0.2300 - val_loss: 0.2348 - val_accuracy: 0.9408 - val_precision_18: 0.0022 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8504 - precision_18: 0.2911 - val_loss: 0.3083 - val_accuracy: 0.9023 - val_precision_18: 0.0652 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8519 - precision_18: 0.3345 - val_loss: 0.2467 - val_accuracy: 0.9525 - val_precision_18: 0.0034 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 3s 6ms/step - loss: 551.5737 - accuracy: 0.7458 - precision_19: 0.1625 - val_loss: 272.7510 - val_accuracy: 0.3473 - val_precision_19: 0.0328 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 96.4186 - accuracy: 0.7640 - precision_19: 0.1763 - val_loss: 16.9627 - val_accuracy: 0.8685 - val_precision_19: 0.0075 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 54.2182 - accuracy: 0.7767 - precision_19: 0.1898 - val_loss: 14.3344 - val_accuracy: 0.6603 - val_precision_19: 0.0255 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 80.0313 - accuracy: 0.7678 - precision_19: 0.1798 - val_loss: 73.2509 - val_accuracy: 0.9523 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 70.3172 - accuracy: 0.7804 - precision_19: 0.1979 - val_loss: 16.7743 - val_accuracy: 0.6914 - val_precision_19: 0.0375 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 33.1101 - accuracy: 0.7862 - precision_19: 0.2080 - val_loss: 13.6811 - val_accuracy: 0.9379 - val_precision_19: 0.0020 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 58.2691 - accuracy: 0.7775 - precision_19: 0.1905 - val_loss: 8.6049 - val_accuracy: 0.8549 - val_precision_19: 0.0173 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 37.0461 - accuracy: 0.7829 - precision_19: 0.1965 - val_loss: 10.5183 - val_accuracy: 0.7934 - val_precision_19: 0.0345 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.1454 - accuracy: 0.7841 - precision_19: 0.2067 - val_loss: 84.8080 - val_accuracy: 0.2415 - val_precision_19: 0.0288 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 38.1786 - accuracy: 0.7836 - precision_19: 0.2040 - val_loss: 58.1855 - val_accuracy: 0.5853 - val_precision_19: 0.0404 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 64.8725 - accuracy: 0.7814 - precision_19: 0.2019 - val_loss: 20.7482 - val_accuracy: 0.9671 - val_precision_19: 0.0108 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 34.8091 - accuracy: 0.7823 - precision_19: 0.2027 - val_loss: 4.5837 - val_accuracy: 0.7560 - val_precision_19: 0.0204 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.6900 - accuracy: 0.7924 - precision_19: 0.2218 - val_loss: 15.9410 - val_accuracy: 0.9707 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 26.6479 - accuracy: 0.7948 - precision_19: 0.2202 - val_loss: 22.4812 - val_accuracy: 0.9657 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.5534 - accuracy: 0.7936 - precision_19: 0.2181 - val_loss: 7.0465 - val_accuracy: 0.8320 - val_precision_19: 0.0136 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 17.5035 - accuracy: 0.7927 - precision_19: 0.2181 - val_loss: 20.0134 - val_accuracy: 0.9693 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 31.8996 - accuracy: 0.7915 - precision_19: 0.2159 - val_loss: 6.4760 - val_accuracy: 0.7434 - val_precision_19: 0.0377 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 28.2408 - accuracy: 0.7930 - precision_19: 0.2168 - val_loss: 4.5344 - val_accuracy: 0.8934 - val_precision_19: 0.0226 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 20.0325 - accuracy: 0.7979 - precision_19: 0.2223 - val_loss: 21.4107 - val_accuracy: 0.4990 - val_precision_19: 0.0388 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 15.2203 - accuracy: 0.7990 - precision_19: 0.2184 - val_loss: 9.3556 - val_accuracy: 0.6203 - val_precision_19: 0.0411 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 12.5566 - accuracy: 0.7995 - precision_19: 0.2164 - val_loss: 2.3621 - val_accuracy: 0.8016 - val_precision_19: 0.0216 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 11.0114 - accuracy: 0.8029 - precision_19: 0.2347 - val_loss: 9.6056 - val_accuracy: 0.9501 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 14.5707 - accuracy: 0.8001 - precision_19: 0.2290 - val_loss: 4.6166 - val_accuracy: 0.9352 - val_precision_19: 0.0093 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.0741 - accuracy: 0.7990 - precision_19: 0.2252 - val_loss: 10.2055 - val_accuracy: 0.6570 - val_precision_19: 0.0449 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.6678 - accuracy: 0.7993 - precision_19: 0.2182 - val_loss: 2.8931 - val_accuracy: 0.9369 - val_precision_19: 0.0040 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.2982 - accuracy: 0.8020 - precision_19: 0.2146 - val_loss: 18.9109 - val_accuracy: 0.5596 - val_precision_19: 0.0414 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.6369 - accuracy: 0.8046 - precision_19: 0.2244 - val_loss: 1.6279 - val_accuracy: 0.8659 - val_precision_19: 0.0202 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.8648 - accuracy: 0.8058 - precision_19: 0.2185 - val_loss: 19.0114 - val_accuracy: 0.5757 - val_precision_19: 0.0409 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.7690 - accuracy: 0.8032 - precision_19: 0.2154 - val_loss: 1.2132 - val_accuracy: 0.8601 - val_precision_19: 0.0083 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.5928 - accuracy: 0.8043 - precision_19: 0.2277 - val_loss: 1.2202 - val_accuracy: 0.8756 - val_precision_19: 0.0289 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.5173 - accuracy: 0.8082 - precision_19: 0.2335 - val_loss: 1.5011 - val_accuracy: 0.9243 - val_precision_19: 0.0029 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.8993 - accuracy: 0.8088 - precision_19: 0.2374 - val_loss: 3.0823 - val_accuracy: 0.9538 - val_precision_19: 0.0467 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.6232 - accuracy: 0.8078 - precision_19: 0.2243 - val_loss: 0.9304 - val_accuracy: 0.9120 - val_precision_19: 0.0227 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.6693 - accuracy: 0.8086 - precision_19: 0.2230 - val_loss: 2.5860 - val_accuracy: 0.7199 - val_precision_19: 0.0299 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.5024 - accuracy: 0.8087 - precision_19: 0.2325 - val_loss: 2.4508 - val_accuracy: 0.6515 - val_precision_19: 0.0412 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.1436 - accuracy: 0.8112 - precision_19: 0.2423 - val_loss: 1.4211 - val_accuracy: 0.7434 - val_precision_19: 0.0358 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6555 - accuracy: 0.8102 - precision_19: 0.2358 - val_loss: 0.8998 - val_accuracy: 0.9263 - val_precision_19: 0.0076 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7000 - accuracy: 0.8114 - precision_19: 0.2248 - val_loss: 0.6628 - val_accuracy: 0.9561 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2825 - accuracy: 0.8113 - precision_19: 0.2294 - val_loss: 0.6160 - val_accuracy: 0.9278 - val_precision_19: 0.0185 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2221 - accuracy: 0.8151 - precision_19: 0.2405 - val_loss: 0.4331 - val_accuracy: 0.9436 - val_precision_19: 0.0297 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9349 - accuracy: 0.8179 - precision_19: 0.2458 - val_loss: 0.9745 - val_accuracy: 0.7232 - val_precision_19: 0.0359 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0125 - accuracy: 0.8147 - precision_19: 0.2378 - val_loss: 0.3740 - val_accuracy: 0.9218 - val_precision_19: 0.0255 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8250 - accuracy: 0.8186 - precision_19: 0.2428 - val_loss: 0.4297 - val_accuracy: 0.8874 - val_precision_19: 0.0288 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6013 - accuracy: 0.8305 - precision_19: 0.2773 - val_loss: 0.3551 - val_accuracy: 0.8956 - val_precision_19: 0.0233 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6714 - accuracy: 0.8286 - precision_19: 0.2652 - val_loss: 0.2654 - val_accuracy: 0.9437 - val_precision_19: 0.0165 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.8290 - precision_19: 0.2697 - val_loss: 0.4607 - val_accuracy: 0.8446 - val_precision_19: 0.0207 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5538 - accuracy: 0.8338 - precision_19: 0.2806 - val_loss: 0.2815 - val_accuracy: 0.9361 - val_precision_19: 0.0151 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5273 - accuracy: 0.8399 - precision_19: 0.3119 - val_loss: 0.2670 - val_accuracy: 0.9316 - val_precision_19: 0.0168 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.8326 - precision_19: 0.2850 - val_loss: 0.2451 - val_accuracy: 0.9534 - val_precision_19: 0.0397 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7187 - accuracy: 0.8267 - precision_19: 0.2542 - val_loss: 0.2564 - val_accuracy: 0.9600 - val_precision_19: 0.0253 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.8368 - precision_19: 0.2954 - val_loss: 0.2600 - val_accuracy: 0.9389 - val_precision_19: 0.0163 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.8307 - precision_19: 0.2730 - val_loss: 0.2264 - val_accuracy: 0.9540 - val_precision_19: 0.0037 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.8294 - precision_19: 0.2697 - val_loss: 1.2656 - val_accuracy: 0.6273 - val_precision_19: 0.0499 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.8330 - precision_19: 0.2944 - val_loss: 0.4391 - val_accuracy: 0.9412 - val_precision_19: 0.0433 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9974 - accuracy: 0.8093 - precision_19: 0.2235 - val_loss: 0.2906 - val_accuracy: 0.9614 - val_precision_19: 0.0116 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0322 - accuracy: 0.8216 - precision_19: 0.2564 - val_loss: 0.3171 - val_accuracy: 0.9311 - val_precision_19: 0.0068 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.8323 - precision_19: 0.2866 - val_loss: 1.1133 - val_accuracy: 0.9636 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.8431 - precision_19: 0.3343 - val_loss: 0.3585 - val_accuracy: 0.8950 - val_precision_19: 0.0387 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8538 - precision_19: 0.4355 - val_loss: 0.2282 - val_accuracy: 0.9395 - val_precision_19: 0.0021 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8531 - precision_19: 0.4210 - val_loss: 0.2619 - val_accuracy: 0.9286 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8563 - precision_19: 0.4817 - val_loss: 0.2334 - val_accuracy: 0.9507 - val_precision_19: 0.0124 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0203 - accuracy: 0.8308 - precision_19: 0.2817 - val_loss: 0.6503 - val_accuracy: 0.6643 - val_precision_19: 0.0535 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.3571 - accuracy: 0.8103 - precision_19: 0.2332 - val_loss: 0.5792 - val_accuracy: 0.8848 - val_precision_19: 0.0105 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.8461 - precision_19: 0.2904 - val_loss: 0.3737 - val_accuracy: 0.8843 - val_precision_19: 0.0182 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8550 - precision_19: 0.4442 - val_loss: 0.2794 - val_accuracy: 0.9368 - val_precision_19: 0.0246 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8573 - precision_19: 0.5075 - val_loss: 0.3153 - val_accuracy: 0.9102 - val_precision_19: 0.0314 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8590 - precision_19: 0.5545 - val_loss: 0.2418 - val_accuracy: 0.9493 - val_precision_19: 0.0202 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8588 - precision_19: 0.5479 - val_loss: 0.3799 - val_accuracy: 0.8686 - val_precision_19: 0.0246 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8583 - precision_19: 0.5336 - val_loss: 0.3129 - val_accuracy: 0.8978 - val_precision_19: 0.0375 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3730 - accuracy: 0.8583 - precision_19: 0.5335 - val_loss: 0.2591 - val_accuracy: 0.9352 - val_precision_19: 0.0253 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8589 - precision_19: 0.5520 - val_loss: 0.3102 - val_accuracy: 0.9066 - val_precision_19: 0.0307 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3716 - accuracy: 0.8582 - precision_19: 0.5327 - val_loss: 0.2386 - val_accuracy: 0.9439 - val_precision_19: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8605 - precision_19: 0.5983 - val_loss: 0.2470 - val_accuracy: 0.9432 - val_precision_19: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8602 - precision_19: 0.5868 - val_loss: 0.2776 - val_accuracy: 0.9245 - val_precision_19: 0.0294 - lr: 5.0000e-04\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8611 - precision_19: 0.6132 - val_loss: 0.2391 - val_accuracy: 0.9419 - val_precision_19: 0.0046 - lr: 5.0000e-04\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3653 - accuracy: 0.8609 - precision_19: 0.6099 - val_loss: 0.2520 - val_accuracy: 0.9377 - val_precision_19: 0.0138 - lr: 5.0000e-04\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8610 - precision_19: 0.6081 - val_loss: 0.2213 - val_accuracy: 0.9518 - val_precision_19: 0.0033 - lr: 5.0000e-04\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8615 - precision_19: 0.6311 - val_loss: 0.2958 - val_accuracy: 0.9105 - val_precision_19: 0.0405 - lr: 5.0000e-04\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8602 - precision_19: 0.5794 - val_loss: 0.2646 - val_accuracy: 0.9307 - val_precision_19: 0.0084 - lr: 5.0000e-04\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8613 - precision_19: 0.6205 - val_loss: 0.2347 - val_accuracy: 0.9417 - val_precision_19: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8614 - precision_19: 0.6262 - val_loss: 0.2841 - val_accuracy: 0.9231 - val_precision_19: 0.0337 - lr: 5.0000e-04\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8617 - precision_19: 0.6353 - val_loss: 0.2507 - val_accuracy: 0.9344 - val_precision_19: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8616 - precision_19: 0.6218 - val_loss: 0.2367 - val_accuracy: 0.9415 - val_precision_19: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8616 - precision_19: 0.6301 - val_loss: 0.2775 - val_accuracy: 0.9242 - val_precision_19: 0.0266 - lr: 5.0000e-04\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8618 - precision_19: 0.6337 - val_loss: 0.2948 - val_accuracy: 0.9168 - val_precision_19: 0.0280 - lr: 5.0000e-04\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8617 - precision_19: 0.6286 - val_loss: 0.2276 - val_accuracy: 0.9539 - val_precision_19: 0.0109 - lr: 5.0000e-04\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8612 - precision_19: 0.6152 - val_loss: 0.2659 - val_accuracy: 0.9311 - val_precision_19: 0.0182 - lr: 5.0000e-04\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8623 - precision_19: 0.6370 - val_loss: 0.2648 - val_accuracy: 0.9348 - val_precision_19: 0.0267 - lr: 5.0000e-04\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8611 - precision_19: 0.6092 - val_loss: 0.3224 - val_accuracy: 0.9077 - val_precision_19: 0.0332 - lr: 5.0000e-04\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8619 - precision_19: 0.6293 - val_loss: 0.2252 - val_accuracy: 0.9536 - val_precision_19: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8609 - precision_19: 0.6107 - val_loss: 0.2521 - val_accuracy: 0.9399 - val_precision_19: 0.0085 - lr: 5.0000e-04\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8602 - precision_19: 0.5826 - val_loss: 0.2780 - val_accuracy: 0.9281 - val_precision_19: 0.0259 - lr: 5.0000e-04\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3622 - accuracy: 0.8623 - precision_19: 0.6438 - val_loss: 0.2589 - val_accuracy: 0.9365 - val_precision_19: 0.0097 - lr: 5.0000e-04\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3627 - accuracy: 0.8619 - precision_19: 0.6311 - val_loss: 0.2501 - val_accuracy: 0.9429 - val_precision_19: 0.0161 - lr: 5.0000e-04\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3655 - accuracy: 0.8612 - precision_19: 0.6156 - val_loss: 0.2870 - val_accuracy: 0.9311 - val_precision_19: 0.0396 - lr: 5.0000e-04\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3637 - accuracy: 0.8614 - precision_19: 0.6131 - val_loss: 0.2856 - val_accuracy: 0.9220 - val_precision_19: 0.0331 - lr: 5.0000e-04\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3642 - accuracy: 0.8621 - precision_19: 0.6282 - val_loss: 0.2531 - val_accuracy: 0.9443 - val_precision_19: 0.0238 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8626 - precision_19: 0.6504 - val_loss: 0.2563 - val_accuracy: 0.9396 - val_precision_19: 0.0000e+00 - lr: 2.5000e-04\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8637 - precision_19: 0.6829 - val_loss: 0.2655 - val_accuracy: 0.9376 - val_precision_19: 0.0232 - lr: 2.5000e-04\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8633 - precision_19: 0.6616 - val_loss: 0.2946 - val_accuracy: 0.9173 - val_precision_19: 0.0316 - lr: 2.5000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 143.0939 - accuracy: 0.7641 - precision_20: 0.1696 - val_loss: 25.4373 - val_accuracy: 0.9650 - val_precision_20: 0.0082 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 89.0070 - accuracy: 0.7712 - precision_20: 0.1869 - val_loss: 23.3326 - val_accuracy: 0.9697 - val_precision_20: 0.0175 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 78.0805 - accuracy: 0.7781 - precision_20: 0.1994 - val_loss: 186.9362 - val_accuracy: 0.4099 - val_precision_20: 0.0361 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 83.3787 - accuracy: 0.7760 - precision_20: 0.2020 - val_loss: 53.2409 - val_accuracy: 0.9211 - val_precision_20: 0.0264 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 74.6218 - accuracy: 0.7763 - precision_20: 0.2022 - val_loss: 21.2884 - val_accuracy: 0.8948 - val_precision_20: 0.0109 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 72.1123 - accuracy: 0.7852 - precision_20: 0.2176 - val_loss: 25.3074 - val_accuracy: 0.9590 - val_precision_20: 0.0049 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 59.1903 - accuracy: 0.7889 - precision_20: 0.2218 - val_loss: 27.5227 - val_accuracy: 0.6828 - val_precision_20: 0.0310 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 59.0866 - accuracy: 0.7832 - precision_20: 0.2130 - val_loss: 9.1609 - val_accuracy: 0.9147 - val_precision_20: 0.0259 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 50.4677 - accuracy: 0.7916 - precision_20: 0.2350 - val_loss: 19.8911 - val_accuracy: 0.6891 - val_precision_20: 0.0164 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 44.4111 - accuracy: 0.7872 - precision_20: 0.2251 - val_loss: 18.9042 - val_accuracy: 0.8297 - val_precision_20: 0.0219 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 85.1964 - accuracy: 0.7825 - precision_20: 0.2116 - val_loss: 11.7174 - val_accuracy: 0.8566 - val_precision_20: 0.0266 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 46.7205 - accuracy: 0.7891 - precision_20: 0.2178 - val_loss: 9.6652 - val_accuracy: 0.9230 - val_precision_20: 0.0057 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 40.9008 - accuracy: 0.7913 - precision_20: 0.2232 - val_loss: 14.0818 - val_accuracy: 0.9101 - val_precision_20: 0.0090 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 59.4781 - accuracy: 0.7923 - precision_20: 0.2266 - val_loss: 47.7077 - val_accuracy: 0.4864 - val_precision_20: 0.0382 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 52.5768 - accuracy: 0.7941 - precision_20: 0.2360 - val_loss: 19.2324 - val_accuracy: 0.9420 - val_precision_20: 0.0023 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 30.3835 - accuracy: 0.7980 - precision_20: 0.2389 - val_loss: 43.0384 - val_accuracy: 0.6295 - val_precision_20: 0.0435 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 53.0601 - accuracy: 0.7888 - precision_20: 0.2240 - val_loss: 6.7504 - val_accuracy: 0.7161 - val_precision_20: 0.0249 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 32.9273 - accuracy: 0.7950 - precision_20: 0.2345 - val_loss: 5.7626 - val_accuracy: 0.7674 - val_precision_20: 0.0294 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 31.2559 - accuracy: 0.7972 - precision_20: 0.2334 - val_loss: 43.8769 - val_accuracy: 0.5149 - val_precision_20: 0.0388 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 42.9267 - accuracy: 0.7955 - precision_20: 0.2366 - val_loss: 8.0107 - val_accuracy: 0.8983 - val_precision_20: 0.0039 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 26.3361 - accuracy: 0.7978 - precision_20: 0.2362 - val_loss: 65.5667 - val_accuracy: 0.5435 - val_precision_20: 0.0421 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 38.1810 - accuracy: 0.7875 - precision_20: 0.2195 - val_loss: 7.7110 - val_accuracy: 0.7773 - val_precision_20: 0.0173 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.1095 - accuracy: 0.8001 - precision_20: 0.2426 - val_loss: 11.2963 - val_accuracy: 0.9163 - val_precision_20: 0.0051 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.6302 - accuracy: 0.8007 - precision_20: 0.2426 - val_loss: 30.1053 - val_accuracy: 0.6147 - val_precision_20: 0.0414 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 24.5395 - accuracy: 0.7949 - precision_20: 0.2325 - val_loss: 6.7268 - val_accuracy: 0.8336 - val_precision_20: 0.0067 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 28.8474 - accuracy: 0.7938 - precision_20: 0.2233 - val_loss: 13.8389 - val_accuracy: 0.8352 - val_precision_20: 0.0159 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.5825 - accuracy: 0.8010 - precision_20: 0.2412 - val_loss: 44.9896 - val_accuracy: 0.5117 - val_precision_20: 0.0390 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 37.1208 - accuracy: 0.7923 - precision_20: 0.2242 - val_loss: 11.1079 - val_accuracy: 0.8943 - val_precision_20: 0.0169 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.2622 - accuracy: 0.8013 - precision_20: 0.2397 - val_loss: 4.1612 - val_accuracy: 0.8421 - val_precision_20: 0.0208 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 28.0450 - accuracy: 0.7930 - precision_20: 0.2268 - val_loss: 7.3227 - val_accuracy: 0.7669 - val_precision_20: 0.0401 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 25.0632 - accuracy: 0.7981 - precision_20: 0.2335 - val_loss: 52.9622 - val_accuracy: 0.4760 - val_precision_20: 0.0388 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.8352 - accuracy: 0.8001 - precision_20: 0.2447 - val_loss: 4.3927 - val_accuracy: 0.7688 - val_precision_20: 0.0163 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.3231 - accuracy: 0.8023 - precision_20: 0.2453 - val_loss: 4.5967 - val_accuracy: 0.9237 - val_precision_20: 0.0044 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.4244 - accuracy: 0.7970 - precision_20: 0.2419 - val_loss: 5.3991 - val_accuracy: 0.8561 - val_precision_20: 0.0055 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.3225 - accuracy: 0.7997 - precision_20: 0.2392 - val_loss: 4.3562 - val_accuracy: 0.8655 - val_precision_20: 0.0138 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.3516 - accuracy: 0.8034 - precision_20: 0.2512 - val_loss: 17.5241 - val_accuracy: 0.6286 - val_precision_20: 0.0379 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.6104 - accuracy: 0.8042 - precision_20: 0.2529 - val_loss: 4.8592 - val_accuracy: 0.7541 - val_precision_20: 0.0295 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.2803 - accuracy: 0.8064 - precision_20: 0.2649 - val_loss: 6.3122 - val_accuracy: 0.8444 - val_precision_20: 0.0212 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.9003 - accuracy: 0.8062 - precision_20: 0.2623 - val_loss: 5.7544 - val_accuracy: 0.8950 - val_precision_20: 0.0162 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 27.0089 - accuracy: 0.7976 - precision_20: 0.2410 - val_loss: 4.8194 - val_accuracy: 0.8120 - val_precision_20: 0.0162 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 17.4379 - accuracy: 0.7981 - precision_20: 0.2399 - val_loss: 4.2596 - val_accuracy: 0.8970 - val_precision_20: 0.0103 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 16.2513 - accuracy: 0.8049 - precision_20: 0.2512 - val_loss: 14.4966 - val_accuracy: 0.8763 - val_precision_20: 0.0236 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 13.4983 - accuracy: 0.8025 - precision_20: 0.2556 - val_loss: 3.1062 - val_accuracy: 0.7320 - val_precision_20: 0.0184 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.3085 - accuracy: 0.8011 - precision_20: 0.2464 - val_loss: 21.8687 - val_accuracy: 0.9096 - val_precision_20: 0.0112 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.8719 - accuracy: 0.8024 - precision_20: 0.2458 - val_loss: 3.7572 - val_accuracy: 0.8904 - val_precision_20: 0.0194 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.2495 - accuracy: 0.8083 - precision_20: 0.2637 - val_loss: 3.2442 - val_accuracy: 0.8122 - val_precision_20: 0.0200 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.3827 - accuracy: 0.8044 - precision_20: 0.2553 - val_loss: 5.5940 - val_accuracy: 0.8913 - val_precision_20: 0.0104 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.3069 - accuracy: 0.8098 - precision_20: 0.2644 - val_loss: 18.9335 - val_accuracy: 0.5470 - val_precision_20: 0.0419 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.7477 - accuracy: 0.8044 - precision_20: 0.2548 - val_loss: 43.1258 - val_accuracy: 0.4941 - val_precision_20: 0.0372 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.2235 - accuracy: 0.8047 - precision_20: 0.2637 - val_loss: 3.1567 - val_accuracy: 0.8965 - val_precision_20: 0.0019 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.6187 - accuracy: 0.8072 - precision_20: 0.2630 - val_loss: 11.8202 - val_accuracy: 0.9510 - val_precision_20: 0.0032 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.9026 - accuracy: 0.8030 - precision_20: 0.2508 - val_loss: 2.7990 - val_accuracy: 0.9002 - val_precision_20: 0.0030 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.0273 - accuracy: 0.8057 - precision_20: 0.2559 - val_loss: 3.6783 - val_accuracy: 0.9032 - val_precision_20: 0.0072 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.5511 - accuracy: 0.8091 - precision_20: 0.2724 - val_loss: 2.8567 - val_accuracy: 0.9044 - val_precision_20: 0.0042 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.3161 - accuracy: 0.8116 - precision_20: 0.2713 - val_loss: 2.0361 - val_accuracy: 0.8146 - val_precision_20: 0.0274 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.4091 - accuracy: 0.8073 - precision_20: 0.2654 - val_loss: 3.5241 - val_accuracy: 0.8462 - val_precision_20: 0.0156 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.5753 - accuracy: 0.8041 - precision_20: 0.2542 - val_loss: 3.3067 - val_accuracy: 0.7866 - val_precision_20: 0.0235 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.3701 - accuracy: 0.8082 - precision_20: 0.2647 - val_loss: 2.0695 - val_accuracy: 0.8221 - val_precision_20: 0.0159 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.3807 - accuracy: 0.8118 - precision_20: 0.2820 - val_loss: 6.3972 - val_accuracy: 0.5869 - val_precision_20: 0.0461 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.6471 - accuracy: 0.8091 - precision_20: 0.2758 - val_loss: 3.1624 - val_accuracy: 0.8897 - val_precision_20: 0.0209 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.7055 - accuracy: 0.8082 - precision_20: 0.2693 - val_loss: 4.1568 - val_accuracy: 0.7967 - val_precision_20: 0.0237 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.9439 - accuracy: 0.8070 - precision_20: 0.2700 - val_loss: 1.7409 - val_accuracy: 0.8882 - val_precision_20: 0.0026 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.3474 - accuracy: 0.8073 - precision_20: 0.2575 - val_loss: 1.1223 - val_accuracy: 0.8566 - val_precision_20: 0.0311 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2225 - accuracy: 0.8097 - precision_20: 0.2740 - val_loss: 0.7254 - val_accuracy: 0.8861 - val_precision_20: 0.0328 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5582 - accuracy: 0.8118 - precision_20: 0.2760 - val_loss: 0.6540 - val_accuracy: 0.9014 - val_precision_20: 0.0167 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.2644 - accuracy: 0.8163 - precision_20: 0.2820 - val_loss: 0.6171 - val_accuracy: 0.8852 - val_precision_20: 0.0252 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1668 - accuracy: 0.8188 - precision_20: 0.2878 - val_loss: 1.3735 - val_accuracy: 0.6809 - val_precision_20: 0.0443 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.0195 - accuracy: 0.8168 - precision_20: 0.2831 - val_loss: 1.6924 - val_accuracy: 0.7935 - val_precision_20: 0.0393 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0557 - accuracy: 0.8203 - precision_20: 0.2877 - val_loss: 0.5110 - val_accuracy: 0.8769 - val_precision_20: 0.0319 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8857 - accuracy: 0.8218 - precision_20: 0.2871 - val_loss: 0.8439 - val_accuracy: 0.6652 - val_precision_20: 0.0475 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8031 - accuracy: 0.8271 - precision_20: 0.3046 - val_loss: 0.5535 - val_accuracy: 0.8500 - val_precision_20: 0.0311 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7339 - accuracy: 0.8317 - precision_20: 0.3199 - val_loss: 0.5840 - val_accuracy: 0.8887 - val_precision_20: 0.0269 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.8343 - precision_20: 0.3301 - val_loss: 0.5160 - val_accuracy: 0.8602 - val_precision_20: 0.0354 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.8358 - precision_20: 0.3387 - val_loss: 0.4482 - val_accuracy: 0.9169 - val_precision_20: 0.0268 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.8358 - precision_20: 0.3294 - val_loss: 0.6231 - val_accuracy: 0.7641 - val_precision_20: 0.0534 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.8342 - precision_20: 0.3319 - val_loss: 0.4041 - val_accuracy: 0.9204 - val_precision_20: 0.0333 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.8431 - precision_20: 0.3656 - val_loss: 0.4155 - val_accuracy: 0.9208 - val_precision_20: 0.0262 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.4689 - accuracy: 0.8194 - precision_20: 0.2813 - val_loss: 16.4298 - val_accuracy: 0.6607 - val_precision_20: 0.0457 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.0570 - accuracy: 0.8102 - precision_20: 0.2572 - val_loss: 0.9107 - val_accuracy: 0.7102 - val_precision_20: 0.0530 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7325 - accuracy: 0.8324 - precision_20: 0.3092 - val_loss: 0.4659 - val_accuracy: 0.8531 - val_precision_20: 0.0308 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.8378 - precision_20: 0.3385 - val_loss: 0.3339 - val_accuracy: 0.9307 - val_precision_20: 0.0132 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.8443 - precision_20: 0.3706 - val_loss: 0.3308 - val_accuracy: 0.9162 - val_precision_20: 0.0288 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.8531 - precision_20: 0.4420 - val_loss: 0.2749 - val_accuracy: 0.9423 - val_precision_20: 0.0092 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.8538 - precision_20: 0.4516 - val_loss: 0.3152 - val_accuracy: 0.9177 - val_precision_20: 0.0341 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.8507 - precision_20: 0.4174 - val_loss: 0.3453 - val_accuracy: 0.9030 - val_precision_20: 0.0461 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8534 - precision_20: 0.4472 - val_loss: 0.3594 - val_accuracy: 0.8580 - val_precision_20: 0.0693 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8570 - precision_20: 0.4976 - val_loss: 0.3288 - val_accuracy: 0.8931 - val_precision_20: 0.0394 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8583 - precision_20: 0.5192 - val_loss: 0.2473 - val_accuracy: 0.9512 - val_precision_20: 0.0333 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8576 - precision_20: 0.5081 - val_loss: 0.2350 - val_accuracy: 0.9504 - val_precision_20: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.8583 - precision_20: 0.5211 - val_loss: 0.2656 - val_accuracy: 0.9354 - val_precision_20: 0.0387 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3972 - accuracy: 0.8576 - precision_20: 0.5064 - val_loss: 0.2522 - val_accuracy: 0.9325 - val_precision_20: 0.0138 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8583 - precision_20: 0.5186 - val_loss: 0.2524 - val_accuracy: 0.9526 - val_precision_20: 0.0068 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8562 - precision_20: 0.4859 - val_loss: 0.2854 - val_accuracy: 0.9200 - val_precision_20: 0.0343 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.8496 - precision_20: 0.4130 - val_loss: 0.3628 - val_accuracy: 0.8927 - val_precision_20: 0.0618 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8564 - precision_20: 0.4880 - val_loss: 0.2549 - val_accuracy: 0.9378 - val_precision_20: 0.0463 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8594 - precision_20: 0.5406 - val_loss: 0.2486 - val_accuracy: 0.9404 - val_precision_20: 0.0423 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8607 - precision_20: 0.5615 - val_loss: 0.3640 - val_accuracy: 0.8985 - val_precision_20: 0.0395 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8526 - precision_20: 0.4400 - val_loss: 0.2644 - val_accuracy: 0.9412 - val_precision_20: 0.0256 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8609 - precision_20: 0.5683 - val_loss: 0.4954 - val_accuracy: 0.8279 - val_precision_20: 0.0284 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8577 - precision_20: 0.5088 - val_loss: 0.2786 - val_accuracy: 0.9273 - val_precision_20: 0.0535 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 255.8870 - accuracy: 0.7590 - precision_21: 0.1625 - val_loss: 32.5726 - val_accuracy: 0.5330 - val_precision_21: 0.0161 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 123.4909 - accuracy: 0.7641 - precision_21: 0.1807 - val_loss: 34.7054 - val_accuracy: 0.7887 - val_precision_21: 0.0212 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 89.1674 - accuracy: 0.7687 - precision_21: 0.1924 - val_loss: 43.0375 - val_accuracy: 0.5133 - val_precision_21: 0.0295 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 74.0024 - accuracy: 0.7750 - precision_21: 0.2094 - val_loss: 32.8220 - val_accuracy: 0.9678 - val_precision_21: 0.0119 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 88.5945 - accuracy: 0.7752 - precision_21: 0.2046 - val_loss: 26.1785 - val_accuracy: 0.8544 - val_precision_21: 0.0206 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 80.3343 - accuracy: 0.7755 - precision_21: 0.2056 - val_loss: 15.7952 - val_accuracy: 0.8570 - val_precision_21: 0.0210 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 69.9503 - accuracy: 0.7752 - precision_21: 0.2104 - val_loss: 77.3539 - val_accuracy: 0.6440 - val_precision_21: 0.0417 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 80.1016 - accuracy: 0.7731 - precision_21: 0.2035 - val_loss: 35.2650 - val_accuracy: 0.9684 - val_precision_21: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 89.4649 - accuracy: 0.7794 - precision_21: 0.2138 - val_loss: 12.2186 - val_accuracy: 0.7678 - val_precision_21: 0.0195 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 60.3991 - accuracy: 0.7827 - precision_21: 0.2248 - val_loss: 29.0528 - val_accuracy: 0.9446 - val_precision_21: 0.0074 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 56.6941 - accuracy: 0.7814 - precision_21: 0.2260 - val_loss: 16.6428 - val_accuracy: 0.8305 - val_precision_21: 0.0459 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 65.9695 - accuracy: 0.7770 - precision_21: 0.2131 - val_loss: 109.9305 - val_accuracy: 0.5893 - val_precision_21: 0.0403 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 55.1304 - accuracy: 0.7868 - precision_21: 0.2330 - val_loss: 16.7121 - val_accuracy: 0.5392 - val_precision_21: 0.0218 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 46.7418 - accuracy: 0.7858 - precision_21: 0.2299 - val_loss: 8.6238 - val_accuracy: 0.8343 - val_precision_21: 0.0202 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 53.4928 - accuracy: 0.7899 - precision_21: 0.2375 - val_loss: 20.8449 - val_accuracy: 0.8682 - val_precision_21: 0.0135 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 45.9235 - accuracy: 0.7858 - precision_21: 0.2325 - val_loss: 10.0730 - val_accuracy: 0.8956 - val_precision_21: 0.0083 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 38.0999 - accuracy: 0.7907 - precision_21: 0.2322 - val_loss: 11.9692 - val_accuracy: 0.7981 - val_precision_21: 0.0219 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 44.5125 - accuracy: 0.7848 - precision_21: 0.2215 - val_loss: 37.4936 - val_accuracy: 0.7891 - val_precision_21: 0.0213 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 51.4013 - accuracy: 0.7897 - precision_21: 0.2273 - val_loss: 43.1045 - val_accuracy: 0.4779 - val_precision_21: 0.0366 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 40.5347 - accuracy: 0.7902 - precision_21: 0.2353 - val_loss: 10.8060 - val_accuracy: 0.8573 - val_precision_21: 0.0086 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 40.3950 - accuracy: 0.7887 - precision_21: 0.2320 - val_loss: 14.6964 - val_accuracy: 0.7859 - val_precision_21: 0.0198 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 35.3131 - accuracy: 0.7911 - precision_21: 0.2368 - val_loss: 6.3465 - val_accuracy: 0.8015 - val_precision_21: 0.0176 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 34.6681 - accuracy: 0.7902 - precision_21: 0.2306 - val_loss: 5.4913 - val_accuracy: 0.7276 - val_precision_21: 0.0227 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 24.1645 - accuracy: 0.7958 - precision_21: 0.2444 - val_loss: 28.3322 - val_accuracy: 0.5107 - val_precision_21: 0.0384 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 34.5165 - accuracy: 0.7922 - precision_21: 0.2349 - val_loss: 8.9592 - val_accuracy: 0.7329 - val_precision_21: 0.0170 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 41.5407 - accuracy: 0.7894 - precision_21: 0.2249 - val_loss: 10.4290 - val_accuracy: 0.7744 - val_precision_21: 0.0310 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 24.9276 - accuracy: 0.7913 - precision_21: 0.2332 - val_loss: 5.7691 - val_accuracy: 0.8807 - val_precision_21: 0.0108 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 25.0818 - accuracy: 0.7974 - precision_21: 0.2367 - val_loss: 12.0256 - val_accuracy: 0.8845 - val_precision_21: 0.0143 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 26.8391 - accuracy: 0.7932 - precision_21: 0.2299 - val_loss: 7.8149 - val_accuracy: 0.8721 - val_precision_21: 0.0120 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 21.5256 - accuracy: 0.7972 - precision_21: 0.2384 - val_loss: 7.4796 - val_accuracy: 0.8685 - val_precision_21: 0.0116 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.3146 - accuracy: 0.7974 - precision_21: 0.2414 - val_loss: 5.8319 - val_accuracy: 0.8267 - val_precision_21: 0.0356 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.8123 - accuracy: 0.7976 - precision_21: 0.2430 - val_loss: 5.7843 - val_accuracy: 0.8338 - val_precision_21: 0.0225 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.5266 - accuracy: 0.8007 - precision_21: 0.2537 - val_loss: 29.1581 - val_accuracy: 0.5501 - val_precision_21: 0.0428 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.1742 - accuracy: 0.7982 - precision_21: 0.2402 - val_loss: 48.0500 - val_accuracy: 0.5401 - val_precision_21: 0.0402 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 20.6901 - accuracy: 0.8022 - precision_21: 0.2454 - val_loss: 9.2128 - val_accuracy: 0.9152 - val_precision_21: 0.0062 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 16.4941 - accuracy: 0.8048 - precision_21: 0.2496 - val_loss: 32.8355 - val_accuracy: 0.5650 - val_precision_21: 0.0402 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 22.1660 - accuracy: 0.7965 - precision_21: 0.2427 - val_loss: 10.5430 - val_accuracy: 0.9526 - val_precision_21: 0.0034 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 18.5143 - accuracy: 0.8020 - precision_21: 0.2474 - val_loss: 12.0957 - val_accuracy: 0.6567 - val_precision_21: 0.0407 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 16.8319 - accuracy: 0.8010 - precision_21: 0.2392 - val_loss: 17.2079 - val_accuracy: 0.5465 - val_precision_21: 0.0399 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.1762 - accuracy: 0.7957 - precision_21: 0.2291 - val_loss: 27.2295 - val_accuracy: 0.5898 - val_precision_21: 0.0421 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.7158 - accuracy: 0.8012 - precision_21: 0.2444 - val_loss: 7.3629 - val_accuracy: 0.9323 - val_precision_21: 0.0052 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.2495 - accuracy: 0.8055 - precision_21: 0.2488 - val_loss: 6.4512 - val_accuracy: 0.7442 - val_precision_21: 0.0388 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.9429 - accuracy: 0.8041 - precision_21: 0.2497 - val_loss: 3.1701 - val_accuracy: 0.9164 - val_precision_21: 0.0075 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.2161 - accuracy: 0.8061 - precision_21: 0.2502 - val_loss: 3.6283 - val_accuracy: 0.8969 - val_precision_21: 0.0148 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.2477 - accuracy: 0.8064 - precision_21: 0.2517 - val_loss: 9.6030 - val_accuracy: 0.6843 - val_precision_21: 0.0455 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.0766 - accuracy: 0.8015 - precision_21: 0.2492 - val_loss: 6.9666 - val_accuracy: 0.9386 - val_precision_21: 0.0062 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.3768 - accuracy: 0.7999 - precision_21: 0.2400 - val_loss: 4.8435 - val_accuracy: 0.6984 - val_precision_21: 0.0257 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.9631 - accuracy: 0.8012 - precision_21: 0.2450 - val_loss: 3.5144 - val_accuracy: 0.9202 - val_precision_21: 0.0081 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.2219 - accuracy: 0.8069 - precision_21: 0.2586 - val_loss: 1.8823 - val_accuracy: 0.8220 - val_precision_21: 0.0186 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.2964 - accuracy: 0.8070 - precision_21: 0.2601 - val_loss: 3.3252 - val_accuracy: 0.9034 - val_precision_21: 0.0112 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.2138 - accuracy: 0.8071 - precision_21: 0.2479 - val_loss: 2.5896 - val_accuracy: 0.8918 - val_precision_21: 0.0147 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.8401 - accuracy: 0.8044 - precision_21: 0.2474 - val_loss: 3.4982 - val_accuracy: 0.9377 - val_precision_21: 0.0040 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.1546 - accuracy: 0.8115 - precision_21: 0.2675 - val_loss: 4.9066 - val_accuracy: 0.5967 - val_precision_21: 0.0420 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.4718 - accuracy: 0.8065 - precision_21: 0.2547 - val_loss: 2.6021 - val_accuracy: 0.8393 - val_precision_21: 0.0234 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.2138 - accuracy: 0.8064 - precision_21: 0.2520 - val_loss: 2.4114 - val_accuracy: 0.9210 - val_precision_21: 0.0014 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.7182 - accuracy: 0.8065 - precision_21: 0.2537 - val_loss: 1.1264 - val_accuracy: 0.8418 - val_precision_21: 0.0187 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.0479 - accuracy: 0.8091 - precision_21: 0.2592 - val_loss: 2.0710 - val_accuracy: 0.7877 - val_precision_21: 0.0189 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.3589 - accuracy: 0.8072 - precision_21: 0.2580 - val_loss: 1.5936 - val_accuracy: 0.8869 - val_precision_21: 0.0225 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.4670 - accuracy: 0.8095 - precision_21: 0.2599 - val_loss: 1.4246 - val_accuracy: 0.8213 - val_precision_21: 0.0189 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.4671 - accuracy: 0.8076 - precision_21: 0.2563 - val_loss: 2.1696 - val_accuracy: 0.8921 - val_precision_21: 0.0279 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.5686 - accuracy: 0.8084 - precision_21: 0.2563 - val_loss: 3.5391 - val_accuracy: 0.6421 - val_precision_21: 0.0347 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 3.3135 - accuracy: 0.8095 - precision_21: 0.2614 - val_loss: 1.4179 - val_accuracy: 0.8537 - val_precision_21: 0.0249 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 3.0147 - accuracy: 0.8078 - precision_21: 0.2534 - val_loss: 1.5713 - val_accuracy: 0.9219 - val_precision_21: 0.0070 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2540 - accuracy: 0.8142 - precision_21: 0.2759 - val_loss: 0.8494 - val_accuracy: 0.7897 - val_precision_21: 0.0231 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2493 - accuracy: 0.8138 - precision_21: 0.2775 - val_loss: 0.9970 - val_accuracy: 0.8966 - val_precision_21: 0.0138 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8260 - accuracy: 0.8140 - precision_21: 0.2773 - val_loss: 0.8455 - val_accuracy: 0.7774 - val_precision_21: 0.0285 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.1940 - accuracy: 0.8122 - precision_21: 0.2747 - val_loss: 1.0130 - val_accuracy: 0.8066 - val_precision_21: 0.0230 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9741 - accuracy: 0.8133 - precision_21: 0.2763 - val_loss: 1.0910 - val_accuracy: 0.9386 - val_precision_21: 0.0041 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7465 - accuracy: 0.8143 - precision_21: 0.2771 - val_loss: 0.6733 - val_accuracy: 0.8316 - val_precision_21: 0.0179 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2774 - accuracy: 0.8130 - precision_21: 0.2752 - val_loss: 0.4789 - val_accuracy: 0.9055 - val_precision_21: 0.0095 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6350 - accuracy: 0.8148 - precision_21: 0.2787 - val_loss: 0.5788 - val_accuracy: 0.8558 - val_precision_21: 0.0320 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3219 - accuracy: 0.8157 - precision_21: 0.2809 - val_loss: 0.6423 - val_accuracy: 0.8911 - val_precision_21: 0.0196 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2696 - accuracy: 0.8158 - precision_21: 0.2743 - val_loss: 0.8421 - val_accuracy: 0.7087 - val_precision_21: 0.0432 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1010 - accuracy: 0.8181 - precision_21: 0.2865 - val_loss: 0.3920 - val_accuracy: 0.8804 - val_precision_21: 0.0196 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9016 - accuracy: 0.8230 - precision_21: 0.3032 - val_loss: 0.3850 - val_accuracy: 0.8706 - val_precision_21: 0.0211 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0524 - accuracy: 0.8198 - precision_21: 0.2956 - val_loss: 0.5682 - val_accuracy: 0.9263 - val_precision_21: 0.0277 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7836 - accuracy: 0.8268 - precision_21: 0.3059 - val_loss: 0.4013 - val_accuracy: 0.8751 - val_precision_21: 0.0294 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.8294 - precision_21: 0.3187 - val_loss: 0.5035 - val_accuracy: 0.7894 - val_precision_21: 0.0494 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.6999 - accuracy: 0.8272 - precision_21: 0.3080 - val_loss: 0.2678 - val_accuracy: 0.9229 - val_precision_21: 0.0071 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9176 - accuracy: 0.8266 - precision_21: 0.3096 - val_loss: 0.2704 - val_accuracy: 0.9378 - val_precision_21: 0.0214 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.8327 - precision_21: 0.3231 - val_loss: 0.3644 - val_accuracy: 0.9199 - val_precision_21: 0.0040 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.8316 - precision_21: 0.3121 - val_loss: 0.2633 - val_accuracy: 0.9320 - val_precision_21: 0.0447 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.8436 - precision_21: 0.3694 - val_loss: 0.3329 - val_accuracy: 0.8997 - val_precision_21: 0.0392 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.8418 - precision_21: 0.3574 - val_loss: 0.4118 - val_accuracy: 0.8410 - val_precision_21: 0.0648 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.8419 - precision_21: 0.3492 - val_loss: 0.3299 - val_accuracy: 0.8879 - val_precision_21: 0.0342 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.8412 - precision_21: 0.3483 - val_loss: 0.2739 - val_accuracy: 0.9332 - val_precision_21: 0.0368 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4382 - accuracy: 0.8469 - precision_21: 0.3851 - val_loss: 0.4140 - val_accuracy: 0.8503 - val_precision_21: 0.0291 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4548 - accuracy: 0.8436 - precision_21: 0.3598 - val_loss: 0.6553 - val_accuracy: 0.6917 - val_precision_21: 0.0542 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.8393 - precision_21: 0.3409 - val_loss: 0.3067 - val_accuracy: 0.8942 - val_precision_21: 0.0351 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0644 - accuracy: 0.8283 - precision_21: 0.2988 - val_loss: 0.2953 - val_accuracy: 0.9288 - val_precision_21: 0.0472 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.8383 - precision_21: 0.3327 - val_loss: 0.2697 - val_accuracy: 0.9392 - val_precision_21: 0.0530 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.8455 - precision_21: 0.3724 - val_loss: 0.2837 - val_accuracy: 0.9184 - val_precision_21: 0.0390 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7447 - accuracy: 0.8331 - precision_21: 0.3175 - val_loss: 0.5244 - val_accuracy: 0.9180 - val_precision_21: 0.0453 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5634 - accuracy: 0.8204 - precision_21: 0.2777 - val_loss: 1.0453 - val_accuracy: 0.6611 - val_precision_21: 0.0526 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.8376 - precision_21: 0.3336 - val_loss: 0.3162 - val_accuracy: 0.9139 - val_precision_21: 0.0456 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8550 - precision_21: 0.4685 - val_loss: 0.4968 - val_accuracy: 0.7821 - val_precision_21: 0.0651 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8558 - precision_21: 0.4780 - val_loss: 0.2657 - val_accuracy: 0.9265 - val_precision_21: 0.0451 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8564 - precision_21: 0.4867 - val_loss: 0.2952 - val_accuracy: 0.9155 - val_precision_21: 0.0251 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8564 - precision_21: 0.4865 - val_loss: 0.3571 - val_accuracy: 0.8866 - val_precision_21: 0.0359 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8796 - accuracy: 0.8427 - precision_21: 0.3637 - val_loss: 1.4993 - val_accuracy: 0.8908 - val_precision_21: 0.0219 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 213.6325 - accuracy: 0.7621 - precision_22: 0.1638 - val_loss: 23.7188 - val_accuracy: 0.9313 - val_precision_22: 0.0051 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 102.2815 - accuracy: 0.7741 - precision_22: 0.1843 - val_loss: 28.5939 - val_accuracy: 0.8965 - val_precision_22: 0.0182 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 91.3537 - accuracy: 0.7815 - precision_22: 0.1905 - val_loss: 72.7218 - val_accuracy: 0.4484 - val_precision_22: 0.0358 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 65.0662 - accuracy: 0.7844 - precision_22: 0.2075 - val_loss: 24.2011 - val_accuracy: 0.8493 - val_precision_22: 0.0251 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 89.0763 - accuracy: 0.7803 - precision_22: 0.2012 - val_loss: 18.9065 - val_accuracy: 0.9088 - val_precision_22: 0.0246 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 62.1207 - accuracy: 0.7881 - precision_22: 0.2055 - val_loss: 12.6290 - val_accuracy: 0.8996 - val_precision_22: 0.0253 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 55.9576 - accuracy: 0.7890 - precision_22: 0.2078 - val_loss: 31.2927 - val_accuracy: 0.9441 - val_precision_22: 0.0049 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 83.5778 - accuracy: 0.7855 - precision_22: 0.2109 - val_loss: 36.4681 - val_accuracy: 0.9596 - val_precision_22: 0.0101 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 60.6874 - accuracy: 0.7870 - precision_22: 0.2059 - val_loss: 23.9813 - val_accuracy: 0.5002 - val_precision_22: 0.0279 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 59.5253 - accuracy: 0.7868 - precision_22: 0.2097 - val_loss: 8.1963 - val_accuracy: 0.8271 - val_precision_22: 0.0215 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 59.7059 - accuracy: 0.7868 - precision_22: 0.2064 - val_loss: 13.8741 - val_accuracy: 0.9047 - val_precision_22: 0.0164 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 37.1182 - accuracy: 0.7929 - precision_22: 0.2148 - val_loss: 48.0614 - val_accuracy: 0.5518 - val_precision_22: 0.0402 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 34.4087 - accuracy: 0.7961 - precision_22: 0.2250 - val_loss: 11.8860 - val_accuracy: 0.8494 - val_precision_22: 0.0203 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 33.2982 - accuracy: 0.7985 - precision_22: 0.2295 - val_loss: 14.2053 - val_accuracy: 0.9147 - val_precision_22: 0.0133 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 56.8530 - accuracy: 0.7932 - precision_22: 0.2251 - val_loss: 10.0325 - val_accuracy: 0.8580 - val_precision_22: 0.0111 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 46.6941 - accuracy: 0.7919 - precision_22: 0.2219 - val_loss: 35.7639 - val_accuracy: 0.9504 - val_precision_22: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 32.3170 - accuracy: 0.7955 - precision_22: 0.2259 - val_loss: 5.8803 - val_accuracy: 0.8257 - val_precision_22: 0.0167 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.7840 - accuracy: 0.7981 - precision_22: 0.2272 - val_loss: 13.0846 - val_accuracy: 0.9040 - val_precision_22: 0.0042 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.9496 - accuracy: 0.7994 - precision_22: 0.2325 - val_loss: 9.4465 - val_accuracy: 0.8702 - val_precision_22: 0.0242 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.2031 - accuracy: 0.7988 - precision_22: 0.2358 - val_loss: 7.0780 - val_accuracy: 0.8779 - val_precision_22: 0.0030 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.0924 - accuracy: 0.7991 - precision_22: 0.2314 - val_loss: 6.3052 - val_accuracy: 0.8912 - val_precision_22: 0.0104 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.9864 - accuracy: 0.8026 - precision_22: 0.2441 - val_loss: 7.3890 - val_accuracy: 0.9046 - val_precision_22: 0.0270 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 26.9566 - accuracy: 0.7982 - precision_22: 0.2367 - val_loss: 8.0689 - val_accuracy: 0.9306 - val_precision_22: 0.0034 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.9240 - accuracy: 0.8019 - precision_22: 0.2426 - val_loss: 12.9389 - val_accuracy: 0.9444 - val_precision_22: 0.0074 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.2645 - accuracy: 0.8025 - precision_22: 0.2470 - val_loss: 18.4366 - val_accuracy: 0.6171 - val_precision_22: 0.0426 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.0874 - accuracy: 0.7996 - precision_22: 0.2360 - val_loss: 6.2083 - val_accuracy: 0.9152 - val_precision_22: 0.0025 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.3147 - accuracy: 0.7994 - precision_22: 0.2270 - val_loss: 6.8163 - val_accuracy: 0.9005 - val_precision_22: 0.0030 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.0581 - accuracy: 0.8057 - precision_22: 0.2528 - val_loss: 6.4690 - val_accuracy: 0.9135 - val_precision_22: 0.0048 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.7823 - accuracy: 0.8044 - precision_22: 0.2396 - val_loss: 3.9039 - val_accuracy: 0.7965 - val_precision_22: 0.0255 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.2799 - accuracy: 0.8039 - precision_22: 0.2473 - val_loss: 8.1676 - val_accuracy: 0.9263 - val_precision_22: 0.0120 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.4318 - accuracy: 0.8046 - precision_22: 0.2521 - val_loss: 16.4492 - val_accuracy: 0.9630 - val_precision_22: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 15.5832 - accuracy: 0.8056 - precision_22: 0.2499 - val_loss: 3.4087 - val_accuracy: 0.8001 - val_precision_22: 0.0206 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 16.4975 - accuracy: 0.8028 - precision_22: 0.2389 - val_loss: 21.3331 - val_accuracy: 0.5628 - val_precision_22: 0.0406 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 12.6570 - accuracy: 0.8046 - precision_22: 0.2493 - val_loss: 14.2330 - val_accuracy: 0.9388 - val_precision_22: 0.0082 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.1551 - accuracy: 0.8018 - precision_22: 0.2353 - val_loss: 6.1596 - val_accuracy: 0.9147 - val_precision_22: 0.0049 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.8875 - accuracy: 0.8068 - precision_22: 0.2521 - val_loss: 7.6562 - val_accuracy: 0.8966 - val_precision_22: 0.0269 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.7069 - accuracy: 0.8061 - precision_22: 0.2488 - val_loss: 3.5141 - val_accuracy: 0.8811 - val_precision_22: 0.0101 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.0645 - accuracy: 0.8063 - precision_22: 0.2456 - val_loss: 33.0457 - val_accuracy: 0.6033 - val_precision_22: 0.0391 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.5165 - accuracy: 0.8059 - precision_22: 0.2526 - val_loss: 3.2569 - val_accuracy: 0.8057 - val_precision_22: 0.0176 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.6478 - accuracy: 0.8061 - precision_22: 0.2472 - val_loss: 3.0452 - val_accuracy: 0.7805 - val_precision_22: 0.0238 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.1417 - accuracy: 0.8079 - precision_22: 0.2572 - val_loss: 23.3018 - val_accuracy: 0.5751 - val_precision_22: 0.0369 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.9363 - accuracy: 0.8066 - precision_22: 0.2564 - val_loss: 2.1444 - val_accuracy: 0.8866 - val_precision_22: 0.0099 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.7559 - accuracy: 0.8074 - precision_22: 0.2576 - val_loss: 3.6142 - val_accuracy: 0.7782 - val_precision_22: 0.0266 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.7613 - accuracy: 0.8055 - precision_22: 0.2500 - val_loss: 3.9284 - val_accuracy: 0.8808 - val_precision_22: 0.0123 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.1756 - accuracy: 0.8093 - precision_22: 0.2679 - val_loss: 5.0819 - val_accuracy: 0.9161 - val_precision_22: 0.0136 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.1973 - accuracy: 0.8059 - precision_22: 0.2486 - val_loss: 3.5853 - val_accuracy: 0.9368 - val_precision_22: 0.0020 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.2110 - accuracy: 0.8053 - precision_22: 0.2496 - val_loss: 2.3220 - val_accuracy: 0.8595 - val_precision_22: 0.0094 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.5702 - accuracy: 0.8117 - precision_22: 0.2738 - val_loss: 2.2585 - val_accuracy: 0.7779 - val_precision_22: 0.0367 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.2176 - accuracy: 0.8126 - precision_22: 0.2775 - val_loss: 4.0750 - val_accuracy: 0.7226 - val_precision_22: 0.0414 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.6238 - accuracy: 0.8100 - precision_22: 0.2694 - val_loss: 5.8285 - val_accuracy: 0.8725 - val_precision_22: 0.0331 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.8933 - accuracy: 0.8052 - precision_22: 0.2558 - val_loss: 2.8835 - val_accuracy: 0.9361 - val_precision_22: 0.0019 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.8360 - accuracy: 0.8068 - precision_22: 0.2570 - val_loss: 3.1190 - val_accuracy: 0.9097 - val_precision_22: 0.0090 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.1945 - accuracy: 0.8108 - precision_22: 0.2721 - val_loss: 2.9285 - val_accuracy: 0.9069 - val_precision_22: 0.0086 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.0485 - accuracy: 0.8092 - precision_22: 0.2647 - val_loss: 5.5137 - val_accuracy: 0.6502 - val_precision_22: 0.0432 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 5.1574 - accuracy: 0.8110 - precision_22: 0.2770 - val_loss: 1.4008 - val_accuracy: 0.8777 - val_precision_22: 0.0141 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.8103 - accuracy: 0.8148 - precision_22: 0.2862 - val_loss: 1.5865 - val_accuracy: 0.8820 - val_precision_22: 0.0078 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.5625 - accuracy: 0.8128 - precision_22: 0.2823 - val_loss: 1.0856 - val_accuracy: 0.8486 - val_precision_22: 0.0103 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.4448 - accuracy: 0.8135 - precision_22: 0.2815 - val_loss: 2.5996 - val_accuracy: 0.8670 - val_precision_22: 0.0309 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.2358 - accuracy: 0.8133 - precision_22: 0.2901 - val_loss: 1.3532 - val_accuracy: 0.8901 - val_precision_22: 0.0128 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.8516 - accuracy: 0.8146 - precision_22: 0.2868 - val_loss: 1.2913 - val_accuracy: 0.7506 - val_precision_22: 0.0311 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.1776 - accuracy: 0.8162 - precision_22: 0.3021 - val_loss: 1.8537 - val_accuracy: 0.9407 - val_precision_22: 0.0066 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.8207 - accuracy: 0.8139 - precision_22: 0.2843 - val_loss: 1.0016 - val_accuracy: 0.9270 - val_precision_22: 0.0062 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.5087 - accuracy: 0.8126 - precision_22: 0.2754 - val_loss: 1.0906 - val_accuracy: 0.9270 - val_precision_22: 0.0046 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.7045 - accuracy: 0.8151 - precision_22: 0.2900 - val_loss: 0.8721 - val_accuracy: 0.8759 - val_precision_22: 0.0081 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.0602 - accuracy: 0.8168 - precision_22: 0.2966 - val_loss: 1.0307 - val_accuracy: 0.8118 - val_precision_22: 0.0174 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.5321 - accuracy: 0.8143 - precision_22: 0.2860 - val_loss: 0.6734 - val_accuracy: 0.8817 - val_precision_22: 0.0109 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0204 - accuracy: 0.8181 - precision_22: 0.3001 - val_loss: 0.7519 - val_accuracy: 0.8478 - val_precision_22: 0.0206 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0906 - accuracy: 0.8147 - precision_22: 0.2898 - val_loss: 1.9633 - val_accuracy: 0.9253 - val_precision_22: 0.0103 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2192 - accuracy: 0.8175 - precision_22: 0.2918 - val_loss: 0.5990 - val_accuracy: 0.9013 - val_precision_22: 0.0030 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4564 - accuracy: 0.8188 - precision_22: 0.2977 - val_loss: 0.5175 - val_accuracy: 0.9005 - val_precision_22: 0.0079 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6206 - accuracy: 0.8186 - precision_22: 0.2977 - val_loss: 0.5625 - val_accuracy: 0.8779 - val_precision_22: 0.0184 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1452 - accuracy: 0.8238 - precision_22: 0.3144 - val_loss: 0.5722 - val_accuracy: 0.7924 - val_precision_22: 0.0317 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9763 - accuracy: 0.8232 - precision_22: 0.3119 - val_loss: 0.7349 - val_accuracy: 0.9039 - val_precision_22: 0.0277 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0817 - accuracy: 0.8240 - precision_22: 0.3134 - val_loss: 0.3900 - val_accuracy: 0.9388 - val_precision_22: 0.0041 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0783 - accuracy: 0.8239 - precision_22: 0.3124 - val_loss: 0.4236 - val_accuracy: 0.9052 - val_precision_22: 0.0063 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9685 - accuracy: 0.8208 - precision_22: 0.2987 - val_loss: 0.3825 - val_accuracy: 0.8819 - val_precision_22: 0.0162 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7709 - accuracy: 0.8272 - precision_22: 0.3143 - val_loss: 0.6370 - val_accuracy: 0.7579 - val_precision_22: 0.0445 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.8358 - precision_22: 0.3522 - val_loss: 0.2784 - val_accuracy: 0.9332 - val_precision_22: 0.0071 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.8339 - precision_22: 0.3376 - val_loss: 0.3060 - val_accuracy: 0.9139 - val_precision_22: 0.0309 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6703 - accuracy: 0.8320 - precision_22: 0.3255 - val_loss: 0.4138 - val_accuracy: 0.9005 - val_precision_22: 0.0219 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.8365 - precision_22: 0.3523 - val_loss: 0.3339 - val_accuracy: 0.8992 - val_precision_22: 0.0216 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.8349 - precision_22: 0.3372 - val_loss: 0.3515 - val_accuracy: 0.8830 - val_precision_22: 0.0267 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4584 - accuracy: 0.8449 - precision_22: 0.3845 - val_loss: 0.4758 - val_accuracy: 0.7954 - val_precision_22: 0.0615 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.8452 - precision_22: 0.3858 - val_loss: 0.3037 - val_accuracy: 0.9066 - val_precision_22: 0.0199 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.8453 - precision_22: 0.3884 - val_loss: 1.5578 - val_accuracy: 0.6188 - val_precision_22: 0.0452 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.8381 - precision_22: 0.3436 - val_loss: 0.2816 - val_accuracy: 0.9180 - val_precision_22: 0.0177 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8491 - precision_22: 0.4106 - val_loss: 0.4193 - val_accuracy: 0.8374 - val_precision_22: 0.0458 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8512 - precision_22: 0.4237 - val_loss: 0.3518 - val_accuracy: 0.8983 - val_precision_22: 0.0249 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8544 - precision_22: 0.4610 - val_loss: 0.2146 - val_accuracy: 0.9541 - val_precision_22: 0.0037 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8576 - precision_22: 0.5035 - val_loss: 0.2755 - val_accuracy: 0.9253 - val_precision_22: 0.0089 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8578 - precision_22: 0.5066 - val_loss: 0.3328 - val_accuracy: 0.9022 - val_precision_22: 0.0649 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8496 - precision_22: 0.4173 - val_loss: 0.2490 - val_accuracy: 0.9285 - val_precision_22: 0.0141 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8536 - precision_22: 0.4546 - val_loss: 0.2703 - val_accuracy: 0.9284 - val_precision_22: 0.0216 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8599 - precision_22: 0.5416 - val_loss: 0.3324 - val_accuracy: 0.9087 - val_precision_22: 0.0422 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8545 - precision_22: 0.4639 - val_loss: 0.2214 - val_accuracy: 0.9438 - val_precision_22: 0.0024 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8523 - precision_22: 0.4396 - val_loss: 0.3144 - val_accuracy: 0.9081 - val_precision_22: 0.0203 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8586 - precision_22: 0.5176 - val_loss: 0.2934 - val_accuracy: 0.9259 - val_precision_22: 0.0148 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3931 - accuracy: 0.8571 - precision_22: 0.4965 - val_loss: 0.2594 - val_accuracy: 0.9166 - val_precision_22: 0.0137 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.8448 - precision_22: 0.3894 - val_loss: 0.4420 - val_accuracy: 0.8286 - val_precision_22: 0.0503 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8569 - precision_22: 0.4943 - val_loss: 0.3278 - val_accuracy: 0.9102 - val_precision_22: 0.0282 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 108.2331 - accuracy: 0.7656 - precision_23: 0.1620 - val_loss: 42.8258 - val_accuracy: 0.7049 - val_precision_23: 0.0161 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 66.4570 - accuracy: 0.7695 - precision_23: 0.1903 - val_loss: 27.3958 - val_accuracy: 0.9541 - val_precision_23: 0.0037 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 58.1215 - accuracy: 0.7793 - precision_23: 0.2023 - val_loss: 7.5264 - val_accuracy: 0.8253 - val_precision_23: 0.0235 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 42.9968 - accuracy: 0.7848 - precision_23: 0.2142 - val_loss: 32.0039 - val_accuracy: 0.9507 - val_precision_23: 0.0031 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 45.6582 - accuracy: 0.7819 - precision_23: 0.2128 - val_loss: 18.6042 - val_accuracy: 0.6443 - val_precision_23: 0.0138 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 46.6634 - accuracy: 0.7788 - precision_23: 0.2124 - val_loss: 12.2480 - val_accuracy: 0.9295 - val_precision_23: 0.0113 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 30.1290 - accuracy: 0.7863 - precision_23: 0.2192 - val_loss: 12.2836 - val_accuracy: 0.6756 - val_precision_23: 0.0236 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 38.3508 - accuracy: 0.7901 - precision_23: 0.2278 - val_loss: 45.0194 - val_accuracy: 0.8224 - val_precision_23: 0.0208 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 32.5939 - accuracy: 0.7942 - precision_23: 0.2314 - val_loss: 18.4105 - val_accuracy: 0.7353 - val_precision_23: 0.0177 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 26.3212 - accuracy: 0.7947 - precision_23: 0.2351 - val_loss: 5.1018 - val_accuracy: 0.7930 - val_precision_23: 0.0149 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.8763 - accuracy: 0.7977 - precision_23: 0.2399 - val_loss: 9.6035 - val_accuracy: 0.8978 - val_precision_23: 0.0113 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.6010 - accuracy: 0.7907 - precision_23: 0.2241 - val_loss: 10.2368 - val_accuracy: 0.9167 - val_precision_23: 0.0076 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.6470 - accuracy: 0.7962 - precision_23: 0.2349 - val_loss: 7.9243 - val_accuracy: 0.8443 - val_precision_23: 0.0116 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.3002 - accuracy: 0.7988 - precision_23: 0.2410 - val_loss: 64.0187 - val_accuracy: 0.5036 - val_precision_23: 0.0377 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 27.0459 - accuracy: 0.7954 - precision_23: 0.2374 - val_loss: 5.6718 - val_accuracy: 0.7959 - val_precision_23: 0.0224 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.4420 - accuracy: 0.7964 - precision_23: 0.2386 - val_loss: 46.3728 - val_accuracy: 0.4970 - val_precision_23: 0.0379 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.2819 - accuracy: 0.7993 - precision_23: 0.2438 - val_loss: 34.1039 - val_accuracy: 0.5574 - val_precision_23: 0.0389 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.8650 - accuracy: 0.7969 - precision_23: 0.2358 - val_loss: 11.8384 - val_accuracy: 0.6523 - val_precision_23: 0.0392 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.2546 - accuracy: 0.7979 - precision_23: 0.2416 - val_loss: 13.6136 - val_accuracy: 0.8194 - val_precision_23: 0.0243 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.4440 - accuracy: 0.8014 - precision_23: 0.2417 - val_loss: 27.7023 - val_accuracy: 0.4989 - val_precision_23: 0.0375 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.8784 - accuracy: 0.7998 - precision_23: 0.2413 - val_loss: 4.6192 - val_accuracy: 0.8085 - val_precision_23: 0.0171 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.7127 - accuracy: 0.8020 - precision_23: 0.2435 - val_loss: 3.1367 - val_accuracy: 0.9255 - val_precision_23: 0.0030 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.4757 - accuracy: 0.7995 - precision_23: 0.2416 - val_loss: 12.7445 - val_accuracy: 0.6003 - val_precision_23: 0.0390 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.5394 - accuracy: 0.7998 - precision_23: 0.2422 - val_loss: 4.3023 - val_accuracy: 0.8918 - val_precision_23: 0.0130 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.7783 - accuracy: 0.8074 - precision_23: 0.2590 - val_loss: 2.6879 - val_accuracy: 0.8861 - val_precision_23: 0.0138 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.6758 - accuracy: 0.7976 - precision_23: 0.2403 - val_loss: 3.0204 - val_accuracy: 0.9367 - val_precision_23: 0.0078 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 13.9369 - accuracy: 0.8029 - precision_23: 0.2438 - val_loss: 3.5231 - val_accuracy: 0.8294 - val_precision_23: 0.0213 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 6.6494 - accuracy: 0.8040 - precision_23: 0.2521 - val_loss: 2.0084 - val_accuracy: 0.8585 - val_precision_23: 0.0166 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 9.5766 - accuracy: 0.8056 - precision_23: 0.2496 - val_loss: 22.4235 - val_accuracy: 0.4680 - val_precision_23: 0.0384 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.3360 - accuracy: 0.8017 - precision_23: 0.2489 - val_loss: 1.9874 - val_accuracy: 0.9378 - val_precision_23: 0.0119 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.7091 - accuracy: 0.8055 - precision_23: 0.2592 - val_loss: 1.7128 - val_accuracy: 0.9350 - val_precision_23: 0.0110 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.1295 - accuracy: 0.8039 - precision_23: 0.2463 - val_loss: 2.5706 - val_accuracy: 0.9360 - val_precision_23: 0.0038 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.5744 - accuracy: 0.8032 - precision_23: 0.2417 - val_loss: 2.6768 - val_accuracy: 0.8522 - val_precision_23: 0.0235 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.5438 - accuracy: 0.8048 - precision_23: 0.2517 - val_loss: 1.2757 - val_accuracy: 0.9158 - val_precision_23: 0.0050 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.6893 - accuracy: 0.8051 - precision_23: 0.2436 - val_loss: 2.5843 - val_accuracy: 0.7468 - val_precision_23: 0.0378 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.2417 - accuracy: 0.8068 - precision_23: 0.2554 - val_loss: 1.1852 - val_accuracy: 0.8290 - val_precision_23: 0.0213 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.5088 - accuracy: 0.8090 - precision_23: 0.2608 - val_loss: 1.1435 - val_accuracy: 0.8684 - val_precision_23: 0.0142 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.2365 - accuracy: 0.8050 - precision_23: 0.2556 - val_loss: 1.4919 - val_accuracy: 0.9274 - val_precision_23: 0.0047 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.6365 - accuracy: 0.8087 - precision_23: 0.2584 - val_loss: 0.9216 - val_accuracy: 0.8915 - val_precision_23: 0.0205 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.3416 - accuracy: 0.8084 - precision_23: 0.2595 - val_loss: 1.0557 - val_accuracy: 0.8263 - val_precision_23: 0.0236 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.3048 - accuracy: 0.8073 - precision_23: 0.2517 - val_loss: 0.8515 - val_accuracy: 0.8235 - val_precision_23: 0.0205 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.7753 - accuracy: 0.8106 - precision_23: 0.2612 - val_loss: 0.6394 - val_accuracy: 0.8763 - val_precision_23: 0.0174 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.6546 - accuracy: 0.8092 - precision_23: 0.2619 - val_loss: 1.0009 - val_accuracy: 0.9054 - val_precision_23: 0.0105 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9065 - accuracy: 0.8116 - precision_23: 0.2724 - val_loss: 0.5831 - val_accuracy: 0.8485 - val_precision_23: 0.0265 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.3324 - accuracy: 0.8134 - precision_23: 0.2711 - val_loss: 1.5356 - val_accuracy: 0.7742 - val_precision_23: 0.0287 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9644 - accuracy: 0.8133 - precision_23: 0.2725 - val_loss: 1.0274 - val_accuracy: 0.7336 - val_precision_23: 0.0491 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7892 - accuracy: 0.8113 - precision_23: 0.2715 - val_loss: 0.5923 - val_accuracy: 0.9407 - val_precision_23: 0.0044 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4606 - accuracy: 0.8175 - precision_23: 0.2839 - val_loss: 0.7409 - val_accuracy: 0.8029 - val_precision_23: 0.0339 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4499 - accuracy: 0.8151 - precision_23: 0.2759 - val_loss: 2.1773 - val_accuracy: 0.6156 - val_precision_23: 0.0445 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.5956 - accuracy: 0.8167 - precision_23: 0.2748 - val_loss: 2.2361 - val_accuracy: 0.6052 - val_precision_23: 0.0471 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.5284 - accuracy: 0.8125 - precision_23: 0.2588 - val_loss: 0.7148 - val_accuracy: 0.8131 - val_precision_23: 0.0618 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.0378 - accuracy: 0.8167 - precision_23: 0.2699 - val_loss: 0.6011 - val_accuracy: 0.9065 - val_precision_23: 0.0267 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.0782 - accuracy: 0.8177 - precision_23: 0.2725 - val_loss: 0.4336 - val_accuracy: 0.9381 - val_precision_23: 0.0041 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8128 - accuracy: 0.8236 - precision_23: 0.2774 - val_loss: 1.4712 - val_accuracy: 0.6097 - val_precision_23: 0.0488 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9096 - accuracy: 0.8205 - precision_23: 0.2736 - val_loss: 1.1700 - val_accuracy: 0.8653 - val_precision_23: 0.0583 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9529 - accuracy: 0.8169 - precision_23: 0.2526 - val_loss: 0.9083 - val_accuracy: 0.6280 - val_precision_23: 0.0473 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7087 - accuracy: 0.8243 - precision_23: 0.2756 - val_loss: 0.2582 - val_accuracy: 0.9416 - val_precision_23: 0.0238 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8002 - accuracy: 0.8255 - precision_23: 0.2793 - val_loss: 0.6579 - val_accuracy: 0.8786 - val_precision_23: 0.0370 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.0769 - accuracy: 0.7936 - precision_23: 0.2129 - val_loss: 3.3079 - val_accuracy: 0.9194 - val_precision_23: 0.0385 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.0140 - accuracy: 0.8043 - precision_23: 0.2289 - val_loss: 0.8157 - val_accuracy: 0.7862 - val_precision_23: 0.0223 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5324 - accuracy: 0.8073 - precision_23: 0.2240 - val_loss: 0.3746 - val_accuracy: 0.9582 - val_precision_23: 0.0181 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7590 - accuracy: 0.8252 - precision_23: 0.2622 - val_loss: 0.5726 - val_accuracy: 0.7807 - val_precision_23: 0.0519 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7127 - accuracy: 0.8210 - precision_23: 0.2508 - val_loss: 0.9805 - val_accuracy: 0.6427 - val_precision_23: 0.0485 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.8235 - precision_23: 0.2531 - val_loss: 0.2591 - val_accuracy: 0.9465 - val_precision_23: 0.0230 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.8409 - precision_23: 0.3169 - val_loss: 0.3009 - val_accuracy: 0.9213 - val_precision_23: 0.0374 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.8410 - precision_23: 0.3183 - val_loss: 0.3254 - val_accuracy: 0.8865 - val_precision_23: 0.0379 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.8366 - precision_23: 0.3040 - val_loss: 0.2704 - val_accuracy: 0.9325 - val_precision_23: 0.0421 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6654 - accuracy: 0.8240 - precision_23: 0.2678 - val_loss: 1.4296 - val_accuracy: 0.8711 - val_precision_23: 0.0381 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9060 - accuracy: 0.8222 - precision_23: 0.2623 - val_loss: 0.2807 - val_accuracy: 0.9170 - val_precision_23: 0.0413 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8392 - precision_23: 0.3160 - val_loss: 0.3006 - val_accuracy: 0.9206 - val_precision_23: 0.0416 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.8392 - precision_23: 0.3255 - val_loss: 0.2359 - val_accuracy: 0.9397 - val_precision_23: 0.0395 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.8407 - precision_23: 0.3314 - val_loss: 0.3455 - val_accuracy: 0.8978 - val_precision_23: 0.0564 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.8379 - precision_23: 0.3154 - val_loss: 0.2825 - val_accuracy: 0.9286 - val_precision_23: 0.0304 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.8373 - precision_23: 0.3116 - val_loss: 0.3242 - val_accuracy: 0.8801 - val_precision_23: 0.0348 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.8367 - precision_23: 0.3163 - val_loss: 0.2429 - val_accuracy: 0.9367 - val_precision_23: 0.0208 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.0716 - accuracy: 0.8122 - precision_23: 0.2451 - val_loss: 9.8705 - val_accuracy: 0.9353 - val_precision_23: 0.0019 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.0478 - accuracy: 0.7961 - precision_23: 0.2060 - val_loss: 3.0305 - val_accuracy: 0.6434 - val_precision_23: 0.0435 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4485 - accuracy: 0.8132 - precision_23: 0.2331 - val_loss: 0.4566 - val_accuracy: 0.9525 - val_precision_23: 0.0166 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5988 - accuracy: 0.8331 - precision_23: 0.2955 - val_loss: 0.2896 - val_accuracy: 0.9178 - val_precision_23: 0.0329 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.8407 - precision_23: 0.3142 - val_loss: 0.2579 - val_accuracy: 0.9471 - val_precision_23: 0.0308 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8516 - precision_23: 0.4016 - val_loss: 0.2727 - val_accuracy: 0.9193 - val_precision_23: 0.0484 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8476 - precision_23: 0.3675 - val_loss: 0.3999 - val_accuracy: 0.8755 - val_precision_23: 0.0459 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.8459 - precision_23: 0.3577 - val_loss: 0.3639 - val_accuracy: 0.8812 - val_precision_23: 0.0735 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8514 - precision_23: 0.4014 - val_loss: 0.2560 - val_accuracy: 0.9269 - val_precision_23: 0.0414 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8517 - precision_23: 0.4127 - val_loss: 0.2258 - val_accuracy: 0.9484 - val_precision_23: 0.0348 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.7776 - accuracy: 0.8071 - precision_23: 0.2320 - val_loss: 2.1201 - val_accuracy: 0.8646 - val_precision_23: 0.0314 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.2035 - accuracy: 0.8066 - precision_23: 0.2286 - val_loss: 0.5521 - val_accuracy: 0.7751 - val_precision_23: 0.0647 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.8317 - precision_23: 0.2911 - val_loss: 0.2643 - val_accuracy: 0.9239 - val_precision_23: 0.0513 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8472 - precision_23: 0.3705 - val_loss: 0.2579 - val_accuracy: 0.9369 - val_precision_23: 0.0209 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8477 - precision_23: 0.3668 - val_loss: 0.2916 - val_accuracy: 0.9035 - val_precision_23: 0.0348 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8456 - precision_23: 0.3646 - val_loss: 0.2310 - val_accuracy: 0.9487 - val_precision_23: 0.0678 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8510 - precision_23: 0.4092 - val_loss: 0.2079 - val_accuracy: 0.9538 - val_precision_23: 0.0072 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8544 - precision_23: 0.4515 - val_loss: 0.2359 - val_accuracy: 0.9432 - val_precision_23: 0.0571 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8558 - precision_23: 0.4714 - val_loss: 0.3900 - val_accuracy: 0.8429 - val_precision_23: 0.0647 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8522 - precision_23: 0.4209 - val_loss: 0.2686 - val_accuracy: 0.9233 - val_precision_23: 0.0387 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8523 - precision_23: 0.4280 - val_loss: 1.4219 - val_accuracy: 0.6354 - val_precision_23: 0.0496 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.8467 - precision_23: 0.3712 - val_loss: 0.2213 - val_accuracy: 0.9411 - val_precision_23: 0.0295 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8529 - precision_23: 0.4318 - val_loss: 0.2915 - val_accuracy: 0.8892 - val_precision_23: 0.0316 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8561 - precision_23: 0.4746 - val_loss: 0.2433 - val_accuracy: 0.9274 - val_precision_23: 0.0283 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 11.0837 - accuracy: 0.8151 - precision_23: 0.2553 - val_loss: 3.5990 - val_accuracy: 0.9337 - val_precision_23: 0.0402 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 789.5082 - accuracy: 0.7562 - precision_24: 0.1597 - val_loss: 29.6637 - val_accuracy: 0.8986 - val_precision_24: 0.0295 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 67.7812 - accuracy: 0.7835 - precision_24: 0.1889 - val_loss: 28.0317 - val_accuracy: 0.9506 - val_precision_24: 0.0156 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 76.4611 - accuracy: 0.7893 - precision_24: 0.1980 - val_loss: 42.7172 - val_accuracy: 0.9643 - val_precision_24: 0.0233 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 71.4581 - accuracy: 0.7918 - precision_24: 0.2106 - val_loss: 45.4948 - val_accuracy: 0.9269 - val_precision_24: 0.0296 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 64.2219 - accuracy: 0.7919 - precision_24: 0.2046 - val_loss: 125.0893 - val_accuracy: 0.5849 - val_precision_24: 0.0422 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 55.4424 - accuracy: 0.7889 - precision_24: 0.2052 - val_loss: 25.9880 - val_accuracy: 0.8937 - val_precision_24: 0.0228 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 67.2684 - accuracy: 0.7916 - precision_24: 0.2091 - val_loss: 17.1759 - val_accuracy: 0.9378 - val_precision_24: 0.0198 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 48.2109 - accuracy: 0.7969 - precision_24: 0.2242 - val_loss: 89.2024 - val_accuracy: 0.5539 - val_precision_24: 0.0410 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 47.8737 - accuracy: 0.7943 - precision_24: 0.2206 - val_loss: 8.4849 - val_accuracy: 0.8472 - val_precision_24: 0.0179 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 39.3251 - accuracy: 0.7934 - precision_24: 0.2242 - val_loss: 7.6375 - val_accuracy: 0.8394 - val_precision_24: 0.0307 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 33.0856 - accuracy: 0.7951 - precision_24: 0.2251 - val_loss: 33.9840 - val_accuracy: 0.6524 - val_precision_24: 0.0425 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 32.3087 - accuracy: 0.7977 - precision_24: 0.2308 - val_loss: 7.2767 - val_accuracy: 0.8651 - val_precision_24: 0.0357 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 26.5152 - accuracy: 0.8012 - precision_24: 0.2344 - val_loss: 6.0440 - val_accuracy: 0.9029 - val_precision_24: 0.0092 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.6397 - accuracy: 0.7985 - precision_24: 0.2393 - val_loss: 45.0212 - val_accuracy: 0.6016 - val_precision_24: 0.0438 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 38.2314 - accuracy: 0.7962 - precision_24: 0.2303 - val_loss: 7.3243 - val_accuracy: 0.9314 - val_precision_24: 0.0086 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.3373 - accuracy: 0.7968 - precision_24: 0.2295 - val_loss: 7.2304 - val_accuracy: 0.8580 - val_precision_24: 0.0099 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.7996 - accuracy: 0.7988 - precision_24: 0.2402 - val_loss: 8.4773 - val_accuracy: 0.8194 - val_precision_24: 0.0170 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.6962 - accuracy: 0.7961 - precision_24: 0.2353 - val_loss: 10.6043 - val_accuracy: 0.9189 - val_precision_24: 0.0181 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.4823 - accuracy: 0.8022 - precision_24: 0.2400 - val_loss: 3.3057 - val_accuracy: 0.7611 - val_precision_24: 0.0211 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 33.8134 - accuracy: 0.7964 - precision_24: 0.2248 - val_loss: 48.2631 - val_accuracy: 0.5515 - val_precision_24: 0.0426 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 23.9116 - accuracy: 0.7970 - precision_24: 0.2301 - val_loss: 8.2881 - val_accuracy: 0.9338 - val_precision_24: 0.0178 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 14.4591 - accuracy: 0.8016 - precision_24: 0.2376 - val_loss: 3.0412 - val_accuracy: 0.8498 - val_precision_24: 0.0242 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 19.1159 - accuracy: 0.8010 - precision_24: 0.2379 - val_loss: 17.3482 - val_accuracy: 0.6177 - val_precision_24: 0.0428 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 11.3463 - accuracy: 0.8027 - precision_24: 0.2454 - val_loss: 4.8279 - val_accuracy: 0.7701 - val_precision_24: 0.0360 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.6206 - accuracy: 0.8025 - precision_24: 0.2403 - val_loss: 2.8351 - val_accuracy: 0.8484 - val_precision_24: 0.0261 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.1213 - accuracy: 0.8003 - precision_24: 0.2379 - val_loss: 3.0113 - val_accuracy: 0.8106 - val_precision_24: 0.0173 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.0750 - accuracy: 0.8026 - precision_24: 0.2453 - val_loss: 2.6689 - val_accuracy: 0.8752 - val_precision_24: 0.0186 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.0059 - accuracy: 0.8001 - precision_24: 0.2407 - val_loss: 2.4035 - val_accuracy: 0.8700 - val_precision_24: 0.0164 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.9775 - accuracy: 0.8008 - precision_24: 0.2369 - val_loss: 2.5390 - val_accuracy: 0.8931 - val_precision_24: 0.0193 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.7102 - accuracy: 0.8050 - precision_24: 0.2448 - val_loss: 18.2356 - val_accuracy: 0.5684 - val_precision_24: 0.0402 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.2488 - accuracy: 0.8024 - precision_24: 0.2448 - val_loss: 2.2186 - val_accuracy: 0.8310 - val_precision_24: 0.0145 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.9592 - accuracy: 0.8031 - precision_24: 0.2413 - val_loss: 1.7539 - val_accuracy: 0.8381 - val_precision_24: 0.0177 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.6934 - accuracy: 0.8007 - precision_24: 0.2341 - val_loss: 1.6871 - val_accuracy: 0.8952 - val_precision_24: 0.0119 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.3259 - accuracy: 0.8037 - precision_24: 0.2422 - val_loss: 19.2249 - val_accuracy: 0.5672 - val_precision_24: 0.0437 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.5550 - accuracy: 0.8011 - precision_24: 0.2339 - val_loss: 2.0940 - val_accuracy: 0.9262 - val_precision_24: 0.0121 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.0146 - accuracy: 0.8008 - precision_24: 0.2412 - val_loss: 1.4406 - val_accuracy: 0.9496 - val_precision_24: 0.0031 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.9052 - accuracy: 0.8031 - precision_24: 0.2404 - val_loss: 1.0798 - val_accuracy: 0.8870 - val_precision_24: 0.0195 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.0664 - accuracy: 0.8066 - precision_24: 0.2479 - val_loss: 1.5428 - val_accuracy: 0.9252 - val_precision_24: 0.0015 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.0758 - accuracy: 0.8019 - precision_24: 0.2365 - val_loss: 0.8342 - val_accuracy: 0.8442 - val_precision_24: 0.0237 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.6190 - accuracy: 0.8090 - precision_24: 0.2606 - val_loss: 0.7320 - val_accuracy: 0.8965 - val_precision_24: 0.0218 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.1235 - accuracy: 0.8085 - precision_24: 0.2528 - val_loss: 2.4298 - val_accuracy: 0.5379 - val_precision_24: 0.0409 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5289 - accuracy: 0.8056 - precision_24: 0.2472 - val_loss: 0.9314 - val_accuracy: 0.8941 - val_precision_24: 0.0204 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3266 - accuracy: 0.8130 - precision_24: 0.2604 - val_loss: 0.5087 - val_accuracy: 0.9146 - val_precision_24: 0.0326 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5461 - accuracy: 0.8055 - precision_24: 0.2479 - val_loss: 0.8089 - val_accuracy: 0.9611 - val_precision_24: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 1.0013 - accuracy: 0.8111 - precision_24: 0.2512 - val_loss: 0.4704 - val_accuracy: 0.9328 - val_precision_24: 0.0367 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8206 - accuracy: 0.8176 - precision_24: 0.2623 - val_loss: 0.5357 - val_accuracy: 0.9418 - val_precision_24: 0.0385 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8410 - accuracy: 0.8134 - precision_24: 0.2548 - val_loss: 0.7884 - val_accuracy: 0.7000 - val_precision_24: 0.0494 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7186 - accuracy: 0.8174 - precision_24: 0.2577 - val_loss: 0.3671 - val_accuracy: 0.8961 - val_precision_24: 0.0352 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5458 - accuracy: 0.8302 - precision_24: 0.2930 - val_loss: 0.3465 - val_accuracy: 0.9294 - val_precision_24: 0.0370 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.8332 - precision_24: 0.2949 - val_loss: 0.4389 - val_accuracy: 0.8434 - val_precision_24: 0.0301 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.8274 - precision_24: 0.2793 - val_loss: 0.2479 - val_accuracy: 0.9559 - val_precision_24: 0.0163 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.8359 - precision_24: 0.3095 - val_loss: 0.6204 - val_accuracy: 0.7332 - val_precision_24: 0.0579 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.8338 - precision_24: 0.3015 - val_loss: 0.2991 - val_accuracy: 0.9391 - val_precision_24: 0.0282 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.8313 - precision_24: 0.2920 - val_loss: 0.2419 - val_accuracy: 0.9548 - val_precision_24: 0.0078 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.8344 - precision_24: 0.2957 - val_loss: 0.3305 - val_accuracy: 0.8913 - val_precision_24: 0.0254 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.8319 - precision_24: 0.2934 - val_loss: 0.4858 - val_accuracy: 0.8035 - val_precision_24: 0.0198 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.8349 - precision_24: 0.3081 - val_loss: 0.3051 - val_accuracy: 0.9122 - val_precision_24: 0.0303 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.8278 - precision_24: 0.2849 - val_loss: 0.4992 - val_accuracy: 0.9325 - val_precision_24: 0.0456 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3460 - accuracy: 0.8146 - precision_24: 0.2595 - val_loss: 2.2023 - val_accuracy: 0.5983 - val_precision_24: 0.0481 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8630 - accuracy: 0.8169 - precision_24: 0.2543 - val_loss: 0.3834 - val_accuracy: 0.8798 - val_precision_24: 0.0322 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.8379 - precision_24: 0.3176 - val_loss: 0.5008 - val_accuracy: 0.7954 - val_precision_24: 0.0209 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9941 - accuracy: 0.8131 - precision_24: 0.2500 - val_loss: 0.5784 - val_accuracy: 0.8544 - val_precision_24: 0.0268 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4212 - accuracy: 0.8340 - precision_24: 0.2860 - val_loss: 0.4839 - val_accuracy: 0.8342 - val_precision_24: 0.0235 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8552 - precision_24: 0.4516 - val_loss: 0.2711 - val_accuracy: 0.9507 - val_precision_24: 0.0360 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8568 - precision_24: 0.4842 - val_loss: 0.3029 - val_accuracy: 0.9214 - val_precision_24: 0.0292 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8566 - precision_24: 0.4787 - val_loss: 0.3180 - val_accuracy: 0.9027 - val_precision_24: 0.0246 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8577 - precision_24: 0.5029 - val_loss: 0.2401 - val_accuracy: 0.9500 - val_precision_24: 0.0350 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8571 - precision_24: 0.4896 - val_loss: 0.2869 - val_accuracy: 0.9116 - val_precision_24: 0.0301 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8583 - precision_24: 0.5161 - val_loss: 0.3755 - val_accuracy: 0.8539 - val_precision_24: 0.0294 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8569 - precision_24: 0.4876 - val_loss: 0.2259 - val_accuracy: 0.9403 - val_precision_24: 0.0272 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3747 - accuracy: 0.8575 - precision_24: 0.4988 - val_loss: 0.2267 - val_accuracy: 0.9542 - val_precision_24: 0.0112 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8563 - precision_24: 0.4750 - val_loss: 0.3720 - val_accuracy: 0.8612 - val_precision_24: 0.0312 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8583 - precision_24: 0.5176 - val_loss: 0.2645 - val_accuracy: 0.9254 - val_precision_24: 0.0341 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3719 - accuracy: 0.8593 - precision_24: 0.5394 - val_loss: 0.2315 - val_accuracy: 0.9472 - val_precision_24: 0.0363 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8597 - precision_24: 0.5491 - val_loss: 0.2033 - val_accuracy: 0.9556 - val_precision_24: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8588 - precision_24: 0.5273 - val_loss: 0.2822 - val_accuracy: 0.9146 - val_precision_24: 0.0494 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8596 - precision_24: 0.5494 - val_loss: 0.3030 - val_accuracy: 0.9023 - val_precision_24: 0.0398 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8580 - precision_24: 0.5095 - val_loss: 0.2799 - val_accuracy: 0.9135 - val_precision_24: 0.0486 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8589 - precision_24: 0.5300 - val_loss: 0.2106 - val_accuracy: 0.9490 - val_precision_24: 0.0030 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8602 - precision_24: 0.5643 - val_loss: 0.3006 - val_accuracy: 0.9043 - val_precision_24: 0.0299 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8590 - precision_24: 0.5315 - val_loss: 0.2679 - val_accuracy: 0.9268 - val_precision_24: 0.0482 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8596 - precision_24: 0.5476 - val_loss: 0.2613 - val_accuracy: 0.9262 - val_precision_24: 0.0346 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8608 - precision_24: 0.5780 - val_loss: 0.2710 - val_accuracy: 0.9179 - val_precision_24: 0.0467 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3661 - accuracy: 0.8601 - precision_24: 0.5619 - val_loss: 0.3132 - val_accuracy: 0.8972 - val_precision_24: 0.0390 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8602 - precision_24: 0.5574 - val_loss: 0.2330 - val_accuracy: 0.9459 - val_precision_24: 0.0155 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8588 - precision_24: 0.5276 - val_loss: 0.3105 - val_accuracy: 0.8921 - val_precision_24: 0.0182 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8603 - precision_24: 0.5660 - val_loss: 0.2057 - val_accuracy: 0.9561 - val_precision_24: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8607 - precision_24: 0.5732 - val_loss: 0.2502 - val_accuracy: 0.9407 - val_precision_24: 0.0430 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8598 - precision_24: 0.5484 - val_loss: 0.4027 - val_accuracy: 0.8315 - val_precision_24: 0.0273 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8591 - precision_24: 0.5318 - val_loss: 0.1905 - val_accuracy: 0.9630 - val_precision_24: 0.0331 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8596 - precision_24: 0.5449 - val_loss: 0.2054 - val_accuracy: 0.9568 - val_precision_24: 0.0369 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8608 - precision_24: 0.5703 - val_loss: 0.2545 - val_accuracy: 0.9278 - val_precision_24: 0.0273 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8605 - precision_24: 0.5652 - val_loss: 0.2350 - val_accuracy: 0.9445 - val_precision_24: 0.0502 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8606 - precision_24: 0.5660 - val_loss: 0.2718 - val_accuracy: 0.9198 - val_precision_24: 0.0481 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8613 - precision_24: 0.5820 - val_loss: 0.3108 - val_accuracy: 0.9037 - val_precision_24: 0.0370 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8606 - precision_24: 0.5692 - val_loss: 0.3060 - val_accuracy: 0.8956 - val_precision_24: 0.0382 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3674 - accuracy: 0.8607 - precision_24: 0.5666 - val_loss: 0.2628 - val_accuracy: 0.9240 - val_precision_24: 0.0345 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3618 - accuracy: 0.8622 - precision_24: 0.6014 - val_loss: 0.2932 - val_accuracy: 0.9127 - val_precision_24: 0.0241 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3662 - accuracy: 0.8606 - precision_24: 0.5656 - val_loss: 0.2758 - val_accuracy: 0.9143 - val_precision_24: 0.0441 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3643 - accuracy: 0.8613 - precision_24: 0.5792 - val_loss: 0.2723 - val_accuracy: 0.9249 - val_precision_24: 0.0351 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 349.3000 - accuracy: 0.7674 - precision_25: 0.1681 - val_loss: 49.7625 - val_accuracy: 0.9463 - val_precision_25: 0.0187 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 78.9660 - accuracy: 0.7825 - precision_25: 0.1968 - val_loss: 13.6526 - val_accuracy: 0.8551 - val_precision_25: 0.0276 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 63.9551 - accuracy: 0.7886 - precision_25: 0.2043 - val_loss: 9.3283 - val_accuracy: 0.7353 - val_precision_25: 0.0273 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 71.5806 - accuracy: 0.7880 - precision_25: 0.2150 - val_loss: 9.4899 - val_accuracy: 0.9521 - val_precision_25: 0.0301 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 70.7191 - accuracy: 0.7927 - precision_25: 0.2162 - val_loss: 15.6351 - val_accuracy: 0.9141 - val_precision_25: 0.0338 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 48.8310 - accuracy: 0.7913 - precision_25: 0.2114 - val_loss: 11.9156 - val_accuracy: 0.7981 - val_precision_25: 0.0390 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 49.3462 - accuracy: 0.7933 - precision_25: 0.2201 - val_loss: 14.6710 - val_accuracy: 0.9040 - val_precision_25: 0.0365 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 38.4091 - accuracy: 0.7921 - precision_25: 0.2271 - val_loss: 11.1390 - val_accuracy: 0.9362 - val_precision_25: 0.0212 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 63.2177 - accuracy: 0.7890 - precision_25: 0.2144 - val_loss: 45.6840 - val_accuracy: 0.9595 - val_precision_25: 0.0109 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 43.0355 - accuracy: 0.7891 - precision_25: 0.2201 - val_loss: 16.7813 - val_accuracy: 0.9112 - val_precision_25: 0.0323 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 37.9400 - accuracy: 0.7962 - precision_25: 0.2279 - val_loss: 12.8085 - val_accuracy: 0.9210 - val_precision_25: 0.0293 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 31.0508 - accuracy: 0.7919 - precision_25: 0.2223 - val_loss: 11.8321 - val_accuracy: 0.9561 - val_precision_25: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 27.1375 - accuracy: 0.7991 - precision_25: 0.2343 - val_loss: 10.8975 - val_accuracy: 0.8504 - val_precision_25: 0.0282 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 27.9429 - accuracy: 0.7953 - precision_25: 0.2248 - val_loss: 7.5195 - val_accuracy: 0.7842 - val_precision_25: 0.0212 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 44.2283 - accuracy: 0.7971 - precision_25: 0.2269 - val_loss: 18.2973 - val_accuracy: 0.5634 - val_precision_25: 0.0414 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 21.1015 - accuracy: 0.7999 - precision_25: 0.2331 - val_loss: 8.6600 - val_accuracy: 0.9306 - val_precision_25: 0.0119 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 22.0858 - accuracy: 0.7985 - precision_25: 0.2361 - val_loss: 19.4591 - val_accuracy: 0.9242 - val_precision_25: 0.0271 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 46.5489 - accuracy: 0.7950 - precision_25: 0.2186 - val_loss: 10.1496 - val_accuracy: 0.8623 - val_precision_25: 0.0293 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 17.2833 - accuracy: 0.7969 - precision_25: 0.2320 - val_loss: 5.6325 - val_accuracy: 0.8630 - val_precision_25: 0.0295 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 18.0682 - accuracy: 0.7939 - precision_25: 0.2280 - val_loss: 7.8232 - val_accuracy: 0.9177 - val_precision_25: 0.0241 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.1696 - accuracy: 0.8015 - precision_25: 0.2381 - val_loss: 15.1477 - val_accuracy: 0.8761 - val_precision_25: 0.0285 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.6746 - accuracy: 0.7989 - precision_25: 0.2321 - val_loss: 8.7408 - val_accuracy: 0.9319 - val_precision_25: 0.0411 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.8933 - accuracy: 0.7993 - precision_25: 0.2324 - val_loss: 3.1104 - val_accuracy: 0.8636 - val_precision_25: 0.0248 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.1353 - accuracy: 0.7949 - precision_25: 0.2289 - val_loss: 15.1595 - val_accuracy: 0.9384 - val_precision_25: 0.0145 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.4448 - accuracy: 0.7985 - precision_25: 0.2280 - val_loss: 5.7779 - val_accuracy: 0.6716 - val_precision_25: 0.0400 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.9948 - accuracy: 0.8023 - precision_25: 0.2442 - val_loss: 2.9884 - val_accuracy: 0.8260 - val_precision_25: 0.0356 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.1311 - accuracy: 0.8016 - precision_25: 0.2409 - val_loss: 6.6285 - val_accuracy: 0.9353 - val_precision_25: 0.0133 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.7502 - accuracy: 0.7997 - precision_25: 0.2414 - val_loss: 5.2375 - val_accuracy: 0.9058 - val_precision_25: 0.0219 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.6292 - accuracy: 0.7988 - precision_25: 0.2343 - val_loss: 7.2062 - val_accuracy: 0.9273 - val_precision_25: 0.0230 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.1927 - accuracy: 0.8012 - precision_25: 0.2357 - val_loss: 10.9758 - val_accuracy: 0.6702 - val_precision_25: 0.0470 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.1037 - accuracy: 0.8014 - precision_25: 0.2408 - val_loss: 3.2210 - val_accuracy: 0.8501 - val_precision_25: 0.0249 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.9695 - accuracy: 0.8026 - precision_25: 0.2457 - val_loss: 2.6916 - val_accuracy: 0.8636 - val_precision_25: 0.0206 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.8416 - accuracy: 0.8016 - precision_25: 0.2390 - val_loss: 11.9508 - val_accuracy: 0.6399 - val_precision_25: 0.0469 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.6168 - accuracy: 0.8028 - precision_25: 0.2432 - val_loss: 11.8882 - val_accuracy: 0.6244 - val_precision_25: 0.0461 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.2800 - accuracy: 0.7991 - precision_25: 0.2345 - val_loss: 2.1361 - val_accuracy: 0.9076 - val_precision_25: 0.0246 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.0829 - accuracy: 0.8030 - precision_25: 0.2451 - val_loss: 6.6471 - val_accuracy: 0.6789 - val_precision_25: 0.0501 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.0585 - accuracy: 0.8017 - precision_25: 0.2436 - val_loss: 2.7017 - val_accuracy: 0.9323 - val_precision_25: 0.0071 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.6379 - accuracy: 0.8053 - precision_25: 0.2493 - val_loss: 7.3768 - val_accuracy: 0.6293 - val_precision_25: 0.0458 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.2006 - accuracy: 0.8039 - precision_25: 0.2518 - val_loss: 1.4062 - val_accuracy: 0.8513 - val_precision_25: 0.0197 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.3628 - accuracy: 0.8025 - precision_25: 0.2493 - val_loss: 2.4232 - val_accuracy: 0.9185 - val_precision_25: 0.0280 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.7514 - accuracy: 0.8033 - precision_25: 0.2516 - val_loss: 1.1491 - val_accuracy: 0.8291 - val_precision_25: 0.0162 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.8840 - accuracy: 0.8055 - precision_25: 0.2460 - val_loss: 1.1691 - val_accuracy: 0.7436 - val_precision_25: 0.0476 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.5484 - accuracy: 0.8072 - precision_25: 0.2542 - val_loss: 1.2296 - val_accuracy: 0.7802 - val_precision_25: 0.0526 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 3.1072 - accuracy: 0.8045 - precision_25: 0.2436 - val_loss: 3.8726 - val_accuracy: 0.6199 - val_precision_25: 0.0445 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.5269 - accuracy: 0.8049 - precision_25: 0.2522 - val_loss: 2.2095 - val_accuracy: 0.6778 - val_precision_25: 0.0430 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.3952 - accuracy: 0.8058 - precision_25: 0.2429 - val_loss: 1.0650 - val_accuracy: 0.7844 - val_precision_25: 0.0481 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.0372 - accuracy: 0.8035 - precision_25: 0.2369 - val_loss: 0.7471 - val_accuracy: 0.8813 - val_precision_25: 0.0244 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4695 - accuracy: 0.8089 - precision_25: 0.2452 - val_loss: 1.0381 - val_accuracy: 0.9103 - val_precision_25: 0.0103 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4313 - accuracy: 0.8093 - precision_25: 0.2509 - val_loss: 0.7039 - val_accuracy: 0.7838 - val_precision_25: 0.0183 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2004 - accuracy: 0.8128 - precision_25: 0.2617 - val_loss: 0.4561 - val_accuracy: 0.9284 - val_precision_25: 0.0191 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1126 - accuracy: 0.8139 - precision_25: 0.2564 - val_loss: 0.7149 - val_accuracy: 0.9565 - val_precision_25: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1294 - accuracy: 0.8131 - precision_25: 0.2527 - val_loss: 0.9302 - val_accuracy: 0.7497 - val_precision_25: 0.0390 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9340 - accuracy: 0.8128 - precision_25: 0.2460 - val_loss: 0.4701 - val_accuracy: 0.9021 - val_precision_25: 0.0208 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8904 - accuracy: 0.8140 - precision_25: 0.2492 - val_loss: 0.5184 - val_accuracy: 0.9168 - val_precision_25: 0.0103 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7765 - accuracy: 0.8198 - precision_25: 0.2680 - val_loss: 0.5535 - val_accuracy: 0.9090 - val_precision_25: 0.0240 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9074 - accuracy: 0.8177 - precision_25: 0.2512 - val_loss: 0.9771 - val_accuracy: 0.5868 - val_precision_25: 0.0487 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0209 - accuracy: 0.8076 - precision_25: 0.2376 - val_loss: 0.3251 - val_accuracy: 0.9273 - val_precision_25: 0.0095 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7027 - accuracy: 0.8233 - precision_25: 0.2661 - val_loss: 0.7403 - val_accuracy: 0.8930 - val_precision_25: 0.0261 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8974 - accuracy: 0.8166 - precision_25: 0.2506 - val_loss: 0.3792 - val_accuracy: 0.8884 - val_precision_25: 0.0176 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8022 - accuracy: 0.8171 - precision_25: 0.2557 - val_loss: 1.9063 - val_accuracy: 0.5112 - val_precision_25: 0.0432 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.8284 - precision_25: 0.2887 - val_loss: 0.6541 - val_accuracy: 0.6924 - val_precision_25: 0.0589 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.8336 - precision_25: 0.2999 - val_loss: 0.4485 - val_accuracy: 0.8378 - val_precision_25: 0.0276 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.8331 - precision_25: 0.2943 - val_loss: 0.3897 - val_accuracy: 0.8744 - val_precision_25: 0.0179 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2965 - accuracy: 0.8172 - precision_25: 0.2525 - val_loss: 1.4873 - val_accuracy: 0.5733 - val_precision_25: 0.0484 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0458 - accuracy: 0.8175 - precision_25: 0.2499 - val_loss: 4.8730 - val_accuracy: 0.5834 - val_precision_25: 0.0462 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.5348 - accuracy: 0.7965 - precision_25: 0.2188 - val_loss: 0.4661 - val_accuracy: 0.9157 - val_precision_25: 0.0233 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9399 - accuracy: 0.8191 - precision_25: 0.2502 - val_loss: 0.2962 - val_accuracy: 0.9110 - val_precision_25: 0.0138 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.8378 - precision_25: 0.3036 - val_loss: 1.1162 - val_accuracy: 0.6444 - val_precision_25: 0.0515 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.8322 - precision_25: 0.2991 - val_loss: 0.2867 - val_accuracy: 0.9301 - val_precision_25: 0.0337 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4272 - accuracy: 0.8485 - precision_25: 0.3767 - val_loss: 0.2777 - val_accuracy: 0.9205 - val_precision_25: 0.0303 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8452 - precision_25: 0.3576 - val_loss: 0.3276 - val_accuracy: 0.8913 - val_precision_25: 0.0366 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.9391 - accuracy: 0.8354 - precision_25: 0.3057 - val_loss: 5.2315 - val_accuracy: 0.8790 - val_precision_25: 0.0245 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.5777 - accuracy: 0.8000 - precision_25: 0.2388 - val_loss: 0.7315 - val_accuracy: 0.8881 - val_precision_25: 0.0231 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7971 - accuracy: 0.8102 - precision_25: 0.2550 - val_loss: 0.4745 - val_accuracy: 0.8809 - val_precision_25: 0.0199 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8328 - accuracy: 0.8191 - precision_25: 0.2677 - val_loss: 0.3621 - val_accuracy: 0.9194 - val_precision_25: 0.0345 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.8351 - precision_25: 0.3107 - val_loss: 0.2992 - val_accuracy: 0.9171 - val_precision_25: 0.0433 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8432 - precision_25: 0.3424 - val_loss: 0.3760 - val_accuracy: 0.8536 - val_precision_25: 0.0251 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.8422 - precision_25: 0.3397 - val_loss: 0.2504 - val_accuracy: 0.9426 - val_precision_25: 0.0382 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8457 - precision_25: 0.3580 - val_loss: 0.3128 - val_accuracy: 0.8966 - val_precision_25: 0.0446 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8528 - precision_25: 0.4264 - val_loss: 0.3908 - val_accuracy: 0.8666 - val_precision_25: 0.0280 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8497 - precision_25: 0.3959 - val_loss: 0.2508 - val_accuracy: 0.9303 - val_precision_25: 0.0246 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.8454 - precision_25: 0.3606 - val_loss: 2.4102 - val_accuracy: 0.8422 - val_precision_25: 0.0275 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.0087 - accuracy: 0.7967 - precision_25: 0.2211 - val_loss: 0.3128 - val_accuracy: 0.9208 - val_precision_25: 0.0390 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.8548 - precision_25: 0.4451 - val_loss: 0.2394 - val_accuracy: 0.9519 - val_precision_25: 0.0564 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8569 - precision_25: 0.4921 - val_loss: 0.2184 - val_accuracy: 0.9600 - val_precision_25: 0.0609 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8581 - precision_25: 0.5222 - val_loss: 0.2626 - val_accuracy: 0.9450 - val_precision_25: 0.0584 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8589 - precision_25: 0.5424 - val_loss: 0.2163 - val_accuracy: 0.9619 - val_precision_25: 0.0196 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8597 - precision_25: 0.5660 - val_loss: 0.2453 - val_accuracy: 0.9402 - val_precision_25: 0.0336 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8592 - precision_25: 0.5487 - val_loss: 0.2708 - val_accuracy: 0.9246 - val_precision_25: 0.0287 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8584 - precision_25: 0.5287 - val_loss: 0.2322 - val_accuracy: 0.9562 - val_precision_25: 0.0482 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8589 - precision_25: 0.5410 - val_loss: 0.2131 - val_accuracy: 0.9641 - val_precision_25: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8587 - precision_25: 0.5372 - val_loss: 0.2702 - val_accuracy: 0.9270 - val_precision_25: 0.0215 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3688 - accuracy: 0.8599 - precision_25: 0.5651 - val_loss: 0.2929 - val_accuracy: 0.9127 - val_precision_25: 0.0255 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3763 - accuracy: 0.8586 - precision_25: 0.5324 - val_loss: 0.2642 - val_accuracy: 0.9160 - val_precision_25: 0.0257 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3708 - accuracy: 0.8593 - precision_25: 0.5522 - val_loss: 0.1805 - val_accuracy: 0.9674 - val_precision_25: 0.0263 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8581 - precision_25: 0.5210 - val_loss: 0.2101 - val_accuracy: 0.9487 - val_precision_25: 0.0030 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8601 - precision_25: 0.5666 - val_loss: 0.3013 - val_accuracy: 0.9048 - val_precision_25: 0.0495 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8578 - precision_25: 0.5114 - val_loss: 0.3070 - val_accuracy: 0.8845 - val_precision_25: 0.0252 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8599 - precision_25: 0.5641 - val_loss: 0.1990 - val_accuracy: 0.9613 - val_precision_25: 0.0186 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8587 - precision_25: 0.5331 - val_loss: 0.2580 - val_accuracy: 0.9314 - val_precision_25: 0.0580 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 228.2723 - accuracy: 0.7645 - precision_26: 0.1651 - val_loss: 29.0749 - val_accuracy: 0.9424 - val_precision_26: 0.0049 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 148.0138 - accuracy: 0.7705 - precision_26: 0.1854 - val_loss: 156.1860 - val_accuracy: 0.6312 - val_precision_26: 0.0494 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 124.2837 - accuracy: 0.7780 - precision_26: 0.1967 - val_loss: 72.1650 - val_accuracy: 0.7130 - val_precision_26: 0.0156 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 85.6900 - accuracy: 0.7770 - precision_26: 0.2022 - val_loss: 25.9385 - val_accuracy: 0.8206 - val_precision_26: 0.0239 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 97.1404 - accuracy: 0.7806 - precision_26: 0.2084 - val_loss: 346.1258 - val_accuracy: 0.5270 - val_precision_26: 0.0425 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 76.0867 - accuracy: 0.7812 - precision_26: 0.2104 - val_loss: 103.7477 - val_accuracy: 0.4878 - val_precision_26: 0.0424 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 96.8509 - accuracy: 0.7820 - precision_26: 0.2178 - val_loss: 41.9080 - val_accuracy: 0.9620 - val_precision_26: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 64.3898 - accuracy: 0.7892 - precision_26: 0.2267 - val_loss: 11.6757 - val_accuracy: 0.8094 - val_precision_26: 0.0173 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 54.0193 - accuracy: 0.7875 - precision_26: 0.2238 - val_loss: 30.8082 - val_accuracy: 0.9543 - val_precision_26: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 57.7512 - accuracy: 0.7899 - precision_26: 0.2261 - val_loss: 18.2628 - val_accuracy: 0.7611 - val_precision_26: 0.0212 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 61.2957 - accuracy: 0.7892 - precision_26: 0.2189 - val_loss: 11.2274 - val_accuracy: 0.8283 - val_precision_26: 0.0246 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 57.5029 - accuracy: 0.7903 - precision_26: 0.2273 - val_loss: 27.3400 - val_accuracy: 0.9087 - val_precision_26: 0.0079 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 52.7801 - accuracy: 0.7942 - precision_26: 0.2278 - val_loss: 73.5447 - val_accuracy: 0.5999 - val_precision_26: 0.0451 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 46.9894 - accuracy: 0.7952 - precision_26: 0.2374 - val_loss: 10.5988 - val_accuracy: 0.8572 - val_precision_26: 0.0236 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 59.4640 - accuracy: 0.7880 - precision_26: 0.2202 - val_loss: 23.0682 - val_accuracy: 0.9350 - val_precision_26: 0.0039 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 62.3861 - accuracy: 0.7958 - precision_26: 0.2297 - val_loss: 17.7510 - val_accuracy: 0.8022 - val_precision_26: 0.0234 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 63.0624 - accuracy: 0.7934 - precision_26: 0.2309 - val_loss: 15.8571 - val_accuracy: 0.9050 - val_precision_26: 0.0064 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 42.8932 - accuracy: 0.7954 - precision_26: 0.2374 - val_loss: 26.3189 - val_accuracy: 0.8480 - val_precision_26: 0.0230 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 56.8050 - accuracy: 0.7944 - precision_26: 0.2359 - val_loss: 18.4765 - val_accuracy: 0.8575 - val_precision_26: 0.0305 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 39.1082 - accuracy: 0.7983 - precision_26: 0.2393 - val_loss: 34.3767 - val_accuracy: 0.9429 - val_precision_26: 0.0098 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 39.2825 - accuracy: 0.8001 - precision_26: 0.2457 - val_loss: 10.2272 - val_accuracy: 0.8872 - val_precision_26: 0.0126 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 43.8517 - accuracy: 0.7965 - precision_26: 0.2403 - val_loss: 6.3296 - val_accuracy: 0.8384 - val_precision_26: 0.0293 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 38.1168 - accuracy: 0.7990 - precision_26: 0.2482 - val_loss: 10.1150 - val_accuracy: 0.8807 - val_precision_26: 0.0162 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 47.6340 - accuracy: 0.7994 - precision_26: 0.2432 - val_loss: 19.2401 - val_accuracy: 0.8591 - val_precision_26: 0.0187 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 36.0874 - accuracy: 0.7990 - precision_26: 0.2386 - val_loss: 22.5939 - val_accuracy: 0.9224 - val_precision_26: 0.0101 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 57.6972 - accuracy: 0.7993 - precision_26: 0.2433 - val_loss: 7.6572 - val_accuracy: 0.7291 - val_precision_26: 0.0456 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.2455 - accuracy: 0.7979 - precision_26: 0.2456 - val_loss: 12.0926 - val_accuracy: 0.8545 - val_precision_26: 0.0248 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 28.7349 - accuracy: 0.8015 - precision_26: 0.2458 - val_loss: 11.9389 - val_accuracy: 0.8628 - val_precision_26: 0.0313 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 37.8660 - accuracy: 0.7990 - precision_26: 0.2508 - val_loss: 7.7781 - val_accuracy: 0.8927 - val_precision_26: 0.0090 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 34.1891 - accuracy: 0.7984 - precision_26: 0.2428 - val_loss: 14.4432 - val_accuracy: 0.9178 - val_precision_26: 0.0079 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 25.4938 - accuracy: 0.8019 - precision_26: 0.2436 - val_loss: 14.1068 - val_accuracy: 0.8932 - val_precision_26: 0.0144 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.9075 - accuracy: 0.8025 - precision_26: 0.2429 - val_loss: 12.8931 - val_accuracy: 0.9257 - val_precision_26: 0.0078 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 25.1119 - accuracy: 0.8036 - precision_26: 0.2493 - val_loss: 10.0481 - val_accuracy: 0.8729 - val_precision_26: 0.0198 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.8206 - accuracy: 0.8026 - precision_26: 0.2531 - val_loss: 10.3487 - val_accuracy: 0.7516 - val_precision_26: 0.0182 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.9673 - accuracy: 0.7999 - precision_26: 0.2441 - val_loss: 13.5693 - val_accuracy: 0.8537 - val_precision_26: 0.0296 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.8618 - accuracy: 0.8067 - precision_26: 0.2568 - val_loss: 4.3413 - val_accuracy: 0.8278 - val_precision_26: 0.0166 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.2618 - accuracy: 0.8031 - precision_26: 0.2553 - val_loss: 9.8914 - val_accuracy: 0.8882 - val_precision_26: 0.0144 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.0411 - accuracy: 0.8054 - precision_26: 0.2539 - val_loss: 10.6267 - val_accuracy: 0.9091 - val_precision_26: 0.0069 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 34.9006 - accuracy: 0.8028 - precision_26: 0.2423 - val_loss: 9.6879 - val_accuracy: 0.9322 - val_precision_26: 0.0054 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 19.2301 - accuracy: 0.8040 - precision_26: 0.2511 - val_loss: 5.2906 - val_accuracy: 0.7553 - val_precision_26: 0.0259 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 17.0044 - accuracy: 0.8056 - precision_26: 0.2567 - val_loss: 4.5480 - val_accuracy: 0.8445 - val_precision_26: 0.0144 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.0937 - accuracy: 0.8022 - precision_26: 0.2440 - val_loss: 4.3399 - val_accuracy: 0.8108 - val_precision_26: 0.0171 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.7611 - accuracy: 0.8066 - precision_26: 0.2630 - val_loss: 6.9652 - val_accuracy: 0.7364 - val_precision_26: 0.0365 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.0632 - accuracy: 0.8051 - precision_26: 0.2606 - val_loss: 5.8111 - val_accuracy: 0.9124 - val_precision_26: 0.0131 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.7102 - accuracy: 0.8072 - precision_26: 0.2591 - val_loss: 9.1834 - val_accuracy: 0.9024 - val_precision_26: 0.0162 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.2053 - accuracy: 0.8092 - precision_26: 0.2694 - val_loss: 5.7554 - val_accuracy: 0.8430 - val_precision_26: 0.0169 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.2964 - accuracy: 0.8030 - precision_26: 0.2478 - val_loss: 3.4107 - val_accuracy: 0.8656 - val_precision_26: 0.0172 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.3403 - accuracy: 0.8081 - precision_26: 0.2699 - val_loss: 6.4371 - val_accuracy: 0.7516 - val_precision_26: 0.0407 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.4152 - accuracy: 0.8093 - precision_26: 0.2721 - val_loss: 5.8731 - val_accuracy: 0.7823 - val_precision_26: 0.0269 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.0304 - accuracy: 0.8128 - precision_26: 0.2769 - val_loss: 2.7123 - val_accuracy: 0.8383 - val_precision_26: 0.0209 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.6383 - accuracy: 0.8086 - precision_26: 0.2611 - val_loss: 3.9298 - val_accuracy: 0.8848 - val_precision_26: 0.0146 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.1089 - accuracy: 0.8104 - precision_26: 0.2695 - val_loss: 4.6299 - val_accuracy: 0.8196 - val_precision_26: 0.0180 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.7498 - accuracy: 0.8111 - precision_26: 0.2752 - val_loss: 3.1409 - val_accuracy: 0.8763 - val_precision_26: 0.0321 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.3553 - accuracy: 0.8120 - precision_26: 0.2726 - val_loss: 9.8418 - val_accuracy: 0.9318 - val_precision_26: 0.0054 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.8094 - accuracy: 0.8111 - precision_26: 0.2764 - val_loss: 6.8073 - val_accuracy: 0.6449 - val_precision_26: 0.0498 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.2031 - accuracy: 0.8094 - precision_26: 0.2579 - val_loss: 6.5707 - val_accuracy: 0.7298 - val_precision_26: 0.0501 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.3462 - accuracy: 0.8110 - precision_26: 0.2722 - val_loss: 3.7748 - val_accuracy: 0.8921 - val_precision_26: 0.0081 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.2293 - accuracy: 0.8113 - precision_26: 0.2680 - val_loss: 2.7962 - val_accuracy: 0.7938 - val_precision_26: 0.0382 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.1343 - accuracy: 0.8126 - precision_26: 0.2791 - val_loss: 5.1786 - val_accuracy: 0.9145 - val_precision_26: 0.0050 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.6202 - accuracy: 0.8141 - precision_26: 0.2783 - val_loss: 2.2950 - val_accuracy: 0.7811 - val_precision_26: 0.0305 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.3597 - accuracy: 0.8130 - precision_26: 0.2754 - val_loss: 3.5923 - val_accuracy: 0.8160 - val_precision_26: 0.0211 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 5.7299 - accuracy: 0.8105 - precision_26: 0.2730 - val_loss: 4.0363 - val_accuracy: 0.9188 - val_precision_26: 0.0146 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 6.1755 - accuracy: 0.8111 - precision_26: 0.2696 - val_loss: 1.9776 - val_accuracy: 0.8150 - val_precision_26: 0.0188 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 5.5637 - accuracy: 0.8126 - precision_26: 0.2729 - val_loss: 3.3234 - val_accuracy: 0.8389 - val_precision_26: 0.0265 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.4632 - accuracy: 0.8111 - precision_26: 0.2772 - val_loss: 1.8337 - val_accuracy: 0.8876 - val_precision_26: 0.0118 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 3.8328 - accuracy: 0.8121 - precision_26: 0.2771 - val_loss: 1.9403 - val_accuracy: 0.7712 - val_precision_26: 0.0262 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.2039 - accuracy: 0.8135 - precision_26: 0.2837 - val_loss: 3.6882 - val_accuracy: 0.7173 - val_precision_26: 0.0467 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.9554 - accuracy: 0.8126 - precision_26: 0.2854 - val_loss: 1.3339 - val_accuracy: 0.8806 - val_precision_26: 0.0228 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.7887 - accuracy: 0.8165 - precision_26: 0.2985 - val_loss: 1.7501 - val_accuracy: 0.8996 - val_precision_26: 0.0108 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.0547 - accuracy: 0.8141 - precision_26: 0.2866 - val_loss: 2.1047 - val_accuracy: 0.7896 - val_precision_26: 0.0481 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.9592 - accuracy: 0.8097 - precision_26: 0.2689 - val_loss: 1.0427 - val_accuracy: 0.8721 - val_precision_26: 0.0217 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.4223 - accuracy: 0.8154 - precision_26: 0.2914 - val_loss: 2.7779 - val_accuracy: 0.6529 - val_precision_26: 0.0496 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0580 - accuracy: 0.8167 - precision_26: 0.2976 - val_loss: 1.2556 - val_accuracy: 0.7905 - val_precision_26: 0.0376 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0615 - accuracy: 0.8156 - precision_26: 0.2926 - val_loss: 1.2328 - val_accuracy: 0.8087 - val_precision_26: 0.0302 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 2.0569 - accuracy: 0.8168 - precision_26: 0.2987 - val_loss: 0.7637 - val_accuracy: 0.8652 - val_precision_26: 0.0332 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.1524 - accuracy: 0.8137 - precision_26: 0.2834 - val_loss: 2.0327 - val_accuracy: 0.6480 - val_precision_26: 0.0330 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7282 - accuracy: 0.8136 - precision_26: 0.2837 - val_loss: 1.2119 - val_accuracy: 0.7954 - val_precision_26: 0.0236 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9509 - accuracy: 0.8139 - precision_26: 0.2892 - val_loss: 0.7706 - val_accuracy: 0.8741 - val_precision_26: 0.0207 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4964 - accuracy: 0.8173 - precision_26: 0.2970 - val_loss: 0.5682 - val_accuracy: 0.8710 - val_precision_26: 0.0324 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8858 - accuracy: 0.8150 - precision_26: 0.2906 - val_loss: 0.9122 - val_accuracy: 0.8656 - val_precision_26: 0.0303 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.1554 - accuracy: 0.8137 - precision_26: 0.2835 - val_loss: 1.2527 - val_accuracy: 0.8069 - val_precision_26: 0.0330 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5541 - accuracy: 0.8157 - precision_26: 0.2845 - val_loss: 1.1491 - val_accuracy: 0.8699 - val_precision_26: 0.0302 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.1717 - accuracy: 0.8116 - precision_26: 0.2694 - val_loss: 0.7625 - val_accuracy: 0.9111 - val_precision_26: 0.0207 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3690 - accuracy: 0.8174 - precision_26: 0.2862 - val_loss: 0.5769 - val_accuracy: 0.8370 - val_precision_26: 0.0607 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7685 - accuracy: 0.8319 - precision_26: 0.3194 - val_loss: 0.4815 - val_accuracy: 0.8907 - val_precision_26: 0.0327 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8006 - accuracy: 0.8281 - precision_26: 0.3034 - val_loss: 0.4247 - val_accuracy: 0.9031 - val_precision_26: 0.0326 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.8325 - precision_26: 0.3213 - val_loss: 0.4495 - val_accuracy: 0.9197 - val_precision_26: 0.0410 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5761 - accuracy: 0.8419 - precision_26: 0.3534 - val_loss: 0.4022 - val_accuracy: 0.8644 - val_precision_26: 0.0329 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.8423 - precision_26: 0.3635 - val_loss: 0.2895 - val_accuracy: 0.9498 - val_precision_26: 0.0033 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.5121 - accuracy: 0.8473 - precision_26: 0.3897 - val_loss: 0.3105 - val_accuracy: 0.9264 - val_precision_26: 0.0464 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.8492 - precision_26: 0.4021 - val_loss: 0.4000 - val_accuracy: 0.9049 - val_precision_26: 0.0158 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.8520 - precision_26: 0.4331 - val_loss: 0.3231 - val_accuracy: 0.9418 - val_precision_26: 0.0118 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8523 - precision_26: 0.4388 - val_loss: 0.2970 - val_accuracy: 0.9321 - val_precision_26: 0.0036 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.8538 - precision_26: 0.4494 - val_loss: 0.3259 - val_accuracy: 0.9057 - val_precision_26: 0.0348 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8534 - precision_26: 0.4458 - val_loss: 0.4748 - val_accuracy: 0.8540 - val_precision_26: 0.0430 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.8447 - precision_26: 0.3707 - val_loss: 0.3239 - val_accuracy: 0.8947 - val_precision_26: 0.0375 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8568 - precision_26: 0.4894 - val_loss: 0.2451 - val_accuracy: 0.9391 - val_precision_26: 0.0481 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8515 - precision_26: 0.4275 - val_loss: 0.2651 - val_accuracy: 0.9254 - val_precision_26: 0.0455 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8572 - precision_26: 0.4958 - val_loss: 0.3110 - val_accuracy: 0.9026 - val_precision_26: 0.0370 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8533 - precision_26: 0.4424 - val_loss: 0.2624 - val_accuracy: 0.9347 - val_precision_26: 0.0152 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 269.3947 - accuracy: 0.7488 - precision_27: 0.1532 - val_loss: 14.2902 - val_accuracy: 0.9293 - val_precision_27: 0.0051 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 93.7067 - accuracy: 0.7647 - precision_27: 0.1707 - val_loss: 34.5808 - val_accuracy: 0.9431 - val_precision_27: 0.0050 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 69.1381 - accuracy: 0.7767 - precision_27: 0.1948 - val_loss: 11.6571 - val_accuracy: 0.7425 - val_precision_27: 0.0242 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 74.5938 - accuracy: 0.7759 - precision_27: 0.1937 - val_loss: 77.1393 - val_accuracy: 0.5315 - val_precision_27: 0.0388 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 54.4001 - accuracy: 0.7856 - precision_27: 0.2121 - val_loss: 12.5325 - val_accuracy: 0.6219 - val_precision_27: 0.0347 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 71.3397 - accuracy: 0.7807 - precision_27: 0.2048 - val_loss: 21.2161 - val_accuracy: 0.9497 - val_precision_27: 0.0032 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 40.2904 - accuracy: 0.7888 - precision_27: 0.2155 - val_loss: 7.9940 - val_accuracy: 0.8269 - val_precision_27: 0.0216 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 58.2253 - accuracy: 0.7908 - precision_27: 0.2246 - val_loss: 14.2776 - val_accuracy: 0.9330 - val_precision_27: 0.0092 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 75.4983 - accuracy: 0.7896 - precision_27: 0.2223 - val_loss: 58.6608 - val_accuracy: 0.9214 - val_precision_27: 0.0140 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 64.9554 - accuracy: 0.7876 - precision_27: 0.2193 - val_loss: 9.0913 - val_accuracy: 0.6153 - val_precision_27: 0.0291 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 31.5141 - accuracy: 0.7931 - precision_27: 0.2287 - val_loss: 103.1003 - val_accuracy: 0.5050 - val_precision_27: 0.0391 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.9378 - accuracy: 0.7906 - precision_27: 0.2220 - val_loss: 30.4800 - val_accuracy: 0.5967 - val_precision_27: 0.0415 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 33.0272 - accuracy: 0.7904 - precision_27: 0.2263 - val_loss: 16.0766 - val_accuracy: 0.9039 - val_precision_27: 0.0175 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 44.7931 - accuracy: 0.7921 - precision_27: 0.2286 - val_loss: 8.6417 - val_accuracy: 0.8120 - val_precision_27: 0.0184 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 39.0753 - accuracy: 0.7932 - precision_27: 0.2330 - val_loss: 7.7479 - val_accuracy: 0.8700 - val_precision_27: 0.0139 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 26.0195 - accuracy: 0.7967 - precision_27: 0.2389 - val_loss: 11.9549 - val_accuracy: 0.9034 - val_precision_27: 0.0084 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 32.6445 - accuracy: 0.7974 - precision_27: 0.2390 - val_loss: 6.4193 - val_accuracy: 0.9058 - val_precision_27: 0.0065 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.5990 - accuracy: 0.7948 - precision_27: 0.2349 - val_loss: 12.1124 - val_accuracy: 0.9435 - val_precision_27: 0.0025 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 24.1863 - accuracy: 0.7940 - precision_27: 0.2336 - val_loss: 13.7395 - val_accuracy: 0.9218 - val_precision_27: 0.0057 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 35.4573 - accuracy: 0.7942 - precision_27: 0.2276 - val_loss: 41.9364 - val_accuracy: 0.5285 - val_precision_27: 0.0415 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.3843 - accuracy: 0.7978 - precision_27: 0.2377 - val_loss: 13.0854 - val_accuracy: 0.9161 - val_precision_27: 0.0052 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 24.1548 - accuracy: 0.7977 - precision_27: 0.2412 - val_loss: 9.4163 - val_accuracy: 0.8324 - val_precision_27: 0.0220 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 47.9883 - accuracy: 0.7956 - precision_27: 0.2314 - val_loss: 5.6428 - val_accuracy: 0.9266 - val_precision_27: 0.0016 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.7273 - accuracy: 0.7996 - precision_27: 0.2443 - val_loss: 4.0548 - val_accuracy: 0.8143 - val_precision_27: 0.0183 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.2775 - accuracy: 0.8022 - precision_27: 0.2493 - val_loss: 4.1705 - val_accuracy: 0.8443 - val_precision_27: 0.0133 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.4634 - accuracy: 0.8016 - precision_27: 0.2468 - val_loss: 12.9301 - val_accuracy: 0.8881 - val_precision_27: 0.0110 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.0340 - accuracy: 0.7949 - precision_27: 0.2355 - val_loss: 11.1122 - val_accuracy: 0.9136 - val_precision_27: 0.0062 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.0543 - accuracy: 0.8020 - precision_27: 0.2417 - val_loss: 7.0271 - val_accuracy: 0.8350 - val_precision_27: 0.0145 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.6890 - accuracy: 0.8002 - precision_27: 0.2479 - val_loss: 5.9169 - val_accuracy: 0.8045 - val_precision_27: 0.0188 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.0187 - accuracy: 0.8016 - precision_27: 0.2463 - val_loss: 6.0081 - val_accuracy: 0.8798 - val_precision_27: 0.0085 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.0389 - accuracy: 0.8021 - precision_27: 0.2442 - val_loss: 5.8184 - val_accuracy: 0.9274 - val_precision_27: 0.0064 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 17.4184 - accuracy: 0.8028 - precision_27: 0.2466 - val_loss: 6.9009 - val_accuracy: 0.9202 - val_precision_27: 0.0083 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.1477 - accuracy: 0.8024 - precision_27: 0.2445 - val_loss: 8.0255 - val_accuracy: 0.8888 - val_precision_27: 0.0095 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 12.9490 - accuracy: 0.8017 - precision_27: 0.2482 - val_loss: 8.0699 - val_accuracy: 0.7078 - val_precision_27: 0.0274 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.1605 - accuracy: 0.8023 - precision_27: 0.2530 - val_loss: 8.1183 - val_accuracy: 0.9269 - val_precision_27: 0.0079 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 11.9571 - accuracy: 0.8036 - precision_27: 0.2477 - val_loss: 2.6253 - val_accuracy: 0.8688 - val_precision_27: 0.0097 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.5881 - accuracy: 0.8033 - precision_27: 0.2486 - val_loss: 3.4027 - val_accuracy: 0.8829 - val_precision_27: 0.0120 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.9101 - accuracy: 0.8033 - precision_27: 0.2515 - val_loss: 3.5863 - val_accuracy: 0.8706 - val_precision_27: 0.0112 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.3130 - accuracy: 0.8032 - precision_27: 0.2476 - val_loss: 4.0957 - val_accuracy: 0.8059 - val_precision_27: 0.0194 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.6085 - accuracy: 0.8032 - precision_27: 0.2513 - val_loss: 3.9978 - val_accuracy: 0.8804 - val_precision_27: 0.0109 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.6164 - accuracy: 0.8045 - precision_27: 0.2494 - val_loss: 3.6551 - val_accuracy: 0.7794 - val_precision_27: 0.0519 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.3641 - accuracy: 0.8064 - precision_27: 0.2620 - val_loss: 5.3986 - val_accuracy: 0.6827 - val_precision_27: 0.0347 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.8959 - accuracy: 0.8069 - precision_27: 0.2603 - val_loss: 7.1124 - val_accuracy: 0.9386 - val_precision_27: 0.0086 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.9193 - accuracy: 0.8039 - precision_27: 0.2490 - val_loss: 3.9336 - val_accuracy: 0.9124 - val_precision_27: 0.0036 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.4019 - accuracy: 0.8095 - precision_27: 0.2717 - val_loss: 4.9272 - val_accuracy: 0.9214 - val_precision_27: 0.0071 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.3798 - accuracy: 0.8077 - precision_27: 0.2605 - val_loss: 2.8993 - val_accuracy: 0.7083 - val_precision_27: 0.0171 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.9788 - accuracy: 0.8045 - precision_27: 0.2511 - val_loss: 3.5852 - val_accuracy: 0.9035 - val_precision_27: 0.0053 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.2280 - accuracy: 0.8051 - precision_27: 0.2604 - val_loss: 2.3173 - val_accuracy: 0.8058 - val_precision_27: 0.0145 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.6332 - accuracy: 0.8083 - precision_27: 0.2619 - val_loss: 3.4107 - val_accuracy: 0.8011 - val_precision_27: 0.0209 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.0771 - accuracy: 0.8040 - precision_27: 0.2560 - val_loss: 2.2524 - val_accuracy: 0.7595 - val_precision_27: 0.0198 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.9005 - accuracy: 0.8088 - precision_27: 0.2669 - val_loss: 2.3879 - val_accuracy: 0.8337 - val_precision_27: 0.0108 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.7417 - accuracy: 0.8066 - precision_27: 0.2621 - val_loss: 2.1161 - val_accuracy: 0.8736 - val_precision_27: 0.0073 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.4905 - accuracy: 0.8103 - precision_27: 0.2716 - val_loss: 2.9118 - val_accuracy: 0.7357 - val_precision_27: 0.0334 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.7534 - accuracy: 0.8071 - precision_27: 0.2601 - val_loss: 3.1985 - val_accuracy: 0.8023 - val_precision_27: 0.0190 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.8449 - accuracy: 0.8055 - precision_27: 0.2592 - val_loss: 1.9550 - val_accuracy: 0.8387 - val_precision_27: 0.0097 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.6342 - accuracy: 0.8063 - precision_27: 0.2614 - val_loss: 7.8223 - val_accuracy: 0.6060 - val_precision_27: 0.0450 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.0116 - accuracy: 0.8075 - precision_27: 0.2671 - val_loss: 4.4018 - val_accuracy: 0.9221 - val_precision_27: 0.0015 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 6.1893 - accuracy: 0.8068 - precision_27: 0.2647 - val_loss: 1.6021 - val_accuracy: 0.7868 - val_precision_27: 0.0204 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.4424 - accuracy: 0.8098 - precision_27: 0.2730 - val_loss: 2.0926 - val_accuracy: 0.8693 - val_precision_27: 0.0158 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.0331 - accuracy: 0.8127 - precision_27: 0.2828 - val_loss: 1.1933 - val_accuracy: 0.8425 - val_precision_27: 0.0251 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 4.6413 - accuracy: 0.8089 - precision_27: 0.2704 - val_loss: 1.3366 - val_accuracy: 0.8314 - val_precision_27: 0.0170 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.9962 - accuracy: 0.8148 - precision_27: 0.2891 - val_loss: 3.1559 - val_accuracy: 0.6689 - val_precision_27: 0.0494 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.3223 - accuracy: 0.8088 - precision_27: 0.2733 - val_loss: 1.6971 - val_accuracy: 0.9055 - val_precision_27: 0.0260 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.1959 - accuracy: 0.8105 - precision_27: 0.2727 - val_loss: 2.0457 - val_accuracy: 0.7221 - val_precision_27: 0.0454 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 4.9146 - accuracy: 0.8113 - precision_27: 0.2766 - val_loss: 1.9409 - val_accuracy: 0.8727 - val_precision_27: 0.0197 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.9702 - accuracy: 0.8058 - precision_27: 0.2626 - val_loss: 1.6834 - val_accuracy: 0.7557 - val_precision_27: 0.0492 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.5366 - accuracy: 0.8131 - precision_27: 0.2863 - val_loss: 0.9835 - val_accuracy: 0.8268 - val_precision_27: 0.0346 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.8841 - accuracy: 0.8152 - precision_27: 0.2909 - val_loss: 1.9006 - val_accuracy: 0.8508 - val_precision_27: 0.0180 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.0382 - accuracy: 0.8104 - precision_27: 0.2713 - val_loss: 1.1352 - val_accuracy: 0.8923 - val_precision_27: 0.0107 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.5089 - accuracy: 0.8127 - precision_27: 0.2789 - val_loss: 0.9312 - val_accuracy: 0.8701 - val_precision_27: 0.0112 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.6337 - accuracy: 0.8102 - precision_27: 0.2722 - val_loss: 0.9671 - val_accuracy: 0.8624 - val_precision_27: 0.0136 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.6493 - accuracy: 0.8124 - precision_27: 0.2815 - val_loss: 1.0933 - val_accuracy: 0.8608 - val_precision_27: 0.0122 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.3410 - accuracy: 0.8121 - precision_27: 0.2827 - val_loss: 1.0318 - val_accuracy: 0.7839 - val_precision_27: 0.0233 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0775 - accuracy: 0.8130 - precision_27: 0.2875 - val_loss: 1.0167 - val_accuracy: 0.8496 - val_precision_27: 0.0167 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0095 - accuracy: 0.8153 - precision_27: 0.2903 - val_loss: 2.0771 - val_accuracy: 0.5751 - val_precision_27: 0.0453 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6880 - accuracy: 0.8152 - precision_27: 0.2920 - val_loss: 0.6924 - val_accuracy: 0.8900 - val_precision_27: 0.0147 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5083 - accuracy: 0.8155 - precision_27: 0.2883 - val_loss: 1.1813 - val_accuracy: 0.7274 - val_precision_27: 0.0526 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3950 - accuracy: 0.8164 - precision_27: 0.2879 - val_loss: 0.7780 - val_accuracy: 0.8343 - val_precision_27: 0.0213 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6689 - accuracy: 0.8144 - precision_27: 0.2819 - val_loss: 0.6416 - val_accuracy: 0.8244 - val_precision_27: 0.0240 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1816 - accuracy: 0.8207 - precision_27: 0.3019 - val_loss: 1.4342 - val_accuracy: 0.6788 - val_precision_27: 0.0493 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1013 - accuracy: 0.8152 - precision_27: 0.2860 - val_loss: 0.6017 - val_accuracy: 0.8379 - val_precision_27: 0.0258 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3209 - accuracy: 0.8186 - precision_27: 0.2885 - val_loss: 0.6150 - val_accuracy: 0.8598 - val_precision_27: 0.0235 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8843 - accuracy: 0.8227 - precision_27: 0.3084 - val_loss: 0.5490 - val_accuracy: 0.8245 - val_precision_27: 0.0258 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.8096 - accuracy: 0.8240 - precision_27: 0.3121 - val_loss: 0.7811 - val_accuracy: 0.7649 - val_precision_27: 0.0428 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.7308 - accuracy: 0.8282 - precision_27: 0.3203 - val_loss: 0.3271 - val_accuracy: 0.9071 - val_precision_27: 0.0044 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6647 - accuracy: 0.8313 - precision_27: 0.3375 - val_loss: 0.5995 - val_accuracy: 0.7592 - val_precision_27: 0.0655 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.6806 - accuracy: 0.8284 - precision_27: 0.3179 - val_loss: 0.4066 - val_accuracy: 0.8685 - val_precision_27: 0.0529 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8605 - accuracy: 0.8213 - precision_27: 0.2924 - val_loss: 0.6109 - val_accuracy: 0.7873 - val_precision_27: 0.0539 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6993 - accuracy: 0.8287 - precision_27: 0.3133 - val_loss: 0.4172 - val_accuracy: 0.8715 - val_precision_27: 0.0313 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.8322 - precision_27: 0.3284 - val_loss: 0.4368 - val_accuracy: 0.8821 - val_precision_27: 0.0305 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.8406 - precision_27: 0.3671 - val_loss: 0.7396 - val_accuracy: 0.6729 - val_precision_27: 0.0572 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7795 - accuracy: 0.8226 - precision_27: 0.3016 - val_loss: 0.2613 - val_accuracy: 0.9454 - val_precision_27: 0.0107 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.8354 - precision_27: 0.3396 - val_loss: 0.4411 - val_accuracy: 0.7999 - val_precision_27: 0.0731 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.8302 - precision_27: 0.3188 - val_loss: 0.3108 - val_accuracy: 0.9102 - val_precision_27: 0.0149 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.0647 - accuracy: 0.8073 - precision_27: 0.2621 - val_loss: 13.4649 - val_accuracy: 0.9017 - val_precision_27: 0.0237 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.8200 - accuracy: 0.8140 - precision_27: 0.2644 - val_loss: 0.2990 - val_accuracy: 0.9315 - val_precision_27: 0.0207 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.8398 - precision_27: 0.3455 - val_loss: 0.3093 - val_accuracy: 0.9182 - val_precision_27: 0.0183 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.8466 - precision_27: 0.3863 - val_loss: 0.2977 - val_accuracy: 0.9279 - val_precision_27: 0.0113 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8488 - precision_27: 0.3999 - val_loss: 0.3478 - val_accuracy: 0.8932 - val_precision_27: 0.0204 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.8472 - precision_27: 0.3890 - val_loss: 0.3129 - val_accuracy: 0.9058 - val_precision_27: 0.0338 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 425.9639 - accuracy: 0.7591 - precision_28: 0.1505 - val_loss: 8.0110 - val_accuracy: 0.8507 - val_precision_28: 0.0305 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 77.9375 - accuracy: 0.7843 - precision_28: 0.1800 - val_loss: 201.0308 - val_accuracy: 0.4904 - val_precision_28: 0.0429 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 90.7579 - accuracy: 0.7905 - precision_28: 0.2013 - val_loss: 30.9200 - val_accuracy: 0.9233 - val_precision_28: 0.0295 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 81.0203 - accuracy: 0.7913 - precision_28: 0.2067 - val_loss: 21.0060 - val_accuracy: 0.9219 - val_precision_28: 0.0326 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 90.7493 - accuracy: 0.7928 - precision_28: 0.2062 - val_loss: 26.0439 - val_accuracy: 0.8822 - val_precision_28: 0.0195 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 46.3541 - accuracy: 0.7936 - precision_28: 0.2122 - val_loss: 5.0601 - val_accuracy: 0.7444 - val_precision_28: 0.0267 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 77.1691 - accuracy: 0.7926 - precision_28: 0.2132 - val_loss: 6.4162 - val_accuracy: 0.7577 - val_precision_28: 0.0243 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 52.4696 - accuracy: 0.7960 - precision_28: 0.2177 - val_loss: 12.4260 - val_accuracy: 0.8088 - val_precision_28: 0.0210 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 66.0302 - accuracy: 0.7967 - precision_28: 0.2232 - val_loss: 18.6279 - val_accuracy: 0.9012 - val_precision_28: 0.0226 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 43.1119 - accuracy: 0.7965 - precision_28: 0.2242 - val_loss: 17.3214 - val_accuracy: 0.8769 - val_precision_28: 0.0177 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 72.0211 - accuracy: 0.8005 - precision_28: 0.2234 - val_loss: 41.4564 - val_accuracy: 0.9470 - val_precision_28: 0.0029 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 51.4497 - accuracy: 0.7974 - precision_28: 0.2238 - val_loss: 42.7612 - val_accuracy: 0.9165 - val_precision_28: 0.0284 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 61.2193 - accuracy: 0.7990 - precision_28: 0.2224 - val_loss: 100.3954 - val_accuracy: 0.4624 - val_precision_28: 0.0417 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 64.3071 - accuracy: 0.7990 - precision_28: 0.2224 - val_loss: 83.8213 - val_accuracy: 0.4808 - val_precision_28: 0.0430 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 37.3978 - accuracy: 0.7970 - precision_28: 0.2249 - val_loss: 5.7302 - val_accuracy: 0.8582 - val_precision_28: 0.0470 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 31.6048 - accuracy: 0.7985 - precision_28: 0.2280 - val_loss: 10.2567 - val_accuracy: 0.8614 - val_precision_28: 0.0274 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 41.7635 - accuracy: 0.8014 - precision_28: 0.2215 - val_loss: 12.3982 - val_accuracy: 0.9057 - val_precision_28: 0.0128 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 43.1956 - accuracy: 0.8024 - precision_28: 0.2304 - val_loss: 26.5733 - val_accuracy: 0.5617 - val_precision_28: 0.0454 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.2668 - accuracy: 0.7988 - precision_28: 0.2239 - val_loss: 14.8977 - val_accuracy: 0.8951 - val_precision_28: 0.0174 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 27.2823 - accuracy: 0.8007 - precision_28: 0.2343 - val_loss: 12.5010 - val_accuracy: 0.8864 - val_precision_28: 0.0180 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.4246 - accuracy: 0.7990 - precision_28: 0.2229 - val_loss: 7.5475 - val_accuracy: 0.8666 - val_precision_28: 0.0141 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 38.4593 - accuracy: 0.8013 - precision_28: 0.2306 - val_loss: 6.1675 - val_accuracy: 0.8389 - val_precision_28: 0.0097 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 33.6727 - accuracy: 0.7998 - precision_28: 0.2234 - val_loss: 14.6348 - val_accuracy: 0.9265 - val_precision_28: 0.0063 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 25.4550 - accuracy: 0.7998 - precision_28: 0.2297 - val_loss: 5.3087 - val_accuracy: 0.7282 - val_precision_28: 0.0271 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 25.5576 - accuracy: 0.8018 - precision_28: 0.2336 - val_loss: 10.0637 - val_accuracy: 0.8835 - val_precision_28: 0.0128 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 37.2624 - accuracy: 0.7994 - precision_28: 0.2229 - val_loss: 22.7564 - val_accuracy: 0.9368 - val_precision_28: 0.0141 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.0387 - accuracy: 0.8074 - precision_28: 0.2482 - val_loss: 3.1895 - val_accuracy: 0.8476 - val_precision_28: 0.0126 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 10.7026 - accuracy: 0.8076 - precision_28: 0.2492 - val_loss: 5.2779 - val_accuracy: 0.8578 - val_precision_28: 0.0155 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 9.3119 - accuracy: 0.8087 - precision_28: 0.2538 - val_loss: 8.5143 - val_accuracy: 0.9037 - val_precision_28: 0.0175 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.2319 - accuracy: 0.8073 - precision_28: 0.2458 - val_loss: 3.1143 - val_accuracy: 0.7728 - val_precision_28: 0.0302 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 16.8443 - accuracy: 0.8052 - precision_28: 0.2385 - val_loss: 2.7360 - val_accuracy: 0.8400 - val_precision_28: 0.0160 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.0466 - accuracy: 0.8043 - precision_28: 0.2457 - val_loss: 7.3542 - val_accuracy: 0.8881 - val_precision_28: 0.0176 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 17.0097 - accuracy: 0.8094 - precision_28: 0.2463 - val_loss: 22.6555 - val_accuracy: 0.5516 - val_precision_28: 0.0451 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.7788 - accuracy: 0.8084 - precision_28: 0.2573 - val_loss: 6.5879 - val_accuracy: 0.8803 - val_precision_28: 0.0191 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.3165 - accuracy: 0.8053 - precision_28: 0.2510 - val_loss: 16.8417 - val_accuracy: 0.9055 - val_precision_28: 0.0210 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.8055 - accuracy: 0.8061 - precision_28: 0.2401 - val_loss: 18.5748 - val_accuracy: 0.5524 - val_precision_28: 0.0455 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.8734 - accuracy: 0.8035 - precision_28: 0.2420 - val_loss: 3.6960 - val_accuracy: 0.8550 - val_precision_28: 0.0151 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.4509 - accuracy: 0.8038 - precision_28: 0.2301 - val_loss: 3.6777 - val_accuracy: 0.8599 - val_precision_28: 0.0114 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.3996 - accuracy: 0.8047 - precision_28: 0.2397 - val_loss: 6.8596 - val_accuracy: 0.8281 - val_precision_28: 0.0236 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.4199 - accuracy: 0.8076 - precision_28: 0.2604 - val_loss: 6.4185 - val_accuracy: 0.9062 - val_precision_28: 0.0150 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.1561 - accuracy: 0.8083 - precision_28: 0.2543 - val_loss: 2.6957 - val_accuracy: 0.8417 - val_precision_28: 0.0125 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.6305 - accuracy: 0.8048 - precision_28: 0.2402 - val_loss: 14.8521 - val_accuracy: 0.8813 - val_precision_28: 0.0237 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.2545 - accuracy: 0.8053 - precision_28: 0.2423 - val_loss: 6.0622 - val_accuracy: 0.7947 - val_precision_28: 0.0205 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.5283 - accuracy: 0.8097 - precision_28: 0.2594 - val_loss: 8.0450 - val_accuracy: 0.6806 - val_precision_28: 0.0469 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.9427 - accuracy: 0.8085 - precision_28: 0.2573 - val_loss: 3.0824 - val_accuracy: 0.8220 - val_precision_28: 0.0169 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.1249 - accuracy: 0.8067 - precision_28: 0.2567 - val_loss: 3.9081 - val_accuracy: 0.8703 - val_precision_28: 0.0213 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.9013 - accuracy: 0.8074 - precision_28: 0.2603 - val_loss: 13.1025 - val_accuracy: 0.9442 - val_precision_28: 0.0026 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.0451 - accuracy: 0.8108 - precision_28: 0.2619 - val_loss: 16.5830 - val_accuracy: 0.5803 - val_precision_28: 0.0475 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.2195 - accuracy: 0.8047 - precision_28: 0.2512 - val_loss: 3.7501 - val_accuracy: 0.9249 - val_precision_28: 0.0120 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.9407 - accuracy: 0.8074 - precision_28: 0.2491 - val_loss: 6.5098 - val_accuracy: 0.8657 - val_precision_28: 0.0247 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.9594 - accuracy: 0.8103 - precision_28: 0.2696 - val_loss: 8.6414 - val_accuracy: 0.6416 - val_precision_28: 0.0493 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.4840 - accuracy: 0.8093 - precision_28: 0.2631 - val_loss: 3.8153 - val_accuracy: 0.8594 - val_precision_28: 0.0187 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 8.7074 - accuracy: 0.8104 - precision_28: 0.2636 - val_loss: 5.1743 - val_accuracy: 0.8390 - val_precision_28: 0.0269 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 12.4555 - accuracy: 0.8097 - precision_28: 0.2672 - val_loss: 12.0522 - val_accuracy: 0.8956 - val_precision_28: 0.0210 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 14.1791 - accuracy: 0.8098 - precision_28: 0.2597 - val_loss: 4.5161 - val_accuracy: 0.8444 - val_precision_28: 0.0144 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 9.0903 - accuracy: 0.8127 - precision_28: 0.2761 - val_loss: 6.9411 - val_accuracy: 0.8686 - val_precision_28: 0.0222 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 7.7039 - accuracy: 0.8113 - precision_28: 0.2725 - val_loss: 3.6860 - val_accuracy: 0.9069 - val_precision_28: 0.0255 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.7045 - accuracy: 0.8107 - precision_28: 0.2657 - val_loss: 2.6725 - val_accuracy: 0.8418 - val_precision_28: 0.0188 - lr: 5.0000e-04\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.4861 - accuracy: 0.8097 - precision_28: 0.2682 - val_loss: 3.2258 - val_accuracy: 0.8797 - val_precision_28: 0.0138 - lr: 5.0000e-04\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.9728 - accuracy: 0.8126 - precision_28: 0.2800 - val_loss: 7.8008 - val_accuracy: 0.6463 - val_precision_28: 0.0498 - lr: 5.0000e-04\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.2586 - accuracy: 0.8075 - precision_28: 0.2575 - val_loss: 4.3098 - val_accuracy: 0.8562 - val_precision_28: 0.0176 - lr: 5.0000e-04\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.0281 - accuracy: 0.8099 - precision_28: 0.2642 - val_loss: 4.9709 - val_accuracy: 0.7005 - val_precision_28: 0.0402 - lr: 5.0000e-04\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.9910 - accuracy: 0.8082 - precision_28: 0.2620 - val_loss: 3.3212 - val_accuracy: 0.9083 - val_precision_28: 0.0045 - lr: 5.0000e-04\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.4230 - accuracy: 0.8085 - precision_28: 0.2562 - val_loss: 3.6889 - val_accuracy: 0.8368 - val_precision_28: 0.0246 - lr: 5.0000e-04\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.7464 - accuracy: 0.8101 - precision_28: 0.2656 - val_loss: 2.2917 - val_accuracy: 0.8615 - val_precision_28: 0.0097 - lr: 5.0000e-04\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.7128 - accuracy: 0.8136 - precision_28: 0.2810 - val_loss: 2.6482 - val_accuracy: 0.7775 - val_precision_28: 0.0242 - lr: 5.0000e-04\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.1804 - accuracy: 0.8108 - precision_28: 0.2714 - val_loss: 4.2177 - val_accuracy: 0.9080 - val_precision_28: 0.0238 - lr: 5.0000e-04\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.5272 - accuracy: 0.8096 - precision_28: 0.2637 - val_loss: 6.0046 - val_accuracy: 0.9184 - val_precision_28: 0.0282 - lr: 5.0000e-04\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.9713 - accuracy: 0.8122 - precision_28: 0.2744 - val_loss: 4.7546 - val_accuracy: 0.8878 - val_precision_28: 0.0175 - lr: 5.0000e-04\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.0639 - accuracy: 0.8141 - precision_28: 0.2787 - val_loss: 9.0257 - val_accuracy: 0.6191 - val_precision_28: 0.0493 - lr: 5.0000e-04\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.9001 - accuracy: 0.8108 - precision_28: 0.2687 - val_loss: 9.1946 - val_accuracy: 0.6072 - val_precision_28: 0.0447 - lr: 5.0000e-04\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.4652 - accuracy: 0.8149 - precision_28: 0.2855 - val_loss: 2.4801 - val_accuracy: 0.8570 - val_precision_28: 0.0177 - lr: 5.0000e-04\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.2720 - accuracy: 0.8102 - precision_28: 0.2663 - val_loss: 2.6382 - val_accuracy: 0.8566 - val_precision_28: 0.0165 - lr: 5.0000e-04\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.6063 - accuracy: 0.8093 - precision_28: 0.2653 - val_loss: 6.1678 - val_accuracy: 0.9166 - val_precision_28: 0.0262 - lr: 5.0000e-04\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.9028 - accuracy: 0.8112 - precision_28: 0.2707 - val_loss: 3.8446 - val_accuracy: 0.9104 - val_precision_28: 0.0093 - lr: 5.0000e-04\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.4893 - accuracy: 0.8119 - precision_28: 0.2695 - val_loss: 3.3627 - val_accuracy: 0.8555 - val_precision_28: 0.0157 - lr: 5.0000e-04\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.4275 - accuracy: 0.8120 - precision_28: 0.2722 - val_loss: 3.3309 - val_accuracy: 0.8824 - val_precision_28: 0.0127 - lr: 5.0000e-04\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 7.3685 - accuracy: 0.8132 - precision_28: 0.2783 - val_loss: 8.1882 - val_accuracy: 0.6551 - val_precision_28: 0.0501 - lr: 5.0000e-04\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 6.4184 - accuracy: 0.8137 - precision_28: 0.2864 - val_loss: 2.4395 - val_accuracy: 0.7860 - val_precision_28: 0.0228 - lr: 5.0000e-04\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 7.5713 - accuracy: 0.8140 - precision_28: 0.2827 - val_loss: 2.4428 - val_accuracy: 0.8575 - val_precision_28: 0.0190 - lr: 5.0000e-04\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 7.8808 - accuracy: 0.8149 - precision_28: 0.2816 - val_loss: 28.7088 - val_accuracy: 0.4323 - val_precision_28: 0.0412 - lr: 5.0000e-04\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 8.1488 - accuracy: 0.8112 - precision_28: 0.2743 - val_loss: 6.0904 - val_accuracy: 0.8965 - val_precision_28: 0.0204 - lr: 5.0000e-04\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.9442 - accuracy: 0.8167 - precision_28: 0.2908 - val_loss: 5.4444 - val_accuracy: 0.6789 - val_precision_28: 0.0390 - lr: 5.0000e-04\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.3400 - accuracy: 0.8130 - precision_28: 0.2797 - val_loss: 2.9560 - val_accuracy: 0.8784 - val_precision_28: 0.0202 - lr: 5.0000e-04\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.1437 - accuracy: 0.8138 - precision_28: 0.2821 - val_loss: 2.0391 - val_accuracy: 0.8974 - val_precision_28: 0.0170 - lr: 5.0000e-04\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.1882 - accuracy: 0.8134 - precision_28: 0.2821 - val_loss: 1.9222 - val_accuracy: 0.8478 - val_precision_28: 0.0277 - lr: 5.0000e-04\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.9054 - accuracy: 0.8138 - precision_28: 0.2805 - val_loss: 13.5381 - val_accuracy: 0.5814 - val_precision_28: 0.0447 - lr: 5.0000e-04\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.4514 - accuracy: 0.8108 - precision_28: 0.2708 - val_loss: 7.6274 - val_accuracy: 0.9018 - val_precision_28: 0.0209 - lr: 5.0000e-04\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.7942 - accuracy: 0.8138 - precision_28: 0.2794 - val_loss: 2.3618 - val_accuracy: 0.8018 - val_precision_28: 0.0248 - lr: 5.0000e-04\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.3193 - accuracy: 0.8179 - precision_28: 0.2937 - val_loss: 10.8234 - val_accuracy: 0.5780 - val_precision_28: 0.0477 - lr: 5.0000e-04\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.0910 - accuracy: 0.8122 - precision_28: 0.2801 - val_loss: 7.0826 - val_accuracy: 0.8682 - val_precision_28: 0.0346 - lr: 5.0000e-04\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.0995 - accuracy: 0.8132 - precision_28: 0.2757 - val_loss: 22.4529 - val_accuracy: 0.5309 - val_precision_28: 0.0448 - lr: 5.0000e-04\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.4251 - accuracy: 0.8120 - precision_28: 0.2770 - val_loss: 2.1811 - val_accuracy: 0.8194 - val_precision_28: 0.0254 - lr: 5.0000e-04\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.5423 - accuracy: 0.8148 - precision_28: 0.2839 - val_loss: 1.2799 - val_accuracy: 0.8536 - val_precision_28: 0.0234 - lr: 5.0000e-04\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.5255 - accuracy: 0.8131 - precision_28: 0.2789 - val_loss: 4.4817 - val_accuracy: 0.7075 - val_precision_28: 0.0410 - lr: 5.0000e-04\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.0341 - accuracy: 0.8129 - precision_28: 0.2781 - val_loss: 1.8096 - val_accuracy: 0.8413 - val_precision_28: 0.0167 - lr: 5.0000e-04\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.6714 - accuracy: 0.8151 - precision_28: 0.2848 - val_loss: 2.6554 - val_accuracy: 0.8867 - val_precision_28: 0.0205 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 7.5578 - accuracy: 0.8136 - precision_28: 0.2852 - val_loss: 6.4831 - val_accuracy: 0.9127 - val_precision_28: 0.0166 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.2421 - accuracy: 0.8158 - precision_28: 0.2846 - val_loss: 2.2062 - val_accuracy: 0.8221 - val_precision_28: 0.0205 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.3572 - accuracy: 0.8156 - precision_28: 0.2915 - val_loss: 2.9395 - val_accuracy: 0.7261 - val_precision_28: 0.0391 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 196.7486 - accuracy: 0.7534 - precision_29: 0.1579 - val_loss: 22.6807 - val_accuracy: 0.8473 - val_precision_29: 0.0108 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 59.0918 - accuracy: 0.7728 - precision_29: 0.1816 - val_loss: 15.6676 - val_accuracy: 0.9524 - val_precision_29: 0.0144 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 44.8980 - accuracy: 0.7824 - precision_29: 0.1973 - val_loss: 8.7385 - val_accuracy: 0.8266 - val_precision_29: 0.0265 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 45.2941 - accuracy: 0.7833 - precision_29: 0.2014 - val_loss: 30.3401 - val_accuracy: 0.6086 - val_precision_29: 0.0457 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 50.3755 - accuracy: 0.7808 - precision_29: 0.2021 - val_loss: 13.4768 - val_accuracy: 0.8524 - val_precision_29: 0.0101 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 38.0919 - accuracy: 0.7832 - precision_29: 0.2079 - val_loss: 20.2624 - val_accuracy: 0.7661 - val_precision_29: 0.0154 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 53.0246 - accuracy: 0.7799 - precision_29: 0.2029 - val_loss: 20.9213 - val_accuracy: 0.5385 - val_precision_29: 0.0246 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 23.3334 - accuracy: 0.7899 - precision_29: 0.2144 - val_loss: 68.6244 - val_accuracy: 0.5028 - val_precision_29: 0.0410 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 24.9810 - accuracy: 0.7922 - precision_29: 0.2191 - val_loss: 18.2115 - val_accuracy: 0.6030 - val_precision_29: 0.0366 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 20.3467 - accuracy: 0.7912 - precision_29: 0.2203 - val_loss: 7.5198 - val_accuracy: 0.9320 - val_precision_29: 0.0072 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 25.8174 - accuracy: 0.7872 - precision_29: 0.2119 - val_loss: 3.9288 - val_accuracy: 0.8412 - val_precision_29: 0.0238 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 28.9927 - accuracy: 0.7860 - precision_29: 0.2123 - val_loss: 10.3506 - val_accuracy: 0.9398 - val_precision_29: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 19.2541 - accuracy: 0.7929 - precision_29: 0.2219 - val_loss: 7.4693 - val_accuracy: 0.9375 - val_precision_29: 0.0042 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 17.7305 - accuracy: 0.7933 - precision_29: 0.2220 - val_loss: 4.6761 - val_accuracy: 0.9094 - val_precision_29: 0.0035 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 17.7493 - accuracy: 0.7938 - precision_29: 0.2294 - val_loss: 3.9716 - val_accuracy: 0.7860 - val_precision_29: 0.0192 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.0644 - accuracy: 0.7897 - precision_29: 0.2164 - val_loss: 11.6901 - val_accuracy: 0.9544 - val_precision_29: 0.0041 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 28.3193 - accuracy: 0.7918 - precision_29: 0.2103 - val_loss: 10.2842 - val_accuracy: 0.6946 - val_precision_29: 0.0349 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.5797 - accuracy: 0.7918 - precision_29: 0.2249 - val_loss: 7.7784 - val_accuracy: 0.6892 - val_precision_29: 0.0500 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.0333 - accuracy: 0.7969 - precision_29: 0.2315 - val_loss: 3.1994 - val_accuracy: 0.8481 - val_precision_29: 0.0143 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.4337 - accuracy: 0.7960 - precision_29: 0.2292 - val_loss: 10.3777 - val_accuracy: 0.8487 - val_precision_29: 0.0263 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.3811 - accuracy: 0.7961 - precision_29: 0.2286 - val_loss: 12.8580 - val_accuracy: 0.5781 - val_precision_29: 0.0442 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.3330 - accuracy: 0.7954 - precision_29: 0.2313 - val_loss: 5.1743 - val_accuracy: 0.8596 - val_precision_29: 0.0151 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 12.6288 - accuracy: 0.7991 - precision_29: 0.2316 - val_loss: 8.3995 - val_accuracy: 0.9159 - val_precision_29: 0.0270 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 11.1685 - accuracy: 0.8009 - precision_29: 0.2354 - val_loss: 2.0974 - val_accuracy: 0.8121 - val_precision_29: 0.0243 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 8.4836 - accuracy: 0.8011 - precision_29: 0.2379 - val_loss: 2.8807 - val_accuracy: 0.8274 - val_precision_29: 0.0184 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 11.0361 - accuracy: 0.8012 - precision_29: 0.2415 - val_loss: 6.8806 - val_accuracy: 0.8636 - val_precision_29: 0.0218 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 13.0100 - accuracy: 0.7964 - precision_29: 0.2222 - val_loss: 7.3082 - val_accuracy: 0.9049 - val_precision_29: 0.0228 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.2379 - accuracy: 0.8027 - precision_29: 0.2399 - val_loss: 3.3998 - val_accuracy: 0.8925 - val_precision_29: 0.0177 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.2731 - accuracy: 0.7995 - precision_29: 0.2329 - val_loss: 8.9078 - val_accuracy: 0.9205 - val_precision_29: 0.0280 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.8965 - accuracy: 0.8040 - precision_29: 0.2412 - val_loss: 9.5161 - val_accuracy: 0.6275 - val_precision_29: 0.0478 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.1381 - accuracy: 0.8033 - precision_29: 0.2416 - val_loss: 1.7013 - val_accuracy: 0.8881 - val_precision_29: 0.0127 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.7337 - accuracy: 0.8000 - precision_29: 0.2375 - val_loss: 3.9721 - val_accuracy: 0.9074 - val_precision_29: 0.0142 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.2339 - accuracy: 0.8055 - precision_29: 0.2471 - val_loss: 2.3467 - val_accuracy: 0.8921 - val_precision_29: 0.0072 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.9828 - accuracy: 0.8059 - precision_29: 0.2448 - val_loss: 5.2480 - val_accuracy: 0.8658 - val_precision_29: 0.0191 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.3487 - accuracy: 0.8037 - precision_29: 0.2458 - val_loss: 2.2951 - val_accuracy: 0.8229 - val_precision_29: 0.0192 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.9726 - accuracy: 0.8072 - precision_29: 0.2563 - val_loss: 6.9964 - val_accuracy: 0.6509 - val_precision_29: 0.0507 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.6310 - accuracy: 0.8049 - precision_29: 0.2516 - val_loss: 1.6628 - val_accuracy: 0.8387 - val_precision_29: 0.0249 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.4331 - accuracy: 0.8078 - precision_29: 0.2562 - val_loss: 1.5018 - val_accuracy: 0.8456 - val_precision_29: 0.0134 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.1800 - accuracy: 0.8056 - precision_29: 0.2406 - val_loss: 2.0499 - val_accuracy: 0.9140 - val_precision_29: 0.0134 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.2369 - accuracy: 0.8097 - precision_29: 0.2598 - val_loss: 1.5032 - val_accuracy: 0.8236 - val_precision_29: 0.0278 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.9438 - accuracy: 0.8087 - precision_29: 0.2558 - val_loss: 2.3925 - val_accuracy: 0.7141 - val_precision_29: 0.0461 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.2330 - accuracy: 0.8053 - precision_29: 0.2456 - val_loss: 4.5381 - val_accuracy: 0.9139 - val_precision_29: 0.0250 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.8394 - accuracy: 0.8084 - precision_29: 0.2496 - val_loss: 3.5467 - val_accuracy: 0.6544 - val_precision_29: 0.0458 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.9185 - accuracy: 0.8047 - precision_29: 0.2367 - val_loss: 1.3776 - val_accuracy: 0.8538 - val_precision_29: 0.0178 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.6899 - accuracy: 0.8084 - precision_29: 0.2601 - val_loss: 1.2982 - val_accuracy: 0.9436 - val_precision_29: 0.0025 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.9191 - accuracy: 0.8117 - precision_29: 0.2637 - val_loss: 1.7445 - val_accuracy: 0.9219 - val_precision_29: 0.0248 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.1454 - accuracy: 0.8095 - precision_29: 0.2522 - val_loss: 0.9646 - val_accuracy: 0.8336 - val_precision_29: 0.0292 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 3.0408 - accuracy: 0.8104 - precision_29: 0.2586 - val_loss: 1.8070 - val_accuracy: 0.7255 - val_precision_29: 0.0359 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.4734 - accuracy: 0.8108 - precision_29: 0.2643 - val_loss: 1.0920 - val_accuracy: 0.8733 - val_precision_29: 0.0129 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.5758 - accuracy: 0.8100 - precision_29: 0.2506 - val_loss: 0.7890 - val_accuracy: 0.8891 - val_precision_29: 0.0305 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 1.6498 - accuracy: 0.8129 - precision_29: 0.2724 - val_loss: 0.8724 - val_accuracy: 0.8999 - val_precision_29: 0.0175 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7294 - accuracy: 0.8172 - precision_29: 0.2799 - val_loss: 0.6722 - val_accuracy: 0.9140 - val_precision_29: 0.0062 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7277 - accuracy: 0.8137 - precision_29: 0.2623 - val_loss: 3.7997 - val_accuracy: 0.6218 - val_precision_29: 0.0403 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8613 - accuracy: 0.8149 - precision_29: 0.2708 - val_loss: 2.4772 - val_accuracy: 0.7757 - val_precision_29: 0.0303 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6973 - accuracy: 0.8141 - precision_29: 0.2668 - val_loss: 4.4138 - val_accuracy: 0.5406 - val_precision_29: 0.0443 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0884 - accuracy: 0.8194 - precision_29: 0.2798 - val_loss: 0.8327 - val_accuracy: 0.7594 - val_precision_29: 0.0510 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3188 - accuracy: 0.8159 - precision_29: 0.2601 - val_loss: 0.6064 - val_accuracy: 0.8568 - val_precision_29: 0.0303 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2280 - accuracy: 0.8185 - precision_29: 0.2710 - val_loss: 0.6203 - val_accuracy: 0.8619 - val_precision_29: 0.0104 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0777 - accuracy: 0.8187 - precision_29: 0.2721 - val_loss: 0.6293 - val_accuracy: 0.8591 - val_precision_29: 0.0274 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9803 - accuracy: 0.8224 - precision_29: 0.2809 - val_loss: 0.3941 - val_accuracy: 0.8843 - val_precision_29: 0.0304 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8582 - accuracy: 0.8220 - precision_29: 0.2754 - val_loss: 0.4541 - val_accuracy: 0.9015 - val_precision_29: 0.0217 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8533 - accuracy: 0.8224 - precision_29: 0.2730 - val_loss: 0.3672 - val_accuracy: 0.8969 - val_precision_29: 0.0249 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.8296 - precision_29: 0.3011 - val_loss: 0.4393 - val_accuracy: 0.8226 - val_precision_29: 0.0608 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.8285 - precision_29: 0.2893 - val_loss: 0.3504 - val_accuracy: 0.9454 - val_precision_29: 0.0308 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.8319 - precision_29: 0.3027 - val_loss: 0.3504 - val_accuracy: 0.9061 - val_precision_29: 0.0461 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.8365 - precision_29: 0.3090 - val_loss: 0.4870 - val_accuracy: 0.7858 - val_precision_29: 0.0705 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.8340 - precision_29: 0.3035 - val_loss: 0.3661 - val_accuracy: 0.9143 - val_precision_29: 0.0263 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.8363 - precision_29: 0.3156 - val_loss: 0.3485 - val_accuracy: 0.8995 - val_precision_29: 0.0345 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.8430 - precision_29: 0.3442 - val_loss: 0.4017 - val_accuracy: 0.9465 - val_precision_29: 0.0192 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.8432 - precision_29: 0.3417 - val_loss: 0.3102 - val_accuracy: 0.9269 - val_precision_29: 0.0260 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.8353 - precision_29: 0.3026 - val_loss: 0.3417 - val_accuracy: 0.8932 - val_precision_29: 0.0375 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4282 - accuracy: 0.8495 - precision_29: 0.3815 - val_loss: 0.3078 - val_accuracy: 0.9181 - val_precision_29: 0.0339 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4037 - accuracy: 0.8533 - precision_29: 0.4236 - val_loss: 0.3073 - val_accuracy: 0.9372 - val_precision_29: 0.0220 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8515 - precision_29: 0.4087 - val_loss: 0.2935 - val_accuracy: 0.9230 - val_precision_29: 0.0446 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4481 - accuracy: 0.8463 - precision_29: 0.3652 - val_loss: 0.2760 - val_accuracy: 0.9370 - val_precision_29: 0.0418 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4228 - accuracy: 0.8507 - precision_29: 0.4024 - val_loss: 0.3250 - val_accuracy: 0.8909 - val_precision_29: 0.0287 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8513 - precision_29: 0.4068 - val_loss: 0.3250 - val_accuracy: 0.9194 - val_precision_29: 0.0323 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8569 - precision_29: 0.4835 - val_loss: 0.2091 - val_accuracy: 0.9607 - val_precision_29: 0.0355 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8514 - precision_29: 0.4040 - val_loss: 0.2729 - val_accuracy: 0.9277 - val_precision_29: 0.0322 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8581 - precision_29: 0.5060 - val_loss: 0.2400 - val_accuracy: 0.9438 - val_precision_29: 0.0403 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8566 - precision_29: 0.4786 - val_loss: 0.2213 - val_accuracy: 0.9547 - val_precision_29: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8543 - precision_29: 0.4423 - val_loss: 0.2612 - val_accuracy: 0.9328 - val_precision_29: 0.0329 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8505 - precision_29: 0.4039 - val_loss: 0.2267 - val_accuracy: 0.9577 - val_precision_29: 0.0417 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8561 - precision_29: 0.4711 - val_loss: 0.2941 - val_accuracy: 0.9143 - val_precision_29: 0.0251 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8547 - precision_29: 0.4489 - val_loss: 0.2862 - val_accuracy: 0.9158 - val_precision_29: 0.0315 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8601 - precision_29: 0.5493 - val_loss: 0.2798 - val_accuracy: 0.9318 - val_precision_29: 0.0306 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8585 - precision_29: 0.5146 - val_loss: 0.2306 - val_accuracy: 0.9480 - val_precision_29: 0.0312 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8594 - precision_29: 0.5352 - val_loss: 0.2965 - val_accuracy: 0.8985 - val_precision_29: 0.0280 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8608 - precision_29: 0.5647 - val_loss: 0.3065 - val_accuracy: 0.8990 - val_precision_29: 0.0291 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8606 - precision_29: 0.5607 - val_loss: 0.2265 - val_accuracy: 0.9523 - val_precision_29: 0.0211 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8601 - precision_29: 0.5498 - val_loss: 0.2544 - val_accuracy: 0.9386 - val_precision_29: 0.0148 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8610 - precision_29: 0.5687 - val_loss: 0.2382 - val_accuracy: 0.9486 - val_precision_29: 0.0236 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8603 - precision_29: 0.5504 - val_loss: 0.2558 - val_accuracy: 0.9403 - val_precision_29: 0.0419 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8623 - precision_29: 0.6003 - val_loss: 0.2158 - val_accuracy: 0.9596 - val_precision_29: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8606 - precision_29: 0.5570 - val_loss: 0.2734 - val_accuracy: 0.9235 - val_precision_29: 0.0348 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8624 - precision_29: 0.6014 - val_loss: 0.2346 - val_accuracy: 0.9482 - val_precision_29: 0.0519 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8615 - precision_29: 0.5845 - val_loss: 0.2746 - val_accuracy: 0.9231 - val_precision_29: 0.0384 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3643 - accuracy: 0.8626 - precision_29: 0.6041 - val_loss: 0.2270 - val_accuracy: 0.9513 - val_precision_29: 0.0613 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8657 - precision_29: 0.6843 - val_loss: 0.2709 - val_accuracy: 0.9216 - val_precision_29: 0.0435 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3566 - accuracy: 0.8652 - precision_29: 0.6627 - val_loss: 0.2326 - val_accuracy: 0.9398 - val_precision_29: 0.0356 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 232.6567 - accuracy: 0.7563 - precision_30: 0.1481 - val_loss: 136.4931 - val_accuracy: 0.9707 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 120.0402 - accuracy: 0.7741 - precision_30: 0.1748 - val_loss: 16.4125 - val_accuracy: 0.8601 - val_precision_30: 0.0322 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 74.4127 - accuracy: 0.7810 - precision_30: 0.1953 - val_loss: 15.5535 - val_accuracy: 0.8542 - val_precision_30: 0.0291 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 62.6848 - accuracy: 0.7854 - precision_30: 0.2049 - val_loss: 29.1947 - val_accuracy: 0.9409 - val_precision_30: 0.0046 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 60.2347 - accuracy: 0.7900 - precision_30: 0.2134 - val_loss: 32.1575 - val_accuracy: 0.9009 - val_precision_30: 0.0080 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 50.9900 - accuracy: 0.7932 - precision_30: 0.2147 - val_loss: 22.5953 - val_accuracy: 0.6426 - val_precision_30: 0.0393 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 84.1613 - accuracy: 0.7876 - precision_30: 0.2083 - val_loss: 12.5574 - val_accuracy: 0.8670 - val_precision_30: 0.0180 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 47.0091 - accuracy: 0.7963 - precision_30: 0.2224 - val_loss: 34.5365 - val_accuracy: 0.6119 - val_precision_30: 0.0410 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 58.1537 - accuracy: 0.7924 - precision_30: 0.2160 - val_loss: 48.8751 - val_accuracy: 0.9287 - val_precision_30: 0.0115 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 68.4778 - accuracy: 0.7994 - precision_30: 0.2177 - val_loss: 27.5089 - val_accuracy: 0.7642 - val_precision_30: 0.0195 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 50.3481 - accuracy: 0.7947 - precision_30: 0.2055 - val_loss: 10.8023 - val_accuracy: 0.8047 - val_precision_30: 0.0160 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 34.2619 - accuracy: 0.8005 - precision_30: 0.2250 - val_loss: 85.0580 - val_accuracy: 0.4822 - val_precision_30: 0.0410 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.6396 - accuracy: 0.8017 - precision_30: 0.2293 - val_loss: 10.9592 - val_accuracy: 0.8753 - val_precision_30: 0.0229 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 40.1414 - accuracy: 0.8006 - precision_30: 0.2216 - val_loss: 20.9970 - val_accuracy: 0.9174 - val_precision_30: 0.0216 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 32.2716 - accuracy: 0.8019 - precision_30: 0.2253 - val_loss: 12.6490 - val_accuracy: 0.8896 - val_precision_30: 0.0195 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.9714 - accuracy: 0.8046 - precision_30: 0.2346 - val_loss: 23.9069 - val_accuracy: 0.8249 - val_precision_30: 0.0267 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 28.2921 - accuracy: 0.8039 - precision_30: 0.2365 - val_loss: 25.7762 - val_accuracy: 0.6588 - val_precision_30: 0.0303 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 26.3911 - accuracy: 0.8012 - precision_30: 0.2343 - val_loss: 9.6784 - val_accuracy: 0.9160 - val_precision_30: 0.0139 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 25.3205 - accuracy: 0.8036 - precision_30: 0.2289 - val_loss: 13.8701 - val_accuracy: 0.9197 - val_precision_30: 0.0312 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.2409 - accuracy: 0.8038 - precision_30: 0.2347 - val_loss: 39.0175 - val_accuracy: 0.5821 - val_precision_30: 0.0445 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 22.2761 - accuracy: 0.8027 - precision_30: 0.2324 - val_loss: 8.2469 - val_accuracy: 0.8098 - val_precision_30: 0.0339 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 21.2102 - accuracy: 0.8041 - precision_30: 0.2386 - val_loss: 16.7553 - val_accuracy: 0.8762 - val_precision_30: 0.0169 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.2339 - accuracy: 0.8060 - precision_30: 0.2477 - val_loss: 3.9529 - val_accuracy: 0.8225 - val_precision_30: 0.0205 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.6819 - accuracy: 0.8041 - precision_30: 0.2308 - val_loss: 11.5395 - val_accuracy: 0.7454 - val_precision_30: 0.0418 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.3040 - accuracy: 0.8035 - precision_30: 0.2380 - val_loss: 7.3267 - val_accuracy: 0.8797 - val_precision_30: 0.0197 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.6123 - accuracy: 0.8063 - precision_30: 0.2395 - val_loss: 4.2977 - val_accuracy: 0.7821 - val_precision_30: 0.0326 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 16.0002 - accuracy: 0.8059 - precision_30: 0.2426 - val_loss: 6.5831 - val_accuracy: 0.8638 - val_precision_30: 0.0188 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.9018 - accuracy: 0.8035 - precision_30: 0.2408 - val_loss: 6.1611 - val_accuracy: 0.8834 - val_precision_30: 0.0279 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 12.3462 - accuracy: 0.8084 - precision_30: 0.2477 - val_loss: 4.7038 - val_accuracy: 0.9059 - val_precision_30: 0.0118 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.3595 - accuracy: 0.8058 - precision_30: 0.2501 - val_loss: 3.8246 - val_accuracy: 0.8611 - val_precision_30: 0.0237 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.2509 - accuracy: 0.8055 - precision_30: 0.2445 - val_loss: 9.1906 - val_accuracy: 0.8984 - val_precision_30: 0.0271 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 14.1691 - accuracy: 0.8079 - precision_30: 0.2452 - val_loss: 6.9555 - val_accuracy: 0.7285 - val_precision_30: 0.0293 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.8085 - accuracy: 0.8018 - precision_30: 0.2303 - val_loss: 10.4466 - val_accuracy: 0.9275 - val_precision_30: 0.0048 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.5081 - accuracy: 0.8021 - precision_30: 0.2201 - val_loss: 8.6950 - val_accuracy: 0.9472 - val_precision_30: 0.0142 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.7834 - accuracy: 0.8085 - precision_30: 0.2448 - val_loss: 6.1973 - val_accuracy: 0.9328 - val_precision_30: 0.0424 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.6285 - accuracy: 0.8067 - precision_30: 0.2293 - val_loss: 6.7366 - val_accuracy: 0.6488 - val_precision_30: 0.0443 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.8484 - accuracy: 0.8051 - precision_30: 0.2310 - val_loss: 2.8229 - val_accuracy: 0.8975 - val_precision_30: 0.0077 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.3730 - accuracy: 0.8086 - precision_30: 0.2381 - val_loss: 2.7293 - val_accuracy: 0.8679 - val_precision_30: 0.0239 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.9621 - accuracy: 0.8083 - precision_30: 0.2387 - val_loss: 2.1319 - val_accuracy: 0.8953 - val_precision_30: 0.0129 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.0423 - accuracy: 0.8090 - precision_30: 0.2338 - val_loss: 8.8942 - val_accuracy: 0.6012 - val_precision_30: 0.0379 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.1136 - accuracy: 0.8063 - precision_30: 0.2278 - val_loss: 2.0118 - val_accuracy: 0.8985 - val_precision_30: 0.0236 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.3536 - accuracy: 0.8095 - precision_30: 0.2372 - val_loss: 1.0827 - val_accuracy: 0.8721 - val_precision_30: 0.0314 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 3.2585 - accuracy: 0.8107 - precision_30: 0.2457 - val_loss: 1.0726 - val_accuracy: 0.8616 - val_precision_30: 0.0286 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 3.0651 - accuracy: 0.8113 - precision_30: 0.2434 - val_loss: 1.0539 - val_accuracy: 0.8830 - val_precision_30: 0.0219 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.5396 - accuracy: 0.8115 - precision_30: 0.2454 - val_loss: 1.5096 - val_accuracy: 0.7656 - val_precision_30: 0.0541 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 3.0189 - accuracy: 0.8105 - precision_30: 0.2339 - val_loss: 6.9069 - val_accuracy: 0.6378 - val_precision_30: 0.0384 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 2.7273 - accuracy: 0.8111 - precision_30: 0.2457 - val_loss: 1.0785 - val_accuracy: 0.8899 - val_precision_30: 0.0187 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2772 - accuracy: 0.8121 - precision_30: 0.2526 - val_loss: 0.8710 - val_accuracy: 0.8453 - val_precision_30: 0.0214 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.9416 - accuracy: 0.8126 - precision_30: 0.2472 - val_loss: 1.4369 - val_accuracy: 0.8872 - val_precision_30: 0.0298 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.3165 - accuracy: 0.8083 - precision_30: 0.2324 - val_loss: 2.4203 - val_accuracy: 0.7205 - val_precision_30: 0.0542 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0469 - accuracy: 0.8137 - precision_30: 0.2470 - val_loss: 0.7189 - val_accuracy: 0.9058 - val_precision_30: 0.0290 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7624 - accuracy: 0.8143 - precision_30: 0.2497 - val_loss: 2.7238 - val_accuracy: 0.6264 - val_precision_30: 0.0502 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4204 - accuracy: 0.8108 - precision_30: 0.2380 - val_loss: 0.5542 - val_accuracy: 0.9244 - val_precision_30: 0.0246 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.5736 - accuracy: 0.8144 - precision_30: 0.2453 - val_loss: 0.6737 - val_accuracy: 0.8993 - val_precision_30: 0.0362 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2803 - accuracy: 0.8121 - precision_30: 0.2297 - val_loss: 0.4322 - val_accuracy: 0.9523 - val_precision_30: 0.0108 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.1043 - accuracy: 0.8161 - precision_30: 0.2434 - val_loss: 0.4221 - val_accuracy: 0.9243 - val_precision_30: 0.0367 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7603 - accuracy: 0.8224 - precision_30: 0.2508 - val_loss: 0.3825 - val_accuracy: 0.9536 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8281 - accuracy: 0.8207 - precision_30: 0.2489 - val_loss: 0.5008 - val_accuracy: 0.8184 - val_precision_30: 0.0476 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.8258 - precision_30: 0.2656 - val_loss: 0.4529 - val_accuracy: 0.8346 - val_precision_30: 0.0625 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.8251 - precision_30: 0.2515 - val_loss: 0.3766 - val_accuracy: 0.8867 - val_precision_30: 0.0363 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.8324 - precision_30: 0.2815 - val_loss: 0.3976 - val_accuracy: 0.8985 - val_precision_30: 0.0271 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.8335 - precision_30: 0.2867 - val_loss: 0.2954 - val_accuracy: 0.9334 - val_precision_30: 0.0317 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.8336 - precision_30: 0.2799 - val_loss: 0.5714 - val_accuracy: 0.7600 - val_precision_30: 0.0663 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.8319 - precision_30: 0.2836 - val_loss: 0.2968 - val_accuracy: 0.9303 - val_precision_30: 0.0168 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.8402 - precision_30: 0.3107 - val_loss: 0.3428 - val_accuracy: 0.9060 - val_precision_30: 0.0960 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8432 - precision_30: 0.3162 - val_loss: 0.2930 - val_accuracy: 0.9248 - val_precision_30: 0.0344 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8470 - precision_30: 0.3409 - val_loss: 0.2864 - val_accuracy: 0.9333 - val_precision_30: 0.0074 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6860 - accuracy: 0.8269 - precision_30: 0.2569 - val_loss: 0.6298 - val_accuracy: 0.9047 - val_precision_30: 0.0443 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.6080 - accuracy: 0.8376 - precision_30: 0.2892 - val_loss: 0.2583 - val_accuracy: 0.9482 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.8406 - precision_30: 0.3058 - val_loss: 0.3236 - val_accuracy: 0.9341 - val_precision_30: 0.0372 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8545 - precision_30: 0.4305 - val_loss: 0.2911 - val_accuracy: 0.9227 - val_precision_30: 0.0265 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.8429 - precision_30: 0.3240 - val_loss: 0.2922 - val_accuracy: 0.9453 - val_precision_30: 0.0080 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8014 - accuracy: 0.8307 - precision_30: 0.2729 - val_loss: 0.3783 - val_accuracy: 0.8577 - val_precision_30: 0.0327 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.8384 - precision_30: 0.3143 - val_loss: 0.2570 - val_accuracy: 0.9377 - val_precision_30: 0.0261 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8537 - precision_30: 0.4240 - val_loss: 0.2776 - val_accuracy: 0.9162 - val_precision_30: 0.0271 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8550 - precision_30: 0.4380 - val_loss: 0.2575 - val_accuracy: 0.9402 - val_precision_30: 0.0068 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8521 - precision_30: 0.4069 - val_loss: 0.3033 - val_accuracy: 0.9206 - val_precision_30: 0.0242 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8559 - precision_30: 0.4572 - val_loss: 0.2053 - val_accuracy: 0.9587 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.6118 - accuracy: 0.8219 - precision_30: 0.2571 - val_loss: 0.4647 - val_accuracy: 0.9466 - val_precision_30: 0.0192 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.8484 - precision_30: 0.3658 - val_loss: 0.3164 - val_accuracy: 0.9239 - val_precision_30: 0.0175 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8574 - precision_30: 0.4883 - val_loss: 0.3209 - val_accuracy: 0.9118 - val_precision_30: 0.0295 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8533 - precision_30: 0.4187 - val_loss: 0.2225 - val_accuracy: 0.9599 - val_precision_30: 0.0059 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8573 - precision_30: 0.4833 - val_loss: 0.2770 - val_accuracy: 0.9394 - val_precision_30: 0.0192 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8760 - accuracy: 0.8347 - precision_30: 0.2695 - val_loss: 0.2977 - val_accuracy: 0.9313 - val_precision_30: 0.0035 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8580 - precision_30: 0.5021 - val_loss: 0.2865 - val_accuracy: 0.9317 - val_precision_30: 0.0174 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8606 - precision_30: 0.5967 - val_loss: 0.2777 - val_accuracy: 0.9292 - val_precision_30: 0.0448 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8616 - precision_30: 0.6202 - val_loss: 0.2530 - val_accuracy: 0.9423 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8613 - precision_30: 0.6195 - val_loss: 0.2715 - val_accuracy: 0.9329 - val_precision_30: 0.0196 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8611 - precision_30: 0.6019 - val_loss: 0.2229 - val_accuracy: 0.9564 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8619 - precision_30: 0.6355 - val_loss: 0.2247 - val_accuracy: 0.9538 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8618 - precision_30: 0.6330 - val_loss: 0.2677 - val_accuracy: 0.9296 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8626 - precision_30: 0.6658 - val_loss: 0.2378 - val_accuracy: 0.9471 - val_precision_30: 0.0029 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3628 - accuracy: 0.8636 - precision_30: 0.7005 - val_loss: 0.2634 - val_accuracy: 0.9278 - val_precision_30: 0.0351 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3634 - accuracy: 0.8629 - precision_30: 0.6635 - val_loss: 0.2078 - val_accuracy: 0.9624 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3652 - accuracy: 0.8621 - precision_30: 0.6438 - val_loss: 0.2839 - val_accuracy: 0.9122 - val_precision_30: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.8616 - precision_30: 0.6259 - val_loss: 0.2292 - val_accuracy: 0.9541 - val_precision_30: 0.0040 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.8633 - precision_30: 0.6762 - val_loss: 0.2439 - val_accuracy: 0.9410 - val_precision_30: 0.0180 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8631 - precision_30: 0.6636 - val_loss: 0.2634 - val_accuracy: 0.9368 - val_precision_30: 0.0345 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8647 - precision_30: 0.7161 - val_loss: 0.2238 - val_accuracy: 0.9509 - val_precision_30: 0.0133 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8649 - precision_30: 0.7206 - val_loss: 0.2571 - val_accuracy: 0.9362 - val_precision_30: 0.0375 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 2s 6ms/step - loss: 294.8786 - accuracy: 0.7626 - precision_31: 0.1518 - val_loss: 36.2367 - val_accuracy: 0.7536 - val_precision_31: 0.0167 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 136.8342 - accuracy: 0.7640 - precision_31: 0.1643 - val_loss: 26.4297 - val_accuracy: 0.6840 - val_precision_31: 0.0109 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 108.5842 - accuracy: 0.7628 - precision_31: 0.1756 - val_loss: 119.1129 - val_accuracy: 0.5401 - val_precision_31: 0.0411 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 126.4869 - accuracy: 0.7685 - precision_31: 0.1840 - val_loss: 90.9625 - val_accuracy: 0.9688 - val_precision_31: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 81.4912 - accuracy: 0.7705 - precision_31: 0.1847 - val_loss: 17.9427 - val_accuracy: 0.9223 - val_precision_31: 0.0223 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 94.3628 - accuracy: 0.7739 - precision_31: 0.1848 - val_loss: 39.8562 - val_accuracy: 0.8695 - val_precision_31: 0.0178 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 76.9202 - accuracy: 0.7703 - precision_31: 0.1937 - val_loss: 63.3334 - val_accuracy: 0.4425 - val_precision_31: 0.0386 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 67.2235 - accuracy: 0.7732 - precision_31: 0.1927 - val_loss: 17.9815 - val_accuracy: 0.8170 - val_precision_31: 0.0211 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 56.5515 - accuracy: 0.7801 - precision_31: 0.2147 - val_loss: 23.1010 - val_accuracy: 0.9655 - val_precision_31: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 54.4133 - accuracy: 0.7806 - precision_31: 0.2043 - val_loss: 12.7203 - val_accuracy: 0.8628 - val_precision_31: 0.0318 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 61.7672 - accuracy: 0.7811 - precision_31: 0.2096 - val_loss: 37.7087 - val_accuracy: 0.9693 - val_precision_31: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 66.2981 - accuracy: 0.7880 - precision_31: 0.2117 - val_loss: 17.0015 - val_accuracy: 0.8412 - val_precision_31: 0.0293 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 41.6964 - accuracy: 0.7875 - precision_31: 0.2188 - val_loss: 35.3486 - val_accuracy: 0.5473 - val_precision_31: 0.0435 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 42.4351 - accuracy: 0.7916 - precision_31: 0.2245 - val_loss: 11.6693 - val_accuracy: 0.8196 - val_precision_31: 0.0148 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 35.8990 - accuracy: 0.7933 - precision_31: 0.2268 - val_loss: 9.5932 - val_accuracy: 0.8825 - val_precision_31: 0.0195 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 36.3733 - accuracy: 0.7905 - precision_31: 0.2199 - val_loss: 16.9447 - val_accuracy: 0.8750 - val_precision_31: 0.0187 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 32.1779 - accuracy: 0.7974 - precision_31: 0.2313 - val_loss: 22.7716 - val_accuracy: 0.5691 - val_precision_31: 0.0420 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.0899 - accuracy: 0.7925 - precision_31: 0.2226 - val_loss: 10.6982 - val_accuracy: 0.8964 - val_precision_31: 0.0194 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.9689 - accuracy: 0.7961 - precision_31: 0.2264 - val_loss: 15.4778 - val_accuracy: 0.9362 - val_precision_31: 0.0322 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 23.8102 - accuracy: 0.7937 - precision_31: 0.2237 - val_loss: 14.0134 - val_accuracy: 0.9289 - val_precision_31: 0.0301 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 22.1887 - accuracy: 0.7966 - precision_31: 0.2280 - val_loss: 10.6098 - val_accuracy: 0.8973 - val_precision_31: 0.0232 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 36.5772 - accuracy: 0.7945 - precision_31: 0.2248 - val_loss: 16.9406 - val_accuracy: 0.6193 - val_precision_31: 0.0443 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 42.9754 - accuracy: 0.7914 - precision_31: 0.2187 - val_loss: 11.7007 - val_accuracy: 0.9306 - val_precision_31: 0.0086 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.3538 - accuracy: 0.8009 - precision_31: 0.2363 - val_loss: 10.3871 - val_accuracy: 0.9061 - val_precision_31: 0.0087 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.4359 - accuracy: 0.7987 - precision_31: 0.2253 - val_loss: 5.6808 - val_accuracy: 0.8047 - val_precision_31: 0.0180 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 21.6869 - accuracy: 0.7967 - precision_31: 0.2311 - val_loss: 23.1370 - val_accuracy: 0.9566 - val_precision_31: 0.0046 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 29.9135 - accuracy: 0.7922 - precision_31: 0.2184 - val_loss: 11.9457 - val_accuracy: 0.8728 - val_precision_31: 0.0290 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 15.1832 - accuracy: 0.8016 - precision_31: 0.2361 - val_loss: 13.8444 - val_accuracy: 0.6809 - val_precision_31: 0.0460 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 17.1325 - accuracy: 0.7977 - precision_31: 0.2297 - val_loss: 5.4007 - val_accuracy: 0.9221 - val_precision_31: 0.0086 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 19.0845 - accuracy: 0.8021 - precision_31: 0.2365 - val_loss: 8.9603 - val_accuracy: 0.9423 - val_precision_31: 0.0423 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 18.6102 - accuracy: 0.7987 - precision_31: 0.2314 - val_loss: 25.6600 - val_accuracy: 0.9529 - val_precision_31: 0.0111 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 30.2384 - accuracy: 0.7891 - precision_31: 0.2071 - val_loss: 3.6643 - val_accuracy: 0.8833 - val_precision_31: 0.0242 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.7901 - accuracy: 0.8039 - precision_31: 0.2304 - val_loss: 5.9587 - val_accuracy: 0.9093 - val_precision_31: 0.0274 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 20.4892 - accuracy: 0.7998 - precision_31: 0.2249 - val_loss: 15.5089 - val_accuracy: 0.7927 - val_precision_31: 0.0172 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 17.6448 - accuracy: 0.7998 - precision_31: 0.2250 - val_loss: 3.2259 - val_accuracy: 0.9262 - val_precision_31: 0.0353 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.1765 - accuracy: 0.8039 - precision_31: 0.2332 - val_loss: 4.4379 - val_accuracy: 0.8329 - val_precision_31: 0.0220 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.0351 - accuracy: 0.7998 - precision_31: 0.2287 - val_loss: 3.5962 - val_accuracy: 0.8225 - val_precision_31: 0.0205 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 8.1486 - accuracy: 0.8031 - precision_31: 0.2387 - val_loss: 3.9144 - val_accuracy: 0.8433 - val_precision_31: 0.0185 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.6784 - accuracy: 0.8056 - precision_31: 0.2371 - val_loss: 5.4543 - val_accuracy: 0.8735 - val_precision_31: 0.0232 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 13.6551 - accuracy: 0.8004 - precision_31: 0.2333 - val_loss: 11.4843 - val_accuracy: 0.6014 - val_precision_31: 0.0438 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 11.7661 - accuracy: 0.8010 - precision_31: 0.2341 - val_loss: 1.6061 - val_accuracy: 0.9113 - val_precision_31: 0.0071 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.5413 - accuracy: 0.8058 - precision_31: 0.2455 - val_loss: 2.1228 - val_accuracy: 0.8073 - val_precision_31: 0.0247 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 7.1163 - accuracy: 0.8048 - precision_31: 0.2359 - val_loss: 4.4326 - val_accuracy: 0.8792 - val_precision_31: 0.0238 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.7820 - accuracy: 0.7953 - precision_31: 0.2311 - val_loss: 2.1134 - val_accuracy: 0.7963 - val_precision_31: 0.0187 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 9.6654 - accuracy: 0.8025 - precision_31: 0.2341 - val_loss: 2.1070 - val_accuracy: 0.8271 - val_precision_31: 0.0239 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.4822 - accuracy: 0.8045 - precision_31: 0.2372 - val_loss: 2.1213 - val_accuracy: 0.8860 - val_precision_31: 0.0195 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.7312 - accuracy: 0.8050 - precision_31: 0.2360 - val_loss: 5.2857 - val_accuracy: 0.9073 - val_precision_31: 0.0256 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.7880 - accuracy: 0.8043 - precision_31: 0.2383 - val_loss: 1.6586 - val_accuracy: 0.8571 - val_precision_31: 0.0212 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.0724 - accuracy: 0.8073 - precision_31: 0.2544 - val_loss: 1.7889 - val_accuracy: 0.9400 - val_precision_31: 0.0111 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.6605 - accuracy: 0.8051 - precision_31: 0.2366 - val_loss: 2.0787 - val_accuracy: 0.8943 - val_precision_31: 0.0215 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.3332 - accuracy: 0.8059 - precision_31: 0.2432 - val_loss: 1.3926 - val_accuracy: 0.8941 - val_precision_31: 0.0223 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.0681 - accuracy: 0.8056 - precision_31: 0.2352 - val_loss: 1.5267 - val_accuracy: 0.9177 - val_precision_31: 0.0254 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 4.1987 - accuracy: 0.8068 - precision_31: 0.2425 - val_loss: 2.5889 - val_accuracy: 0.7376 - val_precision_31: 0.0231 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.8436 - accuracy: 0.8042 - precision_31: 0.2353 - val_loss: 1.2953 - val_accuracy: 0.9157 - val_precision_31: 0.0280 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.4373 - accuracy: 0.8067 - precision_31: 0.2426 - val_loss: 3.1167 - val_accuracy: 0.9271 - val_precision_31: 0.0318 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.5517 - accuracy: 0.8064 - precision_31: 0.2388 - val_loss: 6.9786 - val_accuracy: 0.5801 - val_precision_31: 0.0481 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.5276 - accuracy: 0.8017 - precision_31: 0.2331 - val_loss: 0.6415 - val_accuracy: 0.9142 - val_precision_31: 0.0158 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.5519 - accuracy: 0.8070 - precision_31: 0.2437 - val_loss: 1.3860 - val_accuracy: 0.9464 - val_precision_31: 0.0056 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.2516 - accuracy: 0.8100 - precision_31: 0.2534 - val_loss: 1.3704 - val_accuracy: 0.8684 - val_precision_31: 0.0247 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.7747 - accuracy: 0.8083 - precision_31: 0.2459 - val_loss: 1.3164 - val_accuracy: 0.8577 - val_precision_31: 0.0201 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.0937 - accuracy: 0.8080 - precision_31: 0.2488 - val_loss: 0.6849 - val_accuracy: 0.9234 - val_precision_31: 0.0360 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.8805 - accuracy: 0.8110 - precision_31: 0.2488 - val_loss: 1.1086 - val_accuracy: 0.9253 - val_precision_31: 0.0306 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.7788 - accuracy: 0.8093 - precision_31: 0.2479 - val_loss: 0.7317 - val_accuracy: 0.8564 - val_precision_31: 0.0182 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.3414 - accuracy: 0.8138 - precision_31: 0.2589 - val_loss: 0.6891 - val_accuracy: 0.9196 - val_precision_31: 0.0287 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4972 - accuracy: 0.8131 - precision_31: 0.2493 - val_loss: 0.8258 - val_accuracy: 0.9268 - val_precision_31: 0.0259 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2675 - accuracy: 0.8139 - precision_31: 0.2576 - val_loss: 0.6598 - val_accuracy: 0.9154 - val_precision_31: 0.0255 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2431 - accuracy: 0.8146 - precision_31: 0.2557 - val_loss: 0.8302 - val_accuracy: 0.9228 - val_precision_31: 0.0292 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9985 - accuracy: 0.8180 - precision_31: 0.2763 - val_loss: 0.5184 - val_accuracy: 0.8348 - val_precision_31: 0.0404 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0731 - accuracy: 0.8186 - precision_31: 0.2644 - val_loss: 0.9557 - val_accuracy: 0.9170 - val_precision_31: 0.0251 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.4343 - accuracy: 0.8111 - precision_31: 0.2461 - val_loss: 0.5178 - val_accuracy: 0.9341 - val_precision_31: 0.0388 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9019 - accuracy: 0.8162 - precision_31: 0.2551 - val_loss: 0.4080 - val_accuracy: 0.9495 - val_precision_31: 0.0465 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8118 - accuracy: 0.8218 - precision_31: 0.2682 - val_loss: 0.3347 - val_accuracy: 0.9033 - val_precision_31: 0.0251 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7601 - accuracy: 0.8237 - precision_31: 0.2763 - val_loss: 0.2746 - val_accuracy: 0.9274 - val_precision_31: 0.0511 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0916 - accuracy: 0.8236 - precision_31: 0.2737 - val_loss: 2.4617 - val_accuracy: 0.9424 - val_precision_31: 0.0211 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 3.2844 - accuracy: 0.8036 - precision_31: 0.2314 - val_loss: 0.9180 - val_accuracy: 0.7814 - val_precision_31: 0.0351 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.0209 - accuracy: 0.8112 - precision_31: 0.2430 - val_loss: 0.6198 - val_accuracy: 0.9463 - val_precision_31: 0.0366 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8674 - accuracy: 0.8235 - precision_31: 0.2676 - val_loss: 0.4888 - val_accuracy: 0.8388 - val_precision_31: 0.0364 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.8375 - precision_31: 0.3068 - val_loss: 0.2893 - val_accuracy: 0.9343 - val_precision_31: 0.0390 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.8317 - precision_31: 0.2910 - val_loss: 0.3684 - val_accuracy: 0.8876 - val_precision_31: 0.0644 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.8749 - accuracy: 0.8180 - precision_31: 0.2483 - val_loss: 1.9050 - val_accuracy: 0.6505 - val_precision_31: 0.0310 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 10.9483 - accuracy: 0.7908 - precision_31: 0.1976 - val_loss: 3.7076 - val_accuracy: 0.9313 - val_precision_31: 0.0453 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 2.9616 - accuracy: 0.8051 - precision_31: 0.2187 - val_loss: 2.5345 - val_accuracy: 0.5087 - val_precision_31: 0.0428 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.8706 - accuracy: 0.8143 - precision_31: 0.2403 - val_loss: 0.2945 - val_accuracy: 0.9183 - val_precision_31: 0.0280 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.8281 - precision_31: 0.2684 - val_loss: 0.2535 - val_accuracy: 0.9379 - val_precision_31: 0.0373 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.8323 - precision_31: 0.2753 - val_loss: 0.4041 - val_accuracy: 0.8337 - val_precision_31: 0.0727 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.8416 - precision_31: 0.3074 - val_loss: 0.2561 - val_accuracy: 0.9477 - val_precision_31: 0.0532 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.8406 - precision_31: 0.2978 - val_loss: 0.2628 - val_accuracy: 0.9357 - val_precision_31: 0.0335 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8493 - precision_31: 0.3696 - val_loss: 0.2981 - val_accuracy: 0.9333 - val_precision_31: 0.0381 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8483 - precision_31: 0.3527 - val_loss: 0.2795 - val_accuracy: 0.9223 - val_precision_31: 0.0276 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8485 - precision_31: 0.3635 - val_loss: 0.2598 - val_accuracy: 0.9350 - val_precision_31: 0.0363 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8531 - precision_31: 0.4147 - val_loss: 0.2484 - val_accuracy: 0.9392 - val_precision_31: 0.0150 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8530 - precision_31: 0.4181 - val_loss: 0.2813 - val_accuracy: 0.9364 - val_precision_31: 0.0560 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.8449 - precision_31: 0.3451 - val_loss: 0.4658 - val_accuracy: 0.9421 - val_precision_31: 0.0380 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 6.1974 - accuracy: 0.8115 - precision_31: 0.2376 - val_loss: 13.5874 - val_accuracy: 0.7861 - val_precision_31: 0.0235 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 5.2040 - accuracy: 0.7958 - precision_31: 0.2031 - val_loss: 1.9040 - val_accuracy: 0.6183 - val_precision_31: 0.0514 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7678 - accuracy: 0.8181 - precision_31: 0.2319 - val_loss: 0.3047 - val_accuracy: 0.9111 - val_precision_31: 0.0374 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.8460 - precision_31: 0.3261 - val_loss: 0.2723 - val_accuracy: 0.9262 - val_precision_31: 0.0312 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8502 - precision_31: 0.3698 - val_loss: 0.3076 - val_accuracy: 0.8960 - val_precision_31: 0.0271 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8485 - precision_31: 0.3494 - val_loss: 0.2787 - val_accuracy: 0.9244 - val_precision_31: 0.0287 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8488 - precision_31: 0.3568 - val_loss: 0.3047 - val_accuracy: 0.9062 - val_precision_31: 0.0433 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 3s 6ms/step - loss: 135.5631 - accuracy: 0.7552 - precision_32: 0.1570 - val_loss: 23.2535 - val_accuracy: 0.9608 - val_precision_32: 0.0125 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 53.5643 - accuracy: 0.7727 - precision_32: 0.1728 - val_loss: 21.6268 - val_accuracy: 0.9643 - val_precision_32: 0.0263 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 90.4141 - accuracy: 0.7688 - precision_32: 0.1682 - val_loss: 92.3401 - val_accuracy: 0.3502 - val_precision_32: 0.0346 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 40.5336 - accuracy: 0.7841 - precision_32: 0.1837 - val_loss: 30.8852 - val_accuracy: 0.9626 - val_precision_32: 0.0147 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 37.3935 - accuracy: 0.7867 - precision_32: 0.1922 - val_loss: 22.7918 - val_accuracy: 0.9624 - val_precision_32: 0.0074 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 44.7748 - accuracy: 0.7901 - precision_32: 0.1935 - val_loss: 140.7119 - val_accuracy: 0.2138 - val_precision_32: 0.0307 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 43.4503 - accuracy: 0.7856 - precision_32: 0.1792 - val_loss: 8.3752 - val_accuracy: 0.8937 - val_precision_32: 0.0153 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 33.1526 - accuracy: 0.7957 - precision_32: 0.1984 - val_loss: 6.9438 - val_accuracy: 0.8345 - val_precision_32: 0.0335 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 26.7333 - accuracy: 0.7943 - precision_32: 0.1947 - val_loss: 14.6706 - val_accuracy: 0.9455 - val_precision_32: 0.0080 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.0326 - accuracy: 0.7933 - precision_32: 0.1976 - val_loss: 13.0367 - val_accuracy: 0.9489 - val_precision_32: 0.0062 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 35.8864 - accuracy: 0.7942 - precision_32: 0.1960 - val_loss: 24.4310 - val_accuracy: 0.8589 - val_precision_32: 0.0131 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.1134 - accuracy: 0.7927 - precision_32: 0.1931 - val_loss: 15.2430 - val_accuracy: 0.8925 - val_precision_32: 0.0159 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 25.8649 - accuracy: 0.7999 - precision_32: 0.2053 - val_loss: 6.0122 - val_accuracy: 0.9338 - val_precision_32: 0.0038 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.0363 - accuracy: 0.7994 - precision_32: 0.1979 - val_loss: 5.2914 - val_accuracy: 0.7371 - val_precision_32: 0.0337 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.7187 - accuracy: 0.8025 - precision_32: 0.2077 - val_loss: 7.4692 - val_accuracy: 0.9182 - val_precision_32: 0.0194 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.7980 - accuracy: 0.8026 - precision_32: 0.2046 - val_loss: 3.7071 - val_accuracy: 0.8245 - val_precision_32: 0.0266 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.3813 - accuracy: 0.8019 - precision_32: 0.2056 - val_loss: 11.5968 - val_accuracy: 0.9449 - val_precision_32: 0.0079 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 14.5577 - accuracy: 0.8045 - precision_32: 0.2184 - val_loss: 4.8610 - val_accuracy: 0.8820 - val_precision_32: 0.0164 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 22.6044 - accuracy: 0.8023 - precision_32: 0.2227 - val_loss: 29.4841 - val_accuracy: 0.5874 - val_precision_32: 0.0441 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 11.2108 - accuracy: 0.8038 - precision_32: 0.2137 - val_loss: 2.8636 - val_accuracy: 0.8528 - val_precision_32: 0.0130 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 10.7991 - accuracy: 0.8039 - precision_32: 0.2205 - val_loss: 5.3372 - val_accuracy: 0.9223 - val_precision_32: 0.0043 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.9955 - accuracy: 0.8036 - precision_32: 0.2166 - val_loss: 5.1265 - val_accuracy: 0.9169 - val_precision_32: 0.0103 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.1634 - accuracy: 0.8066 - precision_32: 0.2180 - val_loss: 1.9516 - val_accuracy: 0.8792 - val_precision_32: 0.0062 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.7225 - accuracy: 0.8043 - precision_32: 0.2137 - val_loss: 2.0366 - val_accuracy: 0.8524 - val_precision_32: 0.0147 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.5275 - accuracy: 0.8061 - precision_32: 0.2200 - val_loss: 2.3728 - val_accuracy: 0.8410 - val_precision_32: 0.0197 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 8.1102 - accuracy: 0.8083 - precision_32: 0.2305 - val_loss: 2.4630 - val_accuracy: 0.9009 - val_precision_32: 0.0040 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.4368 - accuracy: 0.8047 - precision_32: 0.2138 - val_loss: 7.7883 - val_accuracy: 0.9544 - val_precision_32: 0.0041 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.6945 - accuracy: 0.8090 - precision_32: 0.2335 - val_loss: 8.0425 - val_accuracy: 0.5871 - val_precision_32: 0.0442 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.4318 - accuracy: 0.8047 - precision_32: 0.2227 - val_loss: 2.1713 - val_accuracy: 0.7493 - val_precision_32: 0.0312 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.8269 - accuracy: 0.8082 - precision_32: 0.2295 - val_loss: 2.7415 - val_accuracy: 0.9212 - val_precision_32: 0.0014 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.8901 - accuracy: 0.8053 - precision_32: 0.2231 - val_loss: 3.8723 - val_accuracy: 0.9211 - val_precision_32: 0.0084 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.0489 - accuracy: 0.8094 - precision_32: 0.2210 - val_loss: 27.1385 - val_accuracy: 0.3998 - val_precision_32: 0.0374 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.2135 - accuracy: 0.8055 - precision_32: 0.2201 - val_loss: 2.4380 - val_accuracy: 0.7346 - val_precision_32: 0.0528 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.9027 - accuracy: 0.8067 - precision_32: 0.2283 - val_loss: 2.9999 - val_accuracy: 0.9278 - val_precision_32: 0.0096 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.7384 - accuracy: 0.8072 - precision_32: 0.2139 - val_loss: 2.1593 - val_accuracy: 0.8921 - val_precision_32: 0.0045 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.7229 - accuracy: 0.8069 - precision_32: 0.2132 - val_loss: 1.7156 - val_accuracy: 0.8931 - val_precision_32: 0.0046 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3139 - accuracy: 0.8089 - precision_32: 0.2200 - val_loss: 8.2299 - val_accuracy: 0.5782 - val_precision_32: 0.0448 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.6505 - accuracy: 0.8091 - precision_32: 0.2259 - val_loss: 1.6678 - val_accuracy: 0.7320 - val_precision_32: 0.0362 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3305 - accuracy: 0.8141 - precision_32: 0.2391 - val_loss: 0.8717 - val_accuracy: 0.8835 - val_precision_32: 0.0081 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9842 - accuracy: 0.8100 - precision_32: 0.2312 - val_loss: 0.7587 - val_accuracy: 0.8625 - val_precision_32: 0.0148 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.0207 - accuracy: 0.8102 - precision_32: 0.2270 - val_loss: 1.2617 - val_accuracy: 0.9234 - val_precision_32: 0.0102 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.7979 - accuracy: 0.8154 - precision_32: 0.2384 - val_loss: 4.1876 - val_accuracy: 0.5535 - val_precision_32: 0.0413 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.7655 - accuracy: 0.8123 - precision_32: 0.2338 - val_loss: 0.8391 - val_accuracy: 0.7748 - val_precision_32: 0.0308 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.5069 - accuracy: 0.8160 - precision_32: 0.2426 - val_loss: 2.7530 - val_accuracy: 0.6306 - val_precision_32: 0.0350 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.5325 - accuracy: 0.8148 - precision_32: 0.2386 - val_loss: 0.5600 - val_accuracy: 0.9071 - val_precision_32: 0.0022 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.1873 - accuracy: 0.8173 - precision_32: 0.2463 - val_loss: 0.7481 - val_accuracy: 0.9472 - val_precision_32: 0.0029 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0008 - accuracy: 0.8202 - precision_32: 0.2514 - val_loss: 0.5125 - val_accuracy: 0.9406 - val_precision_32: 0.0023 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.1189 - accuracy: 0.8189 - precision_32: 0.2430 - val_loss: 0.5939 - val_accuracy: 0.7966 - val_precision_32: 0.0321 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.7768 - accuracy: 0.8238 - precision_32: 0.2623 - val_loss: 0.3409 - val_accuracy: 0.9193 - val_precision_32: 0.0081 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.9573 - accuracy: 0.8224 - precision_32: 0.2521 - val_loss: 2.7168 - val_accuracy: 0.6252 - val_precision_32: 0.0446 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8692 - accuracy: 0.8216 - precision_32: 0.2509 - val_loss: 0.5026 - val_accuracy: 0.9469 - val_precision_32: 0.0247 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.8305 - precision_32: 0.2609 - val_loss: 0.2992 - val_accuracy: 0.9428 - val_precision_32: 0.0167 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.8336 - precision_32: 0.2747 - val_loss: 0.3595 - val_accuracy: 0.9001 - val_precision_32: 0.0338 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.5563 - accuracy: 0.8307 - precision_32: 0.2539 - val_loss: 0.3037 - val_accuracy: 0.9121 - val_precision_32: 0.0359 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7167 - accuracy: 0.8249 - precision_32: 0.2383 - val_loss: 0.3569 - val_accuracy: 0.8849 - val_precision_32: 0.0363 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.8364 - precision_32: 0.2690 - val_loss: 0.3716 - val_accuracy: 0.8907 - val_precision_32: 0.0424 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7040 - accuracy: 0.8272 - precision_32: 0.2384 - val_loss: 0.3929 - val_accuracy: 0.8589 - val_precision_32: 0.0613 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.8338 - precision_32: 0.2529 - val_loss: 0.2489 - val_accuracy: 0.9647 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.8398 - precision_32: 0.2758 - val_loss: 0.2572 - val_accuracy: 0.9532 - val_precision_32: 0.0255 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.8265 - precision_32: 0.2360 - val_loss: 0.4896 - val_accuracy: 0.9572 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.4110 - accuracy: 0.8184 - precision_32: 0.2071 - val_loss: 0.2830 - val_accuracy: 0.9520 - val_precision_32: 0.0106 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4360 - accuracy: 0.8467 - precision_32: 0.3016 - val_loss: 0.4103 - val_accuracy: 0.8429 - val_precision_32: 0.0730 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.8400 - precision_32: 0.2707 - val_loss: 0.2804 - val_accuracy: 0.9269 - val_precision_32: 0.0302 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8462 - precision_32: 0.3008 - val_loss: 0.6520 - val_accuracy: 0.6436 - val_precision_32: 0.0532 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8481 - precision_32: 0.3157 - val_loss: 0.3069 - val_accuracy: 0.9411 - val_precision_32: 0.0224 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3952 - accuracy: 0.8554 - precision_32: 0.4216 - val_loss: 0.2276 - val_accuracy: 0.9494 - val_precision_32: 0.0094 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4717 - accuracy: 0.8456 - precision_32: 0.3051 - val_loss: 0.2248 - val_accuracy: 0.9625 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4321 - accuracy: 0.8477 - precision_32: 0.3241 - val_loss: 0.2998 - val_accuracy: 0.9363 - val_precision_32: 0.0269 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3924 - accuracy: 0.8551 - precision_32: 0.4159 - val_loss: 0.3933 - val_accuracy: 0.8684 - val_precision_32: 0.0800 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3933 - accuracy: 0.8560 - precision_32: 0.4334 - val_loss: 0.2313 - val_accuracy: 0.9619 - val_precision_32: 0.0331 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2566 - accuracy: 0.8456 - precision_32: 0.3001 - val_loss: 2.3784 - val_accuracy: 0.9719 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.4448 - accuracy: 0.8342 - precision_32: 0.2398 - val_loss: 0.2619 - val_accuracy: 0.9250 - val_precision_32: 0.0304 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8553 - precision_32: 0.4200 - val_loss: 0.5791 - val_accuracy: 0.7397 - val_precision_32: 0.0683 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8497 - precision_32: 0.3319 - val_loss: 0.3239 - val_accuracy: 0.8867 - val_precision_32: 0.0348 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8585 - precision_32: 0.5166 - val_loss: 0.2010 - val_accuracy: 0.9696 - val_precision_32: 0.0270 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8581 - precision_32: 0.5007 - val_loss: 0.2214 - val_accuracy: 0.9681 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8584 - precision_32: 0.5159 - val_loss: 0.2640 - val_accuracy: 0.9461 - val_precision_32: 0.0338 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8579 - precision_32: 0.4922 - val_loss: 0.2370 - val_accuracy: 0.9409 - val_precision_32: 0.0426 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8580 - precision_32: 0.4972 - val_loss: 0.2053 - val_accuracy: 0.9606 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8584 - precision_32: 0.5116 - val_loss: 0.2071 - val_accuracy: 0.9618 - val_precision_32: 0.0203 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8596 - precision_32: 0.5580 - val_loss: 0.2356 - val_accuracy: 0.9481 - val_precision_32: 0.0466 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8545 - precision_32: 0.4167 - val_loss: 0.2429 - val_accuracy: 0.9560 - val_precision_32: 0.0664 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.3923 - accuracy: 0.8568 - precision_32: 0.4474 - val_loss: 0.2262 - val_accuracy: 0.9671 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8593 - precision_32: 0.5432 - val_loss: 0.2467 - val_accuracy: 0.9446 - val_precision_32: 0.0274 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8599 - precision_32: 0.5693 - val_loss: 0.2202 - val_accuracy: 0.9587 - val_precision_32: 0.0106 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8588 - precision_32: 0.5287 - val_loss: 0.2419 - val_accuracy: 0.9476 - val_precision_32: 0.0279 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8599 - precision_32: 0.5683 - val_loss: 0.2627 - val_accuracy: 0.9174 - val_precision_32: 0.0311 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.8598 - precision_32: 0.5611 - val_loss: 0.2657 - val_accuracy: 0.9272 - val_precision_32: 0.0535 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8607 - precision_32: 0.5905 - val_loss: 0.2948 - val_accuracy: 0.9027 - val_precision_32: 0.0395 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8604 - precision_32: 0.5807 - val_loss: 0.1927 - val_accuracy: 0.9677 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3694 - accuracy: 0.8598 - precision_32: 0.5527 - val_loss: 0.2423 - val_accuracy: 0.9467 - val_precision_32: 0.0513 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3701 - accuracy: 0.8600 - precision_32: 0.5565 - val_loss: 0.2015 - val_accuracy: 0.9686 - val_precision_32: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3740 - accuracy: 0.8586 - precision_32: 0.5194 - val_loss: 0.4002 - val_accuracy: 0.8381 - val_precision_32: 0.0339 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3793 - accuracy: 0.8590 - precision_32: 0.5260 - val_loss: 0.3104 - val_accuracy: 0.8893 - val_precision_32: 0.0411 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3696 - accuracy: 0.8603 - precision_32: 0.5817 - val_loss: 0.2713 - val_accuracy: 0.9202 - val_precision_32: 0.0434 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8618 - precision_32: 0.6223 - val_loss: 0.2578 - val_accuracy: 0.9299 - val_precision_32: 0.0538 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3707 - accuracy: 0.8599 - precision_32: 0.5714 - val_loss: 0.2172 - val_accuracy: 0.9572 - val_precision_32: 0.0360 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8603 - precision_32: 0.5754 - val_loss: 0.2448 - val_accuracy: 0.9478 - val_precision_32: 0.0694 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8616 - precision_32: 0.6073 - val_loss: 0.2415 - val_accuracy: 0.9499 - val_precision_32: 0.0158 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8603 - precision_32: 0.5908 - val_loss: 0.2743 - val_accuracy: 0.9251 - val_precision_32: 0.0587 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 343.3031 - accuracy: 0.7483 - precision_33: 0.1313 - val_loss: 22.3847 - val_accuracy: 0.8512 - val_precision_33: 0.0185 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 56.2115 - accuracy: 0.7746 - precision_33: 0.1802 - val_loss: 18.6743 - val_accuracy: 0.9314 - val_precision_33: 0.0053 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 34.8668 - accuracy: 0.7855 - precision_33: 0.1992 - val_loss: 10.0856 - val_accuracy: 0.9176 - val_precision_33: 0.0204 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 54.9283 - accuracy: 0.7930 - precision_33: 0.2121 - val_loss: 13.5877 - val_accuracy: 0.8461 - val_precision_33: 0.0303 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 29.7334 - accuracy: 0.7924 - precision_33: 0.2175 - val_loss: 13.0142 - val_accuracy: 0.9192 - val_precision_33: 0.0107 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 39.8969 - accuracy: 0.7951 - precision_33: 0.2157 - val_loss: 7.1865 - val_accuracy: 0.8497 - val_precision_33: 0.0194 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.3425 - accuracy: 0.7925 - precision_33: 0.2185 - val_loss: 16.8891 - val_accuracy: 0.8941 - val_precision_33: 0.0281 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 39.1161 - accuracy: 0.7979 - precision_33: 0.2287 - val_loss: 14.6234 - val_accuracy: 0.8793 - val_precision_33: 0.0315 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 37.2606 - accuracy: 0.7965 - precision_33: 0.2270 - val_loss: 17.8890 - val_accuracy: 0.9633 - val_precision_33: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 37.5181 - accuracy: 0.8009 - precision_33: 0.2257 - val_loss: 12.5734 - val_accuracy: 0.9368 - val_precision_33: 0.0101 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 39.6948 - accuracy: 0.8011 - precision_33: 0.2292 - val_loss: 12.6477 - val_accuracy: 0.9089 - val_precision_33: 0.0156 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 24.6026 - accuracy: 0.8003 - precision_33: 0.2344 - val_loss: 15.4292 - val_accuracy: 0.8453 - val_precision_33: 0.0281 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 30.9066 - accuracy: 0.7999 - precision_33: 0.2241 - val_loss: 14.7644 - val_accuracy: 0.9184 - val_precision_33: 0.0144 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 31.3012 - accuracy: 0.8035 - precision_33: 0.2378 - val_loss: 9.3352 - val_accuracy: 0.8678 - val_precision_33: 0.0207 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 33.5759 - accuracy: 0.7986 - precision_33: 0.2309 - val_loss: 3.9546 - val_accuracy: 0.8206 - val_precision_33: 0.0276 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.9533 - accuracy: 0.8025 - precision_33: 0.2382 - val_loss: 22.5215 - val_accuracy: 0.8852 - val_precision_33: 0.0313 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.3609 - accuracy: 0.7984 - precision_33: 0.2407 - val_loss: 10.6608 - val_accuracy: 0.7182 - val_precision_33: 0.0142 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 36.6633 - accuracy: 0.8014 - precision_33: 0.2333 - val_loss: 9.5910 - val_accuracy: 0.8661 - val_precision_33: 0.0235 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 24.3288 - accuracy: 0.7966 - precision_33: 0.2284 - val_loss: 8.7256 - val_accuracy: 0.8975 - val_precision_33: 0.0232 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.3637 - accuracy: 0.8007 - precision_33: 0.2399 - val_loss: 11.5787 - val_accuracy: 0.9513 - val_precision_33: 0.0415 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 27.3357 - accuracy: 0.8036 - precision_33: 0.2403 - val_loss: 18.2316 - val_accuracy: 0.6035 - val_precision_33: 0.0473 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.6397 - accuracy: 0.8031 - precision_33: 0.2417 - val_loss: 4.3795 - val_accuracy: 0.9177 - val_precision_33: 0.0217 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.7383 - accuracy: 0.7986 - precision_33: 0.2389 - val_loss: 4.2036 - val_accuracy: 0.6904 - val_precision_33: 0.0174 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.5664 - accuracy: 0.8014 - precision_33: 0.2337 - val_loss: 3.8598 - val_accuracy: 0.8967 - val_precision_33: 0.0066 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.4815 - accuracy: 0.8037 - precision_33: 0.2402 - val_loss: 5.0918 - val_accuracy: 0.8771 - val_precision_33: 0.0219 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.5709 - accuracy: 0.8045 - precision_33: 0.2537 - val_loss: 13.5782 - val_accuracy: 0.9136 - val_precision_33: 0.0389 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.8483 - accuracy: 0.8015 - precision_33: 0.2415 - val_loss: 16.5715 - val_accuracy: 0.9522 - val_precision_33: 0.0107 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 20.8694 - accuracy: 0.8008 - precision_33: 0.2288 - val_loss: 4.1516 - val_accuracy: 0.9107 - val_precision_33: 0.0024 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.9192 - accuracy: 0.8019 - precision_33: 0.2408 - val_loss: 4.0244 - val_accuracy: 0.9232 - val_precision_33: 0.0172 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.7074 - accuracy: 0.8044 - precision_33: 0.2508 - val_loss: 6.8984 - val_accuracy: 0.9013 - val_precision_33: 0.0225 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.3689 - accuracy: 0.8030 - precision_33: 0.2437 - val_loss: 4.8898 - val_accuracy: 0.8376 - val_precision_33: 0.0241 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.4221 - accuracy: 0.8054 - precision_33: 0.2476 - val_loss: 13.3835 - val_accuracy: 0.9065 - val_precision_33: 0.0321 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.2711 - accuracy: 0.8094 - precision_33: 0.2579 - val_loss: 2.1689 - val_accuracy: 0.8237 - val_precision_33: 0.0233 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.0432 - accuracy: 0.8046 - precision_33: 0.2498 - val_loss: 3.8078 - val_accuracy: 0.7378 - val_precision_33: 0.0211 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.3597 - accuracy: 0.8022 - precision_33: 0.2456 - val_loss: 4.2325 - val_accuracy: 0.8729 - val_precision_33: 0.0322 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.7737 - accuracy: 0.8031 - precision_33: 0.2464 - val_loss: 12.7261 - val_accuracy: 0.9614 - val_precision_33: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.2270 - accuracy: 0.8045 - precision_33: 0.2494 - val_loss: 4.0324 - val_accuracy: 0.7610 - val_precision_33: 0.0192 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.0338 - accuracy: 0.8089 - precision_33: 0.2704 - val_loss: 2.1373 - val_accuracy: 0.6954 - val_precision_33: 0.0235 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.6382 - accuracy: 0.8047 - precision_33: 0.2620 - val_loss: 4.2057 - val_accuracy: 0.8374 - val_precision_33: 0.0265 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.6319 - accuracy: 0.8067 - precision_33: 0.2574 - val_loss: 2.8393 - val_accuracy: 0.8824 - val_precision_33: 0.0217 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.7154 - accuracy: 0.8065 - precision_33: 0.2639 - val_loss: 1.7005 - val_accuracy: 0.9017 - val_precision_33: 0.0130 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.0260 - accuracy: 0.8074 - precision_33: 0.2582 - val_loss: 4.6498 - val_accuracy: 0.8961 - val_precision_33: 0.0296 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.8030 - accuracy: 0.8014 - precision_33: 0.2365 - val_loss: 7.7172 - val_accuracy: 0.9372 - val_precision_33: 0.0365 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.8830 - accuracy: 0.8067 - precision_33: 0.2496 - val_loss: 5.4428 - val_accuracy: 0.8222 - val_precision_33: 0.0262 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.6964 - accuracy: 0.8029 - precision_33: 0.2470 - val_loss: 1.6977 - val_accuracy: 0.7923 - val_precision_33: 0.0415 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.4050 - accuracy: 0.8100 - precision_33: 0.2660 - val_loss: 1.0162 - val_accuracy: 0.8251 - val_precision_33: 0.0204 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3102 - accuracy: 0.8073 - precision_33: 0.2554 - val_loss: 1.2033 - val_accuracy: 0.8356 - val_precision_33: 0.0243 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.6596 - accuracy: 0.8102 - precision_33: 0.2719 - val_loss: 1.0456 - val_accuracy: 0.7962 - val_precision_33: 0.0243 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.9811 - accuracy: 0.8097 - precision_33: 0.2702 - val_loss: 1.6859 - val_accuracy: 0.7203 - val_precision_33: 0.0401 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 4.9415 - accuracy: 0.8052 - precision_33: 0.2511 - val_loss: 1.6535 - val_accuracy: 0.8439 - val_precision_33: 0.0268 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.8598 - accuracy: 0.8093 - precision_33: 0.2607 - val_loss: 1.0829 - val_accuracy: 0.7665 - val_precision_33: 0.0190 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9054 - accuracy: 0.8111 - precision_33: 0.2717 - val_loss: 1.6237 - val_accuracy: 0.8797 - val_precision_33: 0.0267 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.2461 - accuracy: 0.8120 - precision_33: 0.2716 - val_loss: 0.8131 - val_accuracy: 0.8802 - val_precision_33: 0.0153 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3251 - accuracy: 0.8112 - precision_33: 0.2603 - val_loss: 1.5491 - val_accuracy: 0.8850 - val_precision_33: 0.0215 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.9008 - accuracy: 0.8156 - precision_33: 0.2799 - val_loss: 0.8957 - val_accuracy: 0.8399 - val_precision_33: 0.0245 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.5809 - accuracy: 0.8164 - precision_33: 0.2812 - val_loss: 3.4623 - val_accuracy: 0.6430 - val_precision_33: 0.0495 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.9514 - accuracy: 0.8130 - precision_33: 0.2674 - val_loss: 0.8724 - val_accuracy: 0.8606 - val_precision_33: 0.0288 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.8314 - accuracy: 0.8102 - precision_33: 0.2577 - val_loss: 0.7847 - val_accuracy: 0.8256 - val_precision_33: 0.0254 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.4565 - accuracy: 0.8150 - precision_33: 0.2715 - val_loss: 0.4395 - val_accuracy: 0.8518 - val_precision_33: 0.0465 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.1131 - accuracy: 0.8193 - precision_33: 0.2839 - val_loss: 0.7615 - val_accuracy: 0.9215 - val_precision_33: 0.0057 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.0547 - accuracy: 0.8214 - precision_33: 0.2878 - val_loss: 0.4353 - val_accuracy: 0.9150 - val_precision_33: 0.0087 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.9875 - accuracy: 0.8206 - precision_33: 0.2844 - val_loss: 0.3978 - val_accuracy: 0.9083 - val_precision_33: 0.0122 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.9593 - accuracy: 0.8203 - precision_33: 0.2847 - val_loss: 0.4237 - val_accuracy: 0.8723 - val_precision_33: 0.0275 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.9054 - accuracy: 0.8162 - precision_33: 0.2715 - val_loss: 1.1048 - val_accuracy: 0.7019 - val_precision_33: 0.0556 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7616 - accuracy: 0.8221 - precision_33: 0.2892 - val_loss: 0.3805 - val_accuracy: 0.9259 - val_precision_33: 0.0211 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8097 - accuracy: 0.8222 - precision_33: 0.2821 - val_loss: 0.3566 - val_accuracy: 0.8972 - val_precision_33: 0.0317 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.8260 - precision_33: 0.2950 - val_loss: 0.5788 - val_accuracy: 0.7641 - val_precision_33: 0.0204 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.8279 - precision_33: 0.2994 - val_loss: 0.3592 - val_accuracy: 0.8883 - val_precision_33: 0.0369 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.8322 - precision_33: 0.3139 - val_loss: 0.3283 - val_accuracy: 0.9195 - val_precision_33: 0.0429 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.8359 - precision_33: 0.3254 - val_loss: 0.5885 - val_accuracy: 0.7929 - val_precision_33: 0.0513 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.8235 - precision_33: 0.2814 - val_loss: 0.3477 - val_accuracy: 0.9201 - val_precision_33: 0.0433 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.8335 - precision_33: 0.3061 - val_loss: 0.6188 - val_accuracy: 0.7853 - val_precision_33: 0.0550 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.8393 - precision_33: 0.3269 - val_loss: 0.4517 - val_accuracy: 0.8383 - val_precision_33: 0.0626 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.8385 - precision_33: 0.3258 - val_loss: 0.2987 - val_accuracy: 0.9246 - val_precision_33: 0.0407 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.8346 - precision_33: 0.3157 - val_loss: 0.2369 - val_accuracy: 0.9615 - val_precision_33: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.8365 - precision_33: 0.3161 - val_loss: 0.2753 - val_accuracy: 0.9495 - val_precision_33: 0.0412 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8461 - precision_33: 0.3596 - val_loss: 0.2968 - val_accuracy: 0.9365 - val_precision_33: 0.0428 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.8419 - precision_33: 0.3426 - val_loss: 0.5599 - val_accuracy: 0.7651 - val_precision_33: 0.0195 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8501 - precision_33: 0.3969 - val_loss: 0.2975 - val_accuracy: 0.9435 - val_precision_33: 0.0418 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8469 - precision_33: 0.3683 - val_loss: 0.3328 - val_accuracy: 0.9160 - val_precision_33: 0.0469 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8518 - precision_33: 0.4114 - val_loss: 0.3174 - val_accuracy: 0.8900 - val_precision_33: 0.0228 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.8343 - precision_33: 0.3021 - val_loss: 0.3664 - val_accuracy: 0.9511 - val_precision_33: 0.0261 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.8450 - precision_33: 0.3511 - val_loss: 0.3291 - val_accuracy: 0.8881 - val_precision_33: 0.0368 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8506 - precision_33: 0.3888 - val_loss: 0.2254 - val_accuracy: 0.9552 - val_precision_33: 0.0465 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3896 - accuracy: 0.8558 - precision_33: 0.4568 - val_loss: 0.2569 - val_accuracy: 0.9362 - val_precision_33: 0.0664 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.8918 - accuracy: 0.8360 - precision_33: 0.3076 - val_loss: 2.7120 - val_accuracy: 0.5027 - val_precision_33: 0.0453 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2126 - accuracy: 0.8136 - precision_33: 0.2465 - val_loss: 0.4305 - val_accuracy: 0.8290 - val_precision_33: 0.0819 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.8412 - precision_33: 0.3330 - val_loss: 0.3087 - val_accuracy: 0.9071 - val_precision_33: 0.0362 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4279 - accuracy: 0.8476 - precision_33: 0.3757 - val_loss: 0.3257 - val_accuracy: 0.9033 - val_precision_33: 0.0425 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8520 - precision_33: 0.4111 - val_loss: 0.4187 - val_accuracy: 0.8416 - val_precision_33: 0.0623 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.4302 - accuracy: 0.8470 - precision_33: 0.3702 - val_loss: 0.3616 - val_accuracy: 0.8647 - val_precision_33: 0.0262 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8525 - precision_33: 0.4163 - val_loss: 0.4867 - val_accuracy: 0.8107 - val_precision_33: 0.0446 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.8263 - precision_33: 0.2781 - val_loss: 0.3459 - val_accuracy: 0.8906 - val_precision_33: 0.0386 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8571 - precision_33: 0.4794 - val_loss: 0.2780 - val_accuracy: 0.9281 - val_precision_33: 0.0569 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8603 - precision_33: 0.5500 - val_loss: 0.2779 - val_accuracy: 0.9236 - val_precision_33: 0.0461 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8571 - precision_33: 0.4795 - val_loss: 0.3220 - val_accuracy: 0.8946 - val_precision_33: 0.0340 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.8543 - precision_33: 0.4373 - val_loss: 0.4242 - val_accuracy: 0.8310 - val_precision_33: 0.0263 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8558 - precision_33: 0.4590 - val_loss: 0.2697 - val_accuracy: 0.9488 - val_precision_33: 0.0121 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8593 - precision_33: 0.5209 - val_loss: 0.2516 - val_accuracy: 0.9522 - val_precision_33: 0.0072 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8596 - precision_33: 0.5300 - val_loss: 0.3193 - val_accuracy: 0.8946 - val_precision_33: 0.0348 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 192.5220 - accuracy: 0.7657 - precision_34: 0.1619 - val_loss: 23.4368 - val_accuracy: 0.9409 - val_precision_34: 0.0243 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 95.0483 - accuracy: 0.7707 - precision_34: 0.1808 - val_loss: 114.9060 - val_accuracy: 0.8160 - val_precision_34: 0.0153 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 92.1985 - accuracy: 0.7785 - precision_34: 0.1973 - val_loss: 28.8305 - val_accuracy: 0.8362 - val_precision_34: 0.0185 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 67.0121 - accuracy: 0.7853 - precision_34: 0.2089 - val_loss: 29.0698 - val_accuracy: 0.9573 - val_precision_34: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 58.4593 - accuracy: 0.7878 - precision_34: 0.2031 - val_loss: 37.1569 - val_accuracy: 0.7974 - val_precision_34: 0.0207 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 47.7907 - accuracy: 0.7930 - precision_34: 0.2091 - val_loss: 32.4955 - val_accuracy: 0.5920 - val_precision_34: 0.0475 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 44.4053 - accuracy: 0.7903 - precision_34: 0.2085 - val_loss: 10.8353 - val_accuracy: 0.9414 - val_precision_34: 0.0268 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 49.7672 - accuracy: 0.7904 - precision_34: 0.2073 - val_loss: 10.8290 - val_accuracy: 0.9574 - val_precision_34: 0.0049 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 44.4484 - accuracy: 0.7925 - precision_34: 0.2038 - val_loss: 9.9139 - val_accuracy: 0.8964 - val_precision_34: 0.0094 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 70.9315 - accuracy: 0.7983 - precision_34: 0.2103 - val_loss: 10.6228 - val_accuracy: 0.9289 - val_precision_34: 0.0066 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 51.0187 - accuracy: 0.7956 - precision_34: 0.2111 - val_loss: 6.2887 - val_accuracy: 0.9106 - val_precision_34: 0.0081 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 32.5009 - accuracy: 0.7992 - precision_34: 0.2191 - val_loss: 13.1431 - val_accuracy: 0.9164 - val_precision_34: 0.0114 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 34.8978 - accuracy: 0.7949 - precision_34: 0.2176 - val_loss: 18.4462 - val_accuracy: 0.9562 - val_precision_34: 0.0089 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 40.4322 - accuracy: 0.7992 - precision_34: 0.2207 - val_loss: 8.7873 - val_accuracy: 0.9480 - val_precision_34: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.8174 - accuracy: 0.7961 - precision_34: 0.2146 - val_loss: 7.0846 - val_accuracy: 0.8816 - val_precision_34: 0.0207 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 25.9992 - accuracy: 0.8038 - precision_34: 0.2327 - val_loss: 7.0861 - val_accuracy: 0.7360 - val_precision_34: 0.0448 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 42.4435 - accuracy: 0.7980 - precision_34: 0.2190 - val_loss: 16.5551 - val_accuracy: 0.7500 - val_precision_34: 0.0236 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.2123 - accuracy: 0.7995 - precision_34: 0.2247 - val_loss: 4.4341 - val_accuracy: 0.8863 - val_precision_34: 0.0171 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.7092 - accuracy: 0.8010 - precision_34: 0.2288 - val_loss: 20.4413 - val_accuracy: 0.9303 - val_precision_34: 0.0324 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.2750 - accuracy: 0.8023 - precision_34: 0.2320 - val_loss: 4.0991 - val_accuracy: 0.8796 - val_precision_34: 0.0130 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 20.9750 - accuracy: 0.7975 - precision_34: 0.2220 - val_loss: 4.0864 - val_accuracy: 0.9392 - val_precision_34: 0.0044 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.8359 - accuracy: 0.8032 - precision_34: 0.2348 - val_loss: 5.6270 - val_accuracy: 0.8522 - val_precision_34: 0.0169 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 20.8352 - accuracy: 0.8005 - precision_34: 0.2229 - val_loss: 4.6804 - val_accuracy: 0.9060 - val_precision_34: 0.0180 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 24.9010 - accuracy: 0.8040 - precision_34: 0.2265 - val_loss: 22.8756 - val_accuracy: 0.9532 - val_precision_34: 0.0148 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.1487 - accuracy: 0.8018 - precision_34: 0.2304 - val_loss: 7.5325 - val_accuracy: 0.9205 - val_precision_34: 0.0163 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.1456 - accuracy: 0.8061 - precision_34: 0.2365 - val_loss: 4.7285 - val_accuracy: 0.9052 - val_precision_34: 0.0247 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.2313 - accuracy: 0.8004 - precision_34: 0.2244 - val_loss: 5.7984 - val_accuracy: 0.7236 - val_precision_34: 0.0410 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.0070 - accuracy: 0.8061 - precision_34: 0.2361 - val_loss: 6.2315 - val_accuracy: 0.9265 - val_precision_34: 0.0093 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.1619 - accuracy: 0.8048 - precision_34: 0.2224 - val_loss: 8.8983 - val_accuracy: 0.9013 - val_precision_34: 0.0343 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 17.5593 - accuracy: 0.8030 - precision_34: 0.2227 - val_loss: 30.3213 - val_accuracy: 0.6054 - val_precision_34: 0.0463 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 12.2407 - accuracy: 0.8051 - precision_34: 0.2320 - val_loss: 27.1811 - val_accuracy: 0.5298 - val_precision_34: 0.0455 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.9057 - accuracy: 0.8037 - precision_34: 0.2380 - val_loss: 8.4689 - val_accuracy: 0.9218 - val_precision_34: 0.0336 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.1293 - accuracy: 0.8072 - precision_34: 0.2303 - val_loss: 2.8040 - val_accuracy: 0.9123 - val_precision_34: 0.0231 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.5903 - accuracy: 0.8045 - precision_34: 0.2306 - val_loss: 5.2771 - val_accuracy: 0.9406 - val_precision_34: 0.0156 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.5655 - accuracy: 0.8094 - precision_34: 0.2470 - val_loss: 2.3239 - val_accuracy: 0.8940 - val_precision_34: 0.0153 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.3660 - accuracy: 0.8066 - precision_34: 0.2360 - val_loss: 2.2658 - val_accuracy: 0.9091 - val_precision_34: 0.0156 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.0450 - accuracy: 0.8087 - precision_34: 0.2461 - val_loss: 2.7345 - val_accuracy: 0.9559 - val_precision_34: 0.0044 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.9873 - accuracy: 0.8061 - precision_34: 0.2282 - val_loss: 8.7224 - val_accuracy: 0.5819 - val_precision_34: 0.0466 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.5192 - accuracy: 0.8077 - precision_34: 0.2474 - val_loss: 1.7071 - val_accuracy: 0.8802 - val_precision_34: 0.0062 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.2621 - accuracy: 0.8101 - precision_34: 0.2530 - val_loss: 11.7210 - val_accuracy: 0.5710 - val_precision_34: 0.0466 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.7235 - accuracy: 0.8072 - precision_34: 0.2368 - val_loss: 1.5605 - val_accuracy: 0.8488 - val_precision_34: 0.0198 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.2981 - accuracy: 0.8094 - precision_34: 0.2539 - val_loss: 1.0821 - val_accuracy: 0.8469 - val_precision_34: 0.0305 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.6428 - accuracy: 0.8097 - precision_34: 0.2513 - val_loss: 2.1882 - val_accuracy: 0.9261 - val_precision_34: 0.0062 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.4554 - accuracy: 0.8097 - precision_34: 0.2475 - val_loss: 1.6505 - val_accuracy: 0.9301 - val_precision_34: 0.0017 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.4080 - accuracy: 0.8153 - precision_34: 0.2734 - val_loss: 1.2053 - val_accuracy: 0.8568 - val_precision_34: 0.0062 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3010 - accuracy: 0.8132 - precision_34: 0.2698 - val_loss: 1.2523 - val_accuracy: 0.9220 - val_precision_34: 0.0029 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9089 - accuracy: 0.8113 - precision_34: 0.2550 - val_loss: 1.7413 - val_accuracy: 0.9252 - val_precision_34: 0.0091 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.7538 - accuracy: 0.8123 - precision_34: 0.2570 - val_loss: 1.2768 - val_accuracy: 0.7415 - val_precision_34: 0.0413 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.7480 - accuracy: 0.8098 - precision_34: 0.2526 - val_loss: 0.7781 - val_accuracy: 0.8917 - val_precision_34: 0.0054 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.1158 - accuracy: 0.8136 - precision_34: 0.2651 - val_loss: 0.7760 - val_accuracy: 0.9083 - val_precision_34: 0.0122 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.9892 - accuracy: 0.8143 - precision_34: 0.2664 - val_loss: 0.5963 - val_accuracy: 0.9011 - val_precision_34: 0.0051 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.4723 - accuracy: 0.8187 - precision_34: 0.2810 - val_loss: 0.9185 - val_accuracy: 0.8867 - val_precision_34: 0.0211 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2437 - accuracy: 0.8190 - precision_34: 0.2822 - val_loss: 0.5049 - val_accuracy: 0.9034 - val_precision_34: 0.0052 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.3659 - accuracy: 0.8207 - precision_34: 0.2821 - val_loss: 0.5943 - val_accuracy: 0.8579 - val_precision_34: 0.0189 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2591 - accuracy: 0.8156 - precision_34: 0.2585 - val_loss: 0.3958 - val_accuracy: 0.8584 - val_precision_34: 0.0394 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.0924 - accuracy: 0.8185 - precision_34: 0.2665 - val_loss: 0.4134 - val_accuracy: 0.8530 - val_precision_34: 0.0314 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.7126 - accuracy: 0.8273 - precision_34: 0.2864 - val_loss: 0.4922 - val_accuracy: 0.8234 - val_precision_34: 0.0404 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.7846 - accuracy: 0.8261 - precision_34: 0.2860 - val_loss: 0.3419 - val_accuracy: 0.9205 - val_precision_34: 0.0328 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6085 - accuracy: 0.8303 - precision_34: 0.2864 - val_loss: 0.3936 - val_accuracy: 0.8905 - val_precision_34: 0.0362 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.8315 - precision_34: 0.2901 - val_loss: 0.3184 - val_accuracy: 0.9128 - val_precision_34: 0.0435 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.8416 - precision_34: 0.3379 - val_loss: 0.3348 - val_accuracy: 0.8823 - val_precision_34: 0.0224 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.8341 - precision_34: 0.3011 - val_loss: 0.4432 - val_accuracy: 0.8707 - val_precision_34: 0.0663 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.8318 - precision_34: 0.2893 - val_loss: 0.2741 - val_accuracy: 0.9398 - val_precision_34: 0.0448 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.8391 - precision_34: 0.3110 - val_loss: 0.3171 - val_accuracy: 0.9385 - val_precision_34: 0.0246 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.8451 - precision_34: 0.3455 - val_loss: 0.2147 - val_accuracy: 0.9641 - val_precision_34: 0.0088 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.8383 - precision_34: 0.3118 - val_loss: 0.3491 - val_accuracy: 0.9016 - val_precision_34: 0.0327 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8498 - precision_34: 0.3830 - val_loss: 0.5727 - val_accuracy: 0.7783 - val_precision_34: 0.0732 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.8430 - precision_34: 0.3290 - val_loss: 0.2377 - val_accuracy: 0.9534 - val_precision_34: 0.0325 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8455 - precision_34: 0.3441 - val_loss: 0.3540 - val_accuracy: 0.9130 - val_precision_34: 0.0585 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.8405 - precision_34: 0.3230 - val_loss: 0.3454 - val_accuracy: 0.9581 - val_precision_34: 0.0101 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.8763 - accuracy: 0.8130 - precision_34: 0.2215 - val_loss: 0.3783 - val_accuracy: 0.9212 - val_precision_34: 0.0405 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.8517 - precision_34: 0.3592 - val_loss: 0.3415 - val_accuracy: 0.9506 - val_precision_34: 0.0286 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.4585 - accuracy: 0.8575 - precision_34: 0.4734 - val_loss: 0.2579 - val_accuracy: 0.9489 - val_precision_34: 0.0743 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8592 - precision_34: 0.5295 - val_loss: 0.2556 - val_accuracy: 0.9616 - val_precision_34: 0.1158 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8595 - precision_34: 0.5357 - val_loss: 0.2210 - val_accuracy: 0.9581 - val_precision_34: 0.0381 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8585 - precision_34: 0.5047 - val_loss: 0.2478 - val_accuracy: 0.9484 - val_precision_34: 0.0638 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8585 - precision_34: 0.5080 - val_loss: 0.2116 - val_accuracy: 0.9646 - val_precision_34: 0.0270 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8586 - precision_34: 0.5086 - val_loss: 0.2076 - val_accuracy: 0.9645 - val_precision_34: 0.0093 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8583 - precision_34: 0.4989 - val_loss: 0.2259 - val_accuracy: 0.9610 - val_precision_34: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3805 - accuracy: 0.8586 - precision_34: 0.5078 - val_loss: 0.2722 - val_accuracy: 0.9333 - val_precision_34: 0.0315 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3741 - accuracy: 0.8600 - precision_34: 0.5568 - val_loss: 0.2577 - val_accuracy: 0.9259 - val_precision_34: 0.0239 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3731 - accuracy: 0.8599 - precision_34: 0.5495 - val_loss: 0.2355 - val_accuracy: 0.9575 - val_precision_34: 0.0684 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 0.8598 - precision_34: 0.5505 - val_loss: 0.2440 - val_accuracy: 0.9438 - val_precision_34: 0.0443 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8605 - precision_34: 0.5671 - val_loss: 0.2834 - val_accuracy: 0.9144 - val_precision_34: 0.0361 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8602 - precision_34: 0.5559 - val_loss: 0.2343 - val_accuracy: 0.9469 - val_precision_34: 0.0347 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.8605 - precision_34: 0.5793 - val_loss: 0.2630 - val_accuracy: 0.9312 - val_precision_34: 0.0436 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3664 - accuracy: 0.8616 - precision_34: 0.6039 - val_loss: 0.2424 - val_accuracy: 0.9446 - val_precision_34: 0.0759 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8623 - precision_34: 0.6313 - val_loss: 0.2361 - val_accuracy: 0.9497 - val_precision_34: 0.0571 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8606 - precision_34: 0.5680 - val_loss: 0.2258 - val_accuracy: 0.9530 - val_precision_34: 0.0111 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8606 - precision_34: 0.5719 - val_loss: 0.2536 - val_accuracy: 0.9359 - val_precision_34: 0.0404 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8622 - precision_34: 0.6181 - val_loss: 0.2529 - val_accuracy: 0.9380 - val_precision_34: 0.0531 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8590 - precision_34: 0.5220 - val_loss: 0.2248 - val_accuracy: 0.9544 - val_precision_34: 0.0578 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8619 - precision_34: 0.6079 - val_loss: 0.2354 - val_accuracy: 0.9434 - val_precision_34: 0.0329 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3711 - accuracy: 0.8602 - precision_34: 0.5517 - val_loss: 0.2091 - val_accuracy: 0.9689 - val_precision_34: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8610 - precision_34: 0.5812 - val_loss: 0.2415 - val_accuracy: 0.9370 - val_precision_34: 0.0101 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8617 - precision_34: 0.6070 - val_loss: 0.2053 - val_accuracy: 0.9602 - val_precision_34: 0.0681 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8610 - precision_34: 0.5818 - val_loss: 0.2429 - val_accuracy: 0.9519 - val_precision_34: 0.0541 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8610 - precision_34: 0.5947 - val_loss: 0.2452 - val_accuracy: 0.9522 - val_precision_34: 0.0793 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8604 - precision_34: 0.5637 - val_loss: 0.2353 - val_accuracy: 0.9492 - val_precision_34: 0.0535 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.8616 - precision_34: 0.5899 - val_loss: 0.2141 - val_accuracy: 0.9633 - val_precision_34: 0.0234 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 7ms/step - loss: 365.9545 - accuracy: 0.7674 - precision_35: 0.1529 - val_loss: 124.8433 - val_accuracy: 0.5171 - val_precision_35: 0.0402 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 63.3579 - accuracy: 0.7857 - precision_35: 0.1771 - val_loss: 49.4269 - val_accuracy: 0.9157 - val_precision_35: 0.0101 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 66.0689 - accuracy: 0.7943 - precision_35: 0.2019 - val_loss: 18.3832 - val_accuracy: 0.9298 - val_precision_35: 0.0133 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 48.6873 - accuracy: 0.7908 - precision_35: 0.2068 - val_loss: 24.2815 - val_accuracy: 0.7314 - val_precision_35: 0.0427 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 112.8513 - accuracy: 0.7904 - precision_35: 0.2046 - val_loss: 24.5629 - val_accuracy: 0.8373 - val_precision_35: 0.0289 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 67.2630 - accuracy: 0.7914 - precision_35: 0.2076 - val_loss: 68.2919 - val_accuracy: 0.9563 - val_precision_35: 0.0417 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 55.0866 - accuracy: 0.7950 - precision_35: 0.2168 - val_loss: 8.2739 - val_accuracy: 0.9315 - val_precision_35: 0.0087 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 43.0011 - accuracy: 0.7967 - precision_35: 0.2195 - val_loss: 10.7214 - val_accuracy: 0.7639 - val_precision_35: 0.0307 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 23.6937 - accuracy: 0.7996 - precision_35: 0.2318 - val_loss: 17.7095 - val_accuracy: 0.8958 - val_precision_35: 0.0174 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 40.1296 - accuracy: 0.7989 - precision_35: 0.2254 - val_loss: 13.5904 - val_accuracy: 0.9159 - val_precision_35: 0.0210 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 15.7263 - accuracy: 0.7961 - precision_35: 0.2296 - val_loss: 3.5728 - val_accuracy: 0.8816 - val_precision_35: 0.0222 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 17.4876 - accuracy: 0.7994 - precision_35: 0.2332 - val_loss: 6.7415 - val_accuracy: 0.9428 - val_precision_35: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.8438 - accuracy: 0.7974 - precision_35: 0.2293 - val_loss: 2.9107 - val_accuracy: 0.8737 - val_precision_35: 0.0285 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 16.4081 - accuracy: 0.8010 - precision_35: 0.2383 - val_loss: 4.1861 - val_accuracy: 0.9355 - val_precision_35: 0.0134 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.7215 - accuracy: 0.7998 - precision_35: 0.2409 - val_loss: 5.8036 - val_accuracy: 0.9176 - val_precision_35: 0.0192 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 16.7975 - accuracy: 0.8000 - precision_35: 0.2370 - val_loss: 19.7094 - val_accuracy: 0.6492 - val_precision_35: 0.0497 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 13.4070 - accuracy: 0.8002 - precision_35: 0.2383 - val_loss: 3.5476 - val_accuracy: 0.8285 - val_precision_35: 0.0189 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 10.4047 - accuracy: 0.8014 - precision_35: 0.2381 - val_loss: 3.8201 - val_accuracy: 0.8518 - val_precision_35: 0.0273 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 11.6341 - accuracy: 0.8031 - precision_35: 0.2365 - val_loss: 3.1289 - val_accuracy: 0.8758 - val_precision_35: 0.0237 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 12.8031 - accuracy: 0.8041 - precision_35: 0.2400 - val_loss: 7.8544 - val_accuracy: 0.8455 - val_precision_35: 0.0291 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 19.5010 - accuracy: 0.7999 - precision_35: 0.2334 - val_loss: 5.0709 - val_accuracy: 0.8769 - val_precision_35: 0.0314 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.6942 - accuracy: 0.8031 - precision_35: 0.2404 - val_loss: 7.0187 - val_accuracy: 0.9111 - val_precision_35: 0.0227 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.2540 - accuracy: 0.8034 - precision_35: 0.2405 - val_loss: 3.3182 - val_accuracy: 0.7821 - val_precision_35: 0.0426 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.8357 - accuracy: 0.8044 - precision_35: 0.2402 - val_loss: 18.0173 - val_accuracy: 0.5899 - val_precision_35: 0.0475 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 10.3942 - accuracy: 0.8004 - precision_35: 0.2341 - val_loss: 5.1713 - val_accuracy: 0.9238 - val_precision_35: 0.0117 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.3381 - accuracy: 0.8045 - precision_35: 0.2374 - val_loss: 7.2162 - val_accuracy: 0.6101 - val_precision_35: 0.0468 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.6188 - accuracy: 0.8008 - precision_35: 0.2280 - val_loss: 3.5961 - val_accuracy: 0.8364 - val_precision_35: 0.0205 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.2060 - accuracy: 0.8037 - precision_35: 0.2433 - val_loss: 6.2562 - val_accuracy: 0.8811 - val_precision_35: 0.0199 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.4569 - accuracy: 0.8037 - precision_35: 0.2410 - val_loss: 6.3191 - val_accuracy: 0.8860 - val_precision_35: 0.0178 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 8.6270 - accuracy: 0.8066 - precision_35: 0.2497 - val_loss: 2.5122 - val_accuracy: 0.9211 - val_precision_35: 0.0124 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.3759 - accuracy: 0.8040 - precision_35: 0.2397 - val_loss: 3.2287 - val_accuracy: 0.8908 - val_precision_35: 0.0213 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.4312 - accuracy: 0.8025 - precision_35: 0.2470 - val_loss: 4.4271 - val_accuracy: 0.8476 - val_precision_35: 0.0265 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.4626 - accuracy: 0.8062 - precision_35: 0.2577 - val_loss: 3.4286 - val_accuracy: 0.9115 - val_precision_35: 0.0260 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.2002 - accuracy: 0.8048 - precision_35: 0.2432 - val_loss: 1.6911 - val_accuracy: 0.8785 - val_precision_35: 0.0165 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.6065 - accuracy: 0.8065 - precision_35: 0.2453 - val_loss: 3.2471 - val_accuracy: 0.7538 - val_precision_35: 0.0285 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.3311 - accuracy: 0.8042 - precision_35: 0.2420 - val_loss: 3.4229 - val_accuracy: 0.8834 - val_precision_35: 0.0364 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.8720 - accuracy: 0.8056 - precision_35: 0.2465 - val_loss: 1.8885 - val_accuracy: 0.9246 - val_precision_35: 0.0030 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.0537 - accuracy: 0.8054 - precision_35: 0.2450 - val_loss: 2.3397 - val_accuracy: 0.9416 - val_precision_35: 0.0024 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.1639 - accuracy: 0.8054 - precision_35: 0.2502 - val_loss: 2.6131 - val_accuracy: 0.9159 - val_precision_35: 0.0380 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.7045 - accuracy: 0.8080 - precision_35: 0.2547 - val_loss: 1.4728 - val_accuracy: 0.9019 - val_precision_35: 0.0169 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.9282 - accuracy: 0.8059 - precision_35: 0.2427 - val_loss: 3.6568 - val_accuracy: 0.9147 - val_precision_35: 0.0373 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.6038 - accuracy: 0.8087 - precision_35: 0.2490 - val_loss: 4.8605 - val_accuracy: 0.5548 - val_precision_35: 0.0435 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9383 - accuracy: 0.8083 - precision_35: 0.2625 - val_loss: 1.3408 - val_accuracy: 0.7628 - val_precision_35: 0.0451 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.2335 - accuracy: 0.8060 - precision_35: 0.2414 - val_loss: 2.9440 - val_accuracy: 0.9046 - val_precision_35: 0.0440 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5936 - accuracy: 0.8068 - precision_35: 0.2541 - val_loss: 0.8318 - val_accuracy: 0.8140 - val_precision_35: 0.0389 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 3.0357 - accuracy: 0.8071 - precision_35: 0.2466 - val_loss: 1.0206 - val_accuracy: 0.9114 - val_precision_35: 0.0036 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3106 - accuracy: 0.8103 - precision_35: 0.2592 - val_loss: 1.4145 - val_accuracy: 0.9314 - val_precision_35: 0.0269 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.9968 - accuracy: 0.8114 - precision_35: 0.2651 - val_loss: 0.6580 - val_accuracy: 0.9265 - val_precision_35: 0.0183 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.6299 - accuracy: 0.8110 - precision_35: 0.2546 - val_loss: 0.6214 - val_accuracy: 0.9235 - val_precision_35: 0.0116 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.5817 - accuracy: 0.8121 - precision_35: 0.2591 - val_loss: 0.6043 - val_accuracy: 0.8484 - val_precision_35: 0.0153 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.3222 - accuracy: 0.8145 - precision_35: 0.2664 - val_loss: 0.7266 - val_accuracy: 0.9162 - val_precision_35: 0.0102 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.8422 - accuracy: 0.8111 - precision_35: 0.2527 - val_loss: 0.6261 - val_accuracy: 0.9513 - val_precision_35: 0.0034 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2635 - accuracy: 0.8159 - precision_35: 0.2702 - val_loss: 0.5108 - val_accuracy: 0.8097 - val_precision_35: 0.0376 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0323 - accuracy: 0.8177 - precision_35: 0.2765 - val_loss: 0.5063 - val_accuracy: 0.8641 - val_precision_35: 0.0255 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0515 - accuracy: 0.8171 - precision_35: 0.2725 - val_loss: 0.8137 - val_accuracy: 0.8581 - val_precision_35: 0.0160 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7849 - accuracy: 0.8221 - precision_35: 0.2824 - val_loss: 0.4913 - val_accuracy: 0.8779 - val_precision_35: 0.0178 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8186 - accuracy: 0.8210 - precision_35: 0.2769 - val_loss: 0.3316 - val_accuracy: 0.9275 - val_precision_35: 0.0232 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.8219 - precision_35: 0.2768 - val_loss: 0.3486 - val_accuracy: 0.8931 - val_precision_35: 0.0211 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.7423 - accuracy: 0.8239 - precision_35: 0.2787 - val_loss: 0.8047 - val_accuracy: 0.6185 - val_precision_35: 0.0485 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.7247 - accuracy: 0.8217 - precision_35: 0.2750 - val_loss: 0.2955 - val_accuracy: 0.9355 - val_precision_35: 0.0315 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.8247 - precision_35: 0.2812 - val_loss: 0.3364 - val_accuracy: 0.9019 - val_precision_35: 0.0783 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.8272 - precision_35: 0.2896 - val_loss: 0.2632 - val_accuracy: 0.9430 - val_precision_35: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.8354 - precision_35: 0.2980 - val_loss: 0.6821 - val_accuracy: 0.6407 - val_precision_35: 0.0505 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9394 - accuracy: 0.8186 - precision_35: 0.2564 - val_loss: 0.5881 - val_accuracy: 0.9301 - val_precision_35: 0.0322 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7727 - accuracy: 0.8259 - precision_35: 0.2754 - val_loss: 0.3006 - val_accuracy: 0.9146 - val_precision_35: 0.0217 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.8254 - precision_35: 0.2671 - val_loss: 0.2475 - val_accuracy: 0.9454 - val_precision_35: 0.0398 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.3720 - accuracy: 0.8134 - precision_35: 0.2448 - val_loss: 1.1873 - val_accuracy: 0.8250 - val_precision_35: 0.0323 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5892 - accuracy: 0.8067 - precision_35: 0.2281 - val_loss: 0.3748 - val_accuracy: 0.9099 - val_precision_35: 0.0275 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.8306 - precision_35: 0.2714 - val_loss: 0.2696 - val_accuracy: 0.9494 - val_precision_35: 0.0124 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.8297 - precision_35: 0.2758 - val_loss: 0.3306 - val_accuracy: 0.9056 - val_precision_35: 0.0344 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.8305 - precision_35: 0.2760 - val_loss: 0.3453 - val_accuracy: 0.8958 - val_precision_35: 0.0209 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.5794 - accuracy: 0.8345 - precision_35: 0.2957 - val_loss: 0.3135 - val_accuracy: 0.9172 - val_precision_35: 0.0274 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4603 - accuracy: 0.8434 - precision_35: 0.3275 - val_loss: 0.2628 - val_accuracy: 0.9465 - val_precision_35: 0.0366 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4912 - accuracy: 0.8402 - precision_35: 0.3202 - val_loss: 0.2465 - val_accuracy: 0.9382 - val_precision_35: 0.0411 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4406 - accuracy: 0.8460 - precision_35: 0.3488 - val_loss: 0.3252 - val_accuracy: 0.9036 - val_precision_35: 0.0769 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.8452 - precision_35: 0.3452 - val_loss: 0.2917 - val_accuracy: 0.9055 - val_precision_35: 0.0228 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.4214 - accuracy: 0.8187 - precision_35: 0.2543 - val_loss: 1.5859 - val_accuracy: 0.8916 - val_precision_35: 0.0199 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.1592 - accuracy: 0.8096 - precision_35: 0.2337 - val_loss: 0.2997 - val_accuracy: 0.9329 - val_precision_35: 0.0246 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8477 - precision_35: 0.3530 - val_loss: 0.2263 - val_accuracy: 0.9564 - val_precision_35: 0.0090 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8423 - precision_35: 0.3231 - val_loss: 0.2456 - val_accuracy: 0.9405 - val_precision_35: 0.0260 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8540 - precision_35: 0.4161 - val_loss: 0.2136 - val_accuracy: 0.9511 - val_precision_35: 0.0101 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8558 - precision_35: 0.4475 - val_loss: 0.2881 - val_accuracy: 0.9164 - val_precision_35: 0.0293 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8550 - precision_35: 0.4398 - val_loss: 0.2184 - val_accuracy: 0.9474 - val_precision_35: 0.0452 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8536 - precision_35: 0.4175 - val_loss: 0.2570 - val_accuracy: 0.9524 - val_precision_35: 0.0373 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.8429 - precision_35: 0.3404 - val_loss: 0.2705 - val_accuracy: 0.9319 - val_precision_35: 0.0336 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8518 - precision_35: 0.3897 - val_loss: 0.2725 - val_accuracy: 0.9349 - val_precision_35: 0.0133 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.8430 - precision_35: 0.3321 - val_loss: 0.2838 - val_accuracy: 0.9341 - val_precision_35: 0.0370 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.8488 - precision_35: 0.3653 - val_loss: 0.2240 - val_accuracy: 0.9442 - val_precision_35: 0.0447 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8493 - precision_35: 0.3684 - val_loss: 0.2569 - val_accuracy: 0.9434 - val_precision_35: 0.0457 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.8439 - precision_35: 0.3394 - val_loss: 0.3608 - val_accuracy: 0.8758 - val_precision_35: 0.0808 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.0544 - accuracy: 0.8069 - precision_35: 0.2263 - val_loss: 1.2294 - val_accuracy: 0.9343 - val_precision_35: 0.0404 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2108 - accuracy: 0.8338 - precision_35: 0.2551 - val_loss: 0.2302 - val_accuracy: 0.9567 - val_precision_35: 0.0223 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8596 - precision_35: 0.5392 - val_loss: 0.2542 - val_accuracy: 0.9365 - val_precision_35: 0.0393 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8600 - precision_35: 0.5554 - val_loss: 0.2528 - val_accuracy: 0.9366 - val_precision_35: 0.0214 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.3703 - accuracy: 0.8609 - precision_35: 0.5822 - val_loss: 0.2995 - val_accuracy: 0.9043 - val_precision_35: 0.0234 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8601 - precision_35: 0.5477 - val_loss: 0.2236 - val_accuracy: 0.9550 - val_precision_35: 0.0528 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3695 - accuracy: 0.8595 - precision_35: 0.5378 - val_loss: 0.2747 - val_accuracy: 0.9170 - val_precision_35: 0.0308 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3711 - accuracy: 0.8598 - precision_35: 0.5412 - val_loss: 0.2228 - val_accuracy: 0.9484 - val_precision_35: 0.0542 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3699 - accuracy: 0.8598 - precision_35: 0.5430 - val_loss: 0.2457 - val_accuracy: 0.9339 - val_precision_35: 0.0368 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3675 - accuracy: 0.8596 - precision_35: 0.5374 - val_loss: 0.2088 - val_accuracy: 0.9538 - val_precision_35: 0.0331 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 256.8104 - accuracy: 0.7528 - precision_36: 0.1649 - val_loss: 68.8486 - val_accuracy: 0.9699 - val_precision_36: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 111.7288 - accuracy: 0.7654 - precision_36: 0.1807 - val_loss: 112.8184 - val_accuracy: 0.9713 - val_precision_36: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 127.4781 - accuracy: 0.7688 - precision_36: 0.1772 - val_loss: 127.3596 - val_accuracy: 0.9706 - val_precision_36: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 128.4028 - accuracy: 0.7714 - precision_36: 0.1792 - val_loss: 33.6947 - val_accuracy: 0.9604 - val_precision_36: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 112.3718 - accuracy: 0.7755 - precision_36: 0.1768 - val_loss: 16.9154 - val_accuracy: 0.8625 - val_precision_36: 0.0123 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 68.8951 - accuracy: 0.7827 - precision_36: 0.1946 - val_loss: 54.7654 - val_accuracy: 0.4707 - val_precision_36: 0.0303 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 55.5420 - accuracy: 0.7783 - precision_36: 0.1959 - val_loss: 47.4433 - val_accuracy: 0.9688 - val_precision_36: 0.0213 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 102.4940 - accuracy: 0.7778 - precision_36: 0.1905 - val_loss: 21.1128 - val_accuracy: 0.9480 - val_precision_36: 0.0060 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 88.6591 - accuracy: 0.7852 - precision_36: 0.1918 - val_loss: 62.4484 - val_accuracy: 0.8830 - val_precision_36: 0.0119 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 85.7533 - accuracy: 0.7826 - precision_36: 0.2001 - val_loss: 21.3057 - val_accuracy: 0.9468 - val_precision_36: 0.0057 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 66.9843 - accuracy: 0.7901 - precision_36: 0.2077 - val_loss: 13.7422 - val_accuracy: 0.8721 - val_precision_36: 0.0182 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 47.4473 - accuracy: 0.7901 - precision_36: 0.2094 - val_loss: 26.7451 - val_accuracy: 0.9630 - val_precision_36: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 58.5843 - accuracy: 0.7841 - precision_36: 0.2081 - val_loss: 48.5233 - val_accuracy: 0.9688 - val_precision_36: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 75.2596 - accuracy: 0.7887 - precision_36: 0.2102 - val_loss: 10.7531 - val_accuracy: 0.8935 - val_precision_36: 0.0237 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 41.0138 - accuracy: 0.7964 - precision_36: 0.2206 - val_loss: 13.2674 - val_accuracy: 0.9219 - val_precision_36: 0.0057 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 50.4260 - accuracy: 0.7930 - precision_36: 0.2211 - val_loss: 8.6350 - val_accuracy: 0.8849 - val_precision_36: 0.0200 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 71.7441 - accuracy: 0.7934 - precision_36: 0.2139 - val_loss: 72.8586 - val_accuracy: 0.4168 - val_precision_36: 0.0389 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 33.3623 - accuracy: 0.7925 - precision_36: 0.2163 - val_loss: 36.5714 - val_accuracy: 0.9325 - val_precision_36: 0.0125 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 57.5564 - accuracy: 0.7898 - precision_36: 0.2121 - val_loss: 15.3794 - val_accuracy: 0.9097 - val_precision_36: 0.0091 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 55.9400 - accuracy: 0.7891 - precision_36: 0.2137 - val_loss: 10.1442 - val_accuracy: 0.9036 - val_precision_36: 0.0063 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 26.8488 - accuracy: 0.7987 - precision_36: 0.2251 - val_loss: 9.3327 - val_accuracy: 0.8806 - val_precision_36: 0.0063 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.4816 - accuracy: 0.7973 - precision_36: 0.2343 - val_loss: 25.1450 - val_accuracy: 0.8861 - val_precision_36: 0.0171 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 30.8772 - accuracy: 0.8005 - precision_36: 0.2318 - val_loss: 92.5474 - val_accuracy: 0.5170 - val_precision_36: 0.0426 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 39.3843 - accuracy: 0.7954 - precision_36: 0.2203 - val_loss: 42.0734 - val_accuracy: 0.9232 - val_precision_36: 0.0186 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 41.4760 - accuracy: 0.7988 - precision_36: 0.2244 - val_loss: 14.9631 - val_accuracy: 0.8809 - val_precision_36: 0.0162 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 24.9286 - accuracy: 0.7987 - precision_36: 0.2215 - val_loss: 9.1215 - val_accuracy: 0.9432 - val_precision_36: 0.0074 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.0982 - accuracy: 0.8012 - precision_36: 0.2326 - val_loss: 3.1385 - val_accuracy: 0.8567 - val_precision_36: 0.0176 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 36.0066 - accuracy: 0.7939 - precision_36: 0.2209 - val_loss: 9.4800 - val_accuracy: 0.9332 - val_precision_36: 0.0092 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.7529 - accuracy: 0.8018 - precision_36: 0.2346 - val_loss: 8.1913 - val_accuracy: 0.9064 - val_precision_36: 0.0171 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.1552 - accuracy: 0.8000 - precision_36: 0.2214 - val_loss: 6.7874 - val_accuracy: 0.9427 - val_precision_36: 0.0025 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 32.4625 - accuracy: 0.8007 - precision_36: 0.2308 - val_loss: 16.1389 - val_accuracy: 0.9508 - val_precision_36: 0.0034 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 23.7052 - accuracy: 0.8017 - precision_36: 0.2290 - val_loss: 6.5471 - val_accuracy: 0.8258 - val_precision_36: 0.0168 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.3763 - accuracy: 0.8027 - precision_36: 0.2328 - val_loss: 10.7141 - val_accuracy: 0.9189 - val_precision_36: 0.0222 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.1510 - accuracy: 0.8042 - precision_36: 0.2353 - val_loss: 9.8762 - val_accuracy: 0.8369 - val_precision_36: 0.0240 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.0999 - accuracy: 0.8017 - precision_36: 0.2368 - val_loss: 12.2627 - val_accuracy: 0.8790 - val_precision_36: 0.0166 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.8898 - accuracy: 0.8025 - precision_36: 0.2306 - val_loss: 22.1351 - val_accuracy: 0.7766 - val_precision_36: 0.0216 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.8405 - accuracy: 0.8021 - precision_36: 0.2371 - val_loss: 6.4355 - val_accuracy: 0.9449 - val_precision_36: 0.0079 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.1115 - accuracy: 0.8043 - precision_36: 0.2338 - val_loss: 51.6826 - val_accuracy: 0.5178 - val_precision_36: 0.0410 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.2553 - accuracy: 0.8032 - precision_36: 0.2344 - val_loss: 7.0160 - val_accuracy: 0.6518 - val_precision_36: 0.0316 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 23.7476 - accuracy: 0.8018 - precision_36: 0.2296 - val_loss: 16.9319 - val_accuracy: 0.5725 - val_precision_36: 0.0397 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.5368 - accuracy: 0.8036 - precision_36: 0.2405 - val_loss: 4.9106 - val_accuracy: 0.9167 - val_precision_36: 0.0077 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 12.7200 - accuracy: 0.8063 - precision_36: 0.2445 - val_loss: 2.8461 - val_accuracy: 0.8399 - val_precision_36: 0.0235 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.2105 - accuracy: 0.8035 - precision_36: 0.2358 - val_loss: 2.8967 - val_accuracy: 0.8081 - val_precision_36: 0.0236 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 13.4436 - accuracy: 0.8048 - precision_36: 0.2434 - val_loss: 8.4994 - val_accuracy: 0.9450 - val_precision_36: 0.0027 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.1302 - accuracy: 0.8056 - precision_36: 0.2418 - val_loss: 15.8010 - val_accuracy: 0.5810 - val_precision_36: 0.0441 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 15.3749 - accuracy: 0.8052 - precision_36: 0.2385 - val_loss: 11.4415 - val_accuracy: 0.6106 - val_precision_36: 0.0485 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.0632 - accuracy: 0.8022 - precision_36: 0.2370 - val_loss: 3.2283 - val_accuracy: 0.8915 - val_precision_36: 0.0123 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.8599 - accuracy: 0.8017 - precision_36: 0.2298 - val_loss: 6.2912 - val_accuracy: 0.9235 - val_precision_36: 0.0074 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.1798 - accuracy: 0.8038 - precision_36: 0.2436 - val_loss: 3.3548 - val_accuracy: 0.8648 - val_precision_36: 0.0256 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.2290 - accuracy: 0.8056 - precision_36: 0.2448 - val_loss: 3.4291 - val_accuracy: 0.9241 - val_precision_36: 0.0075 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.7622 - accuracy: 0.8029 - precision_36: 0.2358 - val_loss: 2.7477 - val_accuracy: 0.7698 - val_precision_36: 0.0255 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.4838 - accuracy: 0.8025 - precision_36: 0.2371 - val_loss: 3.5236 - val_accuracy: 0.9232 - val_precision_36: 0.0073 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.9591 - accuracy: 0.8058 - precision_36: 0.2438 - val_loss: 3.5739 - val_accuracy: 0.9215 - val_precision_36: 0.0071 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.9670 - accuracy: 0.8090 - precision_36: 0.2527 - val_loss: 9.6492 - val_accuracy: 0.5778 - val_precision_36: 0.0458 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.4958 - accuracy: 0.8033 - precision_36: 0.2351 - val_loss: 7.7986 - val_accuracy: 0.9115 - val_precision_36: 0.0250 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.9972 - accuracy: 0.8061 - precision_36: 0.2398 - val_loss: 2.1840 - val_accuracy: 0.9017 - val_precision_36: 0.0061 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.6882 - accuracy: 0.8066 - precision_36: 0.2456 - val_loss: 3.3947 - val_accuracy: 0.9023 - val_precision_36: 0.0219 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.1912 - accuracy: 0.8065 - precision_36: 0.2497 - val_loss: 4.5766 - val_accuracy: 0.9241 - val_precision_36: 0.0118 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.5644 - accuracy: 0.8093 - precision_36: 0.2556 - val_loss: 2.3761 - val_accuracy: 0.9206 - val_precision_36: 0.0028 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.9581 - accuracy: 0.8082 - precision_36: 0.2524 - val_loss: 3.5567 - val_accuracy: 0.7858 - val_precision_36: 0.0341 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.8422 - accuracy: 0.8055 - precision_36: 0.2461 - val_loss: 11.3590 - val_accuracy: 0.9493 - val_precision_36: 0.0155 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.5693 - accuracy: 0.8029 - precision_36: 0.2492 - val_loss: 3.4826 - val_accuracy: 0.9364 - val_precision_36: 0.0195 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.2698 - accuracy: 0.8104 - precision_36: 0.2563 - val_loss: 1.7775 - val_accuracy: 0.7101 - val_precision_36: 0.0316 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 5.8216 - accuracy: 0.8085 - precision_36: 0.2567 - val_loss: 2.9059 - val_accuracy: 0.7716 - val_precision_36: 0.0315 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.9259 - accuracy: 0.8090 - precision_36: 0.2510 - val_loss: 1.4019 - val_accuracy: 0.8352 - val_precision_36: 0.0261 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.7834 - accuracy: 0.8098 - precision_36: 0.2560 - val_loss: 1.2063 - val_accuracy: 0.9227 - val_precision_36: 0.0087 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.9076 - accuracy: 0.8070 - precision_36: 0.2485 - val_loss: 8.2099 - val_accuracy: 0.9461 - val_precision_36: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.1971 - accuracy: 0.8089 - precision_36: 0.2533 - val_loss: 1.2379 - val_accuracy: 0.9030 - val_precision_36: 0.0230 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.0447 - accuracy: 0.8085 - precision_36: 0.2535 - val_loss: 1.2454 - val_accuracy: 0.7668 - val_precision_36: 0.0479 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.2682 - accuracy: 0.8039 - precision_36: 0.2470 - val_loss: 1.3556 - val_accuracy: 0.8777 - val_precision_36: 0.0220 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.6420 - accuracy: 0.8096 - precision_36: 0.2576 - val_loss: 1.4627 - val_accuracy: 0.7850 - val_precision_36: 0.0285 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.6947 - accuracy: 0.8079 - precision_36: 0.2538 - val_loss: 1.5593 - val_accuracy: 0.9275 - val_precision_36: 0.0080 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3678 - accuracy: 0.8112 - precision_36: 0.2697 - val_loss: 1.4263 - val_accuracy: 0.9161 - val_precision_36: 0.0270 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.6656 - accuracy: 0.8090 - precision_36: 0.2539 - val_loss: 1.1065 - val_accuracy: 0.9018 - val_precision_36: 0.0091 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.8812 - accuracy: 0.8096 - precision_36: 0.2571 - val_loss: 1.6166 - val_accuracy: 0.9197 - val_precision_36: 0.0199 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.1053 - accuracy: 0.8124 - precision_36: 0.2650 - val_loss: 4.9322 - val_accuracy: 0.6142 - val_precision_36: 0.0503 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.7666 - accuracy: 0.8094 - precision_36: 0.2584 - val_loss: 1.7079 - val_accuracy: 0.9487 - val_precision_36: 0.0091 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.1644 - accuracy: 0.8123 - precision_36: 0.2658 - val_loss: 0.6338 - val_accuracy: 0.8437 - val_precision_36: 0.0252 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.0802 - accuracy: 0.8135 - precision_36: 0.2746 - val_loss: 5.1998 - val_accuracy: 0.5252 - val_precision_36: 0.0454 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.8451 - accuracy: 0.8148 - precision_36: 0.2836 - val_loss: 1.0762 - val_accuracy: 0.9052 - val_precision_36: 0.0228 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.7657 - accuracy: 0.8167 - precision_36: 0.2770 - val_loss: 0.8227 - val_accuracy: 0.7871 - val_precision_36: 0.0292 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.6135 - accuracy: 0.8162 - precision_36: 0.2794 - val_loss: 0.9209 - val_accuracy: 0.7564 - val_precision_36: 0.0282 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.3905 - accuracy: 0.8195 - precision_36: 0.2951 - val_loss: 0.9769 - val_accuracy: 0.8767 - val_precision_36: 0.0197 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.8628 - accuracy: 0.8152 - precision_36: 0.2701 - val_loss: 1.9097 - val_accuracy: 0.5322 - val_precision_36: 0.0439 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2073 - accuracy: 0.8172 - precision_36: 0.2868 - val_loss: 0.5851 - val_accuracy: 0.8839 - val_precision_36: 0.0366 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.1713 - accuracy: 0.8201 - precision_36: 0.2903 - val_loss: 0.6746 - val_accuracy: 0.8390 - val_precision_36: 0.0258 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0383 - accuracy: 0.8227 - precision_36: 0.2979 - val_loss: 2.2796 - val_accuracy: 0.5989 - val_precision_36: 0.0514 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9736 - accuracy: 0.8228 - precision_36: 0.2985 - val_loss: 0.5485 - val_accuracy: 0.7905 - val_precision_36: 0.0275 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.8247 - precision_36: 0.3080 - val_loss: 0.6460 - val_accuracy: 0.8543 - val_precision_36: 0.0484 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.0684 - accuracy: 0.8184 - precision_36: 0.2784 - val_loss: 0.3814 - val_accuracy: 0.8661 - val_precision_36: 0.0602 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5896 - accuracy: 0.8327 - precision_36: 0.3305 - val_loss: 0.4294 - val_accuracy: 0.8659 - val_precision_36: 0.0332 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6336 - accuracy: 0.8320 - precision_36: 0.3222 - val_loss: 0.4177 - val_accuracy: 0.9081 - val_precision_36: 0.0288 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5458 - accuracy: 0.8343 - precision_36: 0.3305 - val_loss: 0.3170 - val_accuracy: 0.9023 - val_precision_36: 0.0393 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4976 - accuracy: 0.8387 - precision_36: 0.3426 - val_loss: 0.2848 - val_accuracy: 0.9214 - val_precision_36: 0.0384 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.8413 - precision_36: 0.3545 - val_loss: 0.3817 - val_accuracy: 0.8969 - val_precision_36: 0.0440 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.8341 - precision_36: 0.3271 - val_loss: 0.4417 - val_accuracy: 0.8482 - val_precision_36: 0.0318 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.8450 - precision_36: 0.3690 - val_loss: 0.3785 - val_accuracy: 0.8852 - val_precision_36: 0.0563 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4505 - accuracy: 0.8482 - precision_36: 0.3966 - val_loss: 0.6047 - val_accuracy: 0.7353 - val_precision_36: 0.0666 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.8424 - precision_36: 0.3537 - val_loss: 0.3298 - val_accuracy: 0.9093 - val_precision_36: 0.0304 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8456 - precision_36: 0.3729 - val_loss: 0.3505 - val_accuracy: 0.8798 - val_precision_36: 0.0296 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 166.6242 - accuracy: 0.7701 - precision_37: 0.1742 - val_loss: 24.3844 - val_accuracy: 0.8759 - val_precision_37: 0.0225 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 57.9171 - accuracy: 0.7726 - precision_37: 0.1735 - val_loss: 34.2623 - val_accuracy: 0.6933 - val_precision_37: 0.0520 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 51.1200 - accuracy: 0.7788 - precision_37: 0.1893 - val_loss: 89.8193 - val_accuracy: 0.4443 - val_precision_37: 0.0396 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 72.2791 - accuracy: 0.7726 - precision_37: 0.1830 - val_loss: 8.7726 - val_accuracy: 0.8129 - val_precision_37: 0.0345 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 35.8680 - accuracy: 0.7866 - precision_37: 0.2073 - val_loss: 11.0930 - val_accuracy: 0.9048 - val_precision_37: 0.0238 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 39.3998 - accuracy: 0.7835 - precision_37: 0.2047 - val_loss: 16.1307 - val_accuracy: 0.9367 - val_precision_37: 0.0276 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 31.0657 - accuracy: 0.7902 - precision_37: 0.2128 - val_loss: 8.0922 - val_accuracy: 0.7806 - val_precision_37: 0.0228 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 30.5968 - accuracy: 0.7849 - precision_37: 0.2043 - val_loss: 10.3715 - val_accuracy: 0.6190 - val_precision_37: 0.0220 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.7592 - accuracy: 0.7876 - precision_37: 0.2134 - val_loss: 11.1598 - val_accuracy: 0.9119 - val_precision_37: 0.0096 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.4124 - accuracy: 0.7955 - precision_37: 0.2285 - val_loss: 6.5545 - val_accuracy: 0.7637 - val_precision_37: 0.0252 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.7629 - accuracy: 0.7930 - precision_37: 0.2211 - val_loss: 10.9456 - val_accuracy: 0.9263 - val_precision_37: 0.0156 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 24.9967 - accuracy: 0.7930 - precision_37: 0.2175 - val_loss: 8.6625 - val_accuracy: 0.8533 - val_precision_37: 0.0172 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 18.5129 - accuracy: 0.7933 - precision_37: 0.2288 - val_loss: 12.3502 - val_accuracy: 0.9565 - val_precision_37: 0.0095 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 18.5220 - accuracy: 0.7945 - precision_37: 0.2243 - val_loss: 25.9873 - val_accuracy: 0.4236 - val_precision_37: 0.0387 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 28.2433 - accuracy: 0.7849 - precision_37: 0.2067 - val_loss: 5.9050 - val_accuracy: 0.7675 - val_precision_37: 0.0175 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 15.3677 - accuracy: 0.7942 - precision_37: 0.2119 - val_loss: 5.4629 - val_accuracy: 0.9076 - val_precision_37: 0.0196 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.2869 - accuracy: 0.8028 - precision_37: 0.2297 - val_loss: 9.0364 - val_accuracy: 0.7282 - val_precision_37: 0.0382 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.5014 - accuracy: 0.7988 - precision_37: 0.2256 - val_loss: 16.9979 - val_accuracy: 0.9666 - val_precision_37: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.1094 - accuracy: 0.7992 - precision_37: 0.2175 - val_loss: 3.5654 - val_accuracy: 0.7328 - val_precision_37: 0.0193 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.6669 - accuracy: 0.8015 - precision_37: 0.2249 - val_loss: 3.8677 - val_accuracy: 0.6623 - val_precision_37: 0.0222 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 9.0782 - accuracy: 0.8013 - precision_37: 0.2260 - val_loss: 3.1129 - val_accuracy: 0.7561 - val_precision_37: 0.0252 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.2060 - accuracy: 0.8036 - precision_37: 0.2360 - val_loss: 3.4250 - val_accuracy: 0.9050 - val_precision_37: 0.0148 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.6698 - accuracy: 0.8034 - precision_37: 0.2251 - val_loss: 6.7441 - val_accuracy: 0.9247 - val_precision_37: 0.0236 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.4911 - accuracy: 0.8063 - precision_37: 0.2419 - val_loss: 1.6759 - val_accuracy: 0.8652 - val_precision_37: 0.0197 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.2858 - accuracy: 0.8036 - precision_37: 0.2294 - val_loss: 2.1542 - val_accuracy: 0.8333 - val_precision_37: 0.0296 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.2105 - accuracy: 0.8066 - precision_37: 0.2368 - val_loss: 3.2595 - val_accuracy: 0.7164 - val_precision_37: 0.0314 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.9668 - accuracy: 0.8057 - precision_37: 0.2390 - val_loss: 2.5649 - val_accuracy: 0.9000 - val_precision_37: 0.0241 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.8269 - accuracy: 0.8055 - precision_37: 0.2379 - val_loss: 4.9475 - val_accuracy: 0.9334 - val_precision_37: 0.0435 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.5771 - accuracy: 0.8058 - precision_37: 0.2351 - val_loss: 2.4504 - val_accuracy: 0.9274 - val_precision_37: 0.0381 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.8294 - accuracy: 0.8055 - precision_37: 0.2349 - val_loss: 2.6044 - val_accuracy: 0.8924 - val_precision_37: 0.0253 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5098 - accuracy: 0.8064 - precision_37: 0.2411 - val_loss: 2.2926 - val_accuracy: 0.9424 - val_precision_37: 0.0305 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5575 - accuracy: 0.8099 - precision_37: 0.2409 - val_loss: 1.6644 - val_accuracy: 0.8906 - val_precision_37: 0.0239 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.1149 - accuracy: 0.8079 - precision_37: 0.2405 - val_loss: 1.1401 - val_accuracy: 0.8607 - val_precision_37: 0.0249 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.4850 - accuracy: 0.8085 - precision_37: 0.2396 - val_loss: 1.2264 - val_accuracy: 0.8898 - val_precision_37: 0.0277 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3964 - accuracy: 0.8107 - precision_37: 0.2533 - val_loss: 1.1355 - val_accuracy: 0.8687 - val_precision_37: 0.0190 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.1736 - accuracy: 0.8109 - precision_37: 0.2455 - val_loss: 0.9164 - val_accuracy: 0.8796 - val_precision_37: 0.0311 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.6652 - accuracy: 0.8140 - precision_37: 0.2561 - val_loss: 0.4153 - val_accuracy: 0.8879 - val_precision_37: 0.0478 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.5018 - accuracy: 0.8112 - precision_37: 0.2454 - val_loss: 1.0631 - val_accuracy: 0.9355 - val_precision_37: 0.0390 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.4321 - accuracy: 0.8139 - precision_37: 0.2439 - val_loss: 2.1414 - val_accuracy: 0.5241 - val_precision_37: 0.0472 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.1868 - accuracy: 0.8151 - precision_37: 0.2552 - val_loss: 0.5474 - val_accuracy: 0.9039 - val_precision_37: 0.0264 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.1324 - accuracy: 0.8176 - precision_37: 0.2596 - val_loss: 0.4505 - val_accuracy: 0.9153 - val_precision_37: 0.0359 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9496 - accuracy: 0.8202 - precision_37: 0.2573 - val_loss: 0.3752 - val_accuracy: 0.9090 - val_precision_37: 0.0356 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.8157 - precision_37: 0.2414 - val_loss: 0.2989 - val_accuracy: 0.9536 - val_precision_37: 0.0543 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.8362 - precision_37: 0.3054 - val_loss: 0.3733 - val_accuracy: 0.9300 - val_precision_37: 0.0358 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.8290 - precision_37: 0.2777 - val_loss: 0.3472 - val_accuracy: 0.9077 - val_precision_37: 0.0591 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.8251 - precision_37: 0.2621 - val_loss: 0.3720 - val_accuracy: 0.8810 - val_precision_37: 0.0772 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.8300 - precision_37: 0.2776 - val_loss: 0.5488 - val_accuracy: 0.7884 - val_precision_37: 0.0578 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.8295 - precision_37: 0.2739 - val_loss: 0.3386 - val_accuracy: 0.9488 - val_precision_37: 0.0357 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.5708 - accuracy: 0.8315 - precision_37: 0.2889 - val_loss: 0.4033 - val_accuracy: 0.9139 - val_precision_37: 0.0285 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5017 - accuracy: 0.8109 - precision_37: 0.2313 - val_loss: 21.4334 - val_accuracy: 0.6371 - val_precision_37: 0.0531 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.3166 - accuracy: 0.7978 - precision_37: 0.2117 - val_loss: 1.2853 - val_accuracy: 0.8159 - val_precision_37: 0.0663 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.4324 - accuracy: 0.8136 - precision_37: 0.2328 - val_loss: 0.7610 - val_accuracy: 0.6941 - val_precision_37: 0.0590 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7074 - accuracy: 0.8271 - precision_37: 0.2610 - val_loss: 0.3549 - val_accuracy: 0.9137 - val_precision_37: 0.0306 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.8435 - precision_37: 0.3179 - val_loss: 0.2851 - val_accuracy: 0.9381 - val_precision_37: 0.0472 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.8527 - precision_37: 0.3836 - val_loss: 0.2705 - val_accuracy: 0.9500 - val_precision_37: 0.0376 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.8532 - precision_37: 0.3900 - val_loss: 0.3146 - val_accuracy: 0.9297 - val_precision_37: 0.0385 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.4309 - accuracy: 0.8512 - precision_37: 0.3728 - val_loss: 0.3188 - val_accuracy: 0.8957 - val_precision_37: 0.0322 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8544 - precision_37: 0.4091 - val_loss: 0.3078 - val_accuracy: 0.9238 - val_precision_37: 0.0340 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8540 - precision_37: 0.4078 - val_loss: 0.2300 - val_accuracy: 0.9534 - val_precision_37: 0.0406 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8544 - precision_37: 0.4139 - val_loss: 0.2714 - val_accuracy: 0.9360 - val_precision_37: 0.0430 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3964 - accuracy: 0.8555 - precision_37: 0.4339 - val_loss: 0.2710 - val_accuracy: 0.9325 - val_precision_37: 0.0395 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3884 - accuracy: 0.8568 - precision_37: 0.4583 - val_loss: 0.3255 - val_accuracy: 0.8896 - val_precision_37: 0.0377 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3845 - accuracy: 0.8567 - precision_37: 0.4549 - val_loss: 0.2499 - val_accuracy: 0.9337 - val_precision_37: 0.0374 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3791 - accuracy: 0.8582 - precision_37: 0.4865 - val_loss: 0.2869 - val_accuracy: 0.9059 - val_precision_37: 0.0242 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3861 - accuracy: 0.8563 - precision_37: 0.4527 - val_loss: 0.2541 - val_accuracy: 0.9369 - val_precision_37: 0.0560 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8575 - precision_37: 0.4711 - val_loss: 0.2966 - val_accuracy: 0.9319 - val_precision_37: 0.0405 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8576 - precision_37: 0.4747 - val_loss: 0.2732 - val_accuracy: 0.9279 - val_precision_37: 0.0370 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8593 - precision_37: 0.5119 - val_loss: 0.2983 - val_accuracy: 0.8951 - val_precision_37: 0.0409 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8582 - precision_37: 0.4856 - val_loss: 0.2082 - val_accuracy: 0.9574 - val_precision_37: 0.0928 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8568 - precision_37: 0.4601 - val_loss: 0.2683 - val_accuracy: 0.9313 - val_precision_37: 0.0459 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3816 - accuracy: 0.8567 - precision_37: 0.4588 - val_loss: 0.3130 - val_accuracy: 0.8830 - val_precision_37: 0.0219 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8558 - precision_37: 0.4443 - val_loss: 0.2795 - val_accuracy: 0.9075 - val_precision_37: 0.0238 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8590 - precision_37: 0.5036 - val_loss: 0.2984 - val_accuracy: 0.8979 - val_precision_37: 0.0407 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8582 - precision_37: 0.4862 - val_loss: 0.3047 - val_accuracy: 0.8976 - val_precision_37: 0.0430 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8571 - precision_37: 0.4712 - val_loss: 0.3223 - val_accuracy: 0.8739 - val_precision_37: 0.0384 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8576 - precision_37: 0.4779 - val_loss: 0.1944 - val_accuracy: 0.9598 - val_precision_37: 0.0789 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8590 - precision_37: 0.5038 - val_loss: 0.2871 - val_accuracy: 0.9278 - val_precision_37: 0.0412 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8592 - precision_37: 0.5084 - val_loss: 0.2085 - val_accuracy: 0.9554 - val_precision_37: 0.0798 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8582 - precision_37: 0.4890 - val_loss: 0.2197 - val_accuracy: 0.9500 - val_precision_37: 0.0544 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8581 - precision_37: 0.4842 - val_loss: 0.2725 - val_accuracy: 0.9329 - val_precision_37: 0.0415 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8594 - precision_37: 0.5122 - val_loss: 0.2827 - val_accuracy: 0.9010 - val_precision_37: 0.0354 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8614 - precision_37: 0.5632 - val_loss: 0.2427 - val_accuracy: 0.9474 - val_precision_37: 0.0390 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.8616 - precision_37: 0.5683 - val_loss: 0.2186 - val_accuracy: 0.9571 - val_precision_37: 0.0376 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8622 - precision_37: 0.5722 - val_loss: 0.2336 - val_accuracy: 0.9473 - val_precision_37: 0.0257 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8631 - precision_37: 0.6009 - val_loss: 0.2307 - val_accuracy: 0.9433 - val_precision_37: 0.0446 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.3625 - accuracy: 0.8622 - precision_37: 0.5757 - val_loss: 0.2886 - val_accuracy: 0.9087 - val_precision_37: 0.0432 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3632 - accuracy: 0.8621 - precision_37: 0.5773 - val_loss: 0.2302 - val_accuracy: 0.9427 - val_precision_37: 0.0479 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.8630 - precision_37: 0.5937 - val_loss: 0.2186 - val_accuracy: 0.9547 - val_precision_37: 0.0830 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3638 - accuracy: 0.8623 - precision_37: 0.5755 - val_loss: 0.2745 - val_accuracy: 0.9227 - val_precision_37: 0.0359 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.8614 - precision_37: 0.5546 - val_loss: 0.2349 - val_accuracy: 0.9405 - val_precision_37: 0.0486 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8632 - precision_37: 0.6017 - val_loss: 0.2820 - val_accuracy: 0.9116 - val_precision_37: 0.0381 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8628 - precision_37: 0.5904 - val_loss: 0.2316 - val_accuracy: 0.9494 - val_precision_37: 0.0394 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8633 - precision_37: 0.6167 - val_loss: 0.2548 - val_accuracy: 0.9240 - val_precision_37: 0.0407 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8646 - precision_37: 0.6325 - val_loss: 0.2799 - val_accuracy: 0.9081 - val_precision_37: 0.0351 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8624 - precision_37: 0.5757 - val_loss: 0.2950 - val_accuracy: 0.9033 - val_precision_37: 0.0243 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8627 - precision_37: 0.5895 - val_loss: 0.2364 - val_accuracy: 0.9415 - val_precision_37: 0.0442 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.8653 - precision_37: 0.6513 - val_loss: 0.2565 - val_accuracy: 0.9292 - val_precision_37: 0.0229 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8657 - precision_37: 0.6475 - val_loss: 0.2204 - val_accuracy: 0.9535 - val_precision_37: 0.0667 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8660 - precision_37: 0.6634 - val_loss: 0.2388 - val_accuracy: 0.9394 - val_precision_37: 0.0338 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8666 - precision_37: 0.6712 - val_loss: 0.2546 - val_accuracy: 0.9343 - val_precision_37: 0.0188 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 186.4342 - accuracy: 0.7515 - precision_38: 0.1576 - val_loss: 34.0640 - val_accuracy: 0.9164 - val_precision_38: 0.0229 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 98.8748 - accuracy: 0.7665 - precision_38: 0.1724 - val_loss: 31.0565 - val_accuracy: 0.9184 - val_precision_38: 0.0464 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 88.4623 - accuracy: 0.7714 - precision_38: 0.1858 - val_loss: 28.6117 - val_accuracy: 0.9529 - val_precision_38: 0.0157 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 99.2522 - accuracy: 0.7754 - precision_38: 0.1945 - val_loss: 32.4150 - val_accuracy: 0.6506 - val_precision_38: 0.0396 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 85.0314 - accuracy: 0.7777 - precision_38: 0.2015 - val_loss: 25.0016 - val_accuracy: 0.9144 - val_precision_38: 0.0279 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 75.7011 - accuracy: 0.7843 - precision_38: 0.2111 - val_loss: 29.5488 - val_accuracy: 0.9376 - val_precision_38: 0.0308 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 69.4169 - accuracy: 0.7864 - precision_38: 0.2136 - val_loss: 39.2903 - val_accuracy: 0.8610 - val_precision_38: 0.0350 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 52.7401 - accuracy: 0.7832 - precision_38: 0.2123 - val_loss: 24.9881 - val_accuracy: 0.9160 - val_precision_38: 0.0334 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 60.0816 - accuracy: 0.7892 - precision_38: 0.2198 - val_loss: 15.4094 - val_accuracy: 0.9516 - val_precision_38: 0.0075 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 55.3766 - accuracy: 0.7849 - precision_38: 0.2130 - val_loss: 16.1774 - val_accuracy: 0.9393 - val_precision_38: 0.0262 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 52.0375 - accuracy: 0.7902 - precision_38: 0.2275 - val_loss: 25.9243 - val_accuracy: 0.9271 - val_precision_38: 0.0237 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 72.5109 - accuracy: 0.7867 - precision_38: 0.2099 - val_loss: 35.4614 - val_accuracy: 0.9209 - val_precision_38: 0.0222 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 52.2880 - accuracy: 0.7860 - precision_38: 0.2134 - val_loss: 16.8392 - val_accuracy: 0.6742 - val_precision_38: 0.0190 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 43.5232 - accuracy: 0.7926 - precision_38: 0.2339 - val_loss: 8.2560 - val_accuracy: 0.8298 - val_precision_38: 0.0449 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 43.3683 - accuracy: 0.7921 - precision_38: 0.2263 - val_loss: 13.0619 - val_accuracy: 0.6584 - val_precision_38: 0.0146 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 58.4897 - accuracy: 0.7898 - precision_38: 0.2231 - val_loss: 12.0535 - val_accuracy: 0.8217 - val_precision_38: 0.0232 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 45.6557 - accuracy: 0.7941 - precision_38: 0.2219 - val_loss: 22.8453 - val_accuracy: 0.9469 - val_precision_38: 0.0060 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 34.4149 - accuracy: 0.7980 - precision_38: 0.2261 - val_loss: 9.3672 - val_accuracy: 0.8547 - val_precision_38: 0.0192 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 63.1730 - accuracy: 0.7931 - precision_38: 0.2144 - val_loss: 17.1903 - val_accuracy: 0.9179 - val_precision_38: 0.0185 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 54.5759 - accuracy: 0.7931 - precision_38: 0.2210 - val_loss: 12.8809 - val_accuracy: 0.9424 - val_precision_38: 0.0051 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 29.4438 - accuracy: 0.7997 - precision_38: 0.2326 - val_loss: 26.1183 - val_accuracy: 0.9438 - val_precision_38: 0.0027 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 36.3384 - accuracy: 0.8016 - precision_38: 0.2328 - val_loss: 15.3704 - val_accuracy: 0.8262 - val_precision_38: 0.0202 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 32.8644 - accuracy: 0.8001 - precision_38: 0.2331 - val_loss: 7.5662 - val_accuracy: 0.8436 - val_precision_38: 0.0176 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 38.1715 - accuracy: 0.8016 - precision_38: 0.2283 - val_loss: 7.9780 - val_accuracy: 0.8214 - val_precision_38: 0.0249 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.9404 - accuracy: 0.8087 - precision_38: 0.2457 - val_loss: 30.0462 - val_accuracy: 0.5684 - val_precision_38: 0.0429 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.0703 - accuracy: 0.8046 - precision_38: 0.2333 - val_loss: 8.2295 - val_accuracy: 0.9053 - val_precision_38: 0.0252 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.4704 - accuracy: 0.8082 - precision_38: 0.2448 - val_loss: 5.4012 - val_accuracy: 0.9122 - val_precision_38: 0.0049 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.5395 - accuracy: 0.8060 - precision_38: 0.2387 - val_loss: 4.4547 - val_accuracy: 0.8617 - val_precision_38: 0.0210 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.0201 - accuracy: 0.8052 - precision_38: 0.2353 - val_loss: 9.7461 - val_accuracy: 0.9130 - val_precision_38: 0.0181 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.5869 - accuracy: 0.8058 - precision_38: 0.2365 - val_loss: 7.6391 - val_accuracy: 0.9132 - val_precision_38: 0.0158 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 14.7773 - accuracy: 0.8059 - precision_38: 0.2372 - val_loss: 9.1064 - val_accuracy: 0.9218 - val_precision_38: 0.0226 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 17.3160 - accuracy: 0.8045 - precision_38: 0.2334 - val_loss: 6.6161 - val_accuracy: 0.9157 - val_precision_38: 0.0078 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 13.8382 - accuracy: 0.8049 - precision_38: 0.2387 - val_loss: 6.1155 - val_accuracy: 0.9223 - val_precision_38: 0.0102 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 13.9296 - accuracy: 0.8044 - precision_38: 0.2399 - val_loss: 5.0329 - val_accuracy: 0.8906 - val_precision_38: 0.0200 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 15.3854 - accuracy: 0.8065 - precision_38: 0.2422 - val_loss: 15.7380 - val_accuracy: 0.9308 - val_precision_38: 0.0307 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.7748 - accuracy: 0.8058 - precision_38: 0.2476 - val_loss: 25.4472 - val_accuracy: 0.4481 - val_precision_38: 0.0402 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 26.8020 - accuracy: 0.7945 - precision_38: 0.2226 - val_loss: 4.2063 - val_accuracy: 0.8897 - val_precision_38: 0.0164 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.4920 - accuracy: 0.8052 - precision_38: 0.2482 - val_loss: 2.6634 - val_accuracy: 0.8335 - val_precision_38: 0.0251 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.1246 - accuracy: 0.8073 - precision_38: 0.2483 - val_loss: 4.6223 - val_accuracy: 0.8774 - val_precision_38: 0.0201 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.0357 - accuracy: 0.8070 - precision_38: 0.2477 - val_loss: 4.5615 - val_accuracy: 0.7148 - val_precision_38: 0.0425 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.7281 - accuracy: 0.8058 - precision_38: 0.2470 - val_loss: 7.9815 - val_accuracy: 0.9335 - val_precision_38: 0.0258 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.2867 - accuracy: 0.8069 - precision_38: 0.2511 - val_loss: 3.8423 - val_accuracy: 0.8986 - val_precision_38: 0.0230 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.2651 - accuracy: 0.8119 - precision_38: 0.2691 - val_loss: 3.0519 - val_accuracy: 0.9013 - val_precision_38: 0.0200 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.3997 - accuracy: 0.8071 - precision_38: 0.2526 - val_loss: 17.0305 - val_accuracy: 0.9594 - val_precision_38: 0.0063 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.1689 - accuracy: 0.8072 - precision_38: 0.2530 - val_loss: 5.7297 - val_accuracy: 0.8980 - val_precision_38: 0.0173 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.3744 - accuracy: 0.8048 - precision_38: 0.2380 - val_loss: 4.9898 - val_accuracy: 0.6948 - val_precision_38: 0.0513 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.6790 - accuracy: 0.8039 - precision_38: 0.2421 - val_loss: 7.1364 - val_accuracy: 0.9464 - val_precision_38: 0.0030 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.3109 - accuracy: 0.8065 - precision_38: 0.2469 - val_loss: 2.2932 - val_accuracy: 0.8616 - val_precision_38: 0.0222 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.5851 - accuracy: 0.8116 - precision_38: 0.2580 - val_loss: 2.1190 - val_accuracy: 0.8346 - val_precision_38: 0.0214 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.0364 - accuracy: 0.8110 - precision_38: 0.2549 - val_loss: 3.5200 - val_accuracy: 0.9055 - val_precision_38: 0.0273 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.6663 - accuracy: 0.8104 - precision_38: 0.2622 - val_loss: 5.5148 - val_accuracy: 0.6936 - val_precision_38: 0.0574 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.3278 - accuracy: 0.8059 - precision_38: 0.2482 - val_loss: 2.4653 - val_accuracy: 0.8157 - val_precision_38: 0.0299 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.6851 - accuracy: 0.8128 - precision_38: 0.2719 - val_loss: 1.8390 - val_accuracy: 0.8845 - val_precision_38: 0.0123 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.7569 - accuracy: 0.8132 - precision_38: 0.2614 - val_loss: 2.2789 - val_accuracy: 0.8389 - val_precision_38: 0.0230 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.7563 - accuracy: 0.8097 - precision_38: 0.2621 - val_loss: 4.8197 - val_accuracy: 0.9105 - val_precision_38: 0.0273 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.9513 - accuracy: 0.8131 - precision_38: 0.2669 - val_loss: 3.6002 - val_accuracy: 0.8817 - val_precision_38: 0.0173 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.8957 - accuracy: 0.8133 - precision_38: 0.2658 - val_loss: 11.8083 - val_accuracy: 0.5033 - val_precision_38: 0.0441 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.6343 - accuracy: 0.8119 - precision_38: 0.2672 - val_loss: 3.5259 - val_accuracy: 0.8780 - val_precision_38: 0.0181 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.1248 - accuracy: 0.8140 - precision_38: 0.2701 - val_loss: 1.8802 - val_accuracy: 0.7581 - val_precision_38: 0.0289 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.2085 - accuracy: 0.8126 - precision_38: 0.2666 - val_loss: 3.2873 - val_accuracy: 0.7148 - val_precision_38: 0.0471 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.7018 - accuracy: 0.8123 - precision_38: 0.2624 - val_loss: 3.7293 - val_accuracy: 0.9242 - val_precision_38: 0.0321 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.4032 - accuracy: 0.8125 - precision_38: 0.2655 - val_loss: 2.1924 - val_accuracy: 0.8955 - val_precision_38: 0.0194 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.0467 - accuracy: 0.8140 - precision_38: 0.2605 - val_loss: 7.6799 - val_accuracy: 0.5902 - val_precision_38: 0.0498 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.6603 - accuracy: 0.8113 - precision_38: 0.2583 - val_loss: 1.1747 - val_accuracy: 0.8587 - val_precision_38: 0.0199 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.3884 - accuracy: 0.8119 - precision_38: 0.2536 - val_loss: 2.2790 - val_accuracy: 0.9086 - val_precision_38: 0.0254 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.3375 - accuracy: 0.8137 - precision_38: 0.2650 - val_loss: 1.7510 - val_accuracy: 0.9004 - val_precision_38: 0.0236 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.8702 - accuracy: 0.8165 - precision_38: 0.2731 - val_loss: 1.4389 - val_accuracy: 0.8625 - val_precision_38: 0.0143 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5696 - accuracy: 0.8149 - precision_38: 0.2662 - val_loss: 2.8085 - val_accuracy: 0.9221 - val_precision_38: 0.0294 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.2968 - accuracy: 0.8146 - precision_38: 0.2602 - val_loss: 1.3111 - val_accuracy: 0.8320 - val_precision_38: 0.0176 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3439 - accuracy: 0.8175 - precision_38: 0.2757 - val_loss: 2.0263 - val_accuracy: 0.9195 - val_precision_38: 0.0318 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.2063 - accuracy: 0.8174 - precision_38: 0.2718 - val_loss: 1.1841 - val_accuracy: 0.8720 - val_precision_38: 0.0156 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.0425 - accuracy: 0.8097 - precision_38: 0.2454 - val_loss: 0.7828 - val_accuracy: 0.9167 - val_precision_38: 0.0040 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9825 - accuracy: 0.8215 - precision_38: 0.2742 - val_loss: 0.4590 - val_accuracy: 0.9150 - val_precision_38: 0.0317 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8051 - accuracy: 0.8244 - precision_38: 0.2759 - val_loss: 0.5768 - val_accuracy: 0.9124 - val_precision_38: 0.0281 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7303 - accuracy: 0.8270 - precision_38: 0.2733 - val_loss: 0.3946 - val_accuracy: 0.9231 - val_precision_38: 0.0340 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7200 - accuracy: 0.8267 - precision_38: 0.2716 - val_loss: 0.3762 - val_accuracy: 0.9247 - val_precision_38: 0.0364 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.8372 - precision_38: 0.3023 - val_loss: 0.4418 - val_accuracy: 0.8791 - val_precision_38: 0.0352 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.8408 - precision_38: 0.3139 - val_loss: 0.3573 - val_accuracy: 0.9129 - val_precision_38: 0.0216 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.8369 - precision_38: 0.3146 - val_loss: 0.3689 - val_accuracy: 0.9095 - val_precision_38: 0.0310 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.8344 - precision_38: 0.2892 - val_loss: 0.4091 - val_accuracy: 0.9010 - val_precision_38: 0.0357 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5151 - accuracy: 0.8405 - precision_38: 0.3141 - val_loss: 0.3445 - val_accuracy: 0.9255 - val_precision_38: 0.0287 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5581 - accuracy: 0.8328 - precision_38: 0.2931 - val_loss: 0.3794 - val_accuracy: 0.9215 - val_precision_38: 0.0330 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.8439 - precision_38: 0.3341 - val_loss: 0.4498 - val_accuracy: 0.9024 - val_precision_38: 0.0233 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4607 - accuracy: 0.8458 - precision_38: 0.3525 - val_loss: 0.9527 - val_accuracy: 0.6614 - val_precision_38: 0.0588 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.8446 - precision_38: 0.3469 - val_loss: 0.3220 - val_accuracy: 0.9437 - val_precision_38: 0.0278 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.8355 - precision_38: 0.3035 - val_loss: 0.3442 - val_accuracy: 0.9099 - val_precision_38: 0.0291 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4384 - accuracy: 0.8471 - precision_38: 0.3585 - val_loss: 0.4530 - val_accuracy: 0.9005 - val_precision_38: 0.0245 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.8456 - precision_38: 0.3603 - val_loss: 0.3126 - val_accuracy: 0.9338 - val_precision_38: 0.0347 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8586 - precision_38: 0.4909 - val_loss: 0.3090 - val_accuracy: 0.9264 - val_precision_38: 0.0292 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8546 - precision_38: 0.4314 - val_loss: 0.3314 - val_accuracy: 0.9176 - val_precision_38: 0.0295 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8559 - precision_38: 0.4468 - val_loss: 0.3747 - val_accuracy: 0.9076 - val_precision_38: 0.0230 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8525 - precision_38: 0.4167 - val_loss: 0.3368 - val_accuracy: 0.9295 - val_precision_38: 0.0202 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.4086 - accuracy: 0.8401 - precision_38: 0.3248 - val_loss: 16.8194 - val_accuracy: 0.4376 - val_precision_38: 0.0428 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.3454 - accuracy: 0.7988 - precision_38: 0.2062 - val_loss: 0.5197 - val_accuracy: 0.9304 - val_precision_38: 0.0381 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.7490 - accuracy: 0.8144 - precision_38: 0.2518 - val_loss: 1.4837 - val_accuracy: 0.9591 - val_precision_38: 0.0506 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0138 - accuracy: 0.8313 - precision_38: 0.2925 - val_loss: 0.2837 - val_accuracy: 0.9199 - val_precision_38: 0.0270 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.8467 - precision_38: 0.3641 - val_loss: 0.2416 - val_accuracy: 0.9522 - val_precision_38: 0.0152 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8569 - precision_38: 0.4649 - val_loss: 0.3068 - val_accuracy: 0.9005 - val_precision_38: 0.0381 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8619 - precision_38: 0.5586 - val_loss: 0.2838 - val_accuracy: 0.9140 - val_precision_38: 0.0255 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8597 - precision_38: 0.5117 - val_loss: 0.2424 - val_accuracy: 0.9401 - val_precision_38: 0.0433 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 7ms/step - loss: 488.1962 - accuracy: 0.7620 - precision_39: 0.1661 - val_loss: 58.0678 - val_accuracy: 0.9295 - val_precision_39: 0.0053 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 108.7966 - accuracy: 0.7847 - precision_39: 0.1711 - val_loss: 8.1939 - val_accuracy: 0.9008 - val_precision_39: 0.0403 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 51.3488 - accuracy: 0.7963 - precision_39: 0.1774 - val_loss: 40.4040 - val_accuracy: 0.9580 - val_precision_39: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 55.3807 - accuracy: 0.7972 - precision_39: 0.1743 - val_loss: 22.3927 - val_accuracy: 0.9242 - val_precision_39: 0.0047 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 61.3634 - accuracy: 0.7971 - precision_39: 0.1858 - val_loss: 21.7319 - val_accuracy: 0.9481 - val_precision_39: 0.0065 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 44.2585 - accuracy: 0.7999 - precision_39: 0.1873 - val_loss: 14.1433 - val_accuracy: 0.8656 - val_precision_39: 0.0174 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 44.0375 - accuracy: 0.8009 - precision_39: 0.1958 - val_loss: 13.5131 - val_accuracy: 0.8010 - val_precision_39: 0.0240 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 44.3969 - accuracy: 0.7996 - precision_39: 0.1975 - val_loss: 7.5384 - val_accuracy: 0.8369 - val_precision_39: 0.0193 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 38.6712 - accuracy: 0.7993 - precision_39: 0.2067 - val_loss: 14.2924 - val_accuracy: 0.9517 - val_precision_39: 0.0039 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 39.6799 - accuracy: 0.8010 - precision_39: 0.2041 - val_loss: 30.6177 - val_accuracy: 0.9021 - val_precision_39: 0.0073 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 45.9478 - accuracy: 0.8027 - precision_39: 0.2161 - val_loss: 24.9945 - val_accuracy: 0.9370 - val_precision_39: 0.0043 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 31.4027 - accuracy: 0.8026 - precision_39: 0.2181 - val_loss: 6.9202 - val_accuracy: 0.8963 - val_precision_39: 0.0124 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 30.8200 - accuracy: 0.8042 - precision_39: 0.2149 - val_loss: 14.9217 - val_accuracy: 0.8990 - val_precision_39: 0.0148 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 31.6955 - accuracy: 0.8034 - precision_39: 0.2163 - val_loss: 6.5698 - val_accuracy: 0.8190 - val_precision_39: 0.0126 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 31.6206 - accuracy: 0.8055 - precision_39: 0.2230 - val_loss: 23.4445 - val_accuracy: 0.9241 - val_precision_39: 0.0167 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.0702 - accuracy: 0.8044 - precision_39: 0.2112 - val_loss: 16.5181 - val_accuracy: 0.8980 - val_precision_39: 0.0202 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 23.8442 - accuracy: 0.8029 - precision_39: 0.2156 - val_loss: 7.6498 - val_accuracy: 0.8846 - val_precision_39: 0.0172 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 29.8285 - accuracy: 0.8040 - precision_39: 0.2179 - val_loss: 7.1222 - val_accuracy: 0.7216 - val_precision_39: 0.0362 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.7530 - accuracy: 0.8055 - precision_39: 0.2249 - val_loss: 7.7870 - val_accuracy: 0.7891 - val_precision_39: 0.0377 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.9519 - accuracy: 0.8051 - precision_39: 0.2289 - val_loss: 9.3226 - val_accuracy: 0.8616 - val_precision_39: 0.0155 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 24.3077 - accuracy: 0.8075 - precision_39: 0.2249 - val_loss: 7.6195 - val_accuracy: 0.8833 - val_precision_39: 0.0185 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.8907 - accuracy: 0.8078 - precision_39: 0.2348 - val_loss: 8.6155 - val_accuracy: 0.6693 - val_precision_39: 0.0368 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.1035 - accuracy: 0.8052 - precision_39: 0.2280 - val_loss: 11.9807 - val_accuracy: 0.6854 - val_precision_39: 0.0419 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.9892 - accuracy: 0.8045 - precision_39: 0.2296 - val_loss: 8.4108 - val_accuracy: 0.8668 - val_precision_39: 0.0156 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.5779 - accuracy: 0.8073 - precision_39: 0.2301 - val_loss: 5.9800 - val_accuracy: 0.8504 - val_precision_39: 0.0135 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 24.0391 - accuracy: 0.8062 - precision_39: 0.2240 - val_loss: 49.3150 - val_accuracy: 0.5017 - val_precision_39: 0.0429 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 19.8523 - accuracy: 0.8041 - precision_39: 0.2228 - val_loss: 5.3025 - val_accuracy: 0.9172 - val_precision_39: 0.0081 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 12.0021 - accuracy: 0.8064 - precision_39: 0.2299 - val_loss: 3.1210 - val_accuracy: 0.8565 - val_precision_39: 0.0242 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 10.6431 - accuracy: 0.8079 - precision_39: 0.2345 - val_loss: 10.5921 - val_accuracy: 0.7077 - val_precision_39: 0.0561 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.9707 - accuracy: 0.8073 - precision_39: 0.2379 - val_loss: 5.6351 - val_accuracy: 0.9145 - val_precision_39: 0.0127 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.3069 - accuracy: 0.8096 - precision_39: 0.2408 - val_loss: 13.5602 - val_accuracy: 0.6312 - val_precision_39: 0.0510 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.9604 - accuracy: 0.8062 - precision_39: 0.2359 - val_loss: 4.0578 - val_accuracy: 0.8428 - val_precision_39: 0.0138 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.7195 - accuracy: 0.8094 - precision_39: 0.2428 - val_loss: 3.1786 - val_accuracy: 0.7929 - val_precision_39: 0.0230 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.0344 - accuracy: 0.8106 - precision_39: 0.2477 - val_loss: 11.0207 - val_accuracy: 0.6350 - val_precision_39: 0.0430 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.4311 - accuracy: 0.8068 - precision_39: 0.2373 - val_loss: 18.1648 - val_accuracy: 0.6056 - val_precision_39: 0.0489 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.1903 - accuracy: 0.8069 - precision_39: 0.2354 - val_loss: 8.9911 - val_accuracy: 0.9298 - val_precision_39: 0.0190 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.4846 - accuracy: 0.8086 - precision_39: 0.2456 - val_loss: 2.2808 - val_accuracy: 0.8353 - val_precision_39: 0.0211 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.2344 - accuracy: 0.8077 - precision_39: 0.2395 - val_loss: 4.1787 - val_accuracy: 0.8821 - val_precision_39: 0.0128 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.2793 - accuracy: 0.8096 - precision_39: 0.2401 - val_loss: 11.3343 - val_accuracy: 0.6457 - val_precision_39: 0.0417 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.7667 - accuracy: 0.8106 - precision_39: 0.2456 - val_loss: 4.3201 - val_accuracy: 0.6243 - val_precision_39: 0.0441 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.3431 - accuracy: 0.8108 - precision_39: 0.2503 - val_loss: 2.3202 - val_accuracy: 0.8266 - val_precision_39: 0.0235 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.3158 - accuracy: 0.8102 - precision_39: 0.2474 - val_loss: 20.0448 - val_accuracy: 0.5932 - val_precision_39: 0.0484 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.2656 - accuracy: 0.8106 - precision_39: 0.2562 - val_loss: 4.8256 - val_accuracy: 0.8685 - val_precision_39: 0.0179 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.6089 - accuracy: 0.8111 - precision_39: 0.2518 - val_loss: 5.3676 - val_accuracy: 0.7270 - val_precision_39: 0.0397 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.5680 - accuracy: 0.8117 - precision_39: 0.2658 - val_loss: 3.1651 - val_accuracy: 0.8062 - val_precision_39: 0.0223 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.5012 - accuracy: 0.8131 - precision_39: 0.2598 - val_loss: 2.7176 - val_accuracy: 0.8508 - val_precision_39: 0.0275 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.5604 - accuracy: 0.8100 - precision_39: 0.2532 - val_loss: 1.9555 - val_accuracy: 0.9139 - val_precision_39: 0.0013 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.9179 - accuracy: 0.8080 - precision_39: 0.2370 - val_loss: 3.1667 - val_accuracy: 0.9173 - val_precision_39: 0.0172 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.4667 - accuracy: 0.8120 - precision_39: 0.2606 - val_loss: 2.3709 - val_accuracy: 0.8129 - val_precision_39: 0.0220 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.4726 - accuracy: 0.8124 - precision_39: 0.2578 - val_loss: 5.5261 - val_accuracy: 0.6216 - val_precision_39: 0.0504 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.6444 - accuracy: 0.8111 - precision_39: 0.2559 - val_loss: 2.6214 - val_accuracy: 0.7884 - val_precision_39: 0.0210 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.8956 - accuracy: 0.8139 - precision_39: 0.2685 - val_loss: 1.9907 - val_accuracy: 0.8506 - val_precision_39: 0.0192 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.2965 - accuracy: 0.8107 - precision_39: 0.2546 - val_loss: 2.1308 - val_accuracy: 0.8492 - val_precision_39: 0.0140 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.9122 - accuracy: 0.8121 - precision_39: 0.2603 - val_loss: 1.8177 - val_accuracy: 0.8663 - val_precision_39: 0.0220 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.4161 - accuracy: 0.8124 - precision_39: 0.2619 - val_loss: 1.3131 - val_accuracy: 0.8960 - val_precision_39: 0.0067 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.0222 - accuracy: 0.8107 - precision_39: 0.2532 - val_loss: 1.4760 - val_accuracy: 0.8051 - val_precision_39: 0.0194 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.5650 - accuracy: 0.8181 - precision_39: 0.2782 - val_loss: 8.6342 - val_accuracy: 0.5650 - val_precision_39: 0.0462 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.5045 - accuracy: 0.8168 - precision_39: 0.2766 - val_loss: 6.3616 - val_accuracy: 0.6066 - val_precision_39: 0.0490 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9386 - accuracy: 0.8153 - precision_39: 0.2699 - val_loss: 1.2620 - val_accuracy: 0.7158 - val_precision_39: 0.0478 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3631 - accuracy: 0.8130 - precision_39: 0.2641 - val_loss: 0.8480 - val_accuracy: 0.8844 - val_precision_39: 0.0083 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.0669 - accuracy: 0.8179 - precision_39: 0.2713 - val_loss: 3.8278 - val_accuracy: 0.5929 - val_precision_39: 0.0477 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.9321 - accuracy: 0.8180 - precision_39: 0.2800 - val_loss: 0.8719 - val_accuracy: 0.7960 - val_precision_39: 0.0188 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.7064 - accuracy: 0.8153 - precision_39: 0.2727 - val_loss: 0.6813 - val_accuracy: 0.9119 - val_precision_39: 0.0098 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.8391 - accuracy: 0.8185 - precision_39: 0.2771 - val_loss: 3.3766 - val_accuracy: 0.5596 - val_precision_39: 0.0471 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5010 - accuracy: 0.8184 - precision_39: 0.2813 - val_loss: 0.9477 - val_accuracy: 0.6982 - val_precision_39: 0.0305 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2579 - accuracy: 0.8207 - precision_39: 0.2800 - val_loss: 0.5581 - val_accuracy: 0.7917 - val_precision_39: 0.0333 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0107 - accuracy: 0.8244 - precision_39: 0.2978 - val_loss: 0.7450 - val_accuracy: 0.9262 - val_precision_39: 0.0295 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0737 - accuracy: 0.8239 - precision_39: 0.2955 - val_loss: 0.5500 - val_accuracy: 0.8787 - val_precision_39: 0.0168 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2778 - accuracy: 0.8195 - precision_39: 0.2747 - val_loss: 0.5761 - val_accuracy: 0.8491 - val_precision_39: 0.0168 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8987 - accuracy: 0.8263 - precision_39: 0.2909 - val_loss: 0.8213 - val_accuracy: 0.7172 - val_precision_39: 0.0529 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8733 - accuracy: 0.8249 - precision_39: 0.2908 - val_loss: 0.4298 - val_accuracy: 0.9235 - val_precision_39: 0.0107 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8029 - accuracy: 0.8272 - precision_39: 0.2880 - val_loss: 0.3787 - val_accuracy: 0.9501 - val_precision_39: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7016 - accuracy: 0.8303 - precision_39: 0.3044 - val_loss: 0.3994 - val_accuracy: 0.9045 - val_precision_39: 0.0261 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8534 - accuracy: 0.8275 - precision_39: 0.2924 - val_loss: 0.4220 - val_accuracy: 0.8794 - val_precision_39: 0.0383 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.8506 - accuracy: 0.8257 - precision_39: 0.2846 - val_loss: 0.5728 - val_accuracy: 0.7495 - val_precision_39: 0.0450 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5876 - accuracy: 0.8365 - precision_39: 0.3214 - val_loss: 0.4011 - val_accuracy: 0.9468 - val_precision_39: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5697 - accuracy: 0.8378 - precision_39: 0.3151 - val_loss: 0.3811 - val_accuracy: 0.8713 - val_precision_39: 0.0264 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5243 - accuracy: 0.8356 - precision_39: 0.3014 - val_loss: 0.3434 - val_accuracy: 0.9182 - val_precision_39: 0.0175 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5792 - accuracy: 0.8368 - precision_39: 0.3069 - val_loss: 0.4314 - val_accuracy: 0.8766 - val_precision_39: 0.0222 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.8313 - precision_39: 0.2882 - val_loss: 0.3911 - val_accuracy: 0.9492 - val_precision_39: 0.0034 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8151 - accuracy: 0.8242 - precision_39: 0.2700 - val_loss: 0.2984 - val_accuracy: 0.9294 - val_precision_39: 0.0087 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.2842 - accuracy: 0.8154 - precision_39: 0.2605 - val_loss: 3.6740 - val_accuracy: 0.9525 - val_precision_39: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.2903 - accuracy: 0.8150 - precision_39: 0.2479 - val_loss: 0.2836 - val_accuracy: 0.9438 - val_precision_39: 0.0211 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.8337 - precision_39: 0.3081 - val_loss: 0.4113 - val_accuracy: 0.8829 - val_precision_39: 0.0480 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8168 - accuracy: 0.8258 - precision_39: 0.2708 - val_loss: 0.4797 - val_accuracy: 0.7988 - val_precision_39: 0.0786 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7523 - accuracy: 0.8257 - precision_39: 0.2722 - val_loss: 0.2863 - val_accuracy: 0.9332 - val_precision_39: 0.0189 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.8400 - precision_39: 0.3275 - val_loss: 0.2849 - val_accuracy: 0.9275 - val_precision_39: 0.0242 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.8401 - precision_39: 0.3277 - val_loss: 0.2167 - val_accuracy: 0.9562 - val_precision_39: 0.0249 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8581 - precision_39: 0.4789 - val_loss: 0.3141 - val_accuracy: 0.9142 - val_precision_39: 0.0235 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8564 - precision_39: 0.4539 - val_loss: 1.4726 - val_accuracy: 0.6200 - val_precision_39: 0.0535 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.8388 - precision_39: 0.3217 - val_loss: 0.4659 - val_accuracy: 0.8006 - val_precision_39: 0.0637 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.8812 - accuracy: 0.8332 - precision_39: 0.2957 - val_loss: 12.5536 - val_accuracy: 0.9455 - val_precision_39: 0.0029 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.3076 - accuracy: 0.7934 - precision_39: 0.1940 - val_loss: 2.6253 - val_accuracy: 0.9043 - val_precision_39: 0.0149 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.1637 - accuracy: 0.8258 - precision_39: 0.2478 - val_loss: 0.3217 - val_accuracy: 0.9196 - val_precision_39: 0.0258 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8470 - precision_39: 0.3340 - val_loss: 0.2692 - val_accuracy: 0.9275 - val_precision_39: 0.0164 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.8348 - precision_39: 0.2714 - val_loss: 0.3393 - val_accuracy: 0.9139 - val_precision_39: 0.0256 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8543 - precision_39: 0.4083 - val_loss: 0.2409 - val_accuracy: 0.9474 - val_precision_39: 0.0328 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8547 - precision_39: 0.4116 - val_loss: 0.2950 - val_accuracy: 0.9349 - val_precision_39: 0.0235 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8502 - precision_39: 0.3725 - val_loss: 0.4183 - val_accuracy: 0.8425 - val_precision_39: 0.0739 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3837 - accuracy: 0.8579 - precision_39: 0.4717 - val_loss: 0.2619 - val_accuracy: 0.9340 - val_precision_39: 0.0372 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 150.8244 - accuracy: 0.7701 - precision_40: 0.1694 - val_loss: 31.5604 - val_accuracy: 0.7441 - val_precision_40: 0.0382 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 52.3160 - accuracy: 0.7764 - precision_40: 0.1877 - val_loss: 46.0717 - val_accuracy: 0.7109 - val_precision_40: 0.0396 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 55.8021 - accuracy: 0.7771 - precision_40: 0.1896 - val_loss: 14.7810 - val_accuracy: 0.9202 - val_precision_40: 0.0157 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 45.7839 - accuracy: 0.7808 - precision_40: 0.1982 - val_loss: 17.2042 - val_accuracy: 0.9437 - val_precision_40: 0.0163 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 39.9889 - accuracy: 0.7873 - precision_40: 0.2148 - val_loss: 15.1349 - val_accuracy: 0.9269 - val_precision_40: 0.0051 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 85.9701 - accuracy: 0.7785 - precision_40: 0.1977 - val_loss: 9.7972 - val_accuracy: 0.8662 - val_precision_40: 0.0240 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 41.0646 - accuracy: 0.7841 - precision_40: 0.2102 - val_loss: 67.8339 - val_accuracy: 0.5301 - val_precision_40: 0.0432 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 34.1849 - accuracy: 0.7852 - precision_40: 0.2092 - val_loss: 50.7070 - val_accuracy: 0.9621 - val_precision_40: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 46.9259 - accuracy: 0.7835 - precision_40: 0.2036 - val_loss: 21.4729 - val_accuracy: 0.9052 - val_precision_40: 0.0205 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 36.1142 - accuracy: 0.7898 - precision_40: 0.2186 - val_loss: 27.6317 - val_accuracy: 0.9621 - val_precision_40: 0.0098 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 41.5175 - accuracy: 0.7919 - precision_40: 0.2110 - val_loss: 16.4498 - val_accuracy: 0.8771 - val_precision_40: 0.0196 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 26.3551 - accuracy: 0.7944 - precision_40: 0.2247 - val_loss: 5.5613 - val_accuracy: 0.8813 - val_precision_40: 0.0197 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 39.2785 - accuracy: 0.7950 - precision_40: 0.2209 - val_loss: 63.9775 - val_accuracy: 0.4527 - val_precision_40: 0.0440 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.3209 - accuracy: 0.7946 - precision_40: 0.2235 - val_loss: 6.4101 - val_accuracy: 0.8944 - val_precision_40: 0.0247 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 24.6025 - accuracy: 0.7984 - precision_40: 0.2235 - val_loss: 15.7705 - val_accuracy: 0.9514 - val_precision_40: 0.0118 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 23.4893 - accuracy: 0.7980 - precision_40: 0.2241 - val_loss: 7.9211 - val_accuracy: 0.7094 - val_precision_40: 0.0446 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.8941 - accuracy: 0.7992 - precision_40: 0.2274 - val_loss: 7.5738 - val_accuracy: 0.8913 - val_precision_40: 0.0213 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.2955 - accuracy: 0.8030 - precision_40: 0.2330 - val_loss: 8.8764 - val_accuracy: 0.8774 - val_precision_40: 0.0282 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.6218 - accuracy: 0.7977 - precision_40: 0.2299 - val_loss: 4.6762 - val_accuracy: 0.8941 - val_precision_40: 0.0272 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 38.1250 - accuracy: 0.7941 - precision_40: 0.2241 - val_loss: 9.5991 - val_accuracy: 0.9357 - val_precision_40: 0.0431 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 19.6480 - accuracy: 0.8033 - precision_40: 0.2263 - val_loss: 54.8229 - val_accuracy: 0.4350 - val_precision_40: 0.0441 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 23.5930 - accuracy: 0.7981 - precision_40: 0.2243 - val_loss: 4.9076 - val_accuracy: 0.7843 - val_precision_40: 0.0396 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 21.5258 - accuracy: 0.7980 - precision_40: 0.2238 - val_loss: 23.7706 - val_accuracy: 0.9593 - val_precision_40: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 17.2967 - accuracy: 0.8038 - precision_40: 0.2283 - val_loss: 5.9346 - val_accuracy: 0.8581 - val_precision_40: 0.0259 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.7705 - accuracy: 0.8041 - precision_40: 0.2365 - val_loss: 15.5615 - val_accuracy: 0.9308 - val_precision_40: 0.0250 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.6506 - accuracy: 0.7961 - precision_40: 0.2179 - val_loss: 5.1403 - val_accuracy: 0.8646 - val_precision_40: 0.0186 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.6898 - accuracy: 0.8040 - precision_40: 0.2344 - val_loss: 2.7227 - val_accuracy: 0.8711 - val_precision_40: 0.0271 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.3164 - accuracy: 0.8024 - precision_40: 0.2341 - val_loss: 4.1882 - val_accuracy: 0.9217 - val_precision_40: 0.0089 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.2196 - accuracy: 0.8014 - precision_40: 0.2266 - val_loss: 11.9417 - val_accuracy: 0.9476 - val_precision_40: 0.0222 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 20.6196 - accuracy: 0.7990 - precision_40: 0.2233 - val_loss: 7.9815 - val_accuracy: 0.9240 - val_precision_40: 0.0285 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.2370 - accuracy: 0.8085 - precision_40: 0.2368 - val_loss: 2.8597 - val_accuracy: 0.8827 - val_precision_40: 0.0223 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.4275 - accuracy: 0.8078 - precision_40: 0.2440 - val_loss: 9.7818 - val_accuracy: 0.6367 - val_precision_40: 0.0472 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.4584 - accuracy: 0.8072 - precision_40: 0.2420 - val_loss: 4.3864 - val_accuracy: 0.8940 - val_precision_40: 0.0373 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.8003 - accuracy: 0.8049 - precision_40: 0.2374 - val_loss: 3.9369 - val_accuracy: 0.9243 - val_precision_40: 0.0302 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.4466 - accuracy: 0.8074 - precision_40: 0.2379 - val_loss: 11.7210 - val_accuracy: 0.9495 - val_precision_40: 0.0141 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.8466 - accuracy: 0.8065 - precision_40: 0.2409 - val_loss: 4.4094 - val_accuracy: 0.8900 - val_precision_40: 0.0234 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.3013 - accuracy: 0.8083 - precision_40: 0.2380 - val_loss: 27.1603 - val_accuracy: 0.4748 - val_precision_40: 0.0451 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.5554 - accuracy: 0.8036 - precision_40: 0.2278 - val_loss: 3.3036 - val_accuracy: 0.8700 - val_precision_40: 0.0314 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.1954 - accuracy: 0.8078 - precision_40: 0.2387 - val_loss: 2.1070 - val_accuracy: 0.9097 - val_precision_40: 0.0242 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.8241 - accuracy: 0.8090 - precision_40: 0.2477 - val_loss: 4.6202 - val_accuracy: 0.9203 - val_precision_40: 0.0225 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.6190 - accuracy: 0.8083 - precision_40: 0.2459 - val_loss: 3.1838 - val_accuracy: 0.9141 - val_precision_40: 0.0284 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.1550 - accuracy: 0.8103 - precision_40: 0.2488 - val_loss: 4.4807 - val_accuracy: 0.8996 - val_precision_40: 0.0256 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.5710 - accuracy: 0.8082 - precision_40: 0.2494 - val_loss: 16.2130 - val_accuracy: 0.6164 - val_precision_40: 0.0504 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.7644 - accuracy: 0.8093 - precision_40: 0.2473 - val_loss: 3.4794 - val_accuracy: 0.6602 - val_precision_40: 0.0506 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.2990 - accuracy: 0.8111 - precision_40: 0.2493 - val_loss: 11.8650 - val_accuracy: 0.5570 - val_precision_40: 0.0466 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.7486 - accuracy: 0.8092 - precision_40: 0.2502 - val_loss: 4.1083 - val_accuracy: 0.9024 - val_precision_40: 0.0227 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.9619 - accuracy: 0.8114 - precision_40: 0.2559 - val_loss: 2.5230 - val_accuracy: 0.8906 - val_precision_40: 0.0211 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.4363 - accuracy: 0.8118 - precision_40: 0.2502 - val_loss: 20.7702 - val_accuracy: 0.5286 - val_precision_40: 0.0449 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.1489 - accuracy: 0.8086 - precision_40: 0.2449 - val_loss: 1.8823 - val_accuracy: 0.8935 - val_precision_40: 0.0121 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.7990 - accuracy: 0.8099 - precision_40: 0.2508 - val_loss: 4.4097 - val_accuracy: 0.6481 - val_precision_40: 0.0531 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.0831 - accuracy: 0.8102 - precision_40: 0.2536 - val_loss: 2.6906 - val_accuracy: 0.9262 - val_precision_40: 0.0131 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.8482 - accuracy: 0.8108 - precision_40: 0.2501 - val_loss: 2.0773 - val_accuracy: 0.9185 - val_precision_40: 0.0014 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.8964 - accuracy: 0.8114 - precision_40: 0.2474 - val_loss: 14.4538 - val_accuracy: 0.5187 - val_precision_40: 0.0461 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.2272 - accuracy: 0.8105 - precision_40: 0.2546 - val_loss: 1.8939 - val_accuracy: 0.8672 - val_precision_40: 0.0229 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.2247 - accuracy: 0.8134 - precision_40: 0.2599 - val_loss: 1.5823 - val_accuracy: 0.8191 - val_precision_40: 0.0229 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.8337 - accuracy: 0.8118 - precision_40: 0.2602 - val_loss: 1.6476 - val_accuracy: 0.8881 - val_precision_40: 0.0221 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.2120 - accuracy: 0.8110 - precision_40: 0.2588 - val_loss: 1.5636 - val_accuracy: 0.9210 - val_precision_40: 0.0201 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.6341 - accuracy: 0.8125 - precision_40: 0.2587 - val_loss: 2.6761 - val_accuracy: 0.7208 - val_precision_40: 0.0464 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.5547 - accuracy: 0.8095 - precision_40: 0.2573 - val_loss: 3.2150 - val_accuracy: 0.9433 - val_precision_40: 0.0543 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.2050 - accuracy: 0.8115 - precision_40: 0.2530 - val_loss: 2.1770 - val_accuracy: 0.9289 - val_precision_40: 0.0238 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.1709 - accuracy: 0.8133 - precision_40: 0.2615 - val_loss: 2.3660 - val_accuracy: 0.6201 - val_precision_40: 0.0459 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5549 - accuracy: 0.8119 - precision_40: 0.2602 - val_loss: 2.1924 - val_accuracy: 0.8969 - val_precision_40: 0.0210 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.8946 - accuracy: 0.8139 - precision_40: 0.2619 - val_loss: 9.9122 - val_accuracy: 0.5707 - val_precision_40: 0.0482 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.1306 - accuracy: 0.8095 - precision_40: 0.2498 - val_loss: 3.5199 - val_accuracy: 0.9449 - val_precision_40: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5065 - accuracy: 0.8145 - precision_40: 0.2614 - val_loss: 1.1835 - val_accuracy: 0.8534 - val_precision_40: 0.0220 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.8992 - accuracy: 0.8092 - precision_40: 0.2484 - val_loss: 1.5694 - val_accuracy: 0.8980 - val_precision_40: 0.0392 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.5953 - accuracy: 0.8149 - precision_40: 0.2637 - val_loss: 0.9496 - val_accuracy: 0.7842 - val_precision_40: 0.0328 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.8624 - accuracy: 0.8143 - precision_40: 0.2665 - val_loss: 0.6751 - val_accuracy: 0.8671 - val_precision_40: 0.0293 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.6358 - accuracy: 0.8135 - precision_40: 0.2668 - val_loss: 1.2813 - val_accuracy: 0.8920 - val_precision_40: 0.0257 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.3717 - accuracy: 0.8157 - precision_40: 0.2745 - val_loss: 1.0327 - val_accuracy: 0.9188 - val_precision_40: 0.0232 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.0261 - accuracy: 0.8167 - precision_40: 0.2724 - val_loss: 0.9090 - val_accuracy: 0.9070 - val_precision_40: 0.0113 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.2496 - accuracy: 0.8155 - precision_40: 0.2651 - val_loss: 1.1524 - val_accuracy: 0.7668 - val_precision_40: 0.0251 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 2.2290 - accuracy: 0.8172 - precision_40: 0.2769 - val_loss: 1.3422 - val_accuracy: 0.7491 - val_precision_40: 0.0390 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.5281 - accuracy: 0.8179 - precision_40: 0.2815 - val_loss: 1.0631 - val_accuracy: 0.9383 - val_precision_40: 0.0023 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.7887 - accuracy: 0.8178 - precision_40: 0.2760 - val_loss: 1.2714 - val_accuracy: 0.6721 - val_precision_40: 0.0540 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5686 - accuracy: 0.8148 - precision_40: 0.2710 - val_loss: 0.6492 - val_accuracy: 0.9211 - val_precision_40: 0.0229 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.4040 - accuracy: 0.8203 - precision_40: 0.2846 - val_loss: 0.6220 - val_accuracy: 0.9191 - val_precision_40: 0.0298 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5605 - accuracy: 0.8178 - precision_40: 0.2768 - val_loss: 0.5950 - val_accuracy: 0.8526 - val_precision_40: 0.0292 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2266 - accuracy: 0.8206 - precision_40: 0.2853 - val_loss: 0.6208 - val_accuracy: 0.8042 - val_precision_40: 0.0273 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.1584 - accuracy: 0.8201 - precision_40: 0.2809 - val_loss: 0.4269 - val_accuracy: 0.9019 - val_precision_40: 0.0235 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2286 - accuracy: 0.8200 - precision_40: 0.2789 - val_loss: 0.6748 - val_accuracy: 0.8712 - val_precision_40: 0.0343 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.3600 - accuracy: 0.8194 - precision_40: 0.2832 - val_loss: 0.4720 - val_accuracy: 0.8865 - val_precision_40: 0.0241 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.3589 - accuracy: 0.8235 - precision_40: 0.2968 - val_loss: 0.6851 - val_accuracy: 0.7652 - val_precision_40: 0.0523 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9106 - accuracy: 0.8239 - precision_40: 0.2908 - val_loss: 1.6547 - val_accuracy: 0.6238 - val_precision_40: 0.0514 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7464 - accuracy: 0.8302 - precision_40: 0.3123 - val_loss: 0.3964 - val_accuracy: 0.8787 - val_precision_40: 0.0423 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7744 - accuracy: 0.8277 - precision_40: 0.3032 - val_loss: 0.3062 - val_accuracy: 0.9248 - val_precision_40: 0.0188 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0040 - accuracy: 0.8256 - precision_40: 0.2971 - val_loss: 0.4362 - val_accuracy: 0.9328 - val_precision_40: 0.0116 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7697 - accuracy: 0.8281 - precision_40: 0.2986 - val_loss: 0.7898 - val_accuracy: 0.6391 - val_precision_40: 0.0558 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.8404 - precision_40: 0.3460 - val_loss: 1.2423 - val_accuracy: 0.6274 - val_precision_40: 0.0543 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.8382 - precision_40: 0.3328 - val_loss: 0.3086 - val_accuracy: 0.9329 - val_precision_40: 0.0368 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.8407 - precision_40: 0.3489 - val_loss: 0.3942 - val_accuracy: 0.8479 - val_precision_40: 0.0579 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.8372 - precision_40: 0.3325 - val_loss: 0.3448 - val_accuracy: 0.9346 - val_precision_40: 0.0505 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8514 - precision_40: 0.4083 - val_loss: 0.2512 - val_accuracy: 0.9433 - val_precision_40: 0.0312 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.8420 - precision_40: 0.3547 - val_loss: 0.2757 - val_accuracy: 0.9222 - val_precision_40: 0.0191 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.5060 - accuracy: 0.8400 - precision_40: 0.3395 - val_loss: 0.2576 - val_accuracy: 0.9472 - val_precision_40: 0.0334 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.8449 - precision_40: 0.3662 - val_loss: 0.6027 - val_accuracy: 0.7421 - val_precision_40: 0.0665 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8506 - precision_40: 0.4017 - val_loss: 0.2814 - val_accuracy: 0.9368 - val_precision_40: 0.0233 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4212 - accuracy: 0.8536 - precision_40: 0.4344 - val_loss: 0.3959 - val_accuracy: 0.8530 - val_precision_40: 0.0846 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.8390 - precision_40: 0.3369 - val_loss: 0.4894 - val_accuracy: 0.7891 - val_precision_40: 0.0652 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.8478 - precision_40: 0.3739 - val_loss: 0.2819 - val_accuracy: 0.9310 - val_precision_40: 0.0492 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 193.3002 - accuracy: 0.7631 - precision_41: 0.1521 - val_loss: 260.4630 - val_accuracy: 0.5815 - val_precision_41: 0.0488 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 86.2897 - accuracy: 0.7742 - precision_41: 0.1687 - val_loss: 48.0916 - val_accuracy: 0.7165 - val_precision_41: 0.0219 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 80.5837 - accuracy: 0.7783 - precision_41: 0.1807 - val_loss: 41.3504 - val_accuracy: 0.8535 - val_precision_41: 0.0255 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 137.1802 - accuracy: 0.7739 - precision_41: 0.1778 - val_loss: 21.3173 - val_accuracy: 0.9387 - val_precision_41: 0.0047 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 54.3825 - accuracy: 0.7799 - precision_41: 0.1884 - val_loss: 32.2420 - val_accuracy: 0.9543 - val_precision_41: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 55.5319 - accuracy: 0.7848 - precision_41: 0.1933 - val_loss: 12.2226 - val_accuracy: 0.8294 - val_precision_41: 0.0297 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 53.6357 - accuracy: 0.7898 - precision_41: 0.2010 - val_loss: 28.9961 - val_accuracy: 0.9538 - val_precision_41: 0.0183 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 50.2734 - accuracy: 0.7895 - precision_41: 0.2031 - val_loss: 21.8392 - val_accuracy: 0.9455 - val_precision_41: 0.0262 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 45.1804 - accuracy: 0.7987 - precision_41: 0.2176 - val_loss: 41.0167 - val_accuracy: 0.9553 - val_precision_41: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 38.2573 - accuracy: 0.7958 - precision_41: 0.2112 - val_loss: 48.4920 - val_accuracy: 0.5661 - val_precision_41: 0.0462 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 41.0156 - accuracy: 0.7989 - precision_41: 0.2084 - val_loss: 120.1970 - val_accuracy: 0.4239 - val_precision_41: 0.0423 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 35.9820 - accuracy: 0.7978 - precision_41: 0.2132 - val_loss: 13.3543 - val_accuracy: 0.9308 - val_precision_41: 0.0129 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 44.9092 - accuracy: 0.7969 - precision_41: 0.2094 - val_loss: 9.5356 - val_accuracy: 0.9009 - val_precision_41: 0.0164 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 58.4826 - accuracy: 0.7927 - precision_41: 0.2059 - val_loss: 17.4686 - val_accuracy: 0.7016 - val_precision_41: 0.0220 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 53.3627 - accuracy: 0.7979 - precision_41: 0.2094 - val_loss: 18.6148 - val_accuracy: 0.9005 - val_precision_41: 0.0093 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 28.8907 - accuracy: 0.8021 - precision_41: 0.2212 - val_loss: 18.9728 - val_accuracy: 0.9345 - val_precision_41: 0.0041 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 29.9349 - accuracy: 0.8027 - precision_41: 0.2106 - val_loss: 9.0859 - val_accuracy: 0.7609 - val_precision_41: 0.0247 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 29.1616 - accuracy: 0.8021 - precision_41: 0.2167 - val_loss: 36.3924 - val_accuracy: 0.5874 - val_precision_41: 0.0476 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 40.7479 - accuracy: 0.7971 - precision_41: 0.2146 - val_loss: 29.2417 - val_accuracy: 0.9638 - val_precision_41: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 40.3055 - accuracy: 0.8021 - precision_41: 0.2102 - val_loss: 8.4117 - val_accuracy: 0.9245 - val_precision_41: 0.0142 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.1636 - accuracy: 0.8030 - precision_41: 0.2274 - val_loss: 7.5447 - val_accuracy: 0.8930 - val_precision_41: 0.0156 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.6508 - accuracy: 0.8053 - precision_41: 0.2242 - val_loss: 9.2906 - val_accuracy: 0.9154 - val_precision_41: 0.0131 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.6864 - accuracy: 0.8044 - precision_41: 0.2191 - val_loss: 14.2770 - val_accuracy: 0.9193 - val_precision_41: 0.0182 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.2432 - accuracy: 0.8055 - precision_41: 0.2255 - val_loss: 4.0321 - val_accuracy: 0.8462 - val_precision_41: 0.0235 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.6076 - accuracy: 0.8070 - precision_41: 0.2301 - val_loss: 8.3304 - val_accuracy: 0.9292 - val_precision_41: 0.0124 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.8913 - accuracy: 0.8022 - precision_41: 0.2276 - val_loss: 29.6787 - val_accuracy: 0.9636 - val_precision_41: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 26.7589 - accuracy: 0.8067 - precision_41: 0.2315 - val_loss: 13.4595 - val_accuracy: 0.9450 - val_precision_41: 0.0089 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.7858 - accuracy: 0.8071 - precision_41: 0.2194 - val_loss: 60.5207 - val_accuracy: 0.4511 - val_precision_41: 0.0418 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.8200 - accuracy: 0.8043 - precision_41: 0.2225 - val_loss: 18.0703 - val_accuracy: 0.6517 - val_precision_41: 0.0527 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.2778 - accuracy: 0.8010 - precision_41: 0.2156 - val_loss: 15.1707 - val_accuracy: 0.9455 - val_precision_41: 0.0235 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.5408 - accuracy: 0.8082 - precision_41: 0.2303 - val_loss: 8.3374 - val_accuracy: 0.9363 - val_precision_41: 0.0087 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 17.7898 - accuracy: 0.8048 - precision_41: 0.2233 - val_loss: 13.4252 - val_accuracy: 0.9484 - val_precision_41: 0.0035 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.0575 - accuracy: 0.8090 - precision_41: 0.2270 - val_loss: 9.6252 - val_accuracy: 0.9255 - val_precision_41: 0.0145 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.7940 - accuracy: 0.8067 - precision_41: 0.2240 - val_loss: 9.9421 - val_accuracy: 0.6832 - val_precision_41: 0.0337 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.0255 - accuracy: 0.8077 - precision_41: 0.2325 - val_loss: 4.9196 - val_accuracy: 0.9200 - val_precision_41: 0.0087 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.0954 - accuracy: 0.8094 - precision_41: 0.2377 - val_loss: 3.3789 - val_accuracy: 0.8595 - val_precision_41: 0.0147 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.0934 - accuracy: 0.8079 - precision_41: 0.2292 - val_loss: 11.6562 - val_accuracy: 0.9409 - val_precision_41: 0.0026 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.5413 - accuracy: 0.8046 - precision_41: 0.2282 - val_loss: 8.0591 - val_accuracy: 0.9312 - val_precision_41: 0.0019 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.6226 - accuracy: 0.8093 - precision_41: 0.2243 - val_loss: 36.4527 - val_accuracy: 0.4427 - val_precision_41: 0.0438 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.1235 - accuracy: 0.8084 - precision_41: 0.2330 - val_loss: 4.8439 - val_accuracy: 0.8948 - val_precision_41: 0.0133 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 10.8049 - accuracy: 0.8102 - precision_41: 0.2460 - val_loss: 24.3757 - val_accuracy: 0.5681 - val_precision_41: 0.0466 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.2657 - accuracy: 0.8057 - precision_41: 0.2164 - val_loss: 2.6261 - val_accuracy: 0.8580 - val_precision_41: 0.0282 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.8012 - accuracy: 0.8097 - precision_41: 0.2355 - val_loss: 4.8549 - val_accuracy: 0.8888 - val_precision_41: 0.0114 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.4641 - accuracy: 0.8083 - precision_41: 0.2366 - val_loss: 3.2200 - val_accuracy: 0.7829 - val_precision_41: 0.0503 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.4841 - accuracy: 0.8101 - precision_41: 0.2368 - val_loss: 4.8043 - val_accuracy: 0.8723 - val_precision_41: 0.0208 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.3179 - accuracy: 0.8109 - precision_41: 0.2369 - val_loss: 3.2842 - val_accuracy: 0.8855 - val_precision_41: 0.0215 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.7049 - accuracy: 0.8094 - precision_41: 0.2348 - val_loss: 2.3272 - val_accuracy: 0.8620 - val_precision_41: 0.0226 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.2649 - accuracy: 0.8138 - precision_41: 0.2552 - val_loss: 4.4991 - val_accuracy: 0.7269 - val_precision_41: 0.0568 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.7046 - accuracy: 0.8095 - precision_41: 0.2360 - val_loss: 6.9915 - val_accuracy: 0.6483 - val_precision_41: 0.0517 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.7079 - accuracy: 0.8127 - precision_41: 0.2490 - val_loss: 1.5741 - val_accuracy: 0.8458 - val_precision_41: 0.0137 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.2340 - accuracy: 0.8106 - precision_41: 0.2419 - val_loss: 15.1469 - val_accuracy: 0.5295 - val_precision_41: 0.0487 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.5782 - accuracy: 0.8110 - precision_41: 0.2454 - val_loss: 1.5790 - val_accuracy: 0.8697 - val_precision_41: 0.0169 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.3119 - accuracy: 0.8092 - precision_41: 0.2390 - val_loss: 3.5648 - val_accuracy: 0.8715 - val_precision_41: 0.0312 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.5223 - accuracy: 0.8132 - precision_41: 0.2489 - val_loss: 3.7693 - val_accuracy: 0.6773 - val_precision_41: 0.0386 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.4995 - accuracy: 0.8134 - precision_41: 0.2548 - val_loss: 4.8795 - val_accuracy: 0.9047 - val_precision_41: 0.0345 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.7340 - accuracy: 0.8110 - precision_41: 0.2424 - val_loss: 6.2167 - val_accuracy: 0.5941 - val_precision_41: 0.0485 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.0047 - accuracy: 0.8127 - precision_41: 0.2507 - val_loss: 2.1003 - val_accuracy: 0.8965 - val_precision_41: 0.0098 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.4994 - accuracy: 0.8085 - precision_41: 0.2349 - val_loss: 1.7062 - val_accuracy: 0.8384 - val_precision_41: 0.0207 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5625 - accuracy: 0.8134 - precision_41: 0.2567 - val_loss: 3.1688 - val_accuracy: 0.6634 - val_precision_41: 0.0492 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5287 - accuracy: 0.8134 - precision_41: 0.2496 - val_loss: 4.3061 - val_accuracy: 0.6268 - val_precision_41: 0.0482 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.8415 - accuracy: 0.8142 - precision_41: 0.2553 - val_loss: 2.0617 - val_accuracy: 0.6829 - val_precision_41: 0.0427 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.1815 - accuracy: 0.8115 - precision_41: 0.2437 - val_loss: 0.9324 - val_accuracy: 0.8565 - val_precision_41: 0.0290 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.0541 - accuracy: 0.8136 - precision_41: 0.2524 - val_loss: 0.9381 - val_accuracy: 0.8124 - val_precision_41: 0.0383 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.4732 - accuracy: 0.8146 - precision_41: 0.2568 - val_loss: 1.0683 - val_accuracy: 0.9143 - val_precision_41: 0.0078 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.0719 - accuracy: 0.8196 - precision_41: 0.2791 - val_loss: 0.7091 - val_accuracy: 0.8927 - val_precision_41: 0.0129 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.9715 - accuracy: 0.8139 - precision_41: 0.2572 - val_loss: 1.3147 - val_accuracy: 0.7365 - val_precision_41: 0.0384 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.7356 - accuracy: 0.8206 - precision_41: 0.2734 - val_loss: 0.5604 - val_accuracy: 0.7975 - val_precision_41: 0.0327 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.7332 - accuracy: 0.8175 - precision_41: 0.2639 - val_loss: 1.1404 - val_accuracy: 0.7097 - val_precision_41: 0.0530 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.4392 - accuracy: 0.8181 - precision_41: 0.2650 - val_loss: 0.8090 - val_accuracy: 0.8688 - val_precision_41: 0.0126 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.3834 - accuracy: 0.8179 - precision_41: 0.2661 - val_loss: 0.9341 - val_accuracy: 0.9167 - val_precision_41: 0.0310 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.3463 - accuracy: 0.8209 - precision_41: 0.2622 - val_loss: 1.6073 - val_accuracy: 0.6175 - val_precision_41: 0.0542 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9555 - accuracy: 0.8211 - precision_41: 0.2702 - val_loss: 0.4343 - val_accuracy: 0.8771 - val_precision_41: 0.0182 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9587 - accuracy: 0.8244 - precision_41: 0.2811 - val_loss: 1.0332 - val_accuracy: 0.9394 - val_precision_41: 0.0233 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7818 - accuracy: 0.8296 - precision_41: 0.2957 - val_loss: 0.3980 - val_accuracy: 0.8724 - val_precision_41: 0.0564 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.8322 - precision_41: 0.3088 - val_loss: 0.3806 - val_accuracy: 0.9046 - val_precision_41: 0.0393 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.8344 - precision_41: 0.3107 - val_loss: 0.4091 - val_accuracy: 0.8736 - val_precision_41: 0.0747 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.8364 - precision_41: 0.3102 - val_loss: 0.7700 - val_accuracy: 0.6944 - val_precision_41: 0.0658 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.8385 - precision_41: 0.3202 - val_loss: 0.3485 - val_accuracy: 0.9005 - val_precision_41: 0.0864 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.8361 - precision_41: 0.3048 - val_loss: 0.2995 - val_accuracy: 0.9057 - val_precision_41: 0.0249 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.8390 - precision_41: 0.3253 - val_loss: 0.2846 - val_accuracy: 0.9246 - val_precision_41: 0.0080 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.8414 - precision_41: 0.3206 - val_loss: 0.2568 - val_accuracy: 0.9442 - val_precision_41: 0.0057 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8512 - precision_41: 0.3922 - val_loss: 0.3618 - val_accuracy: 0.8922 - val_precision_41: 0.0292 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8474 - precision_41: 0.3656 - val_loss: 0.3228 - val_accuracy: 0.8889 - val_precision_41: 0.0273 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.8493 - precision_41: 0.3833 - val_loss: 0.3082 - val_accuracy: 0.8979 - val_precision_41: 0.0358 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8490 - precision_41: 0.3720 - val_loss: 0.3089 - val_accuracy: 0.9092 - val_precision_41: 0.0390 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8484 - precision_41: 0.3677 - val_loss: 0.2468 - val_accuracy: 0.9398 - val_precision_41: 0.0049 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8485 - precision_41: 0.3673 - val_loss: 0.3095 - val_accuracy: 0.9114 - val_precision_41: 0.0193 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8574 - precision_41: 0.4599 - val_loss: 0.2865 - val_accuracy: 0.9100 - val_precision_41: 0.0310 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8494 - precision_41: 0.3695 - val_loss: 0.3322 - val_accuracy: 0.8875 - val_precision_41: 0.0276 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3930 - accuracy: 0.8557 - precision_41: 0.4352 - val_loss: 0.3295 - val_accuracy: 0.8984 - val_precision_41: 0.0378 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8573 - precision_41: 0.4551 - val_loss: 0.2734 - val_accuracy: 0.9382 - val_precision_41: 0.0329 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4417 - accuracy: 0.8481 - precision_41: 0.3668 - val_loss: 0.2561 - val_accuracy: 0.9305 - val_precision_41: 0.0128 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3810 - accuracy: 0.8584 - precision_41: 0.4746 - val_loss: 0.3419 - val_accuracy: 0.8934 - val_precision_41: 0.0254 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8565 - precision_41: 0.4450 - val_loss: 0.3828 - val_accuracy: 0.8517 - val_precision_41: 0.0312 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8523 - precision_41: 0.4015 - val_loss: 0.3120 - val_accuracy: 0.8813 - val_precision_41: 0.0265 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8599 - precision_41: 0.5010 - val_loss: 0.2750 - val_accuracy: 0.9122 - val_precision_41: 0.0299 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8607 - precision_41: 0.5179 - val_loss: 0.2859 - val_accuracy: 0.9135 - val_precision_41: 0.0351 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8545 - precision_41: 0.4289 - val_loss: 0.2479 - val_accuracy: 0.9281 - val_precision_41: 0.0314 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8539 - precision_41: 0.4197 - val_loss: 0.3427 - val_accuracy: 0.8837 - val_precision_41: 0.0203 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8554 - precision_41: 0.4400 - val_loss: 0.2530 - val_accuracy: 0.9228 - val_precision_41: 0.0238 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 348.4473 - accuracy: 0.7630 - precision_42: 0.1595 - val_loss: 26.6211 - val_accuracy: 0.9200 - val_precision_42: 0.0252 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 86.7104 - accuracy: 0.7759 - precision_42: 0.1858 - val_loss: 24.6342 - val_accuracy: 0.7167 - val_precision_42: 0.0200 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 127.8626 - accuracy: 0.7695 - precision_42: 0.1768 - val_loss: 104.5724 - val_accuracy: 0.9674 - val_precision_42: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 82.5522 - accuracy: 0.7806 - precision_42: 0.1917 - val_loss: 58.9387 - val_accuracy: 0.6313 - val_precision_42: 0.0516 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 68.2306 - accuracy: 0.7830 - precision_42: 0.1947 - val_loss: 30.8370 - val_accuracy: 0.7336 - val_precision_42: 0.0332 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 52.7844 - accuracy: 0.7895 - precision_42: 0.2161 - val_loss: 20.5395 - val_accuracy: 0.9270 - val_precision_42: 0.0084 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 62.5287 - accuracy: 0.7888 - precision_42: 0.2053 - val_loss: 46.1239 - val_accuracy: 0.6796 - val_precision_42: 0.0253 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 104.4433 - accuracy: 0.7825 - precision_42: 0.1959 - val_loss: 120.1201 - val_accuracy: 0.4585 - val_precision_42: 0.0441 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 68.9822 - accuracy: 0.7814 - precision_42: 0.1913 - val_loss: 8.3121 - val_accuracy: 0.8681 - val_precision_42: 0.0199 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 40.5527 - accuracy: 0.7926 - precision_42: 0.2107 - val_loss: 8.0561 - val_accuracy: 0.7875 - val_precision_42: 0.0337 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 40.7965 - accuracy: 0.7929 - precision_42: 0.2115 - val_loss: 13.1845 - val_accuracy: 0.8605 - val_precision_42: 0.0167 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 39.3892 - accuracy: 0.7918 - precision_42: 0.2094 - val_loss: 10.3874 - val_accuracy: 0.7937 - val_precision_42: 0.0349 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 37.2979 - accuracy: 0.7956 - precision_42: 0.2162 - val_loss: 23.0984 - val_accuracy: 0.9332 - val_precision_42: 0.0390 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 31.1607 - accuracy: 0.7998 - precision_42: 0.2247 - val_loss: 31.4837 - val_accuracy: 0.4220 - val_precision_42: 0.0411 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 38.0158 - accuracy: 0.7927 - precision_42: 0.2197 - val_loss: 14.5980 - val_accuracy: 0.9144 - val_precision_42: 0.0263 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 36.5537 - accuracy: 0.7982 - precision_42: 0.2224 - val_loss: 13.7022 - val_accuracy: 0.7465 - val_precision_42: 0.0454 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 44.7495 - accuracy: 0.7943 - precision_42: 0.2125 - val_loss: 47.6819 - val_accuracy: 0.5430 - val_precision_42: 0.0481 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 42.4048 - accuracy: 0.8004 - precision_42: 0.2310 - val_loss: 13.5825 - val_accuracy: 0.8606 - val_precision_42: 0.0329 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.3593 - accuracy: 0.8037 - precision_42: 0.2384 - val_loss: 11.3756 - val_accuracy: 0.9121 - val_precision_42: 0.0160 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.9575 - accuracy: 0.7997 - precision_42: 0.2282 - val_loss: 8.5492 - val_accuracy: 0.7304 - val_precision_42: 0.0301 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.3844 - accuracy: 0.7995 - precision_42: 0.2284 - val_loss: 6.6927 - val_accuracy: 0.7726 - val_precision_42: 0.0349 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 29.1203 - accuracy: 0.8011 - precision_42: 0.2245 - val_loss: 14.6399 - val_accuracy: 0.8121 - val_precision_42: 0.0307 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 35.7592 - accuracy: 0.7920 - precision_42: 0.2153 - val_loss: 7.3275 - val_accuracy: 0.8554 - val_precision_42: 0.0315 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 23.3993 - accuracy: 0.8033 - precision_42: 0.2427 - val_loss: 29.0444 - val_accuracy: 0.9597 - val_precision_42: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 49.1219 - accuracy: 0.7898 - precision_42: 0.2034 - val_loss: 13.6307 - val_accuracy: 0.8795 - val_precision_42: 0.0317 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.4117 - accuracy: 0.8022 - precision_42: 0.2257 - val_loss: 10.1186 - val_accuracy: 0.9081 - val_precision_42: 0.0280 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.2655 - accuracy: 0.8034 - precision_42: 0.2385 - val_loss: 6.6676 - val_accuracy: 0.9032 - val_precision_42: 0.0250 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.0391 - accuracy: 0.8057 - precision_42: 0.2474 - val_loss: 7.3370 - val_accuracy: 0.8853 - val_precision_42: 0.0026 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.0159 - accuracy: 0.8052 - precision_42: 0.2396 - val_loss: 8.6433 - val_accuracy: 0.7127 - val_precision_42: 0.0428 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.7349 - accuracy: 0.8056 - precision_42: 0.2433 - val_loss: 6.6952 - val_accuracy: 0.9199 - val_precision_42: 0.0058 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.8154 - accuracy: 0.8075 - precision_42: 0.2450 - val_loss: 4.9151 - val_accuracy: 0.8712 - val_precision_42: 0.0265 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.4296 - accuracy: 0.8047 - precision_42: 0.2336 - val_loss: 14.9220 - val_accuracy: 0.9168 - val_precision_42: 0.0199 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.4697 - accuracy: 0.8070 - precision_42: 0.2455 - val_loss: 5.1977 - val_accuracy: 0.8707 - val_precision_42: 0.0271 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 13.2307 - accuracy: 0.8064 - precision_42: 0.2390 - val_loss: 4.2296 - val_accuracy: 0.8292 - val_precision_42: 0.0350 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 10.1174 - accuracy: 0.8080 - precision_42: 0.2469 - val_loss: 6.8096 - val_accuracy: 0.9213 - val_precision_42: 0.0189 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 11.3173 - accuracy: 0.8074 - precision_42: 0.2459 - val_loss: 6.2065 - val_accuracy: 0.9262 - val_precision_42: 0.0099 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 13.7663 - accuracy: 0.8038 - precision_42: 0.2314 - val_loss: 4.6431 - val_accuracy: 0.8155 - val_precision_42: 0.0259 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 10.8892 - accuracy: 0.8060 - precision_42: 0.2400 - val_loss: 2.7473 - val_accuracy: 0.8284 - val_precision_42: 0.0249 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.2577 - accuracy: 0.8100 - precision_42: 0.2543 - val_loss: 5.6271 - val_accuracy: 0.8873 - val_precision_42: 0.0195 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.5840 - accuracy: 0.8076 - precision_42: 0.2493 - val_loss: 2.5956 - val_accuracy: 0.9071 - val_precision_42: 0.0069 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.4100 - accuracy: 0.8096 - precision_42: 0.2501 - val_loss: 3.2314 - val_accuracy: 0.9091 - val_precision_42: 0.0208 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.2971 - accuracy: 0.8066 - precision_42: 0.2408 - val_loss: 16.6760 - val_accuracy: 0.5795 - val_precision_42: 0.0529 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.8272 - accuracy: 0.8087 - precision_42: 0.2542 - val_loss: 6.9180 - val_accuracy: 0.8207 - val_precision_42: 0.0306 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.9239 - accuracy: 0.8069 - precision_42: 0.2473 - val_loss: 2.6309 - val_accuracy: 0.8665 - val_precision_42: 0.0247 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.0289 - accuracy: 0.8053 - precision_42: 0.2454 - val_loss: 4.1278 - val_accuracy: 0.9291 - val_precision_42: 0.0071 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.1531 - accuracy: 0.8104 - precision_42: 0.2510 - val_loss: 2.8523 - val_accuracy: 0.8861 - val_precision_42: 0.0160 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.1971 - accuracy: 0.8051 - precision_42: 0.2395 - val_loss: 2.5807 - val_accuracy: 0.9354 - val_precision_42: 0.0021 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.4573 - accuracy: 0.8083 - precision_42: 0.2448 - val_loss: 2.4996 - val_accuracy: 0.8515 - val_precision_42: 0.0256 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.4476 - accuracy: 0.8070 - precision_42: 0.2449 - val_loss: 1.8448 - val_accuracy: 0.9182 - val_precision_42: 0.0138 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.4752 - accuracy: 0.8107 - precision_42: 0.2579 - val_loss: 3.2196 - val_accuracy: 0.9103 - val_precision_42: 0.0223 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.3409 - accuracy: 0.8098 - precision_42: 0.2561 - val_loss: 1.9697 - val_accuracy: 0.7521 - val_precision_42: 0.0561 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.7517 - accuracy: 0.8078 - precision_42: 0.2497 - val_loss: 1.2681 - val_accuracy: 0.8667 - val_precision_42: 0.0229 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.1208 - accuracy: 0.8069 - precision_42: 0.2455 - val_loss: 2.8376 - val_accuracy: 0.9027 - val_precision_42: 0.0248 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.4364 - accuracy: 0.8127 - precision_42: 0.2594 - val_loss: 5.8816 - val_accuracy: 0.6028 - val_precision_42: 0.0495 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.9171 - accuracy: 0.8096 - precision_42: 0.2516 - val_loss: 3.5805 - val_accuracy: 0.9234 - val_precision_42: 0.0671 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.6681 - accuracy: 0.8004 - precision_42: 0.2247 - val_loss: 3.5168 - val_accuracy: 0.6299 - val_precision_42: 0.0543 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.1479 - accuracy: 0.8075 - precision_42: 0.2416 - val_loss: 0.7416 - val_accuracy: 0.8596 - val_precision_42: 0.0450 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.7923 - accuracy: 0.8138 - precision_42: 0.2545 - val_loss: 1.1151 - val_accuracy: 0.8907 - val_precision_42: 0.0375 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.6171 - accuracy: 0.8134 - precision_42: 0.2525 - val_loss: 0.9885 - val_accuracy: 0.7425 - val_precision_42: 0.0512 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.3967 - accuracy: 0.8133 - precision_42: 0.2485 - val_loss: 0.7632 - val_accuracy: 0.8741 - val_precision_42: 0.0360 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.8395 - accuracy: 0.8139 - precision_42: 0.2545 - val_loss: 0.8749 - val_accuracy: 0.9177 - val_precision_42: 0.0471 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.1422 - accuracy: 0.8154 - precision_42: 0.2539 - val_loss: 1.6722 - val_accuracy: 0.5235 - val_precision_42: 0.0490 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.0715 - accuracy: 0.8163 - precision_42: 0.2561 - val_loss: 0.4125 - val_accuracy: 0.9143 - val_precision_42: 0.0488 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7256 - accuracy: 0.8297 - precision_42: 0.2849 - val_loss: 0.3907 - val_accuracy: 0.9242 - val_precision_42: 0.0454 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.8390 - precision_42: 0.3160 - val_loss: 0.3435 - val_accuracy: 0.9311 - val_precision_42: 0.0527 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.8429 - precision_42: 0.3428 - val_loss: 0.3969 - val_accuracy: 0.9152 - val_precision_42: 0.0440 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.8463 - precision_42: 0.3629 - val_loss: 0.2793 - val_accuracy: 0.9289 - val_precision_42: 0.0545 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.3021 - accuracy: 0.8248 - precision_42: 0.2701 - val_loss: 34.5858 - val_accuracy: 0.4184 - val_precision_42: 0.0400 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.4552 - accuracy: 0.7968 - precision_42: 0.2131 - val_loss: 0.4878 - val_accuracy: 0.8512 - val_precision_42: 0.0358 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.8303 - precision_42: 0.2801 - val_loss: 0.2626 - val_accuracy: 0.9410 - val_precision_42: 0.0337 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.8445 - precision_42: 0.3419 - val_loss: 0.3443 - val_accuracy: 0.8929 - val_precision_42: 0.0352 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8520 - precision_42: 0.3984 - val_loss: 0.2649 - val_accuracy: 0.9327 - val_precision_42: 0.0154 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8545 - precision_42: 0.4233 - val_loss: 0.3342 - val_accuracy: 0.8816 - val_precision_42: 0.0367 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8519 - precision_42: 0.4015 - val_loss: 0.2871 - val_accuracy: 0.9231 - val_precision_42: 0.0417 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.8465 - precision_42: 0.3717 - val_loss: 0.4079 - val_accuracy: 0.8527 - val_precision_42: 0.0477 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8586 - precision_42: 0.4795 - val_loss: 0.2471 - val_accuracy: 0.9343 - val_precision_42: 0.0603 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8603 - precision_42: 0.5067 - val_loss: 0.2793 - val_accuracy: 0.9091 - val_precision_42: 0.0358 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8558 - precision_42: 0.4444 - val_loss: 0.9347 - val_accuracy: 0.6174 - val_precision_42: 0.0548 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8524 - precision_42: 0.4105 - val_loss: 0.2497 - val_accuracy: 0.9356 - val_precision_42: 0.0539 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.3562 - accuracy: 0.8299 - precision_42: 0.3018 - val_loss: 31.7636 - val_accuracy: 0.9672 - val_precision_42: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.6974 - accuracy: 0.8044 - precision_42: 0.2243 - val_loss: 0.3483 - val_accuracy: 0.9022 - val_precision_42: 0.0285 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0190 - accuracy: 0.8234 - precision_42: 0.2703 - val_loss: 0.3041 - val_accuracy: 0.8944 - val_precision_42: 0.0309 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8527 - precision_42: 0.4025 - val_loss: 0.2601 - val_accuracy: 0.9203 - val_precision_42: 0.0116 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8536 - precision_42: 0.4177 - val_loss: 0.2412 - val_accuracy: 0.9288 - val_precision_42: 0.0223 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3819 - accuracy: 0.8578 - precision_42: 0.4657 - val_loss: 0.3789 - val_accuracy: 0.8660 - val_precision_42: 0.0412 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8610 - precision_42: 0.5218 - val_loss: 0.2434 - val_accuracy: 0.9321 - val_precision_42: 0.0396 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8635 - precision_42: 0.5691 - val_loss: 0.3633 - val_accuracy: 0.8610 - val_precision_42: 0.0354 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8611 - precision_42: 0.5189 - val_loss: 0.2639 - val_accuracy: 0.9179 - val_precision_42: 0.0190 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8600 - precision_42: 0.5014 - val_loss: 0.2505 - val_accuracy: 0.9257 - val_precision_42: 0.0223 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8585 - precision_42: 0.4793 - val_loss: 0.2571 - val_accuracy: 0.9293 - val_precision_42: 0.0323 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8594 - precision_42: 0.4919 - val_loss: 0.2644 - val_accuracy: 0.9096 - val_precision_42: 0.0276 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.8456 - precision_42: 0.3696 - val_loss: 0.3057 - val_accuracy: 0.9171 - val_precision_42: 0.0300 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8504 - precision_42: 0.3973 - val_loss: 0.2260 - val_accuracy: 0.9345 - val_precision_42: 0.0102 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8638 - precision_42: 0.5729 - val_loss: 0.2734 - val_accuracy: 0.9220 - val_precision_42: 0.0303 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8590 - precision_42: 0.4875 - val_loss: 0.3282 - val_accuracy: 0.9005 - val_precision_42: 0.0307 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8519 - precision_42: 0.4134 - val_loss: 0.3629 - val_accuracy: 0.8907 - val_precision_42: 0.0498 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.8517 - precision_42: 0.4180 - val_loss: 0.2744 - val_accuracy: 0.9174 - val_precision_42: 0.0446 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.7346 - accuracy: 0.8158 - precision_42: 0.2574 - val_loss: 0.9673 - val_accuracy: 0.9265 - val_precision_42: 0.0347 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.1572 - accuracy: 0.8115 - precision_42: 0.2303 - val_loss: 0.5616 - val_accuracy: 0.7950 - val_precision_42: 0.0608 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.8402 - precision_42: 0.3068 - val_loss: 0.2671 - val_accuracy: 0.9275 - val_precision_42: 0.0310 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 131.0547 - accuracy: 0.7672 - precision_43: 0.1635 - val_loss: 131.8605 - val_accuracy: 0.5727 - val_precision_43: 0.0488 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 58.3148 - accuracy: 0.7771 - precision_43: 0.1859 - val_loss: 23.4718 - val_accuracy: 0.6940 - val_precision_43: 0.0541 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 62.5792 - accuracy: 0.7801 - precision_43: 0.1971 - val_loss: 10.0160 - val_accuracy: 0.7950 - val_precision_43: 0.0344 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 47.4500 - accuracy: 0.7819 - precision_43: 0.1979 - val_loss: 12.2183 - val_accuracy: 0.9054 - val_precision_43: 0.0301 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 37.7547 - accuracy: 0.7833 - precision_43: 0.2025 - val_loss: 24.4012 - val_accuracy: 0.8051 - val_precision_43: 0.0150 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 66.9314 - accuracy: 0.7809 - precision_43: 0.1965 - val_loss: 14.9841 - val_accuracy: 0.9476 - val_precision_43: 0.0034 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 36.0402 - accuracy: 0.7892 - precision_43: 0.2030 - val_loss: 14.5169 - val_accuracy: 0.9187 - val_precision_43: 0.0014 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 30.3346 - accuracy: 0.7936 - precision_43: 0.2166 - val_loss: 10.1673 - val_accuracy: 0.8765 - val_precision_43: 0.0196 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 30.0052 - accuracy: 0.7948 - precision_43: 0.2117 - val_loss: 11.5204 - val_accuracy: 0.9190 - val_precision_43: 0.0086 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 27.6499 - accuracy: 0.7947 - precision_43: 0.2110 - val_loss: 15.3705 - val_accuracy: 0.6332 - val_precision_43: 0.0463 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 33.2824 - accuracy: 0.7899 - precision_43: 0.2087 - val_loss: 15.8735 - val_accuracy: 0.9632 - val_precision_43: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 28.0206 - accuracy: 0.7937 - precision_43: 0.2072 - val_loss: 10.9540 - val_accuracy: 0.8346 - val_precision_43: 0.0255 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 29.1506 - accuracy: 0.7983 - precision_43: 0.2252 - val_loss: 21.9909 - val_accuracy: 0.9618 - val_precision_43: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 47.4555 - accuracy: 0.7858 - precision_43: 0.1984 - val_loss: 5.9634 - val_accuracy: 0.8175 - val_precision_43: 0.0206 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 23.5165 - accuracy: 0.8003 - precision_43: 0.2285 - val_loss: 8.1372 - val_accuracy: 0.9309 - val_precision_43: 0.0185 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.1808 - accuracy: 0.8032 - precision_43: 0.2292 - val_loss: 42.7509 - val_accuracy: 0.5545 - val_precision_43: 0.0476 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.5947 - accuracy: 0.8016 - precision_43: 0.2230 - val_loss: 6.7923 - val_accuracy: 0.9098 - val_precision_43: 0.0132 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 31.5155 - accuracy: 0.8003 - precision_43: 0.2269 - val_loss: 21.9549 - val_accuracy: 0.5780 - val_precision_43: 0.0460 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 31.8378 - accuracy: 0.7991 - precision_43: 0.2251 - val_loss: 5.2175 - val_accuracy: 0.7574 - val_precision_43: 0.0468 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 31.4046 - accuracy: 0.8003 - precision_43: 0.2278 - val_loss: 6.4241 - val_accuracy: 0.9088 - val_precision_43: 0.0241 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.6534 - accuracy: 0.8027 - precision_43: 0.2323 - val_loss: 6.7498 - val_accuracy: 0.9186 - val_precision_43: 0.0312 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 13.6861 - accuracy: 0.8054 - precision_43: 0.2249 - val_loss: 9.1351 - val_accuracy: 0.9124 - val_precision_43: 0.0244 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.1450 - accuracy: 0.8061 - precision_43: 0.2302 - val_loss: 5.3027 - val_accuracy: 0.8762 - val_precision_43: 0.0181 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 16.0210 - accuracy: 0.8074 - precision_43: 0.2361 - val_loss: 10.3232 - val_accuracy: 0.9477 - val_precision_43: 0.0102 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 18.6924 - accuracy: 0.8058 - precision_43: 0.2375 - val_loss: 26.5030 - val_accuracy: 0.9508 - val_precision_43: 0.0444 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 20.8392 - accuracy: 0.8060 - precision_43: 0.2410 - val_loss: 5.5605 - val_accuracy: 0.9266 - val_precision_43: 0.0367 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.0806 - accuracy: 0.8086 - precision_43: 0.2468 - val_loss: 11.0012 - val_accuracy: 0.9511 - val_precision_43: 0.0081 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.2825 - accuracy: 0.8063 - precision_43: 0.2312 - val_loss: 6.4972 - val_accuracy: 0.9086 - val_precision_43: 0.0241 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 26.0859 - accuracy: 0.8031 - precision_43: 0.2317 - val_loss: 6.1449 - val_accuracy: 0.8891 - val_precision_43: 0.0217 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 14.2555 - accuracy: 0.8077 - precision_43: 0.2277 - val_loss: 3.4989 - val_accuracy: 0.9351 - val_precision_43: 0.0085 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 11.3277 - accuracy: 0.8079 - precision_43: 0.2359 - val_loss: 8.0356 - val_accuracy: 0.9491 - val_precision_43: 0.0073 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 21.4664 - accuracy: 0.8053 - precision_43: 0.2303 - val_loss: 42.8537 - val_accuracy: 0.4775 - val_precision_43: 0.0442 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 26.7822 - accuracy: 0.8030 - precision_43: 0.2242 - val_loss: 3.9774 - val_accuracy: 0.8012 - val_precision_43: 0.0422 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 17.1885 - accuracy: 0.8085 - precision_43: 0.2315 - val_loss: 5.1293 - val_accuracy: 0.9342 - val_precision_43: 0.0259 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.4487 - accuracy: 0.8066 - precision_43: 0.2211 - val_loss: 6.5666 - val_accuracy: 0.9241 - val_precision_43: 0.0470 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.9804 - accuracy: 0.8085 - precision_43: 0.2331 - val_loss: 6.3828 - val_accuracy: 0.9378 - val_precision_43: 0.0487 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.4236 - accuracy: 0.8102 - precision_43: 0.2430 - val_loss: 2.9520 - val_accuracy: 0.7590 - val_precision_43: 0.0295 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 12.2233 - accuracy: 0.8079 - precision_43: 0.2385 - val_loss: 5.1308 - val_accuracy: 0.9281 - val_precision_43: 0.0379 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.3148 - accuracy: 0.8092 - precision_43: 0.2388 - val_loss: 6.0005 - val_accuracy: 0.9437 - val_precision_43: 0.0400 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.3373 - accuracy: 0.8121 - precision_43: 0.2459 - val_loss: 15.0245 - val_accuracy: 0.5657 - val_precision_43: 0.0507 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.8414 - accuracy: 0.8095 - precision_43: 0.2459 - val_loss: 1.9783 - val_accuracy: 0.8695 - val_precision_43: 0.0249 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 14.5028 - accuracy: 0.8075 - precision_43: 0.2368 - val_loss: 2.4238 - val_accuracy: 0.8138 - val_precision_43: 0.0306 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.4361 - accuracy: 0.8100 - precision_43: 0.2457 - val_loss: 2.5718 - val_accuracy: 0.9054 - val_precision_43: 0.0229 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.5863 - accuracy: 0.8093 - precision_43: 0.2401 - val_loss: 3.9494 - val_accuracy: 0.9443 - val_precision_43: 0.0556 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 6.8717 - accuracy: 0.8114 - precision_43: 0.2508 - val_loss: 3.1535 - val_accuracy: 0.9137 - val_precision_43: 0.0320 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.2251 - accuracy: 0.8113 - precision_43: 0.2481 - val_loss: 1.4364 - val_accuracy: 0.8602 - val_precision_43: 0.0294 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.1380 - accuracy: 0.8104 - precision_43: 0.2453 - val_loss: 3.3880 - val_accuracy: 0.9170 - val_precision_43: 0.0446 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.9552 - accuracy: 0.8106 - precision_43: 0.2495 - val_loss: 3.2266 - val_accuracy: 0.9419 - val_precision_43: 0.0054 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.7001 - accuracy: 0.8075 - precision_43: 0.2344 - val_loss: 10.8674 - val_accuracy: 0.5724 - val_precision_43: 0.0487 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.2535 - accuracy: 0.8135 - precision_43: 0.2642 - val_loss: 2.3626 - val_accuracy: 0.9235 - val_precision_43: 0.0063 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.1424 - accuracy: 0.8130 - precision_43: 0.2525 - val_loss: 2.2288 - val_accuracy: 0.9171 - val_precision_43: 0.0327 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.7192 - accuracy: 0.8121 - precision_43: 0.2543 - val_loss: 2.1104 - val_accuracy: 0.9180 - val_precision_43: 0.0056 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.7768 - accuracy: 0.8130 - precision_43: 0.2593 - val_loss: 2.5780 - val_accuracy: 0.8751 - val_precision_43: 0.0242 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.3302 - accuracy: 0.8141 - precision_43: 0.2689 - val_loss: 1.4810 - val_accuracy: 0.9158 - val_precision_43: 0.0120 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.0336 - accuracy: 0.8144 - precision_43: 0.2688 - val_loss: 1.4173 - val_accuracy: 0.8742 - val_precision_43: 0.0247 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.3340 - accuracy: 0.8136 - precision_43: 0.2607 - val_loss: 1.5163 - val_accuracy: 0.8818 - val_precision_43: 0.0161 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.9580 - accuracy: 0.8139 - precision_43: 0.2703 - val_loss: 2.9246 - val_accuracy: 0.9206 - val_precision_43: 0.0388 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.0614 - accuracy: 0.8150 - precision_43: 0.2730 - val_loss: 2.6692 - val_accuracy: 0.9277 - val_precision_43: 0.0345 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.9364 - accuracy: 0.8175 - precision_43: 0.2804 - val_loss: 1.6727 - val_accuracy: 0.7898 - val_precision_43: 0.0201 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.9497 - accuracy: 0.8129 - precision_43: 0.2612 - val_loss: 7.0516 - val_accuracy: 0.5621 - val_precision_43: 0.0510 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9474 - accuracy: 0.8165 - precision_43: 0.2804 - val_loss: 0.8853 - val_accuracy: 0.8593 - val_precision_43: 0.0239 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.1532 - accuracy: 0.8159 - precision_43: 0.2801 - val_loss: 1.8444 - val_accuracy: 0.9355 - val_precision_43: 0.0169 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9984 - accuracy: 0.8155 - precision_43: 0.2769 - val_loss: 0.7126 - val_accuracy: 0.8982 - val_precision_43: 0.0130 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3574 - accuracy: 0.8153 - precision_43: 0.2777 - val_loss: 1.2777 - val_accuracy: 0.8695 - val_precision_43: 0.0169 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3321 - accuracy: 0.8191 - precision_43: 0.2854 - val_loss: 2.4295 - val_accuracy: 0.8247 - val_precision_43: 0.0257 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.6994 - accuracy: 0.8147 - precision_43: 0.2774 - val_loss: 0.7396 - val_accuracy: 0.8529 - val_precision_43: 0.0243 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.5400 - accuracy: 0.8183 - precision_43: 0.2897 - val_loss: 1.0460 - val_accuracy: 0.8783 - val_precision_43: 0.0243 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.8938 - accuracy: 0.8154 - precision_43: 0.2762 - val_loss: 0.8095 - val_accuracy: 0.9049 - val_precision_43: 0.0056 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.6230 - accuracy: 0.8173 - precision_43: 0.2844 - val_loss: 0.8285 - val_accuracy: 0.7599 - val_precision_43: 0.0368 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.1098 - accuracy: 0.8200 - precision_43: 0.2952 - val_loss: 0.7230 - val_accuracy: 0.8488 - val_precision_43: 0.0241 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.9333 - accuracy: 0.8228 - precision_43: 0.3102 - val_loss: 0.5547 - val_accuracy: 0.8669 - val_precision_43: 0.0268 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.8851 - accuracy: 0.8216 - precision_43: 0.3023 - val_loss: 0.9776 - val_accuracy: 0.8899 - val_precision_43: 0.0211 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.8738 - accuracy: 0.8191 - precision_43: 0.2924 - val_loss: 0.8921 - val_accuracy: 0.8916 - val_precision_43: 0.0128 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5181 - accuracy: 0.8214 - precision_43: 0.2993 - val_loss: 0.9600 - val_accuracy: 0.9063 - val_precision_43: 0.0284 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2568 - accuracy: 0.8263 - precision_43: 0.3140 - val_loss: 0.8921 - val_accuracy: 0.8665 - val_precision_43: 0.0216 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.1102 - accuracy: 0.8286 - precision_43: 0.3282 - val_loss: 0.7105 - val_accuracy: 0.7797 - val_precision_43: 0.0464 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.2801 - accuracy: 0.8235 - precision_43: 0.3107 - val_loss: 0.5954 - val_accuracy: 0.9255 - val_precision_43: 0.0099 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.4308 - accuracy: 0.8243 - precision_43: 0.3083 - val_loss: 0.5949 - val_accuracy: 0.9151 - val_precision_43: 0.0195 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0396 - accuracy: 0.8297 - precision_43: 0.3288 - val_loss: 0.4838 - val_accuracy: 0.8340 - val_precision_43: 0.0201 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.9435 - accuracy: 0.8274 - precision_43: 0.3166 - val_loss: 0.4576 - val_accuracy: 0.9164 - val_precision_43: 0.0135 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.8129 - accuracy: 0.8343 - precision_43: 0.3514 - val_loss: 0.3348 - val_accuracy: 0.8802 - val_precision_43: 0.0370 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.8657 - accuracy: 0.8325 - precision_43: 0.3412 - val_loss: 0.7364 - val_accuracy: 0.7105 - val_precision_43: 0.0534 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.6743 - accuracy: 0.8367 - precision_43: 0.3564 - val_loss: 0.4831 - val_accuracy: 0.8863 - val_precision_43: 0.0120 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.8380 - precision_43: 0.3605 - val_loss: 0.3662 - val_accuracy: 0.9394 - val_precision_43: 0.0190 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.8376 - precision_43: 0.3578 - val_loss: 0.5304 - val_accuracy: 0.7671 - val_precision_43: 0.0648 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.8453 - precision_43: 0.3948 - val_loss: 0.2670 - val_accuracy: 0.9345 - val_precision_43: 0.0299 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.8372 - precision_43: 0.3497 - val_loss: 0.4404 - val_accuracy: 0.8841 - val_precision_43: 0.0197 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8530 - precision_43: 0.4367 - val_loss: 0.2299 - val_accuracy: 0.9540 - val_precision_43: 0.0144 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.8471 - precision_43: 0.4045 - val_loss: 0.3127 - val_accuracy: 0.9016 - val_precision_43: 0.0351 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8556 - precision_43: 0.4574 - val_loss: 0.2566 - val_accuracy: 0.9334 - val_precision_43: 0.0253 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8553 - precision_43: 0.4546 - val_loss: 0.3165 - val_accuracy: 0.8927 - val_precision_43: 0.0218 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8585 - precision_43: 0.4823 - val_loss: 0.2948 - val_accuracy: 0.9112 - val_precision_43: 0.0383 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.8613 - precision_43: 0.5132 - val_loss: 0.3319 - val_accuracy: 0.8878 - val_precision_43: 0.0206 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8584 - precision_43: 0.4829 - val_loss: 0.2637 - val_accuracy: 0.9251 - val_precision_43: 0.0161 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.8500 - precision_43: 0.4132 - val_loss: 0.2936 - val_accuracy: 0.9118 - val_precision_43: 0.0287 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8639 - precision_43: 0.5462 - val_loss: 0.3206 - val_accuracy: 0.8868 - val_precision_43: 0.0314 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8636 - precision_43: 0.5421 - val_loss: 0.2780 - val_accuracy: 0.9212 - val_precision_43: 0.0104 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8593 - precision_43: 0.4920 - val_loss: 0.2938 - val_accuracy: 0.9054 - val_precision_43: 0.0301 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8637 - precision_43: 0.5461 - val_loss: 0.2395 - val_accuracy: 0.9400 - val_precision_43: 0.0147 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.2543 - accuracy: 0.8378 - precision_43: 0.3451 - val_loss: 0.4418 - val_accuracy: 0.8933 - val_precision_43: 0.0149 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 [==============================] - 2s 6ms/step - loss: 234.1429 - accuracy: 0.7727 - precision_44: 0.1495 - val_loss: 173.9420 - val_accuracy: 0.6351 - val_precision_44: 0.0536 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 73.6570 - accuracy: 0.7788 - precision_44: 0.1718 - val_loss: 64.4298 - val_accuracy: 0.6587 - val_precision_44: 0.0557 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 70.3328 - accuracy: 0.7834 - precision_44: 0.1869 - val_loss: 30.5515 - val_accuracy: 0.8215 - val_precision_44: 0.0157 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 56.8650 - accuracy: 0.7835 - precision_44: 0.1889 - val_loss: 20.6287 - val_accuracy: 0.9296 - val_precision_44: 0.0037 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 49.2323 - accuracy: 0.7909 - precision_44: 0.2062 - val_loss: 31.9748 - val_accuracy: 0.9432 - val_precision_44: 0.0058 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 39.1804 - accuracy: 0.7970 - precision_44: 0.2057 - val_loss: 11.0854 - val_accuracy: 0.9257 - val_precision_44: 0.0100 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 44.7411 - accuracy: 0.7935 - precision_44: 0.2017 - val_loss: 14.4958 - val_accuracy: 0.7782 - val_precision_44: 0.0487 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 40.5815 - accuracy: 0.7948 - precision_44: 0.2158 - val_loss: 10.7321 - val_accuracy: 0.8041 - val_precision_44: 0.0255 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 35.7567 - accuracy: 0.7979 - precision_44: 0.2170 - val_loss: 12.0937 - val_accuracy: 0.9156 - val_precision_44: 0.0211 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 32.8118 - accuracy: 0.7966 - precision_44: 0.2106 - val_loss: 15.3828 - val_accuracy: 0.9021 - val_precision_44: 0.0269 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 41.3269 - accuracy: 0.7957 - precision_44: 0.2095 - val_loss: 58.5775 - val_accuracy: 0.9186 - val_precision_44: 0.0263 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 33.5680 - accuracy: 0.8030 - precision_44: 0.2288 - val_loss: 8.8512 - val_accuracy: 0.8427 - val_precision_44: 0.0257 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.9500 - accuracy: 0.8004 - precision_44: 0.2207 - val_loss: 16.5922 - val_accuracy: 0.6577 - val_precision_44: 0.0548 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.2005 - accuracy: 0.7968 - precision_44: 0.2199 - val_loss: 15.7899 - val_accuracy: 0.9454 - val_precision_44: 0.0185 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 25.3549 - accuracy: 0.7963 - precision_44: 0.2168 - val_loss: 9.2453 - val_accuracy: 0.7494 - val_precision_44: 0.0488 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 22.4953 - accuracy: 0.7947 - precision_44: 0.2149 - val_loss: 4.7789 - val_accuracy: 0.8259 - val_precision_44: 0.0314 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 19.0361 - accuracy: 0.7993 - precision_44: 0.2245 - val_loss: 9.5541 - val_accuracy: 0.8323 - val_precision_44: 0.0223 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.6274 - accuracy: 0.8023 - precision_44: 0.2371 - val_loss: 4.1239 - val_accuracy: 0.8745 - val_precision_44: 0.0186 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 13.2715 - accuracy: 0.8051 - precision_44: 0.2385 - val_loss: 12.9500 - val_accuracy: 0.8595 - val_precision_44: 0.0204 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 15.2295 - accuracy: 0.7993 - precision_44: 0.2232 - val_loss: 8.9987 - val_accuracy: 0.8482 - val_precision_44: 0.0202 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 10.4738 - accuracy: 0.8011 - precision_44: 0.2368 - val_loss: 4.5224 - val_accuracy: 0.8731 - val_precision_44: 0.0190 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.9021 - accuracy: 0.7970 - precision_44: 0.2222 - val_loss: 3.2119 - val_accuracy: 0.8310 - val_precision_44: 0.0292 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.5314 - accuracy: 0.8053 - precision_44: 0.2383 - val_loss: 2.4795 - val_accuracy: 0.8014 - val_precision_44: 0.0513 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.0159 - accuracy: 0.8035 - precision_44: 0.2302 - val_loss: 2.2997 - val_accuracy: 0.8992 - val_precision_44: 0.0192 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.0977 - accuracy: 0.8048 - precision_44: 0.2352 - val_loss: 4.6531 - val_accuracy: 0.8504 - val_precision_44: 0.0321 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.3718 - accuracy: 0.8015 - precision_44: 0.2280 - val_loss: 2.4288 - val_accuracy: 0.9041 - val_precision_44: 0.0100 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.4523 - accuracy: 0.8009 - precision_44: 0.2339 - val_loss: 3.6717 - val_accuracy: 0.9369 - val_precision_44: 0.0136 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.1847 - accuracy: 0.8035 - precision_44: 0.2288 - val_loss: 2.3432 - val_accuracy: 0.8814 - val_precision_44: 0.0238 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.9851 - accuracy: 0.7988 - precision_44: 0.2290 - val_loss: 2.2997 - val_accuracy: 0.8534 - val_precision_44: 0.0290 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.4071 - accuracy: 0.7981 - precision_44: 0.2289 - val_loss: 5.9083 - val_accuracy: 0.5035 - val_precision_44: 0.0480 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.7218 - accuracy: 0.7972 - precision_44: 0.2273 - val_loss: 1.9378 - val_accuracy: 0.9124 - val_precision_44: 0.0247 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.4722 - accuracy: 0.8042 - precision_44: 0.2343 - val_loss: 1.0513 - val_accuracy: 0.8671 - val_precision_44: 0.0283 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.7614 - accuracy: 0.8041 - precision_44: 0.2333 - val_loss: 2.0421 - val_accuracy: 0.7355 - val_precision_44: 0.0292 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.1357 - accuracy: 0.8037 - precision_44: 0.2311 - val_loss: 4.0119 - val_accuracy: 0.6160 - val_precision_44: 0.0552 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.5857 - accuracy: 0.8061 - precision_44: 0.2414 - val_loss: 1.9672 - val_accuracy: 0.8727 - val_precision_44: 0.0306 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3709 - accuracy: 0.8025 - precision_44: 0.2333 - val_loss: 1.1131 - val_accuracy: 0.7151 - val_precision_44: 0.0575 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.9412 - accuracy: 0.8054 - precision_44: 0.2358 - val_loss: 0.7257 - val_accuracy: 0.8282 - val_precision_44: 0.0567 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.6524 - accuracy: 0.8051 - precision_44: 0.2328 - val_loss: 1.0669 - val_accuracy: 0.9526 - val_precision_44: 0.0093 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5349 - accuracy: 0.8109 - precision_44: 0.2459 - val_loss: 1.7201 - val_accuracy: 0.5853 - val_precision_44: 0.0524 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0799 - accuracy: 0.8131 - precision_44: 0.2478 - val_loss: 0.7442 - val_accuracy: 0.7601 - val_precision_44: 0.0636 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.1740 - accuracy: 0.8124 - precision_44: 0.2435 - val_loss: 0.4808 - val_accuracy: 0.8614 - val_precision_44: 0.0404 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9267 - accuracy: 0.8201 - precision_44: 0.2625 - val_loss: 1.7898 - val_accuracy: 0.6016 - val_precision_44: 0.0539 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.1138 - accuracy: 0.8083 - precision_44: 0.2340 - val_loss: 0.3751 - val_accuracy: 0.8999 - val_precision_44: 0.0299 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.8976 - accuracy: 0.8158 - precision_44: 0.2455 - val_loss: 0.3421 - val_accuracy: 0.9281 - val_precision_44: 0.0489 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.8311 - precision_44: 0.2793 - val_loss: 1.0277 - val_accuracy: 0.6380 - val_precision_44: 0.0569 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6982 - accuracy: 0.8259 - precision_44: 0.2700 - val_loss: 0.3605 - val_accuracy: 0.9118 - val_precision_44: 0.0313 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.8236 - precision_44: 0.2601 - val_loss: 0.3026 - val_accuracy: 0.9361 - val_precision_44: 0.0377 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.8369 - precision_44: 0.2961 - val_loss: 0.2868 - val_accuracy: 0.9409 - val_precision_44: 0.0301 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9692 - accuracy: 0.8178 - precision_44: 0.2499 - val_loss: 0.4084 - val_accuracy: 0.9447 - val_precision_44: 0.0478 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3507 - accuracy: 0.7983 - precision_44: 0.2131 - val_loss: 1.4067 - val_accuracy: 0.9516 - val_precision_44: 0.0290 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.3587 - accuracy: 0.8163 - precision_44: 0.2449 - val_loss: 0.2600 - val_accuracy: 0.9479 - val_precision_44: 0.0458 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.8313 - precision_44: 0.2791 - val_loss: 0.2713 - val_accuracy: 0.9417 - val_precision_44: 0.0473 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.8449 - precision_44: 0.3387 - val_loss: 0.3126 - val_accuracy: 0.9230 - val_precision_44: 0.0544 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.8308 - precision_44: 0.2783 - val_loss: 0.6790 - val_accuracy: 0.7212 - val_precision_44: 0.0716 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9605 - accuracy: 0.8091 - precision_44: 0.2339 - val_loss: 0.7783 - val_accuracy: 0.9475 - val_precision_44: 0.0592 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0105 - accuracy: 0.8179 - precision_44: 0.2450 - val_loss: 0.4697 - val_accuracy: 0.8112 - val_precision_44: 0.0873 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.5907 - accuracy: 0.8169 - precision_44: 0.2387 - val_loss: 0.7015 - val_accuracy: 0.9108 - val_precision_44: 0.0251 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5068 - accuracy: 0.8122 - precision_44: 0.2333 - val_loss: 1.6269 - val_accuracy: 0.7881 - val_precision_44: 0.0527 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.9928 - accuracy: 0.8228 - precision_44: 0.2554 - val_loss: 0.2390 - val_accuracy: 0.9521 - val_precision_44: 0.0565 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.8380 - precision_44: 0.2827 - val_loss: 0.2902 - val_accuracy: 0.9091 - val_precision_44: 0.0332 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 11.1446 - accuracy: 0.8097 - precision_44: 0.2211 - val_loss: 1.7490 - val_accuracy: 0.9442 - val_precision_44: 0.0418 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.8468 - precision_44: 0.2912 - val_loss: 0.2936 - val_accuracy: 0.9366 - val_precision_44: 0.0283 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8560 - precision_44: 0.3900 - val_loss: 0.2846 - val_accuracy: 0.9308 - val_precision_44: 0.0410 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8579 - precision_44: 0.4303 - val_loss: 0.2111 - val_accuracy: 0.9655 - val_precision_44: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8566 - precision_44: 0.4137 - val_loss: 0.2621 - val_accuracy: 0.9311 - val_precision_44: 0.0380 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8590 - precision_44: 0.4641 - val_loss: 0.1969 - val_accuracy: 0.9664 - val_precision_44: 0.0435 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8592 - precision_44: 0.4688 - val_loss: 0.1974 - val_accuracy: 0.9635 - val_precision_44: 0.0156 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8580 - precision_44: 0.4347 - val_loss: 0.2552 - val_accuracy: 0.9338 - val_precision_44: 0.0426 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8590 - precision_44: 0.4633 - val_loss: 0.3647 - val_accuracy: 0.8502 - val_precision_44: 0.0321 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8591 - precision_44: 0.4644 - val_loss: 0.2431 - val_accuracy: 0.9396 - val_precision_44: 0.0376 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8595 - precision_44: 0.4782 - val_loss: 0.2790 - val_accuracy: 0.9180 - val_precision_44: 0.0494 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8593 - precision_44: 0.4707 - val_loss: 0.2744 - val_accuracy: 0.9137 - val_precision_44: 0.0276 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8589 - precision_44: 0.4644 - val_loss: 0.2026 - val_accuracy: 0.9586 - val_precision_44: 0.0149 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8574 - precision_44: 0.4332 - val_loss: 0.3143 - val_accuracy: 0.8840 - val_precision_44: 0.0359 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8591 - precision_44: 0.4649 - val_loss: 0.3624 - val_accuracy: 0.8520 - val_precision_44: 0.0298 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8595 - precision_44: 0.4793 - val_loss: 0.2708 - val_accuracy: 0.9213 - val_precision_44: 0.0424 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8590 - precision_44: 0.4640 - val_loss: 0.3019 - val_accuracy: 0.8909 - val_precision_44: 0.0381 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8611 - precision_44: 0.5205 - val_loss: 0.2217 - val_accuracy: 0.9510 - val_precision_44: 0.0042 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8599 - precision_44: 0.4853 - val_loss: 0.2371 - val_accuracy: 0.9393 - val_precision_44: 0.0025 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8592 - precision_44: 0.4684 - val_loss: 0.2796 - val_accuracy: 0.9121 - val_precision_44: 0.0425 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8607 - precision_44: 0.5100 - val_loss: 0.3272 - val_accuracy: 0.8709 - val_precision_44: 0.0352 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8587 - precision_44: 0.4578 - val_loss: 0.2351 - val_accuracy: 0.9403 - val_precision_44: 0.0295 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8613 - precision_44: 0.5302 - val_loss: 0.2719 - val_accuracy: 0.9157 - val_precision_44: 0.0310 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8597 - precision_44: 0.4815 - val_loss: 0.2585 - val_accuracy: 0.9284 - val_precision_44: 0.0637 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8603 - precision_44: 0.4984 - val_loss: 0.3300 - val_accuracy: 0.8753 - val_precision_44: 0.0388 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3736 - accuracy: 0.8600 - precision_44: 0.4882 - val_loss: 0.3028 - val_accuracy: 0.8903 - val_precision_44: 0.0401 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8629 - precision_44: 0.5877 - val_loss: 0.1981 - val_accuracy: 0.9621 - val_precision_44: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8631 - precision_44: 0.5960 - val_loss: 0.2769 - val_accuracy: 0.9176 - val_precision_44: 0.0468 - lr: 5.0000e-04\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8635 - precision_44: 0.6071 - val_loss: 0.2330 - val_accuracy: 0.9410 - val_precision_44: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8636 - precision_44: 0.6071 - val_loss: 0.2391 - val_accuracy: 0.9385 - val_precision_44: 0.0211 - lr: 5.0000e-04\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8628 - precision_44: 0.5763 - val_loss: 0.2162 - val_accuracy: 0.9544 - val_precision_44: 0.0648 - lr: 5.0000e-04\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8634 - precision_44: 0.5944 - val_loss: 0.2505 - val_accuracy: 0.9350 - val_precision_44: 0.0681 - lr: 5.0000e-04\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8631 - precision_44: 0.5892 - val_loss: 0.2224 - val_accuracy: 0.9484 - val_precision_44: 0.0178 - lr: 5.0000e-04\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8619 - precision_44: 0.5379 - val_loss: 0.3169 - val_accuracy: 0.8900 - val_precision_44: 0.0376 - lr: 5.0000e-04\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8635 - precision_44: 0.5998 - val_loss: 0.2906 - val_accuracy: 0.9023 - val_precision_44: 0.0431 - lr: 5.0000e-04\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8635 - precision_44: 0.5929 - val_loss: 0.4031 - val_accuracy: 0.8197 - val_precision_44: 0.0353 - lr: 5.0000e-04\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.8631 - precision_44: 0.5792 - val_loss: 0.2537 - val_accuracy: 0.9319 - val_precision_44: 0.0487 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8641 - precision_44: 0.6211 - val_loss: 0.2919 - val_accuracy: 0.9076 - val_precision_44: 0.0476 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8635 - precision_44: 0.5951 - val_loss: 0.2657 - val_accuracy: 0.9279 - val_precision_44: 0.0443 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8640 - precision_44: 0.6048 - val_loss: 0.2369 - val_accuracy: 0.9425 - val_precision_44: 0.0392 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 6ms/step - loss: 295.5178 - accuracy: 0.7599 - precision_45: 0.1539 - val_loss: 65.1364 - val_accuracy: 0.9215 - val_precision_45: 0.0031 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 96.1806 - accuracy: 0.7775 - precision_45: 0.1800 - val_loss: 44.5803 - val_accuracy: 0.9355 - val_precision_45: 0.0023 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 65.9756 - accuracy: 0.7889 - precision_45: 0.2019 - val_loss: 13.9810 - val_accuracy: 0.8900 - val_precision_45: 0.0240 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 56.7655 - accuracy: 0.7870 - precision_45: 0.1970 - val_loss: 145.5652 - val_accuracy: 0.2845 - val_precision_45: 0.0405 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 59.0404 - accuracy: 0.7867 - precision_45: 0.2041 - val_loss: 16.7760 - val_accuracy: 0.9357 - val_precision_45: 0.0045 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 62.8871 - accuracy: 0.7827 - precision_45: 0.2003 - val_loss: 14.8080 - val_accuracy: 0.9491 - val_precision_45: 0.0191 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 40.0724 - accuracy: 0.7933 - precision_45: 0.2126 - val_loss: 24.8285 - val_accuracy: 0.9450 - val_precision_45: 0.0064 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 64.5543 - accuracy: 0.7902 - precision_45: 0.2065 - val_loss: 36.7404 - val_accuracy: 0.9334 - val_precision_45: 0.0104 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 76.4618 - accuracy: 0.7849 - precision_45: 0.2034 - val_loss: 11.5951 - val_accuracy: 0.9412 - val_precision_45: 0.0055 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 51.7469 - accuracy: 0.7901 - precision_45: 0.2069 - val_loss: 185.9914 - val_accuracy: 0.5197 - val_precision_45: 0.0485 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 59.0781 - accuracy: 0.7918 - precision_45: 0.2049 - val_loss: 24.7058 - val_accuracy: 0.4934 - val_precision_45: 0.0395 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 32.2532 - accuracy: 0.7964 - precision_45: 0.2182 - val_loss: 9.5211 - val_accuracy: 0.9340 - val_precision_45: 0.0106 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 36.0352 - accuracy: 0.7943 - precision_45: 0.2234 - val_loss: 10.7453 - val_accuracy: 0.7785 - val_precision_45: 0.0291 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 30.5693 - accuracy: 0.7986 - precision_45: 0.2223 - val_loss: 14.0558 - val_accuracy: 0.9346 - val_precision_45: 0.0065 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 46.8475 - accuracy: 0.7985 - precision_45: 0.2179 - val_loss: 24.2773 - val_accuracy: 0.9419 - val_precision_45: 0.0056 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 33.4149 - accuracy: 0.7994 - precision_45: 0.2254 - val_loss: 7.5795 - val_accuracy: 0.8412 - val_precision_45: 0.0265 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 26.6140 - accuracy: 0.8003 - precision_45: 0.2232 - val_loss: 13.8694 - val_accuracy: 0.9119 - val_precision_45: 0.0236 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 20.4698 - accuracy: 0.8030 - precision_45: 0.2251 - val_loss: 7.4910 - val_accuracy: 0.7321 - val_precision_45: 0.0436 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 24.5547 - accuracy: 0.8045 - precision_45: 0.2212 - val_loss: 6.8754 - val_accuracy: 0.9136 - val_precision_45: 0.0092 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 36.9423 - accuracy: 0.8008 - precision_45: 0.2178 - val_loss: 19.1285 - val_accuracy: 0.9331 - val_precision_45: 0.0042 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 31.4877 - accuracy: 0.8050 - precision_45: 0.2334 - val_loss: 9.1097 - val_accuracy: 0.6724 - val_precision_45: 0.0217 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 31.4938 - accuracy: 0.7968 - precision_45: 0.2105 - val_loss: 5.9788 - val_accuracy: 0.9108 - val_precision_45: 0.0100 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 19.0644 - accuracy: 0.8026 - precision_45: 0.2193 - val_loss: 5.3049 - val_accuracy: 0.8107 - val_precision_45: 0.0299 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 18.9755 - accuracy: 0.8013 - precision_45: 0.2244 - val_loss: 5.7837 - val_accuracy: 0.7884 - val_precision_45: 0.0303 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 17.1151 - accuracy: 0.8054 - precision_45: 0.2265 - val_loss: 4.4219 - val_accuracy: 0.8817 - val_precision_45: 0.0194 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.5963 - accuracy: 0.8062 - precision_45: 0.2261 - val_loss: 9.8539 - val_accuracy: 0.9036 - val_precision_45: 0.0357 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 19.1720 - accuracy: 0.8085 - precision_45: 0.2365 - val_loss: 4.1854 - val_accuracy: 0.7617 - val_precision_45: 0.0346 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.9789 - accuracy: 0.8031 - precision_45: 0.2189 - val_loss: 7.9268 - val_accuracy: 0.8133 - val_precision_45: 0.0287 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 15.4042 - accuracy: 0.8024 - precision_45: 0.2245 - val_loss: 17.5659 - val_accuracy: 0.9562 - val_precision_45: 0.0065 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 23.3038 - accuracy: 0.8051 - precision_45: 0.2252 - val_loss: 7.9890 - val_accuracy: 0.9221 - val_precision_45: 0.0300 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.7447 - accuracy: 0.8043 - precision_45: 0.2282 - val_loss: 5.3858 - val_accuracy: 0.9041 - val_precision_45: 0.0133 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 11.8909 - accuracy: 0.8071 - precision_45: 0.2348 - val_loss: 7.2664 - val_accuracy: 0.9320 - val_precision_45: 0.0080 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 12.2645 - accuracy: 0.8067 - precision_45: 0.2432 - val_loss: 2.4119 - val_accuracy: 0.8269 - val_precision_45: 0.0308 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 20.0173 - accuracy: 0.8060 - precision_45: 0.2335 - val_loss: 18.8300 - val_accuracy: 0.6894 - val_precision_45: 0.0216 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.0328 - accuracy: 0.8034 - precision_45: 0.2301 - val_loss: 5.0768 - val_accuracy: 0.9360 - val_precision_45: 0.0023 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 13.2945 - accuracy: 0.8111 - precision_45: 0.2456 - val_loss: 7.0684 - val_accuracy: 0.7088 - val_precision_45: 0.0490 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 13.6648 - accuracy: 0.8045 - precision_45: 0.2265 - val_loss: 5.9516 - val_accuracy: 0.7903 - val_precision_45: 0.0281 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 14.4333 - accuracy: 0.8081 - precision_45: 0.2307 - val_loss: 7.0911 - val_accuracy: 0.6455 - val_precision_45: 0.0539 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 13.9746 - accuracy: 0.8054 - precision_45: 0.2341 - val_loss: 6.7694 - val_accuracy: 0.9407 - val_precision_45: 0.0080 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.5169 - accuracy: 0.8064 - precision_45: 0.2420 - val_loss: 6.3965 - val_accuracy: 0.9471 - val_precision_45: 0.0070 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.8348 - accuracy: 0.8061 - precision_45: 0.2259 - val_loss: 4.2141 - val_accuracy: 0.8951 - val_precision_45: 0.0420 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 7.7502 - accuracy: 0.8087 - precision_45: 0.2447 - val_loss: 2.3002 - val_accuracy: 0.8574 - val_precision_45: 0.0189 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.6409 - accuracy: 0.8091 - precision_45: 0.2435 - val_loss: 4.5065 - val_accuracy: 0.7164 - val_precision_45: 0.0574 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.7585 - accuracy: 0.8051 - precision_45: 0.2288 - val_loss: 6.5399 - val_accuracy: 0.8974 - val_precision_45: 0.0363 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.4637 - accuracy: 0.8073 - precision_45: 0.2333 - val_loss: 5.4997 - val_accuracy: 0.9181 - val_precision_45: 0.0404 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 6.3675 - accuracy: 0.8076 - precision_45: 0.2332 - val_loss: 4.1614 - val_accuracy: 0.8935 - val_precision_45: 0.0371 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 6.2402 - accuracy: 0.8093 - precision_45: 0.2451 - val_loss: 6.4882 - val_accuracy: 0.8930 - val_precision_45: 0.0377 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.8904 - accuracy: 0.8074 - precision_45: 0.2398 - val_loss: 3.2529 - val_accuracy: 0.8692 - val_precision_45: 0.0278 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.3992 - accuracy: 0.8072 - precision_45: 0.2360 - val_loss: 3.0420 - val_accuracy: 0.9321 - val_precision_45: 0.0061 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.4059 - accuracy: 0.8105 - precision_45: 0.2510 - val_loss: 2.9785 - val_accuracy: 0.9022 - val_precision_45: 0.0341 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.3917 - accuracy: 0.8081 - precision_45: 0.2387 - val_loss: 2.3679 - val_accuracy: 0.8988 - val_precision_45: 0.0113 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 6.0096 - accuracy: 0.8134 - precision_45: 0.2561 - val_loss: 6.0051 - val_accuracy: 0.9446 - val_precision_45: 0.0663 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.6150 - accuracy: 0.8083 - precision_45: 0.2463 - val_loss: 11.4981 - val_accuracy: 0.9598 - val_precision_45: 0.0945 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 7.1093 - accuracy: 0.8090 - precision_45: 0.2382 - val_loss: 1.1698 - val_accuracy: 0.8758 - val_precision_45: 0.0289 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.8028 - accuracy: 0.8094 - precision_45: 0.2425 - val_loss: 4.0294 - val_accuracy: 0.9503 - val_precision_45: 0.0463 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.6424 - accuracy: 0.8138 - precision_45: 0.2612 - val_loss: 1.4104 - val_accuracy: 0.8220 - val_precision_45: 0.0263 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.2189 - accuracy: 0.8144 - precision_45: 0.2645 - val_loss: 1.1897 - val_accuracy: 0.8542 - val_precision_45: 0.0333 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.4442 - accuracy: 0.8118 - precision_45: 0.2436 - val_loss: 12.5257 - val_accuracy: 0.5556 - val_precision_45: 0.0547 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 7.1304 - accuracy: 0.8071 - precision_45: 0.2393 - val_loss: 1.8517 - val_accuracy: 0.7396 - val_precision_45: 0.0609 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.1125 - accuracy: 0.8114 - precision_45: 0.2592 - val_loss: 0.9423 - val_accuracy: 0.8561 - val_precision_45: 0.0252 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.2668 - accuracy: 0.8150 - precision_45: 0.2675 - val_loss: 1.4923 - val_accuracy: 0.9296 - val_precision_45: 0.0112 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.6670 - accuracy: 0.8126 - precision_45: 0.2548 - val_loss: 1.5386 - val_accuracy: 0.8768 - val_precision_45: 0.0271 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.3927 - accuracy: 0.8150 - precision_45: 0.2597 - val_loss: 1.1294 - val_accuracy: 0.9292 - val_precision_45: 0.0019 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.1784 - accuracy: 0.8147 - precision_45: 0.2637 - val_loss: 0.7645 - val_accuracy: 0.8355 - val_precision_45: 0.0462 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.1717 - accuracy: 0.8165 - precision_45: 0.2697 - val_loss: 0.8658 - val_accuracy: 0.9277 - val_precision_45: 0.0018 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.0706 - accuracy: 0.8139 - precision_45: 0.2606 - val_loss: 1.0375 - val_accuracy: 0.9293 - val_precision_45: 0.0056 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.7467 - accuracy: 0.8183 - precision_45: 0.2715 - val_loss: 0.7115 - val_accuracy: 0.9154 - val_precision_45: 0.0135 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.6285 - accuracy: 0.8177 - precision_45: 0.2718 - val_loss: 0.6941 - val_accuracy: 0.8964 - val_precision_45: 0.0223 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.7099 - accuracy: 0.8168 - precision_45: 0.2635 - val_loss: 1.1130 - val_accuracy: 0.9417 - val_precision_45: 0.0056 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.1729 - accuracy: 0.8226 - precision_45: 0.2845 - val_loss: 0.6294 - val_accuracy: 0.8336 - val_precision_45: 0.0304 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.2653 - accuracy: 0.8203 - precision_45: 0.2740 - val_loss: 0.7976 - val_accuracy: 0.9281 - val_precision_45: 0.0278 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.4354 - accuracy: 0.8140 - precision_45: 0.2553 - val_loss: 1.2174 - val_accuracy: 0.9528 - val_precision_45: 0.0493 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.4279 - accuracy: 0.8193 - precision_45: 0.2678 - val_loss: 2.3214 - val_accuracy: 0.6402 - val_precision_45: 0.0575 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9803 - accuracy: 0.8210 - precision_45: 0.2757 - val_loss: 0.5353 - val_accuracy: 0.8655 - val_precision_45: 0.0281 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9707 - accuracy: 0.8229 - precision_45: 0.2830 - val_loss: 0.7431 - val_accuracy: 0.9363 - val_precision_45: 0.0426 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.8996 - accuracy: 0.8266 - precision_45: 0.2840 - val_loss: 0.4539 - val_accuracy: 0.9250 - val_precision_45: 0.0259 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.8335 - precision_45: 0.3134 - val_loss: 0.6078 - val_accuracy: 0.6960 - val_precision_45: 0.0360 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.6042 - accuracy: 0.8321 - precision_45: 0.3034 - val_loss: 0.4738 - val_accuracy: 0.8355 - val_precision_45: 0.0239 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.5959 - accuracy: 0.8328 - precision_45: 0.3022 - val_loss: 0.6003 - val_accuracy: 0.7699 - val_precision_45: 0.0727 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5707 - accuracy: 0.8349 - precision_45: 0.3036 - val_loss: 1.0717 - val_accuracy: 0.5891 - val_precision_45: 0.0569 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6488 - accuracy: 0.8292 - precision_45: 0.2907 - val_loss: 0.3782 - val_accuracy: 0.9005 - val_precision_45: 0.0487 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.8396 - precision_45: 0.3251 - val_loss: 0.2753 - val_accuracy: 0.9440 - val_precision_45: 0.0374 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.8429 - precision_45: 0.3378 - val_loss: 0.4044 - val_accuracy: 0.8568 - val_precision_45: 0.0735 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.8377 - precision_45: 0.3206 - val_loss: 0.2481 - val_accuracy: 0.9464 - val_precision_45: 0.0324 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8453 - precision_45: 0.3507 - val_loss: 0.3146 - val_accuracy: 0.9097 - val_precision_45: 0.0808 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.8400 - precision_45: 0.3246 - val_loss: 0.7896 - val_accuracy: 0.6864 - val_precision_45: 0.0673 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.8405 - precision_45: 0.3220 - val_loss: 0.3799 - val_accuracy: 0.8330 - val_precision_45: 0.0288 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8510 - precision_45: 0.3795 - val_loss: 0.2140 - val_accuracy: 0.9602 - val_precision_45: 0.1057 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8525 - precision_45: 0.3989 - val_loss: 0.3943 - val_accuracy: 0.8596 - val_precision_45: 0.0527 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8515 - precision_45: 0.3868 - val_loss: 0.3575 - val_accuracy: 0.8894 - val_precision_45: 0.0328 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8489 - precision_45: 0.3689 - val_loss: 0.4451 - val_accuracy: 0.7960 - val_precision_45: 0.0300 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.6759 - accuracy: 0.8153 - precision_45: 0.2476 - val_loss: 0.8565 - val_accuracy: 0.7945 - val_precision_45: 0.0441 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.3668 - accuracy: 0.8098 - precision_45: 0.2063 - val_loss: 0.2770 - val_accuracy: 0.9396 - val_precision_45: 0.0985 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.8352 - precision_45: 0.2501 - val_loss: 0.2595 - val_accuracy: 0.9641 - val_precision_45: 0.0217 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4352 - accuracy: 0.8523 - precision_45: 0.3409 - val_loss: 0.3350 - val_accuracy: 0.9311 - val_precision_45: 0.1394 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8521 - precision_45: 0.3442 - val_loss: 0.2523 - val_accuracy: 0.9609 - val_precision_45: 0.1000 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8589 - precision_45: 0.4505 - val_loss: 0.2520 - val_accuracy: 0.9504 - val_precision_45: 0.0733 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8609 - precision_45: 0.5072 - val_loss: 0.2823 - val_accuracy: 0.9373 - val_precision_45: 0.0536 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8597 - precision_45: 0.4765 - val_loss: 0.2247 - val_accuracy: 0.9587 - val_precision_45: 0.0462 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.8592 - precision_45: 0.4618 - val_loss: 0.4530 - val_accuracy: 0.7998 - val_precision_45: 0.0784 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 7ms/step - loss: 414.3037 - accuracy: 0.7352 - precision_46: 0.1516 - val_loss: 38.1388 - val_accuracy: 0.6616 - val_precision_46: 0.0530 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 85.7742 - accuracy: 0.7689 - precision_46: 0.1707 - val_loss: 40.3820 - val_accuracy: 0.9622 - val_precision_46: 0.0161 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 66.3021 - accuracy: 0.7779 - precision_46: 0.1828 - val_loss: 23.0018 - val_accuracy: 0.9420 - val_precision_46: 0.0115 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 65.0512 - accuracy: 0.7800 - precision_46: 0.1920 - val_loss: 27.6571 - val_accuracy: 0.9506 - val_precision_46: 0.0175 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 53.5942 - accuracy: 0.7862 - precision_46: 0.1988 - val_loss: 27.1895 - val_accuracy: 0.6415 - val_precision_46: 0.0190 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 58.2429 - accuracy: 0.7813 - precision_46: 0.2005 - val_loss: 54.1862 - val_accuracy: 0.5779 - val_precision_46: 0.0477 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 45.2991 - accuracy: 0.7903 - precision_46: 0.2204 - val_loss: 24.5144 - val_accuracy: 0.7007 - val_precision_46: 0.0500 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 45.0395 - accuracy: 0.7863 - precision_46: 0.2136 - val_loss: 37.2155 - val_accuracy: 0.8671 - val_precision_46: 0.0154 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 38.8347 - accuracy: 0.7851 - precision_46: 0.2087 - val_loss: 40.1840 - val_accuracy: 0.8618 - val_precision_46: 0.0230 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 45.1356 - accuracy: 0.7900 - precision_46: 0.2228 - val_loss: 19.2590 - val_accuracy: 0.8782 - val_precision_46: 0.0233 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 37.9645 - accuracy: 0.7897 - precision_46: 0.2208 - val_loss: 17.6694 - val_accuracy: 0.9206 - val_precision_46: 0.0062 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 48.4899 - accuracy: 0.7905 - precision_46: 0.2152 - val_loss: 22.0695 - val_accuracy: 0.5525 - val_precision_46: 0.0389 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 34.8176 - accuracy: 0.7905 - precision_46: 0.2156 - val_loss: 7.7656 - val_accuracy: 0.8270 - val_precision_46: 0.0268 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 31.0105 - accuracy: 0.7975 - precision_46: 0.2310 - val_loss: 19.2488 - val_accuracy: 0.8107 - val_precision_46: 0.0263 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 32.0623 - accuracy: 0.7942 - precision_46: 0.2258 - val_loss: 25.0794 - val_accuracy: 0.9498 - val_precision_46: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 28.2969 - accuracy: 0.7964 - precision_46: 0.2292 - val_loss: 8.8775 - val_accuracy: 0.8067 - val_precision_46: 0.0280 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 40.8132 - accuracy: 0.7919 - precision_46: 0.2138 - val_loss: 31.8736 - val_accuracy: 0.7456 - val_precision_46: 0.0257 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 33.5839 - accuracy: 0.7919 - precision_46: 0.2184 - val_loss: 27.1968 - val_accuracy: 0.6074 - val_precision_46: 0.0553 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 23.4730 - accuracy: 0.7980 - precision_46: 0.2199 - val_loss: 8.0443 - val_accuracy: 0.9110 - val_precision_46: 0.0175 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 19.2552 - accuracy: 0.7984 - precision_46: 0.2255 - val_loss: 23.7681 - val_accuracy: 0.9169 - val_precision_46: 0.0168 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 19.7298 - accuracy: 0.8007 - precision_46: 0.2250 - val_loss: 21.2940 - val_accuracy: 0.6135 - val_precision_46: 0.0524 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 24.7874 - accuracy: 0.7950 - precision_46: 0.2170 - val_loss: 10.0018 - val_accuracy: 0.9215 - val_precision_46: 0.0140 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 17.0393 - accuracy: 0.7971 - precision_46: 0.2192 - val_loss: 6.9641 - val_accuracy: 0.8175 - val_precision_46: 0.0208 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 14.3565 - accuracy: 0.8045 - precision_46: 0.2324 - val_loss: 11.6116 - val_accuracy: 0.9177 - val_precision_46: 0.0087 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 14.6926 - accuracy: 0.8050 - precision_46: 0.2330 - val_loss: 5.9762 - val_accuracy: 0.8256 - val_precision_46: 0.0248 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 13.9102 - accuracy: 0.8016 - precision_46: 0.2196 - val_loss: 15.9387 - val_accuracy: 0.9559 - val_precision_46: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.6450 - accuracy: 0.8015 - precision_46: 0.2268 - val_loss: 6.0055 - val_accuracy: 0.8360 - val_precision_46: 0.0276 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.9148 - accuracy: 0.8080 - precision_46: 0.2383 - val_loss: 9.1360 - val_accuracy: 0.7171 - val_precision_46: 0.0321 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.3878 - accuracy: 0.8055 - precision_46: 0.2326 - val_loss: 4.0430 - val_accuracy: 0.8648 - val_precision_46: 0.0242 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.4876 - accuracy: 0.8031 - precision_46: 0.2326 - val_loss: 19.2351 - val_accuracy: 0.5877 - val_precision_46: 0.0471 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 13.7375 - accuracy: 0.8023 - precision_46: 0.2272 - val_loss: 8.4919 - val_accuracy: 0.9159 - val_precision_46: 0.0295 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.7075 - accuracy: 0.8069 - precision_46: 0.2306 - val_loss: 2.9882 - val_accuracy: 0.8590 - val_precision_46: 0.0284 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.8602 - accuracy: 0.8053 - precision_46: 0.2286 - val_loss: 3.4170 - val_accuracy: 0.9020 - val_precision_46: 0.0214 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.0197 - accuracy: 0.8101 - precision_46: 0.2367 - val_loss: 5.7241 - val_accuracy: 0.6817 - val_precision_46: 0.0502 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.0078 - accuracy: 0.8052 - precision_46: 0.2371 - val_loss: 3.7301 - val_accuracy: 0.8329 - val_precision_46: 0.0322 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.6836 - accuracy: 0.8059 - precision_46: 0.2316 - val_loss: 4.3733 - val_accuracy: 0.9127 - val_precision_46: 0.0230 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.5535 - accuracy: 0.8023 - precision_46: 0.2221 - val_loss: 14.2983 - val_accuracy: 0.5834 - val_precision_46: 0.0503 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.1380 - accuracy: 0.8083 - precision_46: 0.2362 - val_loss: 3.7417 - val_accuracy: 0.7513 - val_precision_46: 0.0293 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.6324 - accuracy: 0.8024 - precision_46: 0.2281 - val_loss: 5.7898 - val_accuracy: 0.8857 - val_precision_46: 0.0164 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.9684 - accuracy: 0.8085 - precision_46: 0.2281 - val_loss: 3.1970 - val_accuracy: 0.9110 - val_precision_46: 0.0026 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.6225 - accuracy: 0.8105 - precision_46: 0.2353 - val_loss: 1.9443 - val_accuracy: 0.8675 - val_precision_46: 0.0182 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.1800 - accuracy: 0.8055 - precision_46: 0.2345 - val_loss: 3.8802 - val_accuracy: 0.9187 - val_precision_46: 0.0060 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.5261 - accuracy: 0.8112 - precision_46: 0.2343 - val_loss: 25.2031 - val_accuracy: 0.5240 - val_precision_46: 0.0499 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 9.6699 - accuracy: 0.8064 - precision_46: 0.2271 - val_loss: 2.3028 - val_accuracy: 0.8501 - val_precision_46: 0.0156 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.7965 - accuracy: 0.8084 - precision_46: 0.2250 - val_loss: 6.5492 - val_accuracy: 0.5376 - val_precision_46: 0.0500 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 8.6260 - accuracy: 0.8076 - precision_46: 0.2340 - val_loss: 7.2346 - val_accuracy: 0.9118 - val_precision_46: 0.0165 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.2755 - accuracy: 0.8097 - precision_46: 0.2415 - val_loss: 4.4353 - val_accuracy: 0.6429 - val_precision_46: 0.0561 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.3085 - accuracy: 0.8099 - precision_46: 0.2334 - val_loss: 2.4533 - val_accuracy: 0.7236 - val_precision_46: 0.0373 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.1569 - accuracy: 0.8072 - precision_46: 0.2269 - val_loss: 11.7633 - val_accuracy: 0.4721 - val_precision_46: 0.0476 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 6.1193 - accuracy: 0.8049 - precision_46: 0.2327 - val_loss: 2.0759 - val_accuracy: 0.7592 - val_precision_46: 0.0553 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.2901 - accuracy: 0.8137 - precision_46: 0.2504 - val_loss: 1.8431 - val_accuracy: 0.9089 - val_precision_46: 0.0074 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.5802 - accuracy: 0.8114 - precision_46: 0.2422 - val_loss: 1.4049 - val_accuracy: 0.8987 - val_precision_46: 0.0124 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.8498 - accuracy: 0.8138 - precision_46: 0.2488 - val_loss: 1.7082 - val_accuracy: 0.9040 - val_precision_46: 0.0112 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 4.6003 - accuracy: 0.8061 - precision_46: 0.2225 - val_loss: 5.1176 - val_accuracy: 0.9475 - val_precision_46: 0.0037 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.2925 - accuracy: 0.8104 - precision_46: 0.2401 - val_loss: 1.2654 - val_accuracy: 0.8579 - val_precision_46: 0.0269 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.5081 - accuracy: 0.8131 - precision_46: 0.2422 - val_loss: 1.0485 - val_accuracy: 0.8449 - val_precision_46: 0.0253 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.9479 - accuracy: 0.8145 - precision_46: 0.2464 - val_loss: 1.0724 - val_accuracy: 0.8017 - val_precision_46: 0.0265 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.1849 - accuracy: 0.8128 - precision_46: 0.2477 - val_loss: 1.6449 - val_accuracy: 0.9180 - val_precision_46: 0.0073 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.3007 - accuracy: 0.8152 - precision_46: 0.2534 - val_loss: 1.5376 - val_accuracy: 0.8561 - val_precision_46: 0.0194 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.5233 - accuracy: 0.8142 - precision_46: 0.2466 - val_loss: 1.0202 - val_accuracy: 0.7693 - val_precision_46: 0.0159 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.1427 - accuracy: 0.8109 - precision_46: 0.2476 - val_loss: 1.1955 - val_accuracy: 0.9169 - val_precision_46: 0.0113 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.9411 - accuracy: 0.8142 - precision_46: 0.2422 - val_loss: 1.3170 - val_accuracy: 0.9244 - val_precision_46: 0.0149 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.7446 - accuracy: 0.8150 - precision_46: 0.2434 - val_loss: 0.9455 - val_accuracy: 0.9408 - val_precision_46: 0.0055 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.3884 - accuracy: 0.8181 - precision_46: 0.2578 - val_loss: 0.5897 - val_accuracy: 0.8986 - val_precision_46: 0.0164 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.0277 - accuracy: 0.8148 - precision_46: 0.2515 - val_loss: 1.0855 - val_accuracy: 0.9328 - val_precision_46: 0.0063 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1387 - accuracy: 0.8238 - precision_46: 0.2817 - val_loss: 0.6686 - val_accuracy: 0.7211 - val_precision_46: 0.0324 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.4194 - accuracy: 0.8189 - precision_46: 0.2639 - val_loss: 0.7874 - val_accuracy: 0.9355 - val_precision_46: 0.0243 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.0224 - accuracy: 0.8247 - precision_46: 0.2786 - val_loss: 0.6652 - val_accuracy: 0.7532 - val_precision_46: 0.0626 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0514 - accuracy: 0.8224 - precision_46: 0.2670 - val_loss: 0.4965 - val_accuracy: 0.8581 - val_precision_46: 0.0311 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.8399 - accuracy: 0.8259 - precision_46: 0.2737 - val_loss: 0.4890 - val_accuracy: 0.9112 - val_precision_46: 0.0200 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.8736 - accuracy: 0.8244 - precision_46: 0.2753 - val_loss: 0.4919 - val_accuracy: 0.9006 - val_precision_46: 0.0128 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6653 - accuracy: 0.8318 - precision_46: 0.2980 - val_loss: 0.3193 - val_accuracy: 0.9237 - val_precision_46: 0.0099 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.8371 - accuracy: 0.8270 - precision_46: 0.2846 - val_loss: 0.4773 - val_accuracy: 0.9345 - val_precision_46: 0.0110 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7890 - accuracy: 0.8251 - precision_46: 0.2687 - val_loss: 1.1486 - val_accuracy: 0.6785 - val_precision_46: 0.0620 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6857 - accuracy: 0.8285 - precision_46: 0.2779 - val_loss: 0.4429 - val_accuracy: 0.8392 - val_precision_46: 0.0415 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.8330 - precision_46: 0.2921 - val_loss: 0.3350 - val_accuracy: 0.9442 - val_precision_46: 0.0126 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.8416 - precision_46: 0.3152 - val_loss: 0.4484 - val_accuracy: 0.8144 - val_precision_46: 0.0741 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.8392 - precision_46: 0.3074 - val_loss: 0.3773 - val_accuracy: 0.9131 - val_precision_46: 0.0386 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.8376 - precision_46: 0.3006 - val_loss: 0.3303 - val_accuracy: 0.9501 - val_precision_46: 0.0043 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.8375 - precision_46: 0.2959 - val_loss: 0.4208 - val_accuracy: 0.9303 - val_precision_46: 0.0172 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5356 - accuracy: 0.8376 - precision_46: 0.2991 - val_loss: 0.2941 - val_accuracy: 0.9202 - val_precision_46: 0.0265 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.8434 - precision_46: 0.3198 - val_loss: 0.3245 - val_accuracy: 0.9025 - val_precision_46: 0.0306 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8525 - precision_46: 0.3805 - val_loss: 0.2868 - val_accuracy: 0.9167 - val_precision_46: 0.0273 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4229 - accuracy: 0.8501 - precision_46: 0.3633 - val_loss: 0.2951 - val_accuracy: 0.9126 - val_precision_46: 0.0324 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8467 - precision_46: 0.3424 - val_loss: 0.3645 - val_accuracy: 0.8840 - val_precision_46: 0.0592 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5513 - accuracy: 0.8378 - precision_46: 0.3041 - val_loss: 0.2601 - val_accuracy: 0.9426 - val_precision_46: 0.0654 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4534 - accuracy: 0.8468 - precision_46: 0.3367 - val_loss: 0.3322 - val_accuracy: 0.9036 - val_precision_46: 0.0187 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5453 - accuracy: 0.8401 - precision_46: 0.3102 - val_loss: 0.5439 - val_accuracy: 0.7346 - val_precision_46: 0.0720 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7130 - accuracy: 0.8302 - precision_46: 0.2670 - val_loss: 0.3966 - val_accuracy: 0.8968 - val_precision_46: 0.0292 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.8398 - precision_46: 0.2973 - val_loss: 0.2662 - val_accuracy: 0.9375 - val_precision_46: 0.0472 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8535 - precision_46: 0.3936 - val_loss: 0.4787 - val_accuracy: 0.8034 - val_precision_46: 0.0904 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.7132 - accuracy: 0.8251 - precision_46: 0.2588 - val_loss: 1.1865 - val_accuracy: 0.8733 - val_precision_46: 0.0277 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9472 - accuracy: 0.8311 - precision_46: 0.2705 - val_loss: 0.4343 - val_accuracy: 0.8293 - val_precision_46: 0.0856 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.8376 - precision_46: 0.2991 - val_loss: 0.4125 - val_accuracy: 0.8817 - val_precision_46: 0.0420 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.8538 - precision_46: 0.3932 - val_loss: 0.3524 - val_accuracy: 0.8769 - val_precision_46: 0.0252 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4229 - accuracy: 0.8516 - precision_46: 0.3687 - val_loss: 0.3329 - val_accuracy: 0.8830 - val_precision_46: 0.0191 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.0779 - accuracy: 0.8444 - precision_46: 0.3247 - val_loss: 3.2546 - val_accuracy: 0.9305 - val_precision_46: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 37.2929 - accuracy: 0.7954 - precision_46: 0.1878 - val_loss: 0.4617 - val_accuracy: 0.9534 - val_precision_46: 0.0404 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.0901 - accuracy: 0.8206 - precision_46: 0.2330 - val_loss: 0.5309 - val_accuracy: 0.9373 - val_precision_46: 0.0548 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.8307 - precision_46: 0.2533 - val_loss: 0.5234 - val_accuracy: 0.9266 - val_precision_46: 0.0305 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 3s 6ms/step - loss: 248.4238 - accuracy: 0.7540 - precision_47: 0.1585 - val_loss: 48.2322 - val_accuracy: 0.9501 - val_precision_47: 0.0174 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 82.6467 - accuracy: 0.7783 - precision_47: 0.1858 - val_loss: 18.8489 - val_accuracy: 0.6958 - val_precision_47: 0.0241 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 76.5027 - accuracy: 0.7729 - precision_47: 0.1779 - val_loss: 25.2631 - val_accuracy: 0.9538 - val_precision_47: 0.0170 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 71.8681 - accuracy: 0.7824 - precision_47: 0.1931 - val_loss: 211.2842 - val_accuracy: 0.4771 - val_precision_47: 0.0490 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 96.3929 - accuracy: 0.7768 - precision_47: 0.1842 - val_loss: 42.3478 - val_accuracy: 0.7752 - val_precision_47: 0.0196 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 49.7746 - accuracy: 0.7887 - precision_47: 0.2121 - val_loss: 19.6184 - val_accuracy: 0.9482 - val_precision_47: 0.0156 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 65.3215 - accuracy: 0.7883 - precision_47: 0.2019 - val_loss: 23.2370 - val_accuracy: 0.7673 - val_precision_47: 0.0507 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 50.9756 - accuracy: 0.7892 - precision_47: 0.2112 - val_loss: 26.6214 - val_accuracy: 0.9269 - val_precision_47: 0.0090 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 77.9088 - accuracy: 0.7887 - precision_47: 0.2067 - val_loss: 19.6641 - val_accuracy: 0.7186 - val_precision_47: 0.0551 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 37.2041 - accuracy: 0.7950 - precision_47: 0.2211 - val_loss: 12.1335 - val_accuracy: 0.8782 - val_precision_47: 0.0227 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 56.5779 - accuracy: 0.7909 - precision_47: 0.2023 - val_loss: 23.1313 - val_accuracy: 0.8031 - val_precision_47: 0.0303 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 35.5297 - accuracy: 0.7902 - precision_47: 0.2033 - val_loss: 38.7587 - val_accuracy: 0.9296 - val_precision_47: 0.0134 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 31.0631 - accuracy: 0.7980 - precision_47: 0.2162 - val_loss: 9.9625 - val_accuracy: 0.8417 - val_precision_47: 0.0200 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 32.1383 - accuracy: 0.7937 - precision_47: 0.2151 - val_loss: 8.7142 - val_accuracy: 0.8564 - val_precision_47: 0.0249 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 28.4721 - accuracy: 0.8005 - precision_47: 0.2200 - val_loss: 14.4593 - val_accuracy: 0.7220 - val_precision_47: 0.0406 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 24.2681 - accuracy: 0.8019 - precision_47: 0.2233 - val_loss: 11.6790 - val_accuracy: 0.7091 - val_precision_47: 0.0435 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 29.5310 - accuracy: 0.7995 - precision_47: 0.2171 - val_loss: 9.4801 - val_accuracy: 0.8118 - val_precision_47: 0.0257 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 25.2295 - accuracy: 0.8010 - precision_47: 0.2211 - val_loss: 85.7019 - val_accuracy: 0.5194 - val_precision_47: 0.0509 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 26.4342 - accuracy: 0.8007 - precision_47: 0.2218 - val_loss: 19.1444 - val_accuracy: 0.8364 - val_precision_47: 0.0360 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 26.9936 - accuracy: 0.8012 - precision_47: 0.2194 - val_loss: 7.8261 - val_accuracy: 0.8784 - val_precision_47: 0.0515 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 19.6266 - accuracy: 0.8018 - precision_47: 0.2183 - val_loss: 7.4952 - val_accuracy: 0.8854 - val_precision_47: 0.0139 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 23.7415 - accuracy: 0.8011 - precision_47: 0.2187 - val_loss: 12.3314 - val_accuracy: 0.9147 - val_precision_47: 0.0042 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 23.1697 - accuracy: 0.8023 - precision_47: 0.2196 - val_loss: 3.5010 - val_accuracy: 0.8941 - val_precision_47: 0.0404 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 20.7945 - accuracy: 0.8036 - precision_47: 0.2187 - val_loss: 44.3286 - val_accuracy: 0.6156 - val_precision_47: 0.0543 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 17.4053 - accuracy: 0.8051 - precision_47: 0.2268 - val_loss: 15.3123 - val_accuracy: 0.9509 - val_precision_47: 0.0047 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 18.2613 - accuracy: 0.8017 - precision_47: 0.2091 - val_loss: 22.3952 - val_accuracy: 0.9456 - val_precision_47: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 23.3535 - accuracy: 0.8010 - precision_47: 0.2188 - val_loss: 4.7433 - val_accuracy: 0.9112 - val_precision_47: 0.0284 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 15.3701 - accuracy: 0.8069 - precision_47: 0.2349 - val_loss: 8.5420 - val_accuracy: 0.6680 - val_precision_47: 0.0418 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 20.8551 - accuracy: 0.8045 - precision_47: 0.2222 - val_loss: 19.1240 - val_accuracy: 0.6688 - val_precision_47: 0.0606 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 19.9858 - accuracy: 0.8034 - precision_47: 0.2211 - val_loss: 9.4673 - val_accuracy: 0.9066 - val_precision_47: 0.0253 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 14.7289 - accuracy: 0.8065 - precision_47: 0.2291 - val_loss: 22.4590 - val_accuracy: 0.6263 - val_precision_47: 0.0601 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.7217 - accuracy: 0.8060 - precision_47: 0.2300 - val_loss: 7.2547 - val_accuracy: 0.9372 - val_precision_47: 0.0074 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 13.3744 - accuracy: 0.8072 - precision_47: 0.2384 - val_loss: 9.7057 - val_accuracy: 0.9211 - val_precision_47: 0.0301 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 11.4164 - accuracy: 0.8070 - precision_47: 0.2409 - val_loss: 7.1186 - val_accuracy: 0.8736 - val_precision_47: 0.0307 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 15.7821 - accuracy: 0.8038 - precision_47: 0.2268 - val_loss: 4.2227 - val_accuracy: 0.6809 - val_precision_47: 0.0487 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.2014 - accuracy: 0.8079 - precision_47: 0.2422 - val_loss: 2.8953 - val_accuracy: 0.8005 - val_precision_47: 0.0433 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 9.8439 - accuracy: 0.8079 - precision_47: 0.2438 - val_loss: 4.3152 - val_accuracy: 0.8469 - val_precision_47: 0.0258 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 8.9010 - accuracy: 0.8099 - precision_47: 0.2434 - val_loss: 3.3660 - val_accuracy: 0.8396 - val_precision_47: 0.0238 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 9.9406 - accuracy: 0.8097 - precision_47: 0.2478 - val_loss: 17.6711 - val_accuracy: 0.6127 - val_precision_47: 0.0578 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 9.9446 - accuracy: 0.8066 - precision_47: 0.2405 - val_loss: 6.3456 - val_accuracy: 0.8941 - val_precision_47: 0.0265 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 7.2779 - accuracy: 0.8120 - precision_47: 0.2551 - val_loss: 3.1155 - val_accuracy: 0.8531 - val_precision_47: 0.0172 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 9.5100 - accuracy: 0.8091 - precision_47: 0.2397 - val_loss: 5.8592 - val_accuracy: 0.9068 - val_precision_47: 0.0297 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.3334 - accuracy: 0.8083 - precision_47: 0.2407 - val_loss: 3.1891 - val_accuracy: 0.8457 - val_precision_47: 0.0217 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 6.3379 - accuracy: 0.8124 - precision_47: 0.2508 - val_loss: 5.9388 - val_accuracy: 0.6883 - val_precision_47: 0.0623 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 11.1636 - accuracy: 0.8050 - precision_47: 0.2321 - val_loss: 5.5014 - val_accuracy: 0.9386 - val_precision_47: 0.0177 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.2668 - accuracy: 0.8054 - precision_47: 0.2270 - val_loss: 2.2199 - val_accuracy: 0.8750 - val_precision_47: 0.0219 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.6806 - accuracy: 0.8098 - precision_47: 0.2338 - val_loss: 4.4417 - val_accuracy: 0.8674 - val_precision_47: 0.0295 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.7934 - accuracy: 0.8035 - precision_47: 0.2281 - val_loss: 3.0438 - val_accuracy: 0.9187 - val_precision_47: 0.0133 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.3588 - accuracy: 0.8116 - precision_47: 0.2437 - val_loss: 1.6905 - val_accuracy: 0.7876 - val_precision_47: 0.0281 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 7.8322 - accuracy: 0.8080 - precision_47: 0.2352 - val_loss: 2.3279 - val_accuracy: 0.8219 - val_precision_47: 0.0215 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.9925 - accuracy: 0.8084 - precision_47: 0.2328 - val_loss: 3.5499 - val_accuracy: 0.8806 - val_precision_47: 0.0217 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.8898 - accuracy: 0.8112 - precision_47: 0.2460 - val_loss: 3.5028 - val_accuracy: 0.8898 - val_precision_47: 0.0259 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.6760 - accuracy: 0.8140 - precision_47: 0.2537 - val_loss: 3.2415 - val_accuracy: 0.6179 - val_precision_47: 0.0441 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.5606 - accuracy: 0.8130 - precision_47: 0.2466 - val_loss: 3.5080 - val_accuracy: 0.6432 - val_precision_47: 0.0581 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.0243 - accuracy: 0.8118 - precision_47: 0.2451 - val_loss: 1.3280 - val_accuracy: 0.8754 - val_precision_47: 0.0176 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.9638 - accuracy: 0.8147 - precision_47: 0.2574 - val_loss: 2.2955 - val_accuracy: 0.7083 - val_precision_47: 0.0538 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.0245 - accuracy: 0.8112 - precision_47: 0.2391 - val_loss: 1.5527 - val_accuracy: 0.8039 - val_precision_47: 0.0281 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.3466 - accuracy: 0.8124 - precision_47: 0.2459 - val_loss: 1.1181 - val_accuracy: 0.8777 - val_precision_47: 0.0291 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.4457 - accuracy: 0.8124 - precision_47: 0.2450 - val_loss: 1.2436 - val_accuracy: 0.9153 - val_precision_47: 0.0281 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.5805 - accuracy: 0.8144 - precision_47: 0.2495 - val_loss: 1.0928 - val_accuracy: 0.8897 - val_precision_47: 0.0234 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.3946 - accuracy: 0.8147 - precision_47: 0.2514 - val_loss: 4.9771 - val_accuracy: 0.5196 - val_precision_47: 0.0527 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.9179 - accuracy: 0.8161 - precision_47: 0.2565 - val_loss: 0.8824 - val_accuracy: 0.8497 - val_precision_47: 0.0388 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.4810 - accuracy: 0.8177 - precision_47: 0.2592 - val_loss: 4.0253 - val_accuracy: 0.5912 - val_precision_47: 0.0567 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.6267 - accuracy: 0.8168 - precision_47: 0.2578 - val_loss: 0.9567 - val_accuracy: 0.8933 - val_precision_47: 0.0289 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.4979 - accuracy: 0.8150 - precision_47: 0.2483 - val_loss: 1.1828 - val_accuracy: 0.9199 - val_precision_47: 0.0223 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.3098 - accuracy: 0.8170 - precision_47: 0.2530 - val_loss: 0.6740 - val_accuracy: 0.9143 - val_precision_47: 0.0349 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.3020 - accuracy: 0.8189 - precision_47: 0.2588 - val_loss: 1.3734 - val_accuracy: 0.6594 - val_precision_47: 0.0654 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2417 - accuracy: 0.8159 - precision_47: 0.2447 - val_loss: 1.6889 - val_accuracy: 0.6924 - val_precision_47: 0.0611 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0019 - accuracy: 0.8207 - precision_47: 0.2587 - val_loss: 0.4901 - val_accuracy: 0.8625 - val_precision_47: 0.0396 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.1346 - accuracy: 0.8216 - precision_47: 0.2617 - val_loss: 0.4553 - val_accuracy: 0.9205 - val_precision_47: 0.0197 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.8225 - accuracy: 0.8239 - precision_47: 0.2662 - val_loss: 0.6818 - val_accuracy: 0.9269 - val_precision_47: 0.0294 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.9516 - accuracy: 0.8249 - precision_47: 0.2719 - val_loss: 0.5679 - val_accuracy: 0.9335 - val_precision_47: 0.0387 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.8272 - precision_47: 0.2746 - val_loss: 0.5246 - val_accuracy: 0.9343 - val_precision_47: 0.0298 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7960 - accuracy: 0.8239 - precision_47: 0.2604 - val_loss: 0.4791 - val_accuracy: 0.9099 - val_precision_47: 0.0185 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7387 - accuracy: 0.8280 - precision_47: 0.2664 - val_loss: 0.4135 - val_accuracy: 0.9470 - val_precision_47: 0.0767 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.8273 - precision_47: 0.2693 - val_loss: 0.3875 - val_accuracy: 0.8854 - val_precision_47: 0.0541 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.9069 - accuracy: 0.8149 - precision_47: 0.2429 - val_loss: 0.3761 - val_accuracy: 0.8906 - val_precision_47: 0.0346 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.6444 - accuracy: 0.8326 - precision_47: 0.2950 - val_loss: 0.6040 - val_accuracy: 0.7315 - val_precision_47: 0.0755 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.8320 - precision_47: 0.2762 - val_loss: 0.4174 - val_accuracy: 0.8195 - val_precision_47: 0.0848 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8513 - precision_47: 0.3685 - val_loss: 0.2652 - val_accuracy: 0.9389 - val_precision_47: 0.0323 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.8378 - precision_47: 0.3022 - val_loss: 0.4353 - val_accuracy: 0.8162 - val_precision_47: 0.0952 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5467 - accuracy: 0.8346 - precision_47: 0.2810 - val_loss: 0.2975 - val_accuracy: 0.9232 - val_precision_47: 0.0443 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.8475 - precision_47: 0.3462 - val_loss: 0.3230 - val_accuracy: 0.9079 - val_precision_47: 0.0570 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4231 - accuracy: 0.8528 - precision_47: 0.3883 - val_loss: 0.2986 - val_accuracy: 0.9183 - val_precision_47: 0.0654 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4426 - accuracy: 0.8501 - precision_47: 0.3732 - val_loss: 0.2516 - val_accuracy: 0.9416 - val_precision_47: 0.0278 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4327 - accuracy: 0.8538 - precision_47: 0.3962 - val_loss: 0.2924 - val_accuracy: 0.9205 - val_precision_47: 0.0549 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.8435 - precision_47: 0.3261 - val_loss: 0.3346 - val_accuracy: 0.9110 - val_precision_47: 0.0295 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.8458 - precision_47: 0.3395 - val_loss: 0.2524 - val_accuracy: 0.9425 - val_precision_47: 0.0090 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 21.2266 - accuracy: 0.8156 - precision_47: 0.2421 - val_loss: 4.0411 - val_accuracy: 0.8820 - val_precision_47: 0.0092 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 9.8143 - accuracy: 0.8024 - precision_47: 0.1839 - val_loss: 7.9041 - val_accuracy: 0.8795 - val_precision_47: 0.0412 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.0748 - accuracy: 0.8172 - precision_47: 0.2263 - val_loss: 0.3609 - val_accuracy: 0.9208 - val_precision_47: 0.0382 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6880 - accuracy: 0.8313 - precision_47: 0.2622 - val_loss: 0.2902 - val_accuracy: 0.9170 - val_precision_47: 0.0303 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5645 - accuracy: 0.8343 - precision_47: 0.2772 - val_loss: 0.3131 - val_accuracy: 0.9080 - val_precision_47: 0.0335 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8485 - precision_47: 0.3441 - val_loss: 0.3750 - val_accuracy: 0.8743 - val_precision_47: 0.1057 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8565 - precision_47: 0.4116 - val_loss: 0.3301 - val_accuracy: 0.8821 - val_precision_47: 0.0328 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4059 - accuracy: 0.8543 - precision_47: 0.3915 - val_loss: 0.3762 - val_accuracy: 0.8672 - val_precision_47: 0.0915 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8529 - precision_47: 0.3749 - val_loss: 0.2633 - val_accuracy: 0.9331 - val_precision_47: 0.0492 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3957 - accuracy: 0.8577 - precision_47: 0.4391 - val_loss: 0.2977 - val_accuracy: 0.9104 - val_precision_47: 0.0404 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3867 - accuracy: 0.8593 - precision_47: 0.4624 - val_loss: 0.3601 - val_accuracy: 0.8759 - val_precision_47: 0.0236 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8530 - precision_47: 0.3848 - val_loss: 0.3370 - val_accuracy: 0.8988 - val_precision_47: 0.0577 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Training on fold 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 6ms/step - loss: 235.7499 - accuracy: 0.7558 - precision_48: 0.1542 - val_loss: 77.0970 - val_accuracy: 0.9600 - val_precision_48: 0.0132 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 106.9346 - accuracy: 0.7778 - precision_48: 0.1840 - val_loss: 37.6444 - val_accuracy: 0.9570 - val_precision_48: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 130.8811 - accuracy: 0.7803 - precision_48: 0.1868 - val_loss: 175.3410 - val_accuracy: 0.3249 - val_precision_48: 0.0419 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 90.2661 - accuracy: 0.7764 - precision_48: 0.1887 - val_loss: 18.6088 - val_accuracy: 0.8181 - val_precision_48: 0.0233 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 85.7036 - accuracy: 0.7779 - precision_48: 0.1901 - val_loss: 43.6132 - val_accuracy: 0.9641 - val_precision_48: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 56.4079 - accuracy: 0.7845 - precision_48: 0.1990 - val_loss: 26.4172 - val_accuracy: 0.9276 - val_precision_48: 0.0354 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 52.3727 - accuracy: 0.7853 - precision_48: 0.2005 - val_loss: 31.1964 - val_accuracy: 0.8340 - val_precision_48: 0.0351 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 61.6671 - accuracy: 0.7824 - precision_48: 0.1981 - val_loss: 41.5128 - val_accuracy: 0.9461 - val_precision_48: 0.0180 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 69.7270 - accuracy: 0.7868 - precision_48: 0.2078 - val_loss: 71.2232 - val_accuracy: 0.9592 - val_precision_48: 0.0115 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 41.1338 - accuracy: 0.7910 - precision_48: 0.2112 - val_loss: 28.3834 - val_accuracy: 0.6255 - val_precision_48: 0.0492 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 38.1333 - accuracy: 0.7936 - precision_48: 0.2197 - val_loss: 15.2244 - val_accuracy: 0.8719 - val_precision_48: 0.0276 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 77.9148 - accuracy: 0.7846 - precision_48: 0.2007 - val_loss: 69.2568 - val_accuracy: 0.9600 - val_precision_48: 0.0253 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 33.1760 - accuracy: 0.7993 - precision_48: 0.2241 - val_loss: 8.1847 - val_accuracy: 0.8756 - val_precision_48: 0.0185 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 27.2971 - accuracy: 0.7980 - precision_48: 0.2173 - val_loss: 7.4668 - val_accuracy: 0.7630 - val_precision_48: 0.0502 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 28.0511 - accuracy: 0.7972 - precision_48: 0.2182 - val_loss: 8.2967 - val_accuracy: 0.7978 - val_precision_48: 0.0287 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 33.5489 - accuracy: 0.7962 - precision_48: 0.2146 - val_loss: 15.6543 - val_accuracy: 0.6568 - val_precision_48: 0.0416 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 31.8028 - accuracy: 0.7989 - precision_48: 0.2243 - val_loss: 14.6587 - val_accuracy: 0.6166 - val_precision_48: 0.0472 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 24.4020 - accuracy: 0.7980 - precision_48: 0.2161 - val_loss: 6.0509 - val_accuracy: 0.7617 - val_precision_48: 0.0320 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 29.1338 - accuracy: 0.7948 - precision_48: 0.2131 - val_loss: 15.7266 - val_accuracy: 0.6844 - val_precision_48: 0.0603 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 30.0805 - accuracy: 0.7980 - precision_48: 0.2150 - val_loss: 29.9308 - val_accuracy: 0.8133 - val_precision_48: 0.0273 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 19.8981 - accuracy: 0.7968 - precision_48: 0.2135 - val_loss: 10.3013 - val_accuracy: 0.8759 - val_precision_48: 0.0118 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.6583 - accuracy: 0.8000 - precision_48: 0.2243 - val_loss: 10.6509 - val_accuracy: 0.9074 - val_precision_48: 0.0168 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 17.6510 - accuracy: 0.8053 - precision_48: 0.2352 - val_loss: 7.7611 - val_accuracy: 0.8922 - val_precision_48: 0.0143 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.9172 - accuracy: 0.8010 - precision_48: 0.2214 - val_loss: 42.3324 - val_accuracy: 0.5080 - val_precision_48: 0.0499 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.4786 - accuracy: 0.8014 - precision_48: 0.2293 - val_loss: 7.6858 - val_accuracy: 0.8649 - val_precision_48: 0.0146 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.0702 - accuracy: 0.8020 - precision_48: 0.2300 - val_loss: 9.9467 - val_accuracy: 0.7865 - val_precision_48: 0.0219 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 14.2657 - accuracy: 0.8023 - precision_48: 0.2355 - val_loss: 4.2604 - val_accuracy: 0.9005 - val_precision_48: 0.0292 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 13.6713 - accuracy: 0.8029 - precision_48: 0.2291 - val_loss: 6.0186 - val_accuracy: 0.6875 - val_precision_48: 0.0432 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 12.5827 - accuracy: 0.8050 - precision_48: 0.2378 - val_loss: 7.4839 - val_accuracy: 0.6636 - val_precision_48: 0.0502 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 11.5985 - accuracy: 0.8014 - precision_48: 0.2292 - val_loss: 5.2517 - val_accuracy: 0.9099 - val_precision_48: 0.0064 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.5281 - accuracy: 0.8058 - precision_48: 0.2350 - val_loss: 6.1452 - val_accuracy: 0.8944 - val_precision_48: 0.0213 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.0213 - accuracy: 0.8047 - precision_48: 0.2338 - val_loss: 3.8736 - val_accuracy: 0.8560 - val_precision_48: 0.0208 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 11.4148 - accuracy: 0.8030 - precision_48: 0.2323 - val_loss: 4.6629 - val_accuracy: 0.9097 - val_precision_48: 0.0303 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.4616 - accuracy: 0.8084 - precision_48: 0.2493 - val_loss: 7.6647 - val_accuracy: 0.9321 - val_precision_48: 0.0453 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.0582 - accuracy: 0.8096 - precision_48: 0.2497 - val_loss: 2.0380 - val_accuracy: 0.8675 - val_precision_48: 0.0323 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.4125 - accuracy: 0.8095 - precision_48: 0.2536 - val_loss: 4.3117 - val_accuracy: 0.8798 - val_precision_48: 0.0232 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 6.8216 - accuracy: 0.8108 - precision_48: 0.2568 - val_loss: 2.0908 - val_accuracy: 0.8357 - val_precision_48: 0.0292 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 7.2600 - accuracy: 0.8105 - precision_48: 0.2534 - val_loss: 8.2646 - val_accuracy: 0.5917 - val_precision_48: 0.0450 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.4273 - accuracy: 0.8064 - precision_48: 0.2420 - val_loss: 2.5892 - val_accuracy: 0.9094 - val_precision_48: 0.0125 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.5668 - accuracy: 0.8119 - precision_48: 0.2594 - val_loss: 8.2062 - val_accuracy: 0.5788 - val_precision_48: 0.0561 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.8733 - accuracy: 0.8083 - precision_48: 0.2502 - val_loss: 1.8474 - val_accuracy: 0.8049 - val_precision_48: 0.0489 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.5807 - accuracy: 0.8128 - precision_48: 0.2631 - val_loss: 2.2023 - val_accuracy: 0.9201 - val_precision_48: 0.0198 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.6501 - accuracy: 0.8122 - precision_48: 0.2519 - val_loss: 2.7276 - val_accuracy: 0.8340 - val_precision_48: 0.0225 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.6985 - accuracy: 0.8089 - precision_48: 0.2532 - val_loss: 1.4756 - val_accuracy: 0.8613 - val_precision_48: 0.0365 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.1161 - accuracy: 0.8159 - precision_48: 0.2681 - val_loss: 1.2508 - val_accuracy: 0.8190 - val_precision_48: 0.0570 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.5853 - accuracy: 0.8161 - precision_48: 0.2722 - val_loss: 1.6442 - val_accuracy: 0.9004 - val_precision_48: 0.0301 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.4880 - accuracy: 0.8165 - precision_48: 0.2742 - val_loss: 1.1883 - val_accuracy: 0.8008 - val_precision_48: 0.0435 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 4.5587 - accuracy: 0.8124 - precision_48: 0.2592 - val_loss: 2.7805 - val_accuracy: 0.9250 - val_precision_48: 0.0423 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.3656 - accuracy: 0.8051 - precision_48: 0.2402 - val_loss: 1.0419 - val_accuracy: 0.8595 - val_precision_48: 0.0208 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.7923 - accuracy: 0.8150 - precision_48: 0.2583 - val_loss: 1.1596 - val_accuracy: 0.9069 - val_precision_48: 0.0354 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.7366 - accuracy: 0.8174 - precision_48: 0.2753 - val_loss: 1.1958 - val_accuracy: 0.9304 - val_precision_48: 0.0397 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.5642 - accuracy: 0.8186 - precision_48: 0.2754 - val_loss: 0.7599 - val_accuracy: 0.9225 - val_precision_48: 0.0329 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.3735 - accuracy: 0.8196 - precision_48: 0.2798 - val_loss: 1.7940 - val_accuracy: 0.9208 - val_precision_48: 0.0303 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.1024 - accuracy: 0.8215 - precision_48: 0.2729 - val_loss: 0.6058 - val_accuracy: 0.9038 - val_precision_48: 0.0158 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.8329 - accuracy: 0.8293 - precision_48: 0.3005 - val_loss: 0.3352 - val_accuracy: 0.9181 - val_precision_48: 0.0273 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7360 - accuracy: 0.8328 - precision_48: 0.3097 - val_loss: 0.4362 - val_accuracy: 0.8798 - val_precision_48: 0.0300 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7934 - accuracy: 0.8276 - precision_48: 0.2881 - val_loss: 0.4189 - val_accuracy: 0.8697 - val_precision_48: 0.0323 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7229 - accuracy: 0.8270 - precision_48: 0.2854 - val_loss: 0.3512 - val_accuracy: 0.9418 - val_precision_48: 0.0119 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.8419 - precision_48: 0.3349 - val_loss: 0.3762 - val_accuracy: 0.9063 - val_precision_48: 0.0276 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.8713 - accuracy: 0.8296 - precision_48: 0.2914 - val_loss: 0.7944 - val_accuracy: 0.6852 - val_precision_48: 0.0640 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.8320 - precision_48: 0.2950 - val_loss: 0.7527 - val_accuracy: 0.8875 - val_precision_48: 0.0572 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.8858 - accuracy: 0.8142 - precision_48: 0.2492 - val_loss: 0.3931 - val_accuracy: 0.8976 - val_precision_48: 0.0522 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.5489 - accuracy: 0.8103 - precision_48: 0.2376 - val_loss: 1.0294 - val_accuracy: 0.9433 - val_precision_48: 0.0363 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.0683 - accuracy: 0.8224 - precision_48: 0.2689 - val_loss: 0.3597 - val_accuracy: 0.9245 - val_precision_48: 0.0298 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.6202 - accuracy: 0.8207 - precision_48: 0.2575 - val_loss: 0.4963 - val_accuracy: 0.9106 - val_precision_48: 0.0399 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.5734 - accuracy: 0.8100 - precision_48: 0.2453 - val_loss: 0.9378 - val_accuracy: 0.8963 - val_precision_48: 0.0366 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 7.0906 - accuracy: 0.8071 - precision_48: 0.2341 - val_loss: 1.0103 - val_accuracy: 0.8623 - val_precision_48: 0.0380 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1426 - accuracy: 0.8209 - precision_48: 0.2615 - val_loss: 0.6621 - val_accuracy: 0.8064 - val_precision_48: 0.0811 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.5160 - accuracy: 0.8426 - precision_48: 0.3221 - val_loss: 0.3126 - val_accuracy: 0.9267 - val_precision_48: 0.0378 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8554 - precision_48: 0.4158 - val_loss: 0.3301 - val_accuracy: 0.9189 - val_precision_48: 0.0386 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3989 - accuracy: 0.8600 - precision_48: 0.4747 - val_loss: 0.3221 - val_accuracy: 0.9143 - val_precision_48: 0.0202 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4449 - accuracy: 0.8511 - precision_48: 0.3822 - val_loss: 0.3437 - val_accuracy: 0.9145 - val_precision_48: 0.0403 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8585 - precision_48: 0.4552 - val_loss: 0.3381 - val_accuracy: 0.9332 - val_precision_48: 0.0066 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3956 - accuracy: 0.8596 - precision_48: 0.4698 - val_loss: 0.3184 - val_accuracy: 0.9121 - val_precision_48: 0.0465 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8636 - precision_48: 0.5412 - val_loss: 0.2892 - val_accuracy: 0.9176 - val_precision_48: 0.0501 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3792 - accuracy: 0.8636 - precision_48: 0.5391 - val_loss: 0.2743 - val_accuracy: 0.9236 - val_precision_48: 0.0276 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3774 - accuracy: 0.8644 - precision_48: 0.5518 - val_loss: 0.3732 - val_accuracy: 0.8855 - val_precision_48: 0.0390 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3718 - accuracy: 0.8641 - precision_48: 0.5509 - val_loss: 0.3040 - val_accuracy: 0.9084 - val_precision_48: 0.0251 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3709 - accuracy: 0.8642 - precision_48: 0.5516 - val_loss: 0.3073 - val_accuracy: 0.9006 - val_precision_48: 0.0312 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3717 - accuracy: 0.8642 - precision_48: 0.5491 - val_loss: 0.3328 - val_accuracy: 0.9054 - val_precision_48: 0.0251 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 9.4862 - accuracy: 0.8225 - precision_48: 0.2531 - val_loss: 0.3161 - val_accuracy: 0.9429 - val_precision_48: 0.0125 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8567 - precision_48: 0.3354 - val_loss: 0.2299 - val_accuracy: 0.9558 - val_precision_48: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8601 - precision_48: 0.4360 - val_loss: 0.2928 - val_accuracy: 0.9085 - val_precision_48: 0.0229 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8613 - precision_48: 0.4915 - val_loss: 0.2191 - val_accuracy: 0.9538 - val_precision_48: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8611 - precision_48: 0.4815 - val_loss: 0.2122 - val_accuracy: 0.9588 - val_precision_48: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8624 - precision_48: 0.5450 - val_loss: 0.3043 - val_accuracy: 0.9046 - val_precision_48: 0.0237 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8620 - precision_48: 0.5243 - val_loss: 0.2308 - val_accuracy: 0.9536 - val_precision_48: 0.0287 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8621 - precision_48: 0.5306 - val_loss: 0.2385 - val_accuracy: 0.9470 - val_precision_48: 0.0224 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8632 - precision_48: 0.5757 - val_loss: 0.3352 - val_accuracy: 0.8851 - val_precision_48: 0.0279 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8626 - precision_48: 0.5474 - val_loss: 0.2579 - val_accuracy: 0.9281 - val_precision_48: 0.0358 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8636 - precision_48: 0.5934 - val_loss: 0.2553 - val_accuracy: 0.9348 - val_precision_48: 0.0159 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8639 - precision_48: 0.6024 - val_loss: 0.2134 - val_accuracy: 0.9598 - val_precision_48: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8628 - precision_48: 0.5604 - val_loss: 0.2739 - val_accuracy: 0.9263 - val_precision_48: 0.0245 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8639 - precision_48: 0.6065 - val_loss: 0.2613 - val_accuracy: 0.9409 - val_precision_48: 0.0550 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8629 - precision_48: 0.5574 - val_loss: 0.2123 - val_accuracy: 0.9575 - val_precision_48: 0.0177 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8639 - precision_48: 0.5953 - val_loss: 0.2348 - val_accuracy: 0.9449 - val_precision_48: 0.0103 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8646 - precision_48: 0.6214 - val_loss: 0.2604 - val_accuracy: 0.9352 - val_precision_48: 0.0416 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.8646 - precision_48: 0.6300 - val_loss: 0.2427 - val_accuracy: 0.9497 - val_precision_48: 0.0420 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8636 - precision_48: 0.5787 - val_loss: 0.2686 - val_accuracy: 0.9319 - val_precision_48: 0.0322 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3621 - accuracy: 0.8641 - precision_48: 0.6065 - val_loss: 0.3097 - val_accuracy: 0.8990 - val_precision_48: 0.0399 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 7ms/step - loss: 98.1347 - accuracy: 0.7757 - precision_49: 0.1799 - val_loss: 20.2751 - val_accuracy: 0.9553 - val_precision_49: 0.0219 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 33.4860 - accuracy: 0.7861 - precision_49: 0.1939 - val_loss: 12.8384 - val_accuracy: 0.8005 - val_precision_49: 0.0346 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 35.7855 - accuracy: 0.7883 - precision_49: 0.1988 - val_loss: 12.0232 - val_accuracy: 0.9282 - val_precision_49: 0.0097 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 38.6794 - accuracy: 0.7955 - precision_49: 0.2136 - val_loss: 10.1734 - val_accuracy: 0.9361 - val_precision_49: 0.0284 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 24.7890 - accuracy: 0.7928 - precision_49: 0.2143 - val_loss: 6.9124 - val_accuracy: 0.9106 - val_precision_49: 0.0142 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 20.6076 - accuracy: 0.7985 - precision_49: 0.2234 - val_loss: 11.1939 - val_accuracy: 0.9091 - val_precision_49: 0.0222 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 32.7295 - accuracy: 0.7868 - precision_49: 0.2038 - val_loss: 42.3407 - val_accuracy: 0.9604 - val_precision_49: 0.0159 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 29.0128 - accuracy: 0.7928 - precision_49: 0.2150 - val_loss: 16.4762 - val_accuracy: 0.9367 - val_precision_49: 0.0125 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 19.4204 - accuracy: 0.7984 - precision_49: 0.2220 - val_loss: 17.3725 - val_accuracy: 0.5565 - val_precision_49: 0.0515 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 19.9432 - accuracy: 0.7978 - precision_49: 0.2198 - val_loss: 59.2116 - val_accuracy: 0.3930 - val_precision_49: 0.0473 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.4273 - accuracy: 0.7998 - precision_49: 0.2284 - val_loss: 4.2512 - val_accuracy: 0.8993 - val_precision_49: 0.0250 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.4923 - accuracy: 0.8013 - precision_49: 0.2332 - val_loss: 8.1837 - val_accuracy: 0.7260 - val_precision_49: 0.0278 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.9897 - accuracy: 0.7982 - precision_49: 0.2274 - val_loss: 8.9956 - val_accuracy: 0.9415 - val_precision_49: 0.0150 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 27.3110 - accuracy: 0.7993 - precision_49: 0.2254 - val_loss: 20.9973 - val_accuracy: 0.8145 - val_precision_49: 0.0343 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 14.3311 - accuracy: 0.8054 - precision_49: 0.2431 - val_loss: 6.7491 - val_accuracy: 0.9189 - val_precision_49: 0.0210 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 12.0303 - accuracy: 0.8045 - precision_49: 0.2395 - val_loss: 3.6137 - val_accuracy: 0.8821 - val_precision_49: 0.0240 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 17.1480 - accuracy: 0.8056 - precision_49: 0.2374 - val_loss: 4.9377 - val_accuracy: 0.8301 - val_precision_49: 0.0258 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 11.4489 - accuracy: 0.8041 - precision_49: 0.2343 - val_loss: 16.2335 - val_accuracy: 0.5893 - val_precision_49: 0.0533 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 14.2350 - accuracy: 0.8024 - precision_49: 0.2287 - val_loss: 4.7624 - val_accuracy: 0.7712 - val_precision_49: 0.0513 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.6418 - accuracy: 0.8017 - precision_49: 0.2349 - val_loss: 9.9303 - val_accuracy: 0.7905 - val_precision_49: 0.0295 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 19.6581 - accuracy: 0.8058 - precision_49: 0.2415 - val_loss: 14.2387 - val_accuracy: 0.8566 - val_precision_49: 0.0276 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 13.0153 - accuracy: 0.8034 - precision_49: 0.2310 - val_loss: 22.5466 - val_accuracy: 0.5150 - val_precision_49: 0.0513 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 12.4726 - accuracy: 0.8074 - precision_49: 0.2474 - val_loss: 2.6772 - val_accuracy: 0.9213 - val_precision_49: 0.0129 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.4576 - accuracy: 0.8065 - precision_49: 0.2398 - val_loss: 6.7547 - val_accuracy: 0.8235 - val_precision_49: 0.0310 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 18.2707 - accuracy: 0.8050 - precision_49: 0.2324 - val_loss: 13.2958 - val_accuracy: 0.5320 - val_precision_49: 0.0536 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 8.1580 - accuracy: 0.8082 - precision_49: 0.2491 - val_loss: 2.8988 - val_accuracy: 0.8642 - val_precision_49: 0.0340 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.8853 - accuracy: 0.8085 - precision_49: 0.2422 - val_loss: 5.8582 - val_accuracy: 0.8395 - val_precision_49: 0.0352 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 11.4432 - accuracy: 0.8068 - precision_49: 0.2340 - val_loss: 5.6123 - val_accuracy: 0.6903 - val_precision_49: 0.0495 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.1513 - accuracy: 0.8061 - precision_49: 0.2437 - val_loss: 12.3090 - val_accuracy: 0.9521 - val_precision_49: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 12.2075 - accuracy: 0.8080 - precision_49: 0.2325 - val_loss: 3.7179 - val_accuracy: 0.7047 - val_precision_49: 0.0486 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 10.8987 - accuracy: 0.8091 - precision_49: 0.2482 - val_loss: 6.8427 - val_accuracy: 0.9369 - val_precision_49: 0.0359 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.7719 - accuracy: 0.8137 - precision_49: 0.2654 - val_loss: 3.5361 - val_accuracy: 0.7653 - val_precision_49: 0.0320 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.0433 - accuracy: 0.8068 - precision_49: 0.2382 - val_loss: 6.4080 - val_accuracy: 0.8497 - val_precision_49: 0.0321 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.4838 - accuracy: 0.8089 - precision_49: 0.2378 - val_loss: 3.4776 - val_accuracy: 0.9148 - val_precision_49: 0.0310 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.5814 - accuracy: 0.8132 - precision_49: 0.2628 - val_loss: 4.9163 - val_accuracy: 0.9086 - val_precision_49: 0.0278 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.6127 - accuracy: 0.8133 - precision_49: 0.2573 - val_loss: 6.4638 - val_accuracy: 0.8797 - val_precision_49: 0.0264 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.0406 - accuracy: 0.8097 - precision_49: 0.2473 - val_loss: 1.9970 - val_accuracy: 0.8025 - val_precision_49: 0.0212 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 5.3196 - accuracy: 0.8129 - precision_49: 0.2582 - val_loss: 3.5877 - val_accuracy: 0.8130 - val_precision_49: 0.0269 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.7390 - accuracy: 0.8088 - precision_49: 0.2437 - val_loss: 3.2412 - val_accuracy: 0.8887 - val_precision_49: 0.0260 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.6239 - accuracy: 0.8154 - precision_49: 0.2654 - val_loss: 7.1456 - val_accuracy: 0.6031 - val_precision_49: 0.0576 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.2575 - accuracy: 0.8147 - precision_49: 0.2656 - val_loss: 1.6677 - val_accuracy: 0.8900 - val_precision_49: 0.0149 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.6574 - accuracy: 0.8145 - precision_49: 0.2626 - val_loss: 6.0638 - val_accuracy: 0.6191 - val_precision_49: 0.0528 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.5889 - accuracy: 0.8124 - precision_49: 0.2589 - val_loss: 1.0193 - val_accuracy: 0.8624 - val_precision_49: 0.0395 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.9264 - accuracy: 0.8161 - precision_49: 0.2775 - val_loss: 3.9297 - val_accuracy: 0.6425 - val_precision_49: 0.0539 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.4720 - accuracy: 0.8129 - precision_49: 0.2615 - val_loss: 1.4408 - val_accuracy: 0.8684 - val_precision_49: 0.0173 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.1614 - accuracy: 0.8131 - precision_49: 0.2609 - val_loss: 3.2542 - val_accuracy: 0.8973 - val_precision_49: 0.0094 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.8141 - accuracy: 0.8161 - precision_49: 0.2723 - val_loss: 4.2539 - val_accuracy: 0.8172 - val_precision_49: 0.0319 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 6.1649 - accuracy: 0.8129 - precision_49: 0.2556 - val_loss: 3.5647 - val_accuracy: 0.8287 - val_precision_49: 0.0222 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.1825 - accuracy: 0.8134 - precision_49: 0.2648 - val_loss: 2.9470 - val_accuracy: 0.8123 - val_precision_49: 0.0268 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.2922 - accuracy: 0.8177 - precision_49: 0.2750 - val_loss: 3.8715 - val_accuracy: 0.9242 - val_precision_49: 0.0070 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.1088 - accuracy: 0.8160 - precision_49: 0.2730 - val_loss: 1.0912 - val_accuracy: 0.8435 - val_precision_49: 0.0242 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.1844 - accuracy: 0.8161 - precision_49: 0.2774 - val_loss: 3.0692 - val_accuracy: 0.9254 - val_precision_49: 0.0142 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 4.9163 - accuracy: 0.8130 - precision_49: 0.2619 - val_loss: 2.1122 - val_accuracy: 0.8415 - val_precision_49: 0.0254 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.8253 - accuracy: 0.8175 - precision_49: 0.2806 - val_loss: 4.5729 - val_accuracy: 0.5488 - val_precision_49: 0.0530 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.2211 - accuracy: 0.8148 - precision_49: 0.2725 - val_loss: 2.6164 - val_accuracy: 0.8694 - val_precision_49: 0.0251 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.5381 - accuracy: 0.8142 - precision_49: 0.2655 - val_loss: 3.1167 - val_accuracy: 0.9262 - val_precision_49: 0.0019 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.5557 - accuracy: 0.8188 - precision_49: 0.2834 - val_loss: 8.7977 - val_accuracy: 0.5267 - val_precision_49: 0.0502 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.3360 - accuracy: 0.8223 - precision_49: 0.2971 - val_loss: 1.6937 - val_accuracy: 0.6877 - val_precision_49: 0.0304 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.4665 - accuracy: 0.8165 - precision_49: 0.2819 - val_loss: 2.4564 - val_accuracy: 0.9458 - val_precision_49: 0.0038 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.3629 - accuracy: 0.8184 - precision_49: 0.2800 - val_loss: 1.1898 - val_accuracy: 0.9177 - val_precision_49: 0.0015 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.5226 - accuracy: 0.8212 - precision_49: 0.2923 - val_loss: 0.9437 - val_accuracy: 0.7786 - val_precision_49: 0.0341 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.5242 - accuracy: 0.8211 - precision_49: 0.2910 - val_loss: 1.5357 - val_accuracy: 0.7607 - val_precision_49: 0.0451 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.7602 - accuracy: 0.8189 - precision_49: 0.2851 - val_loss: 1.1209 - val_accuracy: 0.8247 - val_precision_49: 0.0308 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.8063 - accuracy: 0.8213 - precision_49: 0.2904 - val_loss: 0.7258 - val_accuracy: 0.8742 - val_precision_49: 0.0109 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.2750 - accuracy: 0.8216 - precision_49: 0.2936 - val_loss: 1.0444 - val_accuracy: 0.8430 - val_precision_49: 0.0241 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.0452 - accuracy: 0.8214 - precision_49: 0.2910 - val_loss: 0.9572 - val_accuracy: 0.8051 - val_precision_49: 0.0252 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.8461 - accuracy: 0.8210 - precision_49: 0.2959 - val_loss: 1.1461 - val_accuracy: 0.9201 - val_precision_49: 0.0016 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.8238 - accuracy: 0.8229 - precision_49: 0.2988 - val_loss: 1.7681 - val_accuracy: 0.6735 - val_precision_49: 0.0517 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.5966 - accuracy: 0.8243 - precision_49: 0.3033 - val_loss: 2.3741 - val_accuracy: 0.6191 - val_precision_49: 0.0582 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.4374 - accuracy: 0.8274 - precision_49: 0.3149 - val_loss: 2.1746 - val_accuracy: 0.5900 - val_precision_49: 0.0520 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.7935 - accuracy: 0.8209 - precision_49: 0.2910 - val_loss: 1.2410 - val_accuracy: 0.8976 - val_precision_49: 0.0263 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.8492 - accuracy: 0.8217 - precision_49: 0.2927 - val_loss: 1.2629 - val_accuracy: 0.6977 - val_precision_49: 0.0461 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.5553 - accuracy: 0.8248 - precision_49: 0.3087 - val_loss: 0.6362 - val_accuracy: 0.9188 - val_precision_49: 0.0046 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.8689 - accuracy: 0.8230 - precision_49: 0.3012 - val_loss: 1.5662 - val_accuracy: 0.8540 - val_precision_49: 0.0293 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.6355 - accuracy: 0.8271 - precision_49: 0.3142 - val_loss: 1.8963 - val_accuracy: 0.6511 - val_precision_49: 0.0608 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2424 - accuracy: 0.8286 - precision_49: 0.3212 - val_loss: 0.5717 - val_accuracy: 0.8223 - val_precision_49: 0.0294 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.3592 - accuracy: 0.8246 - precision_49: 0.3046 - val_loss: 0.7474 - val_accuracy: 0.8260 - val_precision_49: 0.0283 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.3448 - accuracy: 0.8270 - precision_49: 0.3123 - val_loss: 0.5915 - val_accuracy: 0.8102 - val_precision_49: 0.0505 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.3137 - accuracy: 0.8234 - precision_49: 0.2953 - val_loss: 0.7966 - val_accuracy: 0.8800 - val_precision_49: 0.0273 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2386 - accuracy: 0.8293 - precision_49: 0.3248 - val_loss: 0.9265 - val_accuracy: 0.6601 - val_precision_49: 0.0537 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0066 - accuracy: 0.8293 - precision_49: 0.3230 - val_loss: 0.5100 - val_accuracy: 0.8920 - val_precision_49: 0.0235 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1065 - accuracy: 0.8281 - precision_49: 0.3175 - val_loss: 1.6591 - val_accuracy: 0.5657 - val_precision_49: 0.0579 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0010 - accuracy: 0.8276 - precision_49: 0.3140 - val_loss: 0.4858 - val_accuracy: 0.8642 - val_precision_49: 0.0283 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9997 - accuracy: 0.8323 - precision_49: 0.3387 - val_loss: 1.1987 - val_accuracy: 0.9232 - val_precision_49: 0.0085 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.1546 - accuracy: 0.8288 - precision_49: 0.3182 - val_loss: 0.5873 - val_accuracy: 0.9096 - val_precision_49: 0.0164 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.0971 - accuracy: 0.8303 - precision_49: 0.3304 - val_loss: 0.6957 - val_accuracy: 0.8922 - val_precision_49: 0.0298 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9640 - accuracy: 0.8287 - precision_49: 0.3157 - val_loss: 0.6038 - val_accuracy: 0.9099 - val_precision_49: 0.0103 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7593 - accuracy: 0.8349 - precision_49: 0.3442 - val_loss: 0.5113 - val_accuracy: 0.8267 - val_precision_49: 0.0446 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.8489 - accuracy: 0.8328 - precision_49: 0.3343 - val_loss: 0.8420 - val_accuracy: 0.8691 - val_precision_49: 0.0330 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.8349 - precision_49: 0.3402 - val_loss: 0.4255 - val_accuracy: 0.9184 - val_precision_49: 0.0106 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.7426 - accuracy: 0.8360 - precision_49: 0.3458 - val_loss: 0.3239 - val_accuracy: 0.8875 - val_precision_49: 0.0297 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7868 - accuracy: 0.8337 - precision_49: 0.3332 - val_loss: 0.4224 - val_accuracy: 0.8474 - val_precision_49: 0.0283 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7685 - accuracy: 0.8383 - precision_49: 0.3571 - val_loss: 0.4943 - val_accuracy: 0.8853 - val_precision_49: 0.0290 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7671 - accuracy: 0.8342 - precision_49: 0.3385 - val_loss: 0.3557 - val_accuracy: 0.9087 - val_precision_49: 0.0255 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7467 - accuracy: 0.8354 - precision_49: 0.3446 - val_loss: 0.4808 - val_accuracy: 0.8084 - val_precision_49: 0.0675 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7169 - accuracy: 0.8344 - precision_49: 0.3362 - val_loss: 0.4216 - val_accuracy: 0.8868 - val_precision_49: 0.0367 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5650 - accuracy: 0.8442 - precision_49: 0.3838 - val_loss: 0.9513 - val_accuracy: 0.6903 - val_precision_49: 0.0613 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.8404 - precision_49: 0.3611 - val_loss: 0.6113 - val_accuracy: 0.7546 - val_precision_49: 0.0730 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7517 - accuracy: 0.8385 - precision_49: 0.3545 - val_loss: 0.3757 - val_accuracy: 0.9095 - val_precision_49: 0.0089 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5916 - accuracy: 0.8400 - precision_49: 0.3586 - val_loss: 0.5314 - val_accuracy: 0.7552 - val_precision_49: 0.0686 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 6ms/step - loss: 527.2299 - accuracy: 0.7557 - precision_50: 0.1462 - val_loss: 66.1692 - val_accuracy: 0.9495 - val_precision_50: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 136.6611 - accuracy: 0.7738 - precision_50: 0.1682 - val_loss: 131.6811 - val_accuracy: 0.1977 - val_precision_50: 0.0392 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 86.5052 - accuracy: 0.7768 - precision_50: 0.1844 - val_loss: 27.6476 - val_accuracy: 0.7390 - val_precision_50: 0.0413 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 75.5563 - accuracy: 0.7796 - precision_50: 0.1916 - val_loss: 58.4486 - val_accuracy: 0.9371 - val_precision_50: 0.0026 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 78.1676 - accuracy: 0.7807 - precision_50: 0.1896 - val_loss: 14.6509 - val_accuracy: 0.8264 - val_precision_50: 0.0229 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 122.4763 - accuracy: 0.7756 - precision_50: 0.1799 - val_loss: 26.1832 - val_accuracy: 0.9386 - val_precision_50: 0.0137 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 72.3853 - accuracy: 0.7811 - precision_50: 0.1982 - val_loss: 52.0743 - val_accuracy: 0.9537 - val_precision_50: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 60.7332 - accuracy: 0.7884 - precision_50: 0.2101 - val_loss: 87.4531 - val_accuracy: 0.9569 - val_precision_50: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 57.1700 - accuracy: 0.7886 - precision_50: 0.2070 - val_loss: 45.2507 - val_accuracy: 0.9004 - val_precision_50: 0.0297 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 54.2370 - accuracy: 0.7909 - precision_50: 0.2106 - val_loss: 10.3464 - val_accuracy: 0.8473 - val_precision_50: 0.0344 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 65.4824 - accuracy: 0.7900 - precision_50: 0.2072 - val_loss: 14.4379 - val_accuracy: 0.8349 - val_precision_50: 0.0469 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 33.6760 - accuracy: 0.7974 - precision_50: 0.2255 - val_loss: 34.6931 - val_accuracy: 0.8861 - val_precision_50: 0.0327 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 41.4978 - accuracy: 0.7935 - precision_50: 0.2121 - val_loss: 17.8495 - val_accuracy: 0.8475 - val_precision_50: 0.0295 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 28.2562 - accuracy: 0.7979 - precision_50: 0.2234 - val_loss: 41.5655 - val_accuracy: 0.6098 - val_precision_50: 0.0532 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 44.4776 - accuracy: 0.7915 - precision_50: 0.2052 - val_loss: 12.6833 - val_accuracy: 0.6917 - val_precision_50: 0.0574 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 32.3601 - accuracy: 0.7985 - precision_50: 0.2168 - val_loss: 69.3492 - val_accuracy: 0.3674 - val_precision_50: 0.0426 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 25.6254 - accuracy: 0.7988 - precision_50: 0.2250 - val_loss: 18.3130 - val_accuracy: 0.9436 - val_precision_50: 0.0035 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 21.2990 - accuracy: 0.8006 - precision_50: 0.2210 - val_loss: 9.3921 - val_accuracy: 0.9139 - val_precision_50: 0.0057 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 21.1125 - accuracy: 0.7994 - precision_50: 0.2222 - val_loss: 12.7173 - val_accuracy: 0.8328 - val_precision_50: 0.0370 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 34.6843 - accuracy: 0.7998 - precision_50: 0.2203 - val_loss: 13.2698 - val_accuracy: 0.8452 - val_precision_50: 0.0236 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 21.0160 - accuracy: 0.8017 - precision_50: 0.2256 - val_loss: 11.9491 - val_accuracy: 0.8310 - val_precision_50: 0.0294 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 18.9233 - accuracy: 0.7983 - precision_50: 0.2192 - val_loss: 10.4366 - val_accuracy: 0.8607 - val_precision_50: 0.0367 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.0025 - accuracy: 0.8045 - precision_50: 0.2370 - val_loss: 10.4664 - val_accuracy: 0.8674 - val_precision_50: 0.0307 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.4024 - accuracy: 0.8037 - precision_50: 0.2300 - val_loss: 8.8975 - val_accuracy: 0.9346 - val_precision_50: 0.0096 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 14.4794 - accuracy: 0.8034 - precision_50: 0.2331 - val_loss: 6.0784 - val_accuracy: 0.9221 - val_precision_50: 0.0229 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 20.0327 - accuracy: 0.8051 - precision_50: 0.2303 - val_loss: 6.8700 - val_accuracy: 0.9070 - val_precision_50: 0.0285 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.8184 - accuracy: 0.8051 - precision_50: 0.2329 - val_loss: 6.9617 - val_accuracy: 0.7939 - val_precision_50: 0.0335 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 14.2964 - accuracy: 0.8033 - precision_50: 0.2288 - val_loss: 5.3591 - val_accuracy: 0.8445 - val_precision_50: 0.0346 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.9919 - accuracy: 0.8049 - precision_50: 0.2332 - val_loss: 6.6072 - val_accuracy: 0.9294 - val_precision_50: 0.0161 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 18.5098 - accuracy: 0.8030 - precision_50: 0.2253 - val_loss: 6.3305 - val_accuracy: 0.9095 - val_precision_50: 0.0274 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.8919 - accuracy: 0.8095 - precision_50: 0.2436 - val_loss: 18.7302 - val_accuracy: 0.5181 - val_precision_50: 0.0537 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.3738 - accuracy: 0.8049 - precision_50: 0.2307 - val_loss: 4.4237 - val_accuracy: 0.9238 - val_precision_50: 0.0238 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.7066 - accuracy: 0.8075 - precision_50: 0.2356 - val_loss: 9.8498 - val_accuracy: 0.8411 - val_precision_50: 0.0348 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.0755 - accuracy: 0.8035 - precision_50: 0.2283 - val_loss: 7.1751 - val_accuracy: 0.9004 - val_precision_50: 0.0297 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.3725 - accuracy: 0.8065 - precision_50: 0.2346 - val_loss: 2.4060 - val_accuracy: 0.8831 - val_precision_50: 0.0269 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.3705 - accuracy: 0.8083 - precision_50: 0.2410 - val_loss: 1.9011 - val_accuracy: 0.8656 - val_precision_50: 0.0269 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.0594 - accuracy: 0.8067 - precision_50: 0.2390 - val_loss: 2.6091 - val_accuracy: 0.9279 - val_precision_50: 0.0263 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.6165 - accuracy: 0.8070 - precision_50: 0.2339 - val_loss: 1.6468 - val_accuracy: 0.7875 - val_precision_50: 0.0280 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.6469 - accuracy: 0.8076 - precision_50: 0.2374 - val_loss: 3.7205 - val_accuracy: 0.9240 - val_precision_50: 0.0239 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.8883 - accuracy: 0.8132 - precision_50: 0.2538 - val_loss: 8.1283 - val_accuracy: 0.6130 - val_precision_50: 0.0563 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.3731 - accuracy: 0.8081 - precision_50: 0.2385 - val_loss: 1.2777 - val_accuracy: 0.8152 - val_precision_50: 0.0472 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.7435 - accuracy: 0.8076 - precision_50: 0.2404 - val_loss: 1.6844 - val_accuracy: 0.7353 - val_precision_50: 0.0614 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.9372 - accuracy: 0.8100 - precision_50: 0.2470 - val_loss: 1.4181 - val_accuracy: 0.8714 - val_precision_50: 0.0236 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.8375 - accuracy: 0.8101 - precision_50: 0.2427 - val_loss: 1.1103 - val_accuracy: 0.8691 - val_precision_50: 0.0351 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.8027 - accuracy: 0.8100 - precision_50: 0.2386 - val_loss: 2.4844 - val_accuracy: 0.6652 - val_precision_50: 0.0595 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.9423 - accuracy: 0.8101 - precision_50: 0.2481 - val_loss: 0.8690 - val_accuracy: 0.9225 - val_precision_50: 0.0151 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.0585 - accuracy: 0.8111 - precision_50: 0.2412 - val_loss: 1.3243 - val_accuracy: 0.6459 - val_precision_50: 0.0563 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.9292 - accuracy: 0.8137 - precision_50: 0.2483 - val_loss: 2.0049 - val_accuracy: 0.5268 - val_precision_50: 0.0545 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.6203 - accuracy: 0.8107 - precision_50: 0.2438 - val_loss: 2.1769 - val_accuracy: 0.9108 - val_precision_50: 0.0386 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.6461 - accuracy: 0.8137 - precision_50: 0.2499 - val_loss: 0.5640 - val_accuracy: 0.8874 - val_precision_50: 0.0357 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.3789 - accuracy: 0.8162 - precision_50: 0.2558 - val_loss: 0.6019 - val_accuracy: 0.7984 - val_precision_50: 0.0517 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.3156 - accuracy: 0.8166 - precision_50: 0.2537 - val_loss: 0.5684 - val_accuracy: 0.8274 - val_precision_50: 0.0629 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9799 - accuracy: 0.8180 - precision_50: 0.2507 - val_loss: 0.3430 - val_accuracy: 0.9140 - val_precision_50: 0.0206 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7969 - accuracy: 0.8237 - precision_50: 0.2663 - val_loss: 0.4418 - val_accuracy: 0.9404 - val_precision_50: 0.0392 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.8370 - accuracy: 0.8222 - precision_50: 0.2582 - val_loss: 0.4662 - val_accuracy: 0.8476 - val_precision_50: 0.0318 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.8304 - precision_50: 0.2780 - val_loss: 0.3195 - val_accuracy: 0.9488 - val_precision_50: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.8387 - precision_50: 0.3090 - val_loss: 0.8258 - val_accuracy: 0.6984 - val_precision_50: 0.0729 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.6435 - accuracy: 0.8331 - precision_50: 0.2866 - val_loss: 0.3684 - val_accuracy: 0.9025 - val_precision_50: 0.0915 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.8430 - precision_50: 0.3130 - val_loss: 0.4465 - val_accuracy: 0.8423 - val_precision_50: 0.0669 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4898 - accuracy: 0.8440 - precision_50: 0.3249 - val_loss: 0.3081 - val_accuracy: 0.9243 - val_precision_50: 0.0399 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.8445 - precision_50: 0.3243 - val_loss: 0.4135 - val_accuracy: 0.8689 - val_precision_50: 0.0383 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4883 - accuracy: 0.8439 - precision_50: 0.3323 - val_loss: 0.4510 - val_accuracy: 0.8295 - val_precision_50: 0.0398 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.8477 - precision_50: 0.3500 - val_loss: 0.3273 - val_accuracy: 0.8974 - val_precision_50: 0.0424 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6096 - accuracy: 0.8360 - precision_50: 0.2923 - val_loss: 0.3347 - val_accuracy: 0.9218 - val_precision_50: 0.0406 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6324 - accuracy: 0.8354 - precision_50: 0.2922 - val_loss: 0.2185 - val_accuracy: 0.9551 - val_precision_50: 0.0229 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4489 - accuracy: 0.8477 - precision_50: 0.3417 - val_loss: 0.3665 - val_accuracy: 0.8844 - val_precision_50: 0.0421 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8501 - precision_50: 0.3569 - val_loss: 0.3672 - val_accuracy: 0.8713 - val_precision_50: 0.0405 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8503 - precision_50: 0.3603 - val_loss: 0.2955 - val_accuracy: 0.9261 - val_precision_50: 0.0448 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.8400 - precision_50: 0.3103 - val_loss: 0.3412 - val_accuracy: 0.8881 - val_precision_50: 0.0479 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.8422 - precision_50: 0.3199 - val_loss: 0.6571 - val_accuracy: 0.7610 - val_precision_50: 0.0736 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.2575 - accuracy: 0.8116 - precision_50: 0.2344 - val_loss: 1.0984 - val_accuracy: 0.9073 - val_precision_50: 0.0252 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9058 - accuracy: 0.8245 - precision_50: 0.2519 - val_loss: 0.3938 - val_accuracy: 0.8625 - val_precision_50: 0.0223 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.8386 - precision_50: 0.2938 - val_loss: 0.3795 - val_accuracy: 0.8537 - val_precision_50: 0.0384 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.8464 - precision_50: 0.3294 - val_loss: 0.3994 - val_accuracy: 0.8448 - val_precision_50: 0.0907 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8477 - precision_50: 0.3306 - val_loss: 0.2253 - val_accuracy: 0.9452 - val_precision_50: 0.0418 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.5051 - accuracy: 0.8439 - precision_50: 0.3114 - val_loss: 0.3482 - val_accuracy: 0.8788 - val_precision_50: 0.0514 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.5651 - accuracy: 0.8297 - precision_50: 0.2715 - val_loss: 0.7985 - val_accuracy: 0.7705 - val_precision_50: 0.0808 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.8420 - precision_50: 0.3137 - val_loss: 0.2573 - val_accuracy: 0.9236 - val_precision_50: 0.0362 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8556 - precision_50: 0.4075 - val_loss: 0.2021 - val_accuracy: 0.9559 - val_precision_50: 0.0086 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8610 - precision_50: 0.4789 - val_loss: 0.2997 - val_accuracy: 0.9170 - val_precision_50: 0.0556 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8630 - precision_50: 0.5251 - val_loss: 0.2807 - val_accuracy: 0.9246 - val_precision_50: 0.0565 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8576 - precision_50: 0.4304 - val_loss: 0.2349 - val_accuracy: 0.9510 - val_precision_50: 0.0901 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8551 - precision_50: 0.3967 - val_loss: 0.2258 - val_accuracy: 0.9444 - val_precision_50: 0.0583 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8604 - precision_50: 0.4692 - val_loss: 0.2266 - val_accuracy: 0.9477 - val_precision_50: 0.0442 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8611 - precision_50: 0.4829 - val_loss: 0.2499 - val_accuracy: 0.9340 - val_precision_50: 0.0698 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3829 - accuracy: 0.8587 - precision_50: 0.4425 - val_loss: 0.2733 - val_accuracy: 0.9105 - val_precision_50: 0.0517 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.3948 - accuracy: 0.8458 - precision_50: 0.3359 - val_loss: 0.2975 - val_accuracy: 0.9432 - val_precision_50: 0.0578 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3881 - accuracy: 0.8609 - precision_50: 0.4774 - val_loss: 0.2583 - val_accuracy: 0.9409 - val_precision_50: 0.0400 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3646 - accuracy: 0.8650 - precision_50: 0.5722 - val_loss: 0.3115 - val_accuracy: 0.9032 - val_precision_50: 0.0460 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3653 - accuracy: 0.8649 - precision_50: 0.5686 - val_loss: 0.2312 - val_accuracy: 0.9444 - val_precision_50: 0.0277 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.8644 - precision_50: 0.5599 - val_loss: 0.2663 - val_accuracy: 0.9243 - val_precision_50: 0.0459 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8642 - precision_50: 0.5506 - val_loss: 0.2453 - val_accuracy: 0.9349 - val_precision_50: 0.0529 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3657 - accuracy: 0.8643 - precision_50: 0.5527 - val_loss: 0.2522 - val_accuracy: 0.9339 - val_precision_50: 0.0643 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3568 - accuracy: 0.8658 - precision_50: 0.5969 - val_loss: 0.2474 - val_accuracy: 0.9360 - val_precision_50: 0.0832 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8652 - precision_50: 0.5773 - val_loss: 0.2629 - val_accuracy: 0.9226 - val_precision_50: 0.0339 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8646 - precision_50: 0.5626 - val_loss: 0.3323 - val_accuracy: 0.8776 - val_precision_50: 0.0453 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8647 - precision_50: 0.5632 - val_loss: 0.2176 - val_accuracy: 0.9486 - val_precision_50: 0.0464 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8658 - precision_50: 0.5921 - val_loss: 0.3740 - val_accuracy: 0.8686 - val_precision_50: 0.0439 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8653 - precision_50: 0.5746 - val_loss: 0.2468 - val_accuracy: 0.9372 - val_precision_50: 0.0651 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.8682 - precision_50: 0.6449 - val_loss: 0.2369 - val_accuracy: 0.9400 - val_precision_50: 0.0557 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 6ms/step - loss: 198.9172 - accuracy: 0.7719 - precision_51: 0.1646 - val_loss: 39.1626 - val_accuracy: 0.8941 - val_precision_51: 0.0227 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 136.4494 - accuracy: 0.7855 - precision_51: 0.1868 - val_loss: 43.9171 - val_accuracy: 0.6890 - val_precision_51: 0.0584 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 85.3176 - accuracy: 0.7907 - precision_51: 0.1872 - val_loss: 38.7641 - val_accuracy: 0.8928 - val_precision_51: 0.0251 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 77.8696 - accuracy: 0.7917 - precision_51: 0.1951 - val_loss: 46.5700 - val_accuracy: 0.8779 - val_precision_51: 0.0300 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 75.2659 - accuracy: 0.7979 - precision_51: 0.2057 - val_loss: 15.1265 - val_accuracy: 0.8545 - val_precision_51: 0.0361 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 65.3944 - accuracy: 0.7944 - precision_51: 0.1973 - val_loss: 16.8568 - val_accuracy: 0.9028 - val_precision_51: 0.0248 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 74.6577 - accuracy: 0.7963 - precision_51: 0.2159 - val_loss: 53.7451 - val_accuracy: 0.9547 - val_precision_51: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 92.5611 - accuracy: 0.7997 - precision_51: 0.2089 - val_loss: 71.2829 - val_accuracy: 0.4790 - val_precision_51: 0.0519 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 55.5352 - accuracy: 0.7999 - precision_51: 0.2164 - val_loss: 21.7566 - val_accuracy: 0.9033 - val_precision_51: 0.0094 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 55.3359 - accuracy: 0.8055 - precision_51: 0.2227 - val_loss: 81.1202 - val_accuracy: 0.5877 - val_precision_51: 0.0549 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 61.0830 - accuracy: 0.8022 - precision_51: 0.2134 - val_loss: 13.5348 - val_accuracy: 0.9184 - val_precision_51: 0.0140 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 39.2719 - accuracy: 0.8031 - precision_51: 0.2192 - val_loss: 18.6687 - val_accuracy: 0.7402 - val_precision_51: 0.0330 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 41.5942 - accuracy: 0.8003 - precision_51: 0.2138 - val_loss: 30.8377 - val_accuracy: 0.9543 - val_precision_51: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 40.9293 - accuracy: 0.7999 - precision_51: 0.2201 - val_loss: 8.6578 - val_accuracy: 0.7846 - val_precision_51: 0.0284 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 35.5335 - accuracy: 0.8042 - precision_51: 0.2229 - val_loss: 18.6391 - val_accuracy: 0.7544 - val_precision_51: 0.0321 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 42.3982 - accuracy: 0.7994 - precision_51: 0.2156 - val_loss: 29.3033 - val_accuracy: 0.9194 - val_precision_51: 0.0306 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 55.7314 - accuracy: 0.8012 - precision_51: 0.2129 - val_loss: 21.8526 - val_accuracy: 0.9386 - val_precision_51: 0.0085 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 28.8682 - accuracy: 0.7998 - precision_51: 0.2154 - val_loss: 19.0983 - val_accuracy: 0.8974 - val_precision_51: 0.0297 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 34.2242 - accuracy: 0.8065 - precision_51: 0.2211 - val_loss: 15.2690 - val_accuracy: 0.6829 - val_precision_51: 0.0567 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 33.4369 - accuracy: 0.8019 - precision_51: 0.2135 - val_loss: 31.5718 - val_accuracy: 0.5404 - val_precision_51: 0.0491 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 42.5827 - accuracy: 0.8002 - precision_51: 0.2145 - val_loss: 11.7744 - val_accuracy: 0.8911 - val_precision_51: 0.0145 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 22.2918 - accuracy: 0.8054 - precision_51: 0.2216 - val_loss: 23.9306 - val_accuracy: 0.5782 - val_precision_51: 0.0546 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 38.7446 - accuracy: 0.8032 - precision_51: 0.2189 - val_loss: 7.9063 - val_accuracy: 0.8084 - val_precision_51: 0.0428 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 20.8686 - accuracy: 0.8052 - precision_51: 0.2274 - val_loss: 7.5895 - val_accuracy: 0.8880 - val_precision_51: 0.0139 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 21.4348 - accuracy: 0.8063 - precision_51: 0.2281 - val_loss: 9.0280 - val_accuracy: 0.9195 - val_precision_51: 0.0065 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 19.4399 - accuracy: 0.8035 - precision_51: 0.2193 - val_loss: 23.6835 - val_accuracy: 0.6185 - val_precision_51: 0.0561 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.9122 - accuracy: 0.8084 - precision_51: 0.2375 - val_loss: 4.7966 - val_accuracy: 0.8773 - val_precision_51: 0.0161 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 18.2059 - accuracy: 0.8082 - precision_51: 0.2316 - val_loss: 5.1135 - val_accuracy: 0.8215 - val_precision_51: 0.0208 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.0181 - accuracy: 0.8085 - precision_51: 0.2318 - val_loss: 7.7673 - val_accuracy: 0.8676 - val_precision_51: 0.0242 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 14.6495 - accuracy: 0.8091 - precision_51: 0.2328 - val_loss: 14.9514 - val_accuracy: 0.6109 - val_precision_51: 0.0539 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.4583 - accuracy: 0.8072 - precision_51: 0.2340 - val_loss: 10.0259 - val_accuracy: 0.9321 - val_precision_51: 0.0090 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 13.2736 - accuracy: 0.8085 - precision_51: 0.2340 - val_loss: 4.4038 - val_accuracy: 0.8976 - val_precision_51: 0.0075 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 14.4749 - accuracy: 0.8088 - precision_51: 0.2316 - val_loss: 8.5771 - val_accuracy: 0.9254 - val_precision_51: 0.0129 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 14.0558 - accuracy: 0.8087 - precision_51: 0.2311 - val_loss: 4.6981 - val_accuracy: 0.9027 - val_precision_51: 0.0081 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 14.2982 - accuracy: 0.8070 - precision_51: 0.2289 - val_loss: 4.2978 - val_accuracy: 0.7241 - val_precision_51: 0.0372 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 11.7112 - accuracy: 0.8097 - precision_51: 0.2326 - val_loss: 5.3128 - val_accuracy: 0.9035 - val_precision_51: 0.0140 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.3253 - accuracy: 0.8112 - precision_51: 0.2345 - val_loss: 3.1095 - val_accuracy: 0.7396 - val_precision_51: 0.0312 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.5204 - accuracy: 0.8068 - precision_51: 0.2375 - val_loss: 5.8560 - val_accuracy: 0.9302 - val_precision_51: 0.0085 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.5125 - accuracy: 0.8116 - precision_51: 0.2379 - val_loss: 25.9764 - val_accuracy: 0.5586 - val_precision_51: 0.0556 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.5460 - accuracy: 0.8076 - precision_51: 0.2417 - val_loss: 3.0762 - val_accuracy: 0.8265 - val_precision_51: 0.0491 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 9.9294 - accuracy: 0.8064 - precision_51: 0.2288 - val_loss: 4.7103 - val_accuracy: 0.8951 - val_precision_51: 0.0153 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.4149 - accuracy: 0.8088 - precision_51: 0.2305 - val_loss: 5.2360 - val_accuracy: 0.7990 - val_precision_51: 0.0474 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.6474 - accuracy: 0.8116 - precision_51: 0.2473 - val_loss: 8.5188 - val_accuracy: 0.9073 - val_precision_51: 0.0244 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.5778 - accuracy: 0.8127 - precision_51: 0.2489 - val_loss: 2.3960 - val_accuracy: 0.7230 - val_precision_51: 0.0398 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.8259 - accuracy: 0.8110 - precision_51: 0.2493 - val_loss: 3.4518 - val_accuracy: 0.8212 - val_precision_51: 0.0226 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 6.7449 - accuracy: 0.8109 - precision_51: 0.2464 - val_loss: 9.7948 - val_accuracy: 0.5647 - val_precision_51: 0.0549 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.8898 - accuracy: 0.8092 - precision_51: 0.2482 - val_loss: 2.8070 - val_accuracy: 0.8776 - val_precision_51: 0.0246 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.5475 - accuracy: 0.8137 - precision_51: 0.2496 - val_loss: 3.9811 - val_accuracy: 0.8443 - val_precision_51: 0.0279 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.8530 - accuracy: 0.8092 - precision_51: 0.2412 - val_loss: 1.8900 - val_accuracy: 0.8297 - val_precision_51: 0.0196 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.7549 - accuracy: 0.8113 - precision_51: 0.2468 - val_loss: 2.1759 - val_accuracy: 0.8666 - val_precision_51: 0.0080 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 4.4214 - accuracy: 0.8144 - precision_51: 0.2529 - val_loss: 1.5442 - val_accuracy: 0.7597 - val_precision_51: 0.0402 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.8584 - accuracy: 0.8128 - precision_51: 0.2514 - val_loss: 1.7627 - val_accuracy: 0.9066 - val_precision_51: 0.0135 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.3989 - accuracy: 0.8182 - precision_51: 0.2625 - val_loss: 1.1740 - val_accuracy: 0.8273 - val_precision_51: 0.0393 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.1347 - accuracy: 0.8175 - precision_51: 0.2640 - val_loss: 1.3136 - val_accuracy: 0.6615 - val_precision_51: 0.0469 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.0075 - accuracy: 0.8141 - precision_51: 0.2565 - val_loss: 1.3679 - val_accuracy: 0.9267 - val_precision_51: 0.0077 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.2120 - accuracy: 0.8149 - precision_51: 0.2500 - val_loss: 1.2951 - val_accuracy: 0.9238 - val_precision_51: 0.0107 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.6300 - accuracy: 0.8157 - precision_51: 0.2631 - val_loss: 1.2985 - val_accuracy: 0.9270 - val_precision_51: 0.0153 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.1052 - accuracy: 0.8159 - precision_51: 0.2627 - val_loss: 1.1854 - val_accuracy: 0.9326 - val_precision_51: 0.0201 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.8569 - accuracy: 0.8172 - precision_51: 0.2647 - val_loss: 1.8468 - val_accuracy: 0.5743 - val_precision_51: 0.0547 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.8916 - accuracy: 0.8176 - precision_51: 0.2634 - val_loss: 2.3967 - val_accuracy: 0.6439 - val_precision_51: 0.0544 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.4909 - accuracy: 0.8179 - precision_51: 0.2620 - val_loss: 0.5305 - val_accuracy: 0.8923 - val_precision_51: 0.0268 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1715 - accuracy: 0.8207 - precision_51: 0.2679 - val_loss: 0.6163 - val_accuracy: 0.8444 - val_precision_51: 0.0219 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2458 - accuracy: 0.8219 - precision_51: 0.2665 - val_loss: 1.9788 - val_accuracy: 0.5915 - val_precision_51: 0.0559 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0174 - accuracy: 0.8214 - precision_51: 0.2664 - val_loss: 2.9661 - val_accuracy: 0.5150 - val_precision_51: 0.0519 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.8932 - accuracy: 0.8246 - precision_51: 0.2712 - val_loss: 0.5216 - val_accuracy: 0.7906 - val_precision_51: 0.0373 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.8049 - accuracy: 0.8283 - precision_51: 0.2816 - val_loss: 0.6147 - val_accuracy: 0.7538 - val_precision_51: 0.0491 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.8362 - precision_51: 0.3057 - val_loss: 0.5923 - val_accuracy: 0.7301 - val_precision_51: 0.0629 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.8277 - precision_51: 0.2672 - val_loss: 0.6709 - val_accuracy: 0.9074 - val_precision_51: 0.0255 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7755 - accuracy: 0.8300 - precision_51: 0.2779 - val_loss: 0.3293 - val_accuracy: 0.9037 - val_precision_51: 0.0584 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.8333 - precision_51: 0.2887 - val_loss: 0.3518 - val_accuracy: 0.8954 - val_precision_51: 0.0362 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.8321 - precision_51: 0.2809 - val_loss: 0.3229 - val_accuracy: 0.9037 - val_precision_51: 0.0347 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.8449 - precision_51: 0.3231 - val_loss: 0.3031 - val_accuracy: 0.9240 - val_precision_51: 0.0810 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6146 - accuracy: 0.8319 - precision_51: 0.2680 - val_loss: 0.7101 - val_accuracy: 0.7814 - val_precision_51: 0.0654 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5864 - accuracy: 0.8314 - precision_51: 0.2781 - val_loss: 0.3702 - val_accuracy: 0.9304 - val_precision_51: 0.0085 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.8431 - precision_51: 0.3174 - val_loss: 0.3398 - val_accuracy: 0.9141 - val_precision_51: 0.0327 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.8353 - precision_51: 0.2895 - val_loss: 0.5268 - val_accuracy: 0.7936 - val_precision_51: 0.0408 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.8055 - accuracy: 0.8146 - precision_51: 0.2328 - val_loss: 1.0730 - val_accuracy: 0.8945 - val_precision_51: 0.0340 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2542 - accuracy: 0.8236 - precision_51: 0.2531 - val_loss: 0.3191 - val_accuracy: 0.9165 - val_precision_51: 0.0434 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.8448 - precision_51: 0.3128 - val_loss: 0.3747 - val_accuracy: 0.9289 - val_precision_51: 0.0385 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4384 - accuracy: 0.8493 - precision_51: 0.3313 - val_loss: 0.3789 - val_accuracy: 0.8682 - val_precision_51: 0.0271 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8558 - precision_51: 0.3877 - val_loss: 0.2659 - val_accuracy: 0.9404 - val_precision_51: 0.0092 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.8489 - precision_51: 0.3301 - val_loss: 0.4408 - val_accuracy: 0.8109 - val_precision_51: 0.0906 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8551 - precision_51: 0.3905 - val_loss: 0.2705 - val_accuracy: 0.9365 - val_precision_51: 0.1102 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3886 - accuracy: 0.8577 - precision_51: 0.4156 - val_loss: 0.3232 - val_accuracy: 0.9026 - val_precision_51: 0.0431 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8577 - precision_51: 0.4232 - val_loss: 0.3114 - val_accuracy: 0.9100 - val_precision_51: 0.1149 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8586 - precision_51: 0.4340 - val_loss: 0.2635 - val_accuracy: 0.9276 - val_precision_51: 0.0439 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.8349 - precision_51: 0.2843 - val_loss: 0.4718 - val_accuracy: 0.7999 - val_precision_51: 0.0778 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8568 - precision_51: 0.4157 - val_loss: 0.2246 - val_accuracy: 0.9472 - val_precision_51: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0411 - accuracy: 0.8368 - precision_51: 0.2903 - val_loss: 0.4372 - val_accuracy: 0.8988 - val_precision_51: 0.0588 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.8421 - precision_51: 0.3125 - val_loss: 0.3451 - val_accuracy: 0.8877 - val_precision_51: 0.0601 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.8511 - precision_51: 0.3633 - val_loss: 0.2408 - val_accuracy: 0.9427 - val_precision_51: 0.0443 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8529 - precision_51: 0.3652 - val_loss: 0.2833 - val_accuracy: 0.9183 - val_precision_51: 0.0449 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8532 - precision_51: 0.3763 - val_loss: 0.2839 - val_accuracy: 0.9452 - val_precision_51: 0.0825 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.0709 - accuracy: 0.8060 - precision_51: 0.2218 - val_loss: 1.7349 - val_accuracy: 0.8730 - val_precision_51: 0.0401 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.8594 - precision_51: 0.4363 - val_loss: 0.2864 - val_accuracy: 0.9213 - val_precision_51: 0.0334 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8600 - precision_51: 0.4492 - val_loss: 0.2955 - val_accuracy: 0.9085 - val_precision_51: 0.0248 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8631 - precision_51: 0.5235 - val_loss: 0.1988 - val_accuracy: 0.9585 - val_precision_51: 0.0143 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8621 - precision_51: 0.4964 - val_loss: 0.2834 - val_accuracy: 0.9162 - val_precision_51: 0.0493 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8629 - precision_51: 0.5159 - val_loss: 0.2276 - val_accuracy: 0.9446 - val_precision_51: 0.0112 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8624 - precision_51: 0.5031 - val_loss: 0.2923 - val_accuracy: 0.9134 - val_precision_51: 0.0573 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 6ms/step - loss: 796.7299 - accuracy: 0.7423 - precision_52: 0.1409 - val_loss: 24.5860 - val_accuracy: 0.9262 - val_precision_52: 0.0115 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 55.6467 - accuracy: 0.7707 - precision_52: 0.1624 - val_loss: 48.5954 - val_accuracy: 0.9603 - val_precision_52: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 38.2982 - accuracy: 0.7825 - precision_52: 0.1895 - val_loss: 28.2741 - val_accuracy: 0.5353 - val_precision_52: 0.0560 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 42.2778 - accuracy: 0.7810 - precision_52: 0.1865 - val_loss: 38.2239 - val_accuracy: 0.8315 - val_precision_52: 0.0388 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 67.2639 - accuracy: 0.7757 - precision_52: 0.1860 - val_loss: 15.1267 - val_accuracy: 0.9175 - val_precision_52: 0.0062 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 32.4776 - accuracy: 0.7883 - precision_52: 0.2129 - val_loss: 10.3978 - val_accuracy: 0.8877 - val_precision_52: 0.0271 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 38.3326 - accuracy: 0.7859 - precision_52: 0.1945 - val_loss: 15.4504 - val_accuracy: 0.8705 - val_precision_52: 0.0265 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 25.8845 - accuracy: 0.7917 - precision_52: 0.2154 - val_loss: 6.8933 - val_accuracy: 0.7329 - val_precision_52: 0.0383 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 50.4533 - accuracy: 0.7787 - precision_52: 0.1901 - val_loss: 10.7990 - val_accuracy: 0.9090 - val_precision_52: 0.0276 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 28.8904 - accuracy: 0.7942 - precision_52: 0.2160 - val_loss: 7.0906 - val_accuracy: 0.7516 - val_precision_52: 0.0402 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 28.1073 - accuracy: 0.7908 - precision_52: 0.2157 - val_loss: 15.1440 - val_accuracy: 0.8887 - val_precision_52: 0.0334 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 23.7505 - accuracy: 0.7918 - precision_52: 0.2122 - val_loss: 11.3298 - val_accuracy: 0.9194 - val_precision_52: 0.0409 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 26.3136 - accuracy: 0.7927 - precision_52: 0.2180 - val_loss: 10.7164 - val_accuracy: 0.8771 - val_precision_52: 0.0231 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 26.0359 - accuracy: 0.7940 - precision_52: 0.2133 - val_loss: 20.7274 - val_accuracy: 0.9188 - val_precision_52: 0.0305 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 40.1813 - accuracy: 0.7864 - precision_52: 0.2001 - val_loss: 5.7129 - val_accuracy: 0.8844 - val_precision_52: 0.0260 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 27.5469 - accuracy: 0.7930 - precision_52: 0.2045 - val_loss: 20.0020 - val_accuracy: 0.7271 - val_precision_52: 0.0327 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 26.2594 - accuracy: 0.7933 - precision_52: 0.2116 - val_loss: 9.7436 - val_accuracy: 0.8839 - val_precision_52: 0.0266 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 34.0492 - accuracy: 0.7952 - precision_52: 0.2142 - val_loss: 16.4164 - val_accuracy: 0.7954 - val_precision_52: 0.0343 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 17.3328 - accuracy: 0.7996 - precision_52: 0.2269 - val_loss: 4.6428 - val_accuracy: 0.8456 - val_precision_52: 0.0342 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 30.9664 - accuracy: 0.7926 - precision_52: 0.2110 - val_loss: 9.8396 - val_accuracy: 0.6589 - val_precision_52: 0.0583 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 18.4484 - accuracy: 0.7989 - precision_52: 0.2236 - val_loss: 4.7740 - val_accuracy: 0.8171 - val_precision_52: 0.0360 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.3939 - accuracy: 0.8009 - precision_52: 0.2228 - val_loss: 8.5222 - val_accuracy: 0.8938 - val_precision_52: 0.0199 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 14.8577 - accuracy: 0.8018 - precision_52: 0.2250 - val_loss: 6.6352 - val_accuracy: 0.8957 - val_precision_52: 0.0155 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 28.8362 - accuracy: 0.7953 - precision_52: 0.2129 - val_loss: 7.9069 - val_accuracy: 0.7568 - val_precision_52: 0.0562 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 13.3286 - accuracy: 0.8041 - precision_52: 0.2286 - val_loss: 3.0775 - val_accuracy: 0.8150 - val_precision_52: 0.0301 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 12.4593 - accuracy: 0.8061 - precision_52: 0.2316 - val_loss: 4.7486 - val_accuracy: 0.7599 - val_precision_52: 0.0311 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.9308 - accuracy: 0.7991 - precision_52: 0.2209 - val_loss: 13.3686 - val_accuracy: 0.5801 - val_precision_52: 0.0560 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 17.2074 - accuracy: 0.8036 - precision_52: 0.2283 - val_loss: 6.9645 - val_accuracy: 0.9363 - val_precision_52: 0.0157 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 16.1414 - accuracy: 0.8003 - precision_52: 0.2203 - val_loss: 3.0202 - val_accuracy: 0.8526 - val_precision_52: 0.0102 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.7615 - accuracy: 0.8087 - precision_52: 0.2377 - val_loss: 7.7640 - val_accuracy: 0.8103 - val_precision_52: 0.0325 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.2448 - accuracy: 0.8063 - precision_52: 0.2361 - val_loss: 4.3155 - val_accuracy: 0.9182 - val_precision_52: 0.0063 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.7547 - accuracy: 0.8026 - precision_52: 0.2260 - val_loss: 6.3600 - val_accuracy: 0.9058 - val_precision_52: 0.0262 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 9.0135 - accuracy: 0.8096 - precision_52: 0.2355 - val_loss: 3.0368 - val_accuracy: 0.7149 - val_precision_52: 0.0485 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.5654 - accuracy: 0.8096 - precision_52: 0.2392 - val_loss: 9.8658 - val_accuracy: 0.5812 - val_precision_52: 0.0574 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.1861 - accuracy: 0.8053 - precision_52: 0.2295 - val_loss: 6.9462 - val_accuracy: 0.9288 - val_precision_52: 0.0123 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 8.0485 - accuracy: 0.8088 - precision_52: 0.2354 - val_loss: 3.2341 - val_accuracy: 0.7961 - val_precision_52: 0.0478 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.5386 - accuracy: 0.8074 - precision_52: 0.2376 - val_loss: 4.3003 - val_accuracy: 0.8182 - val_precision_52: 0.0223 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.8638 - accuracy: 0.8098 - precision_52: 0.2382 - val_loss: 8.4581 - val_accuracy: 0.9376 - val_precision_52: 0.0217 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.5352 - accuracy: 0.8073 - precision_52: 0.2357 - val_loss: 4.0024 - val_accuracy: 0.8084 - val_precision_52: 0.0284 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 9.2428 - accuracy: 0.8133 - precision_52: 0.2541 - val_loss: 2.3415 - val_accuracy: 0.8669 - val_precision_52: 0.0152 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 13.4281 - accuracy: 0.8072 - precision_52: 0.2323 - val_loss: 4.4920 - val_accuracy: 0.9117 - val_precision_52: 0.0069 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.5418 - accuracy: 0.8088 - precision_52: 0.2423 - val_loss: 2.9759 - val_accuracy: 0.9143 - val_precision_52: 0.0087 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.9278 - accuracy: 0.8112 - precision_52: 0.2411 - val_loss: 14.2727 - val_accuracy: 0.4848 - val_precision_52: 0.0514 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.5599 - accuracy: 0.8116 - precision_52: 0.2492 - val_loss: 2.3486 - val_accuracy: 0.8415 - val_precision_52: 0.0295 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.7235 - accuracy: 0.8108 - precision_52: 0.2440 - val_loss: 2.5633 - val_accuracy: 0.9229 - val_precision_52: 0.0018 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 6.0695 - accuracy: 0.8082 - precision_52: 0.2362 - val_loss: 5.4630 - val_accuracy: 0.9252 - val_precision_52: 0.0112 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 5.2857 - accuracy: 0.8125 - precision_52: 0.2565 - val_loss: 3.6409 - val_accuracy: 0.9066 - val_precision_52: 0.0160 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.9830 - accuracy: 0.8090 - precision_52: 0.2443 - val_loss: 1.5906 - val_accuracy: 0.8635 - val_precision_52: 0.0113 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.2176 - accuracy: 0.8103 - precision_52: 0.2461 - val_loss: 2.4042 - val_accuracy: 0.9134 - val_precision_52: 0.0127 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.5113 - accuracy: 0.8112 - precision_52: 0.2469 - val_loss: 1.7290 - val_accuracy: 0.7908 - val_precision_52: 0.0381 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.9135 - accuracy: 0.8151 - precision_52: 0.2669 - val_loss: 4.2709 - val_accuracy: 0.5542 - val_precision_52: 0.0544 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.0449 - accuracy: 0.8108 - precision_52: 0.2512 - val_loss: 4.3930 - val_accuracy: 0.6097 - val_precision_52: 0.0573 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.6050 - accuracy: 0.8135 - precision_52: 0.2572 - val_loss: 1.2915 - val_accuracy: 0.8062 - val_precision_52: 0.0365 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.1750 - accuracy: 0.8132 - precision_52: 0.2625 - val_loss: 1.1210 - val_accuracy: 0.7968 - val_precision_52: 0.0580 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.1971 - accuracy: 0.8151 - precision_52: 0.2562 - val_loss: 6.8278 - val_accuracy: 0.5595 - val_precision_52: 0.0512 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.6271 - accuracy: 0.8134 - precision_52: 0.2620 - val_loss: 4.4004 - val_accuracy: 0.8744 - val_precision_52: 0.0304 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.7820 - accuracy: 0.8140 - precision_52: 0.2599 - val_loss: 4.1111 - val_accuracy: 0.8653 - val_precision_52: 0.0323 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.9673 - accuracy: 0.8125 - precision_52: 0.2540 - val_loss: 1.2837 - val_accuracy: 0.8252 - val_precision_52: 0.0362 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.9953 - accuracy: 0.8175 - precision_52: 0.2765 - val_loss: 3.2908 - val_accuracy: 0.8733 - val_precision_52: 0.0214 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.1582 - accuracy: 0.8181 - precision_52: 0.2736 - val_loss: 1.7874 - val_accuracy: 0.8288 - val_precision_52: 0.0165 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.9566 - accuracy: 0.8136 - precision_52: 0.2618 - val_loss: 2.0976 - val_accuracy: 0.8690 - val_precision_52: 0.0288 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.9688 - accuracy: 0.8174 - precision_52: 0.2708 - val_loss: 4.1062 - val_accuracy: 0.9010 - val_precision_52: 0.0200 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.6304 - accuracy: 0.8169 - precision_52: 0.2663 - val_loss: 3.5803 - val_accuracy: 0.6587 - val_precision_52: 0.0506 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.3378 - accuracy: 0.8153 - precision_52: 0.2697 - val_loss: 2.0381 - val_accuracy: 0.6697 - val_precision_52: 0.0610 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.8185 - accuracy: 0.8163 - precision_52: 0.2720 - val_loss: 4.2511 - val_accuracy: 0.9136 - val_precision_52: 0.0141 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.9803 - accuracy: 0.8197 - precision_52: 0.2785 - val_loss: 2.0428 - val_accuracy: 0.8829 - val_precision_52: 0.0223 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.0439 - accuracy: 0.8201 - precision_52: 0.2753 - val_loss: 2.8001 - val_accuracy: 0.6228 - val_precision_52: 0.0586 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.8730 - accuracy: 0.8172 - precision_52: 0.2777 - val_loss: 0.9918 - val_accuracy: 0.8812 - val_precision_52: 0.0086 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.8216 - accuracy: 0.8191 - precision_52: 0.2730 - val_loss: 0.8307 - val_accuracy: 0.8278 - val_precision_52: 0.0332 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.8220 - accuracy: 0.8218 - precision_52: 0.2842 - val_loss: 0.5293 - val_accuracy: 0.8922 - val_precision_52: 0.0269 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.7250 - accuracy: 0.8230 - precision_52: 0.2915 - val_loss: 0.6049 - val_accuracy: 0.8668 - val_precision_52: 0.0295 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1265 - accuracy: 0.8276 - precision_52: 0.3044 - val_loss: 0.5804 - val_accuracy: 0.8709 - val_precision_52: 0.0307 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.1850 - accuracy: 0.8264 - precision_52: 0.3031 - val_loss: 0.9334 - val_accuracy: 0.8779 - val_precision_52: 0.0249 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.3472 - accuracy: 0.8224 - precision_52: 0.2849 - val_loss: 0.7819 - val_accuracy: 0.8860 - val_precision_52: 0.0127 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.0791 - accuracy: 0.8257 - precision_52: 0.2958 - val_loss: 0.5260 - val_accuracy: 0.8825 - val_precision_52: 0.0205 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.2353 - accuracy: 0.8236 - precision_52: 0.2876 - val_loss: 0.5382 - val_accuracy: 0.8848 - val_precision_52: 0.0194 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7938 - accuracy: 0.8320 - precision_52: 0.3168 - val_loss: 0.5914 - val_accuracy: 0.9181 - val_precision_52: 0.0301 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.8326 - precision_52: 0.3237 - val_loss: 0.9139 - val_accuracy: 0.7055 - val_precision_52: 0.0632 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7638 - accuracy: 0.8331 - precision_52: 0.3205 - val_loss: 0.7665 - val_accuracy: 0.7173 - val_precision_52: 0.0637 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.8357 - precision_52: 0.3264 - val_loss: 0.4198 - val_accuracy: 0.8964 - val_precision_52: 0.0495 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.8379 - precision_52: 0.3405 - val_loss: 0.4338 - val_accuracy: 0.8235 - val_precision_52: 0.0691 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.8401 - precision_52: 0.3436 - val_loss: 0.3694 - val_accuracy: 0.8880 - val_precision_52: 0.0515 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4515 - accuracy: 0.8467 - precision_52: 0.3736 - val_loss: 0.3180 - val_accuracy: 0.9084 - val_precision_52: 0.0508 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8537 - precision_52: 0.4175 - val_loss: 0.4402 - val_accuracy: 0.8352 - val_precision_52: 0.0369 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.8452 - precision_52: 0.3652 - val_loss: 0.3150 - val_accuracy: 0.9328 - val_precision_52: 0.0589 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.8490 - precision_52: 0.3857 - val_loss: 0.2931 - val_accuracy: 0.9474 - val_precision_52: 0.0135 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8510 - precision_52: 0.3900 - val_loss: 0.3346 - val_accuracy: 0.8981 - val_precision_52: 0.0462 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8543 - precision_52: 0.4166 - val_loss: 0.3430 - val_accuracy: 0.9014 - val_precision_52: 0.0407 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8511 - precision_52: 0.3998 - val_loss: 0.2901 - val_accuracy: 0.9427 - val_precision_52: 0.0540 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8549 - precision_52: 0.4202 - val_loss: 0.3726 - val_accuracy: 0.8863 - val_precision_52: 0.0528 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8578 - precision_52: 0.4485 - val_loss: 0.3907 - val_accuracy: 0.8792 - val_precision_52: 0.0466 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8523 - precision_52: 0.4013 - val_loss: 0.4009 - val_accuracy: 0.8746 - val_precision_52: 0.0704 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8569 - precision_52: 0.4389 - val_loss: 0.2859 - val_accuracy: 0.9266 - val_precision_52: 0.0244 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8547 - precision_52: 0.4242 - val_loss: 0.2851 - val_accuracy: 0.9258 - val_precision_52: 0.0520 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8574 - precision_52: 0.4401 - val_loss: 0.2943 - val_accuracy: 0.9237 - val_precision_52: 0.0450 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8537 - precision_52: 0.4116 - val_loss: 0.3668 - val_accuracy: 0.9147 - val_precision_52: 0.0359 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4008 - accuracy: 0.8564 - precision_52: 0.4328 - val_loss: 0.2905 - val_accuracy: 0.9251 - val_precision_52: 0.0200 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5270 - accuracy: 0.8476 - precision_52: 0.3729 - val_loss: 2.4084 - val_accuracy: 0.8556 - val_precision_52: 0.0494 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.1551 - accuracy: 0.7980 - precision_52: 0.2156 - val_loss: 3.8933 - val_accuracy: 0.8753 - val_precision_52: 0.0406 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.0658 - accuracy: 0.8191 - precision_52: 0.2401 - val_loss: 0.3416 - val_accuracy: 0.9308 - val_precision_52: 0.0274 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 6ms/step - loss: 459.3661 - accuracy: 0.7610 - precision_53: 0.1506 - val_loss: 56.7040 - val_accuracy: 0.8740 - val_precision_53: 0.0173 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 74.9156 - accuracy: 0.7734 - precision_53: 0.1612 - val_loss: 35.6751 - val_accuracy: 0.9597 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 80.0671 - accuracy: 0.7826 - precision_53: 0.1756 - val_loss: 77.5494 - val_accuracy: 0.6023 - val_precision_53: 0.0591 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 69.4933 - accuracy: 0.7832 - precision_53: 0.1842 - val_loss: 23.5832 - val_accuracy: 0.7232 - val_precision_53: 0.0207 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 71.4977 - accuracy: 0.7745 - precision_53: 0.1747 - val_loss: 68.3746 - val_accuracy: 0.9578 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 58.2368 - accuracy: 0.7914 - precision_53: 0.1954 - val_loss: 10.8583 - val_accuracy: 0.7651 - val_precision_53: 0.0310 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 52.3688 - accuracy: 0.7857 - precision_53: 0.1909 - val_loss: 14.6447 - val_accuracy: 0.8414 - val_precision_53: 0.0210 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 38.8024 - accuracy: 0.7912 - precision_53: 0.1993 - val_loss: 13.5583 - val_accuracy: 0.9223 - val_precision_53: 0.0123 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 38.9690 - accuracy: 0.7991 - precision_53: 0.2119 - val_loss: 44.3475 - val_accuracy: 0.5935 - val_precision_53: 0.0548 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 40.8810 - accuracy: 0.7893 - precision_53: 0.2013 - val_loss: 17.9145 - val_accuracy: 0.9362 - val_precision_53: 0.0358 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 40.0022 - accuracy: 0.7983 - precision_53: 0.2122 - val_loss: 7.7348 - val_accuracy: 0.8400 - val_precision_53: 0.0419 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 34.9478 - accuracy: 0.7950 - precision_53: 0.2072 - val_loss: 5.4102 - val_accuracy: 0.9122 - val_precision_53: 0.0309 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 30.3058 - accuracy: 0.7965 - precision_53: 0.2076 - val_loss: 11.6439 - val_accuracy: 0.8424 - val_precision_53: 0.0195 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 44.7587 - accuracy: 0.7906 - precision_53: 0.2047 - val_loss: 47.1550 - val_accuracy: 0.8061 - val_precision_53: 0.0354 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 32.5827 - accuracy: 0.7969 - precision_53: 0.2197 - val_loss: 7.7001 - val_accuracy: 0.8433 - val_precision_53: 0.0289 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 42.4572 - accuracy: 0.7930 - precision_53: 0.2080 - val_loss: 16.9259 - val_accuracy: 0.9379 - val_precision_53: 0.0225 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 26.7100 - accuracy: 0.8013 - precision_53: 0.2133 - val_loss: 6.1959 - val_accuracy: 0.8303 - val_precision_53: 0.0301 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 20.3515 - accuracy: 0.8024 - precision_53: 0.2208 - val_loss: 24.0503 - val_accuracy: 0.8955 - val_precision_53: 0.0274 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 20.6204 - accuracy: 0.8048 - precision_53: 0.2233 - val_loss: 6.7270 - val_accuracy: 0.9267 - val_precision_53: 0.0268 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 27.3235 - accuracy: 0.7943 - precision_53: 0.2064 - val_loss: 10.3436 - val_accuracy: 0.9205 - val_precision_53: 0.0351 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.1351 - accuracy: 0.8064 - precision_53: 0.2196 - val_loss: 6.8015 - val_accuracy: 0.8750 - val_precision_53: 0.0235 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.5038 - accuracy: 0.8049 - precision_53: 0.2221 - val_loss: 32.8211 - val_accuracy: 0.6312 - val_precision_53: 0.0620 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 23.0915 - accuracy: 0.8015 - precision_53: 0.2161 - val_loss: 21.5585 - val_accuracy: 0.6147 - val_precision_53: 0.0589 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 20.6864 - accuracy: 0.8009 - precision_53: 0.2242 - val_loss: 10.7921 - val_accuracy: 0.8580 - val_precision_53: 0.0357 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 14.8489 - accuracy: 0.8024 - precision_53: 0.2157 - val_loss: 5.9217 - val_accuracy: 0.9093 - val_precision_53: 0.0157 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 12.7710 - accuracy: 0.8023 - precision_53: 0.2140 - val_loss: 37.5725 - val_accuracy: 0.4641 - val_precision_53: 0.0502 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 16.9264 - accuracy: 0.8047 - precision_53: 0.2286 - val_loss: 3.1713 - val_accuracy: 0.9004 - val_precision_53: 0.0222 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.4862 - accuracy: 0.8025 - precision_53: 0.2179 - val_loss: 3.6491 - val_accuracy: 0.7975 - val_precision_53: 0.0256 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.8595 - accuracy: 0.8076 - precision_53: 0.2219 - val_loss: 13.5388 - val_accuracy: 0.9122 - val_precision_53: 0.0139 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.8714 - accuracy: 0.8030 - precision_53: 0.2167 - val_loss: 6.2972 - val_accuracy: 0.9489 - val_precision_53: 0.0156 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.5593 - accuracy: 0.8033 - precision_53: 0.2117 - val_loss: 3.9600 - val_accuracy: 0.8119 - val_precision_53: 0.0210 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.5549 - accuracy: 0.8036 - precision_53: 0.2083 - val_loss: 2.5825 - val_accuracy: 0.8661 - val_precision_53: 0.0193 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.6894 - accuracy: 0.8088 - precision_53: 0.2112 - val_loss: 7.0001 - val_accuracy: 0.9149 - val_precision_53: 0.0147 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 8.4718 - accuracy: 0.8094 - precision_53: 0.2194 - val_loss: 10.6119 - val_accuracy: 0.4896 - val_precision_53: 0.0483 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.6953 - accuracy: 0.7992 - precision_53: 0.1992 - val_loss: 5.0714 - val_accuracy: 0.8819 - val_precision_53: 0.0044 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.7994 - accuracy: 0.8075 - precision_53: 0.2083 - val_loss: 7.9749 - val_accuracy: 0.6508 - val_precision_53: 0.0619 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.0768 - accuracy: 0.8064 - precision_53: 0.2085 - val_loss: 6.1443 - val_accuracy: 0.9200 - val_precision_53: 0.0132 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.2204 - accuracy: 0.8129 - precision_53: 0.2210 - val_loss: 1.5886 - val_accuracy: 0.7795 - val_precision_53: 0.0288 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.8841 - accuracy: 0.8092 - precision_53: 0.2096 - val_loss: 3.0720 - val_accuracy: 0.8605 - val_precision_53: 0.0035 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.5985 - accuracy: 0.8094 - precision_53: 0.2093 - val_loss: 4.8946 - val_accuracy: 0.6536 - val_precision_53: 0.0531 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.2210 - accuracy: 0.8114 - precision_53: 0.2092 - val_loss: 7.7938 - val_accuracy: 0.5518 - val_precision_53: 0.0526 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.9610 - accuracy: 0.8112 - precision_53: 0.2062 - val_loss: 3.0318 - val_accuracy: 0.9279 - val_precision_53: 0.0041 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 6.7091 - accuracy: 0.8103 - precision_53: 0.2132 - val_loss: 9.3368 - val_accuracy: 0.4589 - val_precision_53: 0.0486 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 5.1812 - accuracy: 0.8088 - precision_53: 0.2069 - val_loss: 1.9171 - val_accuracy: 0.9065 - val_precision_53: 0.0026 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.0164 - accuracy: 0.8124 - precision_53: 0.2070 - val_loss: 1.8504 - val_accuracy: 0.8899 - val_precision_53: 0.0049 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.5001 - accuracy: 0.8131 - precision_53: 0.2124 - val_loss: 1.0744 - val_accuracy: 0.7818 - val_precision_53: 0.0306 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.6995 - accuracy: 0.8152 - precision_53: 0.2145 - val_loss: 1.0238 - val_accuracy: 0.9044 - val_precision_53: 0.0145 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.6512 - accuracy: 0.8174 - precision_53: 0.2201 - val_loss: 2.9656 - val_accuracy: 0.6091 - val_precision_53: 0.0589 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.6374 - accuracy: 0.8151 - precision_53: 0.2085 - val_loss: 1.1446 - val_accuracy: 0.9085 - val_precision_53: 0.0092 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.6127 - accuracy: 0.8160 - precision_53: 0.2054 - val_loss: 3.1888 - val_accuracy: 0.6068 - val_precision_53: 0.0604 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.6427 - accuracy: 0.8170 - precision_53: 0.2115 - val_loss: 1.3213 - val_accuracy: 0.9402 - val_precision_53: 0.0032 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.4560 - accuracy: 0.8193 - precision_53: 0.2053 - val_loss: 0.6422 - val_accuracy: 0.8972 - val_precision_53: 0.0065 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2136 - accuracy: 0.8219 - precision_53: 0.2158 - val_loss: 0.5492 - val_accuracy: 0.9240 - val_precision_53: 0.0056 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1081 - accuracy: 0.8196 - precision_53: 0.2021 - val_loss: 0.5158 - val_accuracy: 0.9115 - val_precision_53: 0.0083 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2649 - accuracy: 0.8196 - precision_53: 0.1955 - val_loss: 0.5107 - val_accuracy: 0.9271 - val_precision_53: 0.0100 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1045 - accuracy: 0.8240 - precision_53: 0.2123 - val_loss: 0.3035 - val_accuracy: 0.9219 - val_precision_53: 0.0347 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7856 - accuracy: 0.8288 - precision_53: 0.2100 - val_loss: 0.3044 - val_accuracy: 0.9384 - val_precision_53: 0.0146 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7913 - accuracy: 0.8278 - precision_53: 0.2137 - val_loss: 0.4060 - val_accuracy: 0.8534 - val_precision_53: 0.0820 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.8292 - precision_53: 0.1970 - val_loss: 0.9447 - val_accuracy: 0.6793 - val_precision_53: 0.0695 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 20.0766 - accuracy: 0.8074 - precision_53: 0.1727 - val_loss: 7.3829 - val_accuracy: 0.9590 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.1761 - accuracy: 0.7934 - precision_53: 0.1687 - val_loss: 1.4227 - val_accuracy: 0.9591 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.2710 - accuracy: 0.8156 - precision_53: 0.1852 - val_loss: 0.8008 - val_accuracy: 0.9599 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.6703 - accuracy: 0.8115 - precision_53: 0.1744 - val_loss: 2.1546 - val_accuracy: 0.9607 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0568 - accuracy: 0.8228 - precision_53: 0.1756 - val_loss: 0.3333 - val_accuracy: 0.9600 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.8314 - precision_53: 0.1960 - val_loss: 0.4025 - val_accuracy: 0.8780 - val_precision_53: 0.0677 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.8376 - precision_53: 0.1983 - val_loss: 0.4177 - val_accuracy: 0.9608 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5024 - accuracy: 0.8421 - precision_53: 0.1938 - val_loss: 0.2874 - val_accuracy: 0.9569 - val_precision_53: 0.0889 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4502 - accuracy: 0.8478 - precision_53: 0.2031 - val_loss: 0.2757 - val_accuracy: 0.9584 - val_precision_53: 0.0923 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4414 - accuracy: 0.8496 - precision_53: 0.2048 - val_loss: 0.3004 - val_accuracy: 0.9615 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4905 - accuracy: 0.8415 - precision_53: 0.2059 - val_loss: 0.2780 - val_accuracy: 0.9553 - val_precision_53: 0.0789 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4449 - accuracy: 0.8480 - precision_53: 0.2068 - val_loss: 0.2682 - val_accuracy: 0.9610 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8542 - precision_53: 0.2336 - val_loss: 0.2485 - val_accuracy: 0.9618 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4769 - accuracy: 0.8444 - precision_53: 0.2053 - val_loss: 0.2496 - val_accuracy: 0.9595 - val_precision_53: 0.0256 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8519 - precision_53: 0.1996 - val_loss: 0.2528 - val_accuracy: 0.9591 - val_precision_53: 0.0943 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.8450 - precision_53: 0.2012 - val_loss: 0.3127 - val_accuracy: 0.9466 - val_precision_53: 0.0711 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.8457 - precision_53: 0.2093 - val_loss: 0.2355 - val_accuracy: 0.9610 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8530 - precision_53: 0.2183 - val_loss: 0.2436 - val_accuracy: 0.9592 - val_precision_53: 0.0444 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8535 - precision_53: 0.2176 - val_loss: 0.2421 - val_accuracy: 0.9617 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8490 - precision_53: 0.2151 - val_loss: 0.2485 - val_accuracy: 0.9568 - val_precision_53: 0.0370 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4417 - accuracy: 0.8477 - precision_53: 0.2186 - val_loss: 0.2626 - val_accuracy: 0.9530 - val_precision_53: 0.0493 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8539 - precision_53: 0.2297 - val_loss: 0.2390 - val_accuracy: 0.9616 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.8452 - precision_53: 0.1955 - val_loss: 0.2646 - val_accuracy: 0.9508 - val_precision_53: 0.0405 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.5548 - accuracy: 0.8416 - precision_53: 0.2156 - val_loss: 0.3264 - val_accuracy: 0.9582 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 14.8419 - accuracy: 0.8044 - precision_53: 0.1706 - val_loss: 0.6230 - val_accuracy: 0.9612 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.7039 - accuracy: 0.8143 - precision_53: 0.1704 - val_loss: 0.5768 - val_accuracy: 0.9562 - val_precision_53: 0.0227 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.8252 - accuracy: 0.8280 - precision_53: 0.1740 - val_loss: 0.4367 - val_accuracy: 0.9428 - val_precision_53: 0.0752 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.8344 - precision_53: 0.1777 - val_loss: 0.2689 - val_accuracy: 0.9578 - val_precision_53: 0.0448 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8504 - precision_53: 0.1874 - val_loss: 0.2467 - val_accuracy: 0.9618 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8484 - precision_53: 0.1994 - val_loss: 0.3046 - val_accuracy: 0.9530 - val_precision_53: 0.1701 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8569 - precision_53: 0.1905 - val_loss: 0.2498 - val_accuracy: 0.9612 - val_precision_53: 0.0625 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4003 - accuracy: 0.8574 - precision_53: 0.2131 - val_loss: 0.3241 - val_accuracy: 0.9403 - val_precision_53: 0.1856 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4010 - accuracy: 0.8557 - precision_53: 0.2039 - val_loss: 0.2667 - val_accuracy: 0.9577 - val_precision_53: 0.0303 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4457 - accuracy: 0.8497 - precision_53: 0.2201 - val_loss: 0.2708 - val_accuracy: 0.9610 - val_precision_53: 0.1364 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4343 - accuracy: 0.8484 - precision_53: 0.1891 - val_loss: 0.4170 - val_accuracy: 0.8701 - val_precision_53: 0.1127 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 8.4566 - accuracy: 0.8069 - precision_53: 0.1637 - val_loss: 0.9814 - val_accuracy: 0.9204 - val_precision_53: 0.0291 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1356 - accuracy: 0.8209 - precision_53: 0.1703 - val_loss: 0.3049 - val_accuracy: 0.9594 - val_precision_53: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8567 - precision_53: 0.1839 - val_loss: 0.2607 - val_accuracy: 0.9491 - val_precision_53: 0.0054 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3885 - accuracy: 0.8603 - precision_53: 0.2553 - val_loss: 0.2732 - val_accuracy: 0.9570 - val_precision_53: 0.0135 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8609 - precision_53: 0.2783 - val_loss: 0.2832 - val_accuracy: 0.9499 - val_precision_53: 0.0169 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8542 - precision_53: 0.2326 - val_loss: 0.3417 - val_accuracy: 0.9186 - val_precision_53: 0.1455 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 6ms/step - loss: 99.8557 - accuracy: 0.7538 - precision_54: 0.1504 - val_loss: 11.9946 - val_accuracy: 0.9274 - val_precision_54: 0.0474 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 42.8548 - accuracy: 0.7777 - precision_54: 0.1688 - val_loss: 50.0685 - val_accuracy: 0.7080 - val_precision_54: 0.0287 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 42.1360 - accuracy: 0.7753 - precision_54: 0.1668 - val_loss: 12.0806 - val_accuracy: 0.8110 - val_precision_54: 0.0320 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 32.6805 - accuracy: 0.7828 - precision_54: 0.1842 - val_loss: 20.9456 - val_accuracy: 0.9518 - val_precision_54: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 34.5720 - accuracy: 0.7841 - precision_54: 0.1833 - val_loss: 15.5381 - val_accuracy: 0.9446 - val_precision_54: 0.0163 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 29.5449 - accuracy: 0.7831 - precision_54: 0.1802 - val_loss: 8.7343 - val_accuracy: 0.9160 - val_precision_54: 0.0167 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 23.6541 - accuracy: 0.7962 - precision_54: 0.2029 - val_loss: 23.5122 - val_accuracy: 0.8994 - val_precision_54: 0.0241 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 24.0405 - accuracy: 0.7960 - precision_54: 0.2042 - val_loss: 4.9968 - val_accuracy: 0.8186 - val_precision_54: 0.0270 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 23.7080 - accuracy: 0.7915 - precision_54: 0.1924 - val_loss: 7.6643 - val_accuracy: 0.8838 - val_precision_54: 0.0437 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 20.9799 - accuracy: 0.7997 - precision_54: 0.2071 - val_loss: 6.4003 - val_accuracy: 0.7809 - val_precision_54: 0.0594 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 22.4649 - accuracy: 0.7976 - precision_54: 0.2036 - val_loss: 12.6001 - val_accuracy: 0.7702 - val_precision_54: 0.0367 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 21.4276 - accuracy: 0.7963 - precision_54: 0.1958 - val_loss: 14.2703 - val_accuracy: 0.9520 - val_precision_54: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 18.9209 - accuracy: 0.8018 - precision_54: 0.2038 - val_loss: 4.9114 - val_accuracy: 0.8913 - val_precision_54: 0.0306 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 22.4504 - accuracy: 0.7970 - precision_54: 0.1991 - val_loss: 4.9048 - val_accuracy: 0.8534 - val_precision_54: 0.0257 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 14.2393 - accuracy: 0.8040 - precision_54: 0.2129 - val_loss: 8.6477 - val_accuracy: 0.6797 - val_precision_54: 0.0619 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 11.1707 - accuracy: 0.8079 - precision_54: 0.2144 - val_loss: 3.4101 - val_accuracy: 0.8741 - val_precision_54: 0.0151 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.6809 - accuracy: 0.8015 - precision_54: 0.1993 - val_loss: 24.1115 - val_accuracy: 0.9578 - val_precision_54: 0.0182 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.3178 - accuracy: 0.8019 - precision_54: 0.1997 - val_loss: 3.8911 - val_accuracy: 0.9031 - val_precision_54: 0.0188 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.1185 - accuracy: 0.8085 - precision_54: 0.2071 - val_loss: 7.1532 - val_accuracy: 0.9246 - val_precision_54: 0.0057 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 15.9760 - accuracy: 0.8066 - precision_54: 0.2084 - val_loss: 10.3444 - val_accuracy: 0.4680 - val_precision_54: 0.0519 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 10.2103 - accuracy: 0.8096 - precision_54: 0.2137 - val_loss: 17.6271 - val_accuracy: 0.6396 - val_precision_54: 0.0590 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.1383 - accuracy: 0.8072 - precision_54: 0.2102 - val_loss: 11.8900 - val_accuracy: 0.6412 - val_precision_54: 0.0622 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.7486 - accuracy: 0.8090 - precision_54: 0.2152 - val_loss: 8.0868 - val_accuracy: 0.6482 - val_precision_54: 0.0560 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.4347 - accuracy: 0.8081 - precision_54: 0.2110 - val_loss: 6.1932 - val_accuracy: 0.9373 - val_precision_54: 0.0087 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.1041 - accuracy: 0.8085 - precision_54: 0.2075 - val_loss: 4.5380 - val_accuracy: 0.9124 - val_precision_54: 0.0128 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.1525 - accuracy: 0.8122 - precision_54: 0.2195 - val_loss: 3.2874 - val_accuracy: 0.8601 - val_precision_54: 0.0286 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.2217 - accuracy: 0.8096 - precision_54: 0.2074 - val_loss: 2.3718 - val_accuracy: 0.8661 - val_precision_54: 0.0229 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.2024 - accuracy: 0.8131 - precision_54: 0.2253 - val_loss: 9.2345 - val_accuracy: 0.6340 - val_precision_54: 0.0620 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.2511 - accuracy: 0.8069 - precision_54: 0.2096 - val_loss: 6.3123 - val_accuracy: 0.9480 - val_precision_54: 0.0153 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.5394 - accuracy: 0.8094 - precision_54: 0.2051 - val_loss: 3.7060 - val_accuracy: 0.9183 - val_precision_54: 0.0206 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.5160 - accuracy: 0.8103 - precision_54: 0.1935 - val_loss: 2.6195 - val_accuracy: 0.8919 - val_precision_54: 0.0188 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.9869 - accuracy: 0.8104 - precision_54: 0.2080 - val_loss: 3.9599 - val_accuracy: 0.9162 - val_precision_54: 0.0197 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.6810 - accuracy: 0.8122 - precision_54: 0.2085 - val_loss: 1.9126 - val_accuracy: 0.7961 - val_precision_54: 0.0495 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.5664 - accuracy: 0.8141 - precision_54: 0.2179 - val_loss: 6.4898 - val_accuracy: 0.9505 - val_precision_54: 0.0064 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.6302 - accuracy: 0.8108 - precision_54: 0.2005 - val_loss: 2.3248 - val_accuracy: 0.9029 - val_precision_54: 0.0154 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.0552 - accuracy: 0.8143 - precision_54: 0.2122 - val_loss: 1.4476 - val_accuracy: 0.8713 - val_precision_54: 0.0263 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.5608 - accuracy: 0.8147 - precision_54: 0.2190 - val_loss: 1.4056 - val_accuracy: 0.8217 - val_precision_54: 0.0383 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 4.0719 - accuracy: 0.8125 - precision_54: 0.2132 - val_loss: 2.3172 - val_accuracy: 0.9286 - val_precision_54: 0.0064 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.0531 - accuracy: 0.8119 - precision_54: 0.2096 - val_loss: 1.2933 - val_accuracy: 0.8742 - val_precision_54: 0.0212 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 3.1316 - accuracy: 0.8150 - precision_54: 0.2132 - val_loss: 1.7799 - val_accuracy: 0.7952 - val_precision_54: 0.0303 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.3597 - accuracy: 0.8145 - precision_54: 0.2155 - val_loss: 2.6258 - val_accuracy: 0.6928 - val_precision_54: 0.0544 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 3.0333 - accuracy: 0.8119 - precision_54: 0.2085 - val_loss: 1.6893 - val_accuracy: 0.8987 - val_precision_54: 0.0239 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.0580 - accuracy: 0.8153 - precision_54: 0.2157 - val_loss: 1.4031 - val_accuracy: 0.9272 - val_precision_54: 0.0181 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.8310 - accuracy: 0.8134 - precision_54: 0.2145 - val_loss: 1.8859 - val_accuracy: 0.8636 - val_precision_54: 0.0149 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.8124 - accuracy: 0.8161 - precision_54: 0.2168 - val_loss: 0.8656 - val_accuracy: 0.8432 - val_precision_54: 0.0317 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.1856 - accuracy: 0.8166 - precision_54: 0.2170 - val_loss: 2.0565 - val_accuracy: 0.9449 - val_precision_54: 0.0166 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.0395 - accuracy: 0.8169 - precision_54: 0.2182 - val_loss: 0.8841 - val_accuracy: 0.8385 - val_precision_54: 0.0530 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.7536 - accuracy: 0.8173 - precision_54: 0.2245 - val_loss: 0.7364 - val_accuracy: 0.8609 - val_precision_54: 0.0393 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.5298 - accuracy: 0.8220 - precision_54: 0.2374 - val_loss: 0.5856 - val_accuracy: 0.8836 - val_precision_54: 0.0134 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.4205 - accuracy: 0.8224 - precision_54: 0.2466 - val_loss: 0.9922 - val_accuracy: 0.9495 - val_precision_54: 0.0058 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1749 - accuracy: 0.8230 - precision_54: 0.2339 - val_loss: 0.7755 - val_accuracy: 0.7612 - val_precision_54: 0.0606 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.4312 - accuracy: 0.8208 - precision_54: 0.2344 - val_loss: 1.5937 - val_accuracy: 0.7332 - val_precision_54: 0.0458 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.1153 - accuracy: 0.8232 - precision_54: 0.2372 - val_loss: 1.0133 - val_accuracy: 0.7325 - val_precision_54: 0.0652 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0306 - accuracy: 0.8242 - precision_54: 0.2464 - val_loss: 0.4871 - val_accuracy: 0.8921 - val_precision_54: 0.0354 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9708 - accuracy: 0.8251 - precision_54: 0.2390 - val_loss: 0.7335 - val_accuracy: 0.7707 - val_precision_54: 0.0675 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7714 - accuracy: 0.8294 - precision_54: 0.2582 - val_loss: 0.3851 - val_accuracy: 0.8681 - val_precision_54: 0.0478 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7603 - accuracy: 0.8320 - precision_54: 0.2582 - val_loss: 0.3233 - val_accuracy: 0.9105 - val_precision_54: 0.0470 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.8301 - precision_54: 0.2512 - val_loss: 0.5216 - val_accuracy: 0.8188 - val_precision_54: 0.0676 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.8368 - precision_54: 0.2705 - val_loss: 0.5230 - val_accuracy: 0.9477 - val_precision_54: 0.0051 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6650 - accuracy: 0.8315 - precision_54: 0.2501 - val_loss: 0.4519 - val_accuracy: 0.8530 - val_precision_54: 0.0428 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.8390 - precision_54: 0.2743 - val_loss: 0.3560 - val_accuracy: 0.9369 - val_precision_54: 0.0325 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6768 - accuracy: 0.8339 - precision_54: 0.2579 - val_loss: 0.3034 - val_accuracy: 0.9460 - val_precision_54: 0.0498 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7368 - accuracy: 0.8290 - precision_54: 0.2333 - val_loss: 0.6362 - val_accuracy: 0.8240 - val_precision_54: 0.0792 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.6794 - accuracy: 0.8310 - precision_54: 0.2346 - val_loss: 0.3584 - val_accuracy: 0.9513 - val_precision_54: 0.0201 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.8335 - precision_54: 0.2362 - val_loss: 0.3098 - val_accuracy: 0.9432 - val_precision_54: 0.0187 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5087 - accuracy: 0.8413 - precision_54: 0.2649 - val_loss: 0.3603 - val_accuracy: 0.8984 - val_precision_54: 0.0298 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.8462 - precision_54: 0.2718 - val_loss: 0.2774 - val_accuracy: 0.9414 - val_precision_54: 0.0237 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.8445 - precision_54: 0.2694 - val_loss: 0.2962 - val_accuracy: 0.9266 - val_precision_54: 0.0216 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.7244 - accuracy: 0.8359 - precision_54: 0.2436 - val_loss: 0.4003 - val_accuracy: 0.9213 - val_precision_54: 0.0511 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.8487 - precision_54: 0.2899 - val_loss: 0.2981 - val_accuracy: 0.9347 - val_precision_54: 0.0482 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8512 - precision_54: 0.3008 - val_loss: 0.2645 - val_accuracy: 0.9428 - val_precision_54: 0.0184 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7039 - accuracy: 0.8376 - precision_54: 0.2415 - val_loss: 0.2995 - val_accuracy: 0.9233 - val_precision_54: 0.0412 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4172 - accuracy: 0.8552 - precision_54: 0.3363 - val_loss: 0.2810 - val_accuracy: 0.9379 - val_precision_54: 0.0285 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8543 - precision_54: 0.3087 - val_loss: 0.3309 - val_accuracy: 0.8984 - val_precision_54: 0.0453 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8543 - precision_54: 0.3259 - val_loss: 0.2748 - val_accuracy: 0.9300 - val_precision_54: 0.0067 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8583 - precision_54: 0.3838 - val_loss: 0.2983 - val_accuracy: 0.9102 - val_precision_54: 0.0467 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3889 - accuracy: 0.8594 - precision_54: 0.4002 - val_loss: 0.2875 - val_accuracy: 0.9317 - val_precision_54: 0.0356 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.8420 - precision_54: 0.2613 - val_loss: 0.8442 - val_accuracy: 0.9400 - val_precision_54: 0.0033 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 9.6985 - accuracy: 0.8069 - precision_54: 0.1626 - val_loss: 2.0211 - val_accuracy: 0.9505 - val_precision_54: 0.0359 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.5779 - accuracy: 0.8080 - precision_54: 0.1605 - val_loss: 0.8087 - val_accuracy: 0.9536 - val_precision_54: 0.0088 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6971 - accuracy: 0.8297 - precision_54: 0.1844 - val_loss: 0.2968 - val_accuracy: 0.9405 - val_precision_54: 0.0132 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.8494 - precision_54: 0.2332 - val_loss: 0.2900 - val_accuracy: 0.9374 - val_precision_54: 0.0058 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3922 - accuracy: 0.8595 - precision_54: 0.3170 - val_loss: 0.2589 - val_accuracy: 0.9513 - val_precision_54: 0.0135 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3888 - accuracy: 0.8578 - precision_54: 0.2827 - val_loss: 0.2927 - val_accuracy: 0.9392 - val_precision_54: 0.0032 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3981 - accuracy: 0.8577 - precision_54: 0.2976 - val_loss: 0.3080 - val_accuracy: 0.9255 - val_precision_54: 0.0078 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3854 - accuracy: 0.8592 - precision_54: 0.3173 - val_loss: 0.2602 - val_accuracy: 0.9532 - val_precision_54: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3865 - accuracy: 0.8597 - precision_54: 0.3290 - val_loss: 0.3394 - val_accuracy: 0.9197 - val_precision_54: 0.1302 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3762 - accuracy: 0.8617 - precision_54: 0.4101 - val_loss: 0.3169 - val_accuracy: 0.9278 - val_precision_54: 0.1358 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8617 - precision_54: 0.4167 - val_loss: 0.2432 - val_accuracy: 0.9542 - val_precision_54: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8599 - precision_54: 0.3573 - val_loss: 0.2649 - val_accuracy: 0.9539 - val_precision_54: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3729 - accuracy: 0.8611 - precision_54: 0.3926 - val_loss: 0.2600 - val_accuracy: 0.9445 - val_precision_54: 0.0386 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3780 - accuracy: 0.8615 - precision_54: 0.4186 - val_loss: 0.2454 - val_accuracy: 0.9533 - val_precision_54: 0.0085 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.8623 - precision_54: 0.4499 - val_loss: 0.2672 - val_accuracy: 0.9505 - val_precision_54: 0.0247 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8575 - precision_54: 0.3288 - val_loss: 0.2878 - val_accuracy: 0.9376 - val_precision_54: 0.0308 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8616 - precision_54: 0.4258 - val_loss: 0.2576 - val_accuracy: 0.9491 - val_precision_54: 0.0112 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8604 - precision_54: 0.3879 - val_loss: 0.2635 - val_accuracy: 0.9349 - val_precision_54: 0.0131 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8621 - precision_54: 0.4528 - val_loss: 0.3083 - val_accuracy: 0.9247 - val_precision_54: 0.0240 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8615 - precision_54: 0.4217 - val_loss: 0.2847 - val_accuracy: 0.9275 - val_precision_54: 0.0103 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2155 - accuracy: 0.8487 - precision_54: 0.2603 - val_loss: 9.2470 - val_accuracy: 0.5550 - val_precision_54: 0.0611 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.4337 - accuracy: 0.8233 - precision_54: 0.1877 - val_loss: 0.2732 - val_accuracy: 0.9480 - val_precision_54: 0.0052 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 6ms/step - loss: 245.0044 - accuracy: 0.7756 - precision_55: 0.1601 - val_loss: 16.9149 - val_accuracy: 0.8314 - val_precision_55: 0.0364 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 78.1189 - accuracy: 0.7832 - precision_55: 0.1802 - val_loss: 26.0444 - val_accuracy: 0.5340 - val_precision_55: 0.0498 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 87.3586 - accuracy: 0.7867 - precision_55: 0.1916 - val_loss: 17.0078 - val_accuracy: 0.7617 - val_precision_55: 0.0478 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 77.6474 - accuracy: 0.7859 - precision_55: 0.1887 - val_loss: 21.3005 - val_accuracy: 0.8543 - val_precision_55: 0.0261 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 104.4433 - accuracy: 0.7923 - precision_55: 0.2021 - val_loss: 33.8688 - val_accuracy: 0.9282 - val_precision_55: 0.0169 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 45.2997 - accuracy: 0.7942 - precision_55: 0.2080 - val_loss: 21.8934 - val_accuracy: 0.8474 - val_precision_55: 0.0308 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 84.1012 - accuracy: 0.7954 - precision_55: 0.2009 - val_loss: 14.2345 - val_accuracy: 0.8459 - val_precision_55: 0.0304 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 76.7703 - accuracy: 0.7981 - precision_55: 0.2025 - val_loss: 240.9982 - val_accuracy: 0.5461 - val_precision_55: 0.0586 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 67.7937 - accuracy: 0.7944 - precision_55: 0.2041 - val_loss: 11.3302 - val_accuracy: 0.8724 - val_precision_55: 0.0289 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 30.5871 - accuracy: 0.7980 - precision_55: 0.2119 - val_loss: 41.5902 - val_accuracy: 0.9444 - val_precision_55: 0.0208 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 35.9025 - accuracy: 0.8041 - precision_55: 0.2221 - val_loss: 81.2923 - val_accuracy: 0.5715 - val_precision_55: 0.0600 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 35.7908 - accuracy: 0.8003 - precision_55: 0.2090 - val_loss: 30.9249 - val_accuracy: 0.5808 - val_precision_55: 0.0583 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 31.8852 - accuracy: 0.8021 - precision_55: 0.2167 - val_loss: 24.2317 - val_accuracy: 0.9150 - val_precision_55: 0.0294 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 32.3793 - accuracy: 0.7981 - precision_55: 0.2065 - val_loss: 15.3236 - val_accuracy: 0.9325 - val_precision_55: 0.0050 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 39.2507 - accuracy: 0.7998 - precision_55: 0.2112 - val_loss: 14.5988 - val_accuracy: 0.8642 - val_precision_55: 0.0286 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 26.6741 - accuracy: 0.8020 - precision_55: 0.2118 - val_loss: 8.9868 - val_accuracy: 0.8636 - val_precision_55: 0.0310 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 26.8575 - accuracy: 0.7989 - precision_55: 0.2162 - val_loss: 19.0607 - val_accuracy: 0.9106 - val_precision_55: 0.0165 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 33.6912 - accuracy: 0.8055 - precision_55: 0.2213 - val_loss: 17.4727 - val_accuracy: 0.9042 - val_precision_55: 0.0240 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 57.4532 - accuracy: 0.7987 - precision_55: 0.2048 - val_loss: 13.7052 - val_accuracy: 0.8955 - val_precision_55: 0.0259 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 22.2720 - accuracy: 0.8013 - precision_55: 0.2195 - val_loss: 9.7553 - val_accuracy: 0.8863 - val_precision_55: 0.0246 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 26.1501 - accuracy: 0.8016 - precision_55: 0.2170 - val_loss: 5.1704 - val_accuracy: 0.8897 - val_precision_55: 0.0266 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 22.7475 - accuracy: 0.8018 - precision_55: 0.2169 - val_loss: 8.7410 - val_accuracy: 0.7052 - val_precision_55: 0.0665 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 30.0640 - accuracy: 0.8032 - precision_55: 0.2175 - val_loss: 20.4141 - val_accuracy: 0.5554 - val_precision_55: 0.0570 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 28.0010 - accuracy: 0.8078 - precision_55: 0.2289 - val_loss: 9.7847 - val_accuracy: 0.8788 - val_precision_55: 0.0295 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.2667 - accuracy: 0.8063 - precision_55: 0.2293 - val_loss: 12.0104 - val_accuracy: 0.9282 - val_precision_55: 0.0384 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 35.1646 - accuracy: 0.8049 - precision_55: 0.2169 - val_loss: 10.0560 - val_accuracy: 0.7013 - val_precision_55: 0.0699 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 18.0306 - accuracy: 0.8011 - precision_55: 0.2241 - val_loss: 17.4760 - val_accuracy: 0.8840 - val_precision_55: 0.0402 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.9122 - accuracy: 0.8082 - precision_55: 0.2256 - val_loss: 52.8882 - val_accuracy: 0.5230 - val_precision_55: 0.0574 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 17.5736 - accuracy: 0.8084 - precision_55: 0.2280 - val_loss: 3.7748 - val_accuracy: 0.8290 - val_precision_55: 0.0247 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 35.5369 - accuracy: 0.8021 - precision_55: 0.2160 - val_loss: 5.4538 - val_accuracy: 0.7554 - val_precision_55: 0.0344 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 23.5386 - accuracy: 0.8073 - precision_55: 0.2287 - val_loss: 13.4125 - val_accuracy: 0.9416 - val_precision_55: 0.0439 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 21.0261 - accuracy: 0.8085 - precision_55: 0.2325 - val_loss: 4.2698 - val_accuracy: 0.7833 - val_precision_55: 0.0431 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 12.8286 - accuracy: 0.8101 - precision_55: 0.2384 - val_loss: 42.0316 - val_accuracy: 0.5386 - val_precision_55: 0.0598 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 19.3376 - accuracy: 0.8068 - precision_55: 0.2260 - val_loss: 5.2227 - val_accuracy: 0.8434 - val_precision_55: 0.0265 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 26.6814 - accuracy: 0.8081 - precision_55: 0.2287 - val_loss: 3.1253 - val_accuracy: 0.7742 - val_precision_55: 0.0326 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 18.9498 - accuracy: 0.8056 - precision_55: 0.2298 - val_loss: 5.1704 - val_accuracy: 0.9259 - val_precision_55: 0.0178 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 23.3926 - accuracy: 0.8103 - precision_55: 0.2337 - val_loss: 10.0696 - val_accuracy: 0.9217 - val_precision_55: 0.0387 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.9645 - accuracy: 0.8069 - precision_55: 0.2321 - val_loss: 3.1747 - val_accuracy: 0.7755 - val_precision_55: 0.0318 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.8224 - accuracy: 0.8099 - precision_55: 0.2379 - val_loss: 4.6119 - val_accuracy: 0.8964 - val_precision_55: 0.0182 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.1133 - accuracy: 0.8068 - precision_55: 0.2302 - val_loss: 7.6728 - val_accuracy: 0.8529 - val_precision_55: 0.0357 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 20.7282 - accuracy: 0.8049 - precision_55: 0.2223 - val_loss: 21.1841 - val_accuracy: 0.5267 - val_precision_55: 0.0552 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 19.2285 - accuracy: 0.8071 - precision_55: 0.2308 - val_loss: 2.1268 - val_accuracy: 0.8110 - val_precision_55: 0.0262 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 17.6996 - accuracy: 0.8081 - precision_55: 0.2265 - val_loss: 2.8958 - val_accuracy: 0.7835 - val_precision_55: 0.0345 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 15.8322 - accuracy: 0.8066 - precision_55: 0.2296 - val_loss: 11.8027 - val_accuracy: 0.9166 - val_precision_55: 0.0246 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.1820 - accuracy: 0.8103 - precision_55: 0.2412 - val_loss: 4.8433 - val_accuracy: 0.6699 - val_precision_55: 0.0539 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 13.9637 - accuracy: 0.8106 - precision_55: 0.2436 - val_loss: 5.7832 - val_accuracy: 0.7517 - val_precision_55: 0.0690 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.6543 - accuracy: 0.8104 - precision_55: 0.2381 - val_loss: 6.4064 - val_accuracy: 0.9139 - val_precision_55: 0.0246 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.6030 - accuracy: 0.8080 - precision_55: 0.2314 - val_loss: 3.5151 - val_accuracy: 0.8416 - val_precision_55: 0.0262 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.5636 - accuracy: 0.8120 - precision_55: 0.2419 - val_loss: 1.5587 - val_accuracy: 0.8033 - val_precision_55: 0.0385 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.9746 - accuracy: 0.8122 - precision_55: 0.2473 - val_loss: 2.6912 - val_accuracy: 0.8268 - val_precision_55: 0.0205 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 11.5868 - accuracy: 0.8105 - precision_55: 0.2371 - val_loss: 11.7201 - val_accuracy: 0.5363 - val_precision_55: 0.0574 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.7551 - accuracy: 0.8104 - precision_55: 0.2348 - val_loss: 4.2297 - val_accuracy: 0.9051 - val_precision_55: 0.0221 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.9527 - accuracy: 0.8130 - precision_55: 0.2483 - val_loss: 2.0579 - val_accuracy: 0.8398 - val_precision_55: 0.0351 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.9246 - accuracy: 0.8157 - precision_55: 0.2471 - val_loss: 3.1823 - val_accuracy: 0.8929 - val_precision_55: 0.0093 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 8.5309 - accuracy: 0.8123 - precision_55: 0.2416 - val_loss: 4.5047 - val_accuracy: 0.6181 - val_precision_55: 0.0640 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 7.0667 - accuracy: 0.8140 - precision_55: 0.2512 - val_loss: 5.5688 - val_accuracy: 0.9020 - val_precision_55: 0.0513 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 8.7813 - accuracy: 0.8163 - precision_55: 0.2482 - val_loss: 5.9159 - val_accuracy: 0.9039 - val_precision_55: 0.0339 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 11.9072 - accuracy: 0.8101 - precision_55: 0.2312 - val_loss: 7.7200 - val_accuracy: 0.5962 - val_precision_55: 0.0629 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.2548 - accuracy: 0.8118 - precision_55: 0.2469 - val_loss: 5.3799 - val_accuracy: 0.6476 - val_precision_55: 0.0648 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.5791 - accuracy: 0.8141 - precision_55: 0.2575 - val_loss: 3.5279 - val_accuracy: 0.8760 - val_precision_55: 0.0202 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.9448 - accuracy: 0.8166 - precision_55: 0.2536 - val_loss: 5.5784 - val_accuracy: 0.6306 - val_precision_55: 0.0634 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 12.0170 - accuracy: 0.8129 - precision_55: 0.2377 - val_loss: 1.9538 - val_accuracy: 0.8848 - val_precision_55: 0.0056 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.7282 - accuracy: 0.8219 - precision_55: 0.2705 - val_loss: 4.1182 - val_accuracy: 0.8589 - val_precision_55: 0.0493 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.6487 - accuracy: 0.8149 - precision_55: 0.2537 - val_loss: 1.9732 - val_accuracy: 0.8751 - val_precision_55: 0.0122 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 4.1391 - accuracy: 0.8165 - precision_55: 0.2471 - val_loss: 11.7173 - val_accuracy: 0.5622 - val_precision_55: 0.0597 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.6803 - accuracy: 0.8192 - precision_55: 0.2633 - val_loss: 11.3430 - val_accuracy: 0.5345 - val_precision_55: 0.0569 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.1731 - accuracy: 0.8170 - precision_55: 0.2541 - val_loss: 3.3049 - val_accuracy: 0.9182 - val_precision_55: 0.0033 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.1083 - accuracy: 0.8180 - precision_55: 0.2561 - val_loss: 5.1689 - val_accuracy: 0.5890 - val_precision_55: 0.0583 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.2085 - accuracy: 0.8156 - precision_55: 0.2505 - val_loss: 1.0983 - val_accuracy: 0.9157 - val_precision_55: 0.0047 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.7129 - accuracy: 0.8205 - precision_55: 0.2667 - val_loss: 2.5622 - val_accuracy: 0.9386 - val_precision_55: 0.0032 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.3453 - accuracy: 0.8227 - precision_55: 0.2754 - val_loss: 1.0674 - val_accuracy: 0.8934 - val_precision_55: 0.0052 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.7838 - accuracy: 0.8192 - precision_55: 0.2631 - val_loss: 0.9466 - val_accuracy: 0.7959 - val_precision_55: 0.0377 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.8854 - accuracy: 0.8228 - precision_55: 0.2736 - val_loss: 2.3212 - val_accuracy: 0.6654 - val_precision_55: 0.0656 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.5486 - accuracy: 0.8221 - precision_55: 0.2759 - val_loss: 0.7299 - val_accuracy: 0.9193 - val_precision_55: 0.0101 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2936 - accuracy: 0.8257 - precision_55: 0.2821 - val_loss: 0.8184 - val_accuracy: 0.8881 - val_precision_55: 0.0180 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.6834 - accuracy: 0.8215 - precision_55: 0.2687 - val_loss: 0.6107 - val_accuracy: 0.8404 - val_precision_55: 0.0270 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.2132 - accuracy: 0.8232 - precision_55: 0.2728 - val_loss: 0.8953 - val_accuracy: 0.9010 - val_precision_55: 0.0162 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.3051 - accuracy: 0.8234 - precision_55: 0.2751 - val_loss: 0.5049 - val_accuracy: 0.8941 - val_precision_55: 0.0254 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.9760 - accuracy: 0.8282 - precision_55: 0.2849 - val_loss: 0.8725 - val_accuracy: 0.9423 - val_precision_55: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.8237 - accuracy: 0.8279 - precision_55: 0.2866 - val_loss: 0.6582 - val_accuracy: 0.8273 - val_precision_55: 0.0321 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7657 - accuracy: 0.8304 - precision_55: 0.2878 - val_loss: 0.4788 - val_accuracy: 0.7877 - val_precision_55: 0.0778 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.6337 - accuracy: 0.8340 - precision_55: 0.2974 - val_loss: 0.4580 - val_accuracy: 0.9122 - val_precision_55: 0.0072 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.8369 - precision_55: 0.2987 - val_loss: 0.4168 - val_accuracy: 0.8888 - val_precision_55: 0.0376 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.8369 - precision_55: 0.2983 - val_loss: 0.3679 - val_accuracy: 0.8913 - val_precision_55: 0.0354 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.8444 - precision_55: 0.3270 - val_loss: 0.5448 - val_accuracy: 0.7793 - val_precision_55: 0.0566 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.8461 - precision_55: 0.3363 - val_loss: 0.3611 - val_accuracy: 0.9425 - val_precision_55: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.8479 - precision_55: 0.3474 - val_loss: 0.3415 - val_accuracy: 0.9000 - val_precision_55: 0.0905 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.8402 - precision_55: 0.3087 - val_loss: 0.4606 - val_accuracy: 0.8326 - val_precision_55: 0.0789 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8567 - precision_55: 0.4094 - val_loss: 0.2889 - val_accuracy: 0.9250 - val_precision_55: 0.0173 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.8511 - precision_55: 0.3632 - val_loss: 0.5641 - val_accuracy: 0.7546 - val_precision_55: 0.0835 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.8391 - precision_55: 0.3062 - val_loss: 0.3275 - val_accuracy: 0.9283 - val_precision_55: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5321 - accuracy: 0.8426 - precision_55: 0.3135 - val_loss: 0.5607 - val_accuracy: 0.9058 - val_precision_55: 0.0188 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.5172 - accuracy: 0.8433 - precision_55: 0.3198 - val_loss: 0.3025 - val_accuracy: 0.9263 - val_precision_55: 0.0021 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.8405 - precision_55: 0.3076 - val_loss: 0.3311 - val_accuracy: 0.9054 - val_precision_55: 0.0359 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3883 - accuracy: 0.8607 - precision_55: 0.4554 - val_loss: 0.2679 - val_accuracy: 0.9423 - val_precision_55: 0.0076 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.8463 - precision_55: 0.3252 - val_loss: 0.3648 - val_accuracy: 0.9564 - val_precision_55: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 5.8124 - accuracy: 0.8142 - precision_55: 0.2397 - val_loss: 1.2368 - val_accuracy: 0.9241 - val_precision_55: 0.0133 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0048 - accuracy: 0.8326 - precision_55: 0.2767 - val_loss: 0.4096 - val_accuracy: 0.8949 - val_precision_55: 0.0198 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.8498 - precision_55: 0.3521 - val_loss: 0.2890 - val_accuracy: 0.9283 - val_precision_55: 0.0128 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8611 - precision_55: 0.4654 - val_loss: 0.3490 - val_accuracy: 0.8964 - val_precision_55: 0.0389 - lr: 0.0010\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Training on fold 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 2s 7ms/step - loss: 152.3674 - accuracy: 0.7649 - precision_56: 0.1478 - val_loss: 33.9453 - val_accuracy: 0.8574 - val_precision_56: 0.0219 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 100.9188 - accuracy: 0.7781 - precision_56: 0.1622 - val_loss: 59.2897 - val_accuracy: 0.6393 - val_precision_56: 0.0195 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 73.7469 - accuracy: 0.7801 - precision_56: 0.1757 - val_loss: 98.2371 - val_accuracy: 0.9516 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 73.8268 - accuracy: 0.7820 - precision_56: 0.1820 - val_loss: 20.1906 - val_accuracy: 0.8558 - val_precision_56: 0.0314 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 69.2603 - accuracy: 0.7882 - precision_56: 0.1905 - val_loss: 15.9836 - val_accuracy: 0.7433 - val_precision_56: 0.0315 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 74.9169 - accuracy: 0.7942 - precision_56: 0.2066 - val_loss: 53.3719 - val_accuracy: 0.2540 - val_precision_56: 0.0403 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 67.7306 - accuracy: 0.7858 - precision_56: 0.1908 - val_loss: 89.3993 - val_accuracy: 0.3661 - val_precision_56: 0.0494 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 60.0400 - accuracy: 0.7848 - precision_56: 0.1997 - val_loss: 29.5241 - val_accuracy: 0.9352 - val_precision_56: 0.0056 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 53.5005 - accuracy: 0.7858 - precision_56: 0.1888 - val_loss: 21.5659 - val_accuracy: 0.8602 - val_precision_56: 0.0084 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 42.4106 - accuracy: 0.7935 - precision_56: 0.2149 - val_loss: 11.7201 - val_accuracy: 0.8393 - val_precision_56: 0.0215 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 41.2756 - accuracy: 0.7992 - precision_56: 0.2139 - val_loss: 78.3487 - val_accuracy: 0.2749 - val_precision_56: 0.0442 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 35.9708 - accuracy: 0.7991 - precision_56: 0.2268 - val_loss: 96.0076 - val_accuracy: 0.4342 - val_precision_56: 0.0547 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 33.3639 - accuracy: 0.8002 - precision_56: 0.2261 - val_loss: 16.8292 - val_accuracy: 0.9159 - val_precision_56: 0.0095 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 27.8143 - accuracy: 0.8040 - precision_56: 0.2304 - val_loss: 8.6713 - val_accuracy: 0.7722 - val_precision_56: 0.0310 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 29.4440 - accuracy: 0.8028 - precision_56: 0.2277 - val_loss: 8.6789 - val_accuracy: 0.7919 - val_precision_56: 0.0366 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 23.8848 - accuracy: 0.8025 - precision_56: 0.2224 - val_loss: 11.6574 - val_accuracy: 0.8684 - val_precision_56: 0.0158 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 27.3135 - accuracy: 0.8029 - precision_56: 0.2224 - val_loss: 13.5451 - val_accuracy: 0.8413 - val_precision_56: 0.0146 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 23.1007 - accuracy: 0.8058 - precision_56: 0.2268 - val_loss: 19.3645 - val_accuracy: 0.8841 - val_precision_56: 0.0119 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 20.7916 - accuracy: 0.8043 - precision_56: 0.2218 - val_loss: 11.1102 - val_accuracy: 0.6132 - val_precision_56: 0.0563 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 29.2130 - accuracy: 0.7994 - precision_56: 0.2117 - val_loss: 11.3565 - val_accuracy: 0.8986 - val_precision_56: 0.0080 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 16.6479 - accuracy: 0.8091 - precision_56: 0.2179 - val_loss: 11.0320 - val_accuracy: 0.6588 - val_precision_56: 0.0457 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 13.6934 - accuracy: 0.8077 - precision_56: 0.2211 - val_loss: 6.6543 - val_accuracy: 0.9013 - val_precision_56: 0.0176 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 12.0852 - accuracy: 0.8103 - precision_56: 0.2319 - val_loss: 3.8281 - val_accuracy: 0.8660 - val_precision_56: 0.0169 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 9.0925 - accuracy: 0.8110 - precision_56: 0.2323 - val_loss: 3.5272 - val_accuracy: 0.7966 - val_precision_56: 0.0350 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 10.1655 - accuracy: 0.8114 - precision_56: 0.2246 - val_loss: 11.5139 - val_accuracy: 0.5686 - val_precision_56: 0.0626 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 8.9554 - accuracy: 0.8088 - precision_56: 0.2250 - val_loss: 8.9612 - val_accuracy: 0.9457 - val_precision_56: 0.0365 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 10.4559 - accuracy: 0.8107 - precision_56: 0.2253 - val_loss: 6.0397 - val_accuracy: 0.9498 - val_precision_56: 0.0497 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 8.0671 - accuracy: 0.8111 - precision_56: 0.2164 - val_loss: 2.8031 - val_accuracy: 0.7567 - val_precision_56: 0.0528 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.0877 - accuracy: 0.8099 - precision_56: 0.2194 - val_loss: 2.8371 - val_accuracy: 0.7646 - val_precision_56: 0.0635 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.1144 - accuracy: 0.8119 - precision_56: 0.2279 - val_loss: 2.5636 - val_accuracy: 0.7347 - val_precision_56: 0.0525 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 6.5548 - accuracy: 0.8128 - precision_56: 0.2261 - val_loss: 1.9796 - val_accuracy: 0.8205 - val_precision_56: 0.0378 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.9891 - accuracy: 0.8141 - precision_56: 0.2279 - val_loss: 1.4419 - val_accuracy: 0.8592 - val_precision_56: 0.0403 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 5.0203 - accuracy: 0.8139 - precision_56: 0.2268 - val_loss: 1.9937 - val_accuracy: 0.7919 - val_precision_56: 0.0558 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.2401 - accuracy: 0.8110 - precision_56: 0.2181 - val_loss: 5.9266 - val_accuracy: 0.9505 - val_precision_56: 0.0072 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 6.3622 - accuracy: 0.8101 - precision_56: 0.2156 - val_loss: 1.8501 - val_accuracy: 0.9236 - val_precision_56: 0.0115 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.5126 - accuracy: 0.8129 - precision_56: 0.2108 - val_loss: 1.1760 - val_accuracy: 0.8619 - val_precision_56: 0.0294 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 2.3229 - accuracy: 0.8154 - precision_56: 0.2162 - val_loss: 1.1304 - val_accuracy: 0.9012 - val_precision_56: 0.0231 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.3057 - accuracy: 0.8134 - precision_56: 0.2177 - val_loss: 0.7351 - val_accuracy: 0.8881 - val_precision_56: 0.0227 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 2.0345 - accuracy: 0.8133 - precision_56: 0.2093 - val_loss: 1.4905 - val_accuracy: 0.7091 - val_precision_56: 0.0723 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.3968 - accuracy: 0.8110 - precision_56: 0.2024 - val_loss: 1.0637 - val_accuracy: 0.7110 - val_precision_56: 0.0673 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.7001 - accuracy: 0.8132 - precision_56: 0.1992 - val_loss: 0.7952 - val_accuracy: 0.9096 - val_precision_56: 0.0305 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.4298 - accuracy: 0.8169 - precision_56: 0.2083 - val_loss: 2.8658 - val_accuracy: 0.5167 - val_precision_56: 0.0598 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0616 - accuracy: 0.8155 - precision_56: 0.2090 - val_loss: 0.7793 - val_accuracy: 0.9435 - val_precision_56: 0.0043 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0669 - accuracy: 0.8179 - precision_56: 0.1958 - val_loss: 1.0710 - val_accuracy: 0.7046 - val_precision_56: 0.0662 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.8743 - accuracy: 0.8189 - precision_56: 0.2138 - val_loss: 0.3879 - val_accuracy: 0.9241 - val_precision_56: 0.0097 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.9869 - accuracy: 0.8174 - precision_56: 0.2110 - val_loss: 0.5398 - val_accuracy: 0.9336 - val_precision_56: 0.0419 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.8379 - accuracy: 0.8213 - precision_56: 0.2200 - val_loss: 0.4666 - val_accuracy: 0.9254 - val_precision_56: 0.0432 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.7038 - accuracy: 0.8303 - precision_56: 0.2318 - val_loss: 0.4373 - val_accuracy: 0.9114 - val_precision_56: 0.0428 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.9997 - accuracy: 0.8229 - precision_56: 0.2168 - val_loss: 1.5943 - val_accuracy: 0.9348 - val_precision_56: 0.0028 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 1.9005 - accuracy: 0.8150 - precision_56: 0.2027 - val_loss: 0.6560 - val_accuracy: 0.9182 - val_precision_56: 0.0421 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7674 - accuracy: 0.8237 - precision_56: 0.2270 - val_loss: 0.8930 - val_accuracy: 0.6582 - val_precision_56: 0.0738 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.8365 - precision_56: 0.2541 - val_loss: 0.3116 - val_accuracy: 0.9410 - val_precision_56: 0.0179 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.8285 - precision_56: 0.2365 - val_loss: 0.5633 - val_accuracy: 0.8675 - val_precision_56: 0.0580 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.8373 - precision_56: 0.2562 - val_loss: 0.3235 - val_accuracy: 0.9405 - val_precision_56: 0.0370 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.8369 - precision_56: 0.2565 - val_loss: 0.3214 - val_accuracy: 0.9140 - val_precision_56: 0.0319 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.8470 - precision_56: 0.3096 - val_loss: 0.4227 - val_accuracy: 0.8920 - val_precision_56: 0.0525 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8479 - precision_56: 0.2999 - val_loss: 0.3329 - val_accuracy: 0.9110 - val_precision_56: 0.0438 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 3.1383 - accuracy: 0.8118 - precision_56: 0.2091 - val_loss: 0.8808 - val_accuracy: 0.8819 - val_precision_56: 0.0292 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.0578 - accuracy: 0.8232 - precision_56: 0.2094 - val_loss: 0.5619 - val_accuracy: 0.7372 - val_precision_56: 0.0851 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.8368 - precision_56: 0.2407 - val_loss: 0.2901 - val_accuracy: 0.9499 - val_precision_56: 0.0263 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.8493 - precision_56: 0.2858 - val_loss: 0.2979 - val_accuracy: 0.9276 - val_precision_56: 0.0649 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 7.1505 - accuracy: 0.8303 - precision_56: 0.2326 - val_loss: 33.4130 - val_accuracy: 0.9602 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 29.5295 - accuracy: 0.7922 - precision_56: 0.1659 - val_loss: 2.3886 - val_accuracy: 0.9134 - val_precision_56: 0.0148 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.4115 - accuracy: 0.8122 - precision_56: 0.1766 - val_loss: 2.0191 - val_accuracy: 0.9438 - val_precision_56: 0.0128 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.5632 - accuracy: 0.8183 - precision_56: 0.1631 - val_loss: 0.8546 - val_accuracy: 0.6806 - val_precision_56: 0.0761 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.8407 - precision_56: 0.1955 - val_loss: 0.3179 - val_accuracy: 0.9515 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8462 - precision_56: 0.2249 - val_loss: 0.2602 - val_accuracy: 0.9441 - val_precision_56: 0.0087 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8496 - precision_56: 0.2344 - val_loss: 0.2803 - val_accuracy: 0.9418 - val_precision_56: 0.0151 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.8462 - precision_56: 0.2366 - val_loss: 0.3933 - val_accuracy: 0.8477 - val_precision_56: 0.1146 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.8494 - precision_56: 0.2424 - val_loss: 0.2471 - val_accuracy: 0.9485 - val_precision_56: 0.0119 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4497 - accuracy: 0.8484 - precision_56: 0.2482 - val_loss: 0.3112 - val_accuracy: 0.9274 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4331 - accuracy: 0.8516 - precision_56: 0.2738 - val_loss: 0.2986 - val_accuracy: 0.9356 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8553 - precision_56: 0.3051 - val_loss: 0.2415 - val_accuracy: 0.9483 - val_precision_56: 0.0060 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4500 - accuracy: 0.8496 - precision_56: 0.2729 - val_loss: 0.3231 - val_accuracy: 0.9061 - val_precision_56: 0.0141 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4774 - accuracy: 0.8467 - precision_56: 0.2614 - val_loss: 0.2824 - val_accuracy: 0.9289 - val_precision_56: 0.0068 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.8524 - precision_56: 0.2884 - val_loss: 0.2790 - val_accuracy: 0.9252 - val_precision_56: 0.0041 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.8413 - precision_56: 0.2395 - val_loss: 0.7664 - val_accuracy: 0.7036 - val_precision_56: 0.0796 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 25.5085 - accuracy: 0.7939 - precision_56: 0.1708 - val_loss: 0.8082 - val_accuracy: 0.9469 - val_precision_56: 0.0396 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 1.3426 - accuracy: 0.8200 - precision_56: 0.1692 - val_loss: 0.6896 - val_accuracy: 0.9586 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.8408 - accuracy: 0.8279 - precision_56: 0.1718 - val_loss: 0.3479 - val_accuracy: 0.9558 - val_precision_56: 0.0694 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.7251 - accuracy: 0.8331 - precision_56: 0.1820 - val_loss: 0.6184 - val_accuracy: 0.9554 - val_precision_56: 0.0282 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.4693 - accuracy: 0.8142 - precision_56: 0.1643 - val_loss: 1.2310 - val_accuracy: 0.9600 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.9503 - accuracy: 0.8305 - precision_56: 0.1833 - val_loss: 0.4694 - val_accuracy: 0.9585 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8526 - precision_56: 0.1617 - val_loss: 0.2671 - val_accuracy: 0.9554 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8536 - precision_56: 0.2133 - val_loss: 0.2741 - val_accuracy: 0.9447 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8565 - precision_56: 0.2287 - val_loss: 0.2685 - val_accuracy: 0.9552 - val_precision_56: 0.0395 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4077 - accuracy: 0.8561 - precision_56: 0.2570 - val_loss: 0.2463 - val_accuracy: 0.9552 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8485 - precision_56: 0.2526 - val_loss: 0.2488 - val_accuracy: 0.9535 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8536 - precision_56: 0.2988 - val_loss: 0.2534 - val_accuracy: 0.9515 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8588 - precision_56: 0.3191 - val_loss: 0.2683 - val_accuracy: 0.9564 - val_precision_56: 0.0508 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8600 - precision_56: 0.3281 - val_loss: 0.2611 - val_accuracy: 0.9485 - val_precision_56: 0.0060 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8605 - precision_56: 0.3491 - val_loss: 0.2865 - val_accuracy: 0.9385 - val_precision_56: 0.1398 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 2.4831 - accuracy: 0.8229 - precision_56: 0.1933 - val_loss: 1.9217 - val_accuracy: 0.9567 - val_precision_56: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 4.3939 - accuracy: 0.8162 - precision_56: 0.1759 - val_loss: 0.4278 - val_accuracy: 0.8758 - val_precision_56: 0.0863 - lr: 5.0000e-04\n",
            "Epoch 95/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 1.1823 - accuracy: 0.8240 - precision_56: 0.1830 - val_loss: 0.2710 - val_accuracy: 0.9520 - val_precision_56: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 96/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.8470 - precision_56: 0.2226 - val_loss: 0.2739 - val_accuracy: 0.9426 - val_precision_56: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 97/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3998 - accuracy: 0.8568 - precision_56: 0.2972 - val_loss: 0.2306 - val_accuracy: 0.9535 - val_precision_56: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.4364 - accuracy: 0.8515 - precision_56: 0.2544 - val_loss: 0.2493 - val_accuracy: 0.9508 - val_precision_56: 0.0000e+00 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 0.3821 - accuracy: 0.8600 - precision_56: 0.3590 - val_loss: 0.2671 - val_accuracy: 0.9350 - val_precision_56: 0.0056 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "112/112 [==============================] - 1s 4ms/step - loss: 0.3686 - accuracy: 0.8633 - precision_56: 0.4870 - val_loss: 0.2878 - val_accuracy: 0.9305 - val_precision_56: 0.1763 - lr: 5.0000e-04\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Average F1 score (test): nan\n",
            "Average Precision score (test): nan\n",
            "Average F1 score (Train): nan\n",
            "Average Precision score (Train): nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the deep learning model"
      ],
      "metadata": {
        "id": "akZ-eBCfFUQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save deep learning model\n",
        "deep_learning_model.save('deep_learning_model.h5')"
      ],
      "metadata": {
        "id": "nezk0eMuFUF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying a convolutional neural network for classification"
      ],
      "metadata": {
        "id": "BSdX-nxgu2_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = pd.Timestamp('2020-01-01')\n",
        "end_date = pd.Timestamp('2021-12-31 23:45:00')\n",
        "\n",
        "# Filter rows that are outside of the specified timeframe\n",
        "df_filtered = df_lagged[(df_lagged.index > end_date)]\n",
        "\n",
        "df_filtered.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "XMhbI8KVfqjS",
        "outputId": "4a2532a3-3975-460e-93ff-c92237d7f1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     redispatch  wind_direction_degrees  \\\n",
              "timestamp                                                 \n",
              "2022-01-01 00:00:00         0.0                   270.0   \n",
              "2022-01-01 00:15:00         0.0                   265.0   \n",
              "2022-01-01 00:30:00         0.0                   270.0   \n",
              "2022-01-01 00:45:00         0.0                   270.0   \n",
              "2022-01-01 01:00:00         0.0                   270.0   \n",
              "\n",
              "                     wind_direction_degrees_lag1  wind_direction_degrees_lag2  \\\n",
              "timestamp                                                                       \n",
              "2022-01-01 00:00:00                        270.0                        270.0   \n",
              "2022-01-01 00:15:00                        270.0                        270.0   \n",
              "2022-01-01 00:30:00                        265.0                        270.0   \n",
              "2022-01-01 00:45:00                        270.0                        265.0   \n",
              "2022-01-01 01:00:00                        270.0                        270.0   \n",
              "\n",
              "                     wind_direction_degrees_lag3  radiation_global_J/m2  \\\n",
              "timestamp                                                                 \n",
              "2022-01-01 00:00:00                        270.0                    0.0   \n",
              "2022-01-01 00:15:00                        270.0                    0.0   \n",
              "2022-01-01 00:30:00                        270.0                    0.0   \n",
              "2022-01-01 00:45:00                        270.0                    0.0   \n",
              "2022-01-01 01:00:00                        265.0                    0.0   \n",
              "\n",
              "                     radiation_global_J/m2_lag1  radiation_global_J/m2_lag2  \\\n",
              "timestamp                                                                     \n",
              "2022-01-01 00:00:00                         0.0                         0.0   \n",
              "2022-01-01 00:15:00                         0.0                         0.0   \n",
              "2022-01-01 00:30:00                         0.0                         0.0   \n",
              "2022-01-01 00:45:00                         0.0                         0.0   \n",
              "2022-01-01 01:00:00                         0.0                         0.0   \n",
              "\n",
              "                     radiation_global_J/m2_lag3  air_temperature_K  ...  \\\n",
              "timestamp                                                           ...   \n",
              "2022-01-01 00:00:00                         0.0             282.05  ...   \n",
              "2022-01-01 00:15:00                         0.0             282.10  ...   \n",
              "2022-01-01 00:30:00                         0.0             282.35  ...   \n",
              "2022-01-01 00:45:00                         0.0             282.55  ...   \n",
              "2022-01-01 01:00:00                         0.0             282.65  ...   \n",
              "\n",
              "                     residual_load_MWh  residual_load_MWh_lag1  \\\n",
              "timestamp                                                        \n",
              "2022-01-01 00:00:00             212.98                  215.08   \n",
              "2022-01-01 00:15:00             209.07                  212.98   \n",
              "2022-01-01 00:30:00             208.60                  209.07   \n",
              "2022-01-01 00:45:00             199.50                  208.60   \n",
              "2022-01-01 01:00:00             194.30                  199.50   \n",
              "\n",
              "                     residual_load_MWh_lag2  residual_load_MWh_lag3  \\\n",
              "timestamp                                                             \n",
              "2022-01-01 00:00:00                  223.97                  230.88   \n",
              "2022-01-01 00:15:00                  215.08                  223.97   \n",
              "2022-01-01 00:30:00                  212.98                  215.08   \n",
              "2022-01-01 00:45:00                  209.07                  212.98   \n",
              "2022-01-01 01:00:00                  208.60                  209.07   \n",
              "\n",
              "                     pumped_storage_MWh  pumped_storage_MWh_lag1  \\\n",
              "timestamp                                                          \n",
              "2022-01-01 00:00:00               39.98                    50.40   \n",
              "2022-01-01 00:15:00               39.67                    39.98   \n",
              "2022-01-01 00:30:00               43.30                    39.67   \n",
              "2022-01-01 00:45:00               46.33                    43.30   \n",
              "2022-01-01 01:00:00               39.12                    46.33   \n",
              "\n",
              "                     pumped_storage_MWh_lag2  pumped_storage_MWh_lag3  \\\n",
              "timestamp                                                               \n",
              "2022-01-01 00:00:00                    46.20                    47.45   \n",
              "2022-01-01 00:15:00                    50.40                    46.20   \n",
              "2022-01-01 00:30:00                    39.98                    50.40   \n",
              "2022-01-01 00:45:00                    39.67                    39.98   \n",
              "2022-01-01 01:00:00                    43.30                    39.67   \n",
              "\n",
              "                     weekday  season  \n",
              "timestamp                             \n",
              "2022-01-01 00:00:00        0       2  \n",
              "2022-01-01 00:15:00        0       2  \n",
              "2022-01-01 00:30:00        0       2  \n",
              "2022-01-01 00:45:00        0       2  \n",
              "2022-01-01 01:00:00        0       2  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cc8a328-faa8-40e7-9667-f8494726ac18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>redispatch</th>\n",
              "      <th>wind_direction_degrees</th>\n",
              "      <th>wind_direction_degrees_lag1</th>\n",
              "      <th>wind_direction_degrees_lag2</th>\n",
              "      <th>wind_direction_degrees_lag3</th>\n",
              "      <th>radiation_global_J/m2</th>\n",
              "      <th>radiation_global_J/m2_lag1</th>\n",
              "      <th>radiation_global_J/m2_lag2</th>\n",
              "      <th>radiation_global_J/m2_lag3</th>\n",
              "      <th>air_temperature_K</th>\n",
              "      <th>...</th>\n",
              "      <th>residual_load_MWh</th>\n",
              "      <th>residual_load_MWh_lag1</th>\n",
              "      <th>residual_load_MWh_lag2</th>\n",
              "      <th>residual_load_MWh_lag3</th>\n",
              "      <th>pumped_storage_MWh</th>\n",
              "      <th>pumped_storage_MWh_lag1</th>\n",
              "      <th>pumped_storage_MWh_lag2</th>\n",
              "      <th>pumped_storage_MWh_lag3</th>\n",
              "      <th>weekday</th>\n",
              "      <th>season</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-01-01 00:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>282.05</td>\n",
              "      <td>...</td>\n",
              "      <td>212.98</td>\n",
              "      <td>215.08</td>\n",
              "      <td>223.97</td>\n",
              "      <td>230.88</td>\n",
              "      <td>39.98</td>\n",
              "      <td>50.40</td>\n",
              "      <td>46.20</td>\n",
              "      <td>47.45</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 00:15:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>282.10</td>\n",
              "      <td>...</td>\n",
              "      <td>209.07</td>\n",
              "      <td>212.98</td>\n",
              "      <td>215.08</td>\n",
              "      <td>223.97</td>\n",
              "      <td>39.67</td>\n",
              "      <td>39.98</td>\n",
              "      <td>50.40</td>\n",
              "      <td>46.20</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 00:30:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>282.35</td>\n",
              "      <td>...</td>\n",
              "      <td>208.60</td>\n",
              "      <td>209.07</td>\n",
              "      <td>212.98</td>\n",
              "      <td>215.08</td>\n",
              "      <td>43.30</td>\n",
              "      <td>39.67</td>\n",
              "      <td>39.98</td>\n",
              "      <td>50.40</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 00:45:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>282.55</td>\n",
              "      <td>...</td>\n",
              "      <td>199.50</td>\n",
              "      <td>208.60</td>\n",
              "      <td>209.07</td>\n",
              "      <td>212.98</td>\n",
              "      <td>46.33</td>\n",
              "      <td>43.30</td>\n",
              "      <td>39.67</td>\n",
              "      <td>39.98</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-01 01:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>282.65</td>\n",
              "      <td>...</td>\n",
              "      <td>194.30</td>\n",
              "      <td>199.50</td>\n",
              "      <td>208.60</td>\n",
              "      <td>209.07</td>\n",
              "      <td>39.12</td>\n",
              "      <td>46.33</td>\n",
              "      <td>43.30</td>\n",
              "      <td>39.67</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cc8a328-faa8-40e7-9667-f8494726ac18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cc8a328-faa8-40e7-9667-f8494726ac18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cc8a328-faa8-40e7-9667-f8494726ac18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd2bfef2-6aa9-439b-85fd-49138dee46ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd2bfef2-6aa9-439b-85fd-49138dee46ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd2bfef2-6aa9-439b-85fd-49138dee46ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_filtered"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the cutoff point for splitting the data into train and test sets based on time\n",
        "train_time = '2021-12-31'  # Define your train time\n",
        "test_time_start = '2022-12-01'\n",
        "test_time_end = '2023-01-01'\n",
        "\n",
        "# Split the data into train and test sets based on time\n",
        "train = df_filtered[(df_filtered.index > train_time) & (df_filtered.index < test_time_start)]\n",
        "test = df_filtered[(df_filtered.index >= test_time_start) & (df_filtered.index < test_time_end)]\n",
        "\n",
        "# Prepare the data\n",
        "X_train = train.drop(columns=['redispatch'])  # Extract features\n",
        "y_train = train['redispatch']  # Extract target\n",
        "\n",
        "X_test = test.drop(columns=['redispatch'])  # Extract features\n",
        "y_test = test['redispatch']  # Extract target"
      ],
      "metadata": {
        "id": "I40eFnN-u2uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize or scale the features if necessary\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Balance the classes in the training data using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "W8x-NUwawmtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using cross validation with CNN model"
      ],
      "metadata": {
        "id": "DFNUQg3iql_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the input data to have a 3D shape\n",
        "X_train_balanced_reshaped = np.expand_dims(X_train_balanced, axis=-1)\n",
        "X_test_scaled_reshaped = np.expand_dims(X_test_scaled, axis=-1)\n",
        "\n",
        "# Define the number of splits for time series cross-validation\n",
        "n_splits = 5\n",
        "\n",
        "# Define the TimeSeriesSplit cross-validation strategy\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# Define model architecture\n",
        "def make_model(input_shape, num_classes):\n",
        "    input_layer = Input(input_shape)\n",
        "\n",
        "    conv1 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = ReLU()(conv1)\n",
        "\n",
        "    conv2 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = ReLU()(conv2)\n",
        "\n",
        "    conv3 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = ReLU()(conv3)\n",
        "\n",
        "    gap = GlobalAveragePooling1D()(conv3)\n",
        "\n",
        "    output_layer = Dense(num_classes, activation=\"softmax\")(gap)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Model parameters\n",
        "input_shape = X_train_balanced_reshaped.shape[1:]\n",
        "num_classes = len(np.unique(y_train_balanced))\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\"),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
        "]\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "train_f1_scores = []\n",
        "train_precision_scores = []\n",
        "test_f1_scores = []\n",
        "test_precision_scores = []\n",
        "\n",
        "# Iterate over each fold\n",
        "for fold, (train_index, test_index) in enumerate(tscv.split(X_train_balanced_reshaped), 1):\n",
        "    print(f\"Training on fold {fold}/{n_splits}\")\n",
        "\n",
        "    # Get the data for this fold\n",
        "    X_train_fold, X_val_fold = X_train_balanced_reshaped[train_index], X_train_balanced_reshaped[test_index]\n",
        "    y_train_fold, y_val_fold = y_train_balanced[train_index], y_train_balanced[test_index]\n",
        "\n",
        "    # Create model instance\n",
        "    model = make_model(input_shape, num_classes)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        epochs=500,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred_val = model.predict(X_val_fold)\n",
        "    y_pred_val_classes = np.argmax(y_pred_val, axis=1)\n",
        "\n",
        "    # Calculate evaluation metrics for validation set\n",
        "    f1 = f1_score(y_val_fold, y_pred_val_classes, average='macro')\n",
        "    precision = precision_score(y_val_fold, y_pred_val_classes, average='macro')\n",
        "\n",
        "    f1_scores.append(f1)\n",
        "    precision_scores.append(precision)\n",
        "\n",
        "    # Predict on the training set\n",
        "    y_pred_train = model.predict(X_train_fold)\n",
        "    y_pred_train_classes = np.argmax(y_pred_train, axis=1)\n",
        "\n",
        "    # Calculate evaluation metrics for training set\n",
        "    train_f1 = f1_score(y_train_fold, y_pred_train_classes, average='macro')\n",
        "    train_precision = precision_score(y_train_fold, y_pred_train_classes, average='macro')\n",
        "\n",
        "    train_f1_scores.append(train_f1)\n",
        "    train_precision_scores.append(train_precision)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_test = model.predict(X_test_scaled_reshaped)\n",
        "    y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
        "\n",
        "    # Calculate evaluation metrics for test set\n",
        "    test_f1 = f1_score(y_test, y_pred_test_classes, average='macro')\n",
        "    test_precision = precision_score(y_test, y_pred_test_classes, average='macro')\n",
        "\n",
        "    test_f1_scores.append(test_f1)\n",
        "    test_precision_scores.append(test_precision)\n",
        "\n",
        "# Print average scores across all folds\n",
        "print(\"Average F1 score (validation):\", np.mean(f1_scores))\n",
        "print(\"Average precision score (validation):\", np.mean(precision_scores))\n",
        "print(\"Average F1 score (train):\", np.mean(train_f1_scores))\n",
        "print(\"Average precision score (train):\", np.mean(train_precision_scores))\n",
        "print(\"Average F1 score (test):\", np.mean(test_f1_scores))\n",
        "print(\"Average precision score (test):\", np.mean(test_precision_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W25vErw9u2jB",
        "outputId": "27126c8c-ab93-4df7-c2e4-6c910546114f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1/5\n",
            "Epoch 1/500\n",
            "280/280 [==============================] - 6s 7ms/step - loss: 0.1080 - accuracy: 0.9729 - val_loss: 0.6433 - val_accuracy: 0.8777 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0575 - accuracy: 0.9860 - val_loss: 0.6115 - val_accuracy: 0.8777 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0508 - accuracy: 0.9860 - val_loss: 0.6887 - val_accuracy: 0.8777 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0469 - accuracy: 0.9862 - val_loss: 1.0179 - val_accuracy: 0.8777 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.9479 - val_accuracy: 0.8777 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0383 - accuracy: 0.9873 - val_loss: 0.7310 - val_accuracy: 0.8773 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9869 - val_loss: 0.9649 - val_accuracy: 0.8766 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "280/280 [==============================] - 2s 7ms/step - loss: 0.0318 - accuracy: 0.9883 - val_loss: 0.6445 - val_accuracy: 0.8395 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0293 - accuracy: 0.9887 - val_loss: 0.7470 - val_accuracy: 0.8692 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0265 - accuracy: 0.9908 - val_loss: 0.7125 - val_accuracy: 0.8629 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0277 - accuracy: 0.9901 - val_loss: 1.2258 - val_accuracy: 0.8740 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9904 - val_loss: 1.3708 - val_accuracy: 0.8771 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.8610 - val_accuracy: 0.8708 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0217 - accuracy: 0.9917 - val_loss: 0.8200 - val_accuracy: 0.8677 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 1.3306 - val_accuracy: 0.8765 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 1.4924 - val_accuracy: 0.8724 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 1.2282 - val_accuracy: 0.8739 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.9397 - val_accuracy: 0.8698 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 1.7645 - val_accuracy: 0.8777 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 1.6379 - val_accuracy: 0.8769 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 1.4748 - val_accuracy: 0.8763 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0150 - accuracy: 0.9945 - val_loss: 1.6981 - val_accuracy: 0.8770 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 1.4688 - val_accuracy: 0.8725 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 1.4084 - val_accuracy: 0.8722 - lr: 5.0000e-04\n",
            "Epoch 25/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 1.4443 - val_accuracy: 0.8724 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 1.1855 - val_accuracy: 0.8717 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 1.5219 - val_accuracy: 0.8754 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 1.8078 - val_accuracy: 0.8757 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 1.1512 - val_accuracy: 0.8679 - lr: 5.0000e-04\n",
            "Epoch 30/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 1.5341 - val_accuracy: 0.8718 - lr: 5.0000e-04\n",
            "Epoch 31/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 1.7138 - val_accuracy: 0.8729 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 1.5138 - val_accuracy: 0.8708 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 1.8566 - val_accuracy: 0.8738 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 1.4449 - val_accuracy: 0.8709 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 1.4392 - val_accuracy: 0.8717 - lr: 5.0000e-04\n",
            "Epoch 36/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 1.5657 - val_accuracy: 0.8717 - lr: 5.0000e-04\n",
            "Epoch 37/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 1.3396 - val_accuracy: 0.8714 - lr: 5.0000e-04\n",
            "Epoch 38/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 1.2779 - val_accuracy: 0.8684 - lr: 5.0000e-04\n",
            "Epoch 39/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 1.2166 - val_accuracy: 0.8634 - lr: 5.0000e-04\n",
            "Epoch 40/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 1.7185 - val_accuracy: 0.8724 - lr: 5.0000e-04\n",
            "Epoch 41/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 1.8500 - val_accuracy: 0.8737 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 1.6686 - val_accuracy: 0.8718 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.6593 - val_accuracy: 0.8730 - lr: 2.5000e-04\n",
            "Epoch 44/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 1.3060 - val_accuracy: 0.8705 - lr: 2.5000e-04\n",
            "Epoch 45/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 1.6144 - val_accuracy: 0.8711 - lr: 2.5000e-04\n",
            "Epoch 46/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 1.7267 - val_accuracy: 0.8732 - lr: 2.5000e-04\n",
            "Epoch 47/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 1.7914 - val_accuracy: 0.8734 - lr: 2.5000e-04\n",
            "Epoch 48/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 1.5704 - val_accuracy: 0.8713 - lr: 2.5000e-04\n",
            "Epoch 49/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 1.8425 - val_accuracy: 0.8740 - lr: 2.5000e-04\n",
            "Epoch 50/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 1.7075 - val_accuracy: 0.8734 - lr: 2.5000e-04\n",
            "Epoch 51/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 1.6031 - val_accuracy: 0.8710 - lr: 2.5000e-04\n",
            "Epoch 52/500\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 1.5227 - val_accuracy: 0.8702 - lr: 2.5000e-04\n",
            "Epoch 52: early stopping\n",
            "280/280 [==============================] - 1s 2ms/step\n",
            "280/280 [==============================] - 1s 2ms/step\n",
            "93/93 [==============================] - 0s 2ms/step\n",
            "Training on fold 2/5\n",
            "Epoch 1/500\n",
            "560/560 [==============================] - 5s 6ms/step - loss: 0.2342 - accuracy: 0.9213 - val_loss: 0.7475 - val_accuracy: 0.7280 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.2033 - accuracy: 0.9310 - val_loss: 0.6692 - val_accuracy: 0.7345 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9321 - val_loss: 0.7049 - val_accuracy: 0.7291 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1845 - accuracy: 0.9345 - val_loss: 0.7809 - val_accuracy: 0.7367 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1771 - accuracy: 0.9355 - val_loss: 0.9182 - val_accuracy: 0.7325 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1732 - accuracy: 0.9367 - val_loss: 0.6417 - val_accuracy: 0.7402 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1669 - accuracy: 0.9376 - val_loss: 0.6872 - val_accuracy: 0.7451 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1617 - accuracy: 0.9402 - val_loss: 0.8298 - val_accuracy: 0.7437 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1596 - accuracy: 0.9399 - val_loss: 0.7385 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1583 - accuracy: 0.9396 - val_loss: 1.0700 - val_accuracy: 0.7294 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1560 - accuracy: 0.9419 - val_loss: 0.9081 - val_accuracy: 0.7354 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1526 - accuracy: 0.9403 - val_loss: 0.8740 - val_accuracy: 0.7420 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1497 - accuracy: 0.9416 - val_loss: 0.6891 - val_accuracy: 0.7432 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1485 - accuracy: 0.9429 - val_loss: 0.8197 - val_accuracy: 0.7343 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1466 - accuracy: 0.9445 - val_loss: 0.8584 - val_accuracy: 0.7315 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1441 - accuracy: 0.9439 - val_loss: 0.7534 - val_accuracy: 0.7401 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1416 - accuracy: 0.9446 - val_loss: 0.8259 - val_accuracy: 0.7419 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1417 - accuracy: 0.9459 - val_loss: 0.7498 - val_accuracy: 0.7203 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1383 - accuracy: 0.9464 - val_loss: 0.8356 - val_accuracy: 0.7442 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1389 - accuracy: 0.9454 - val_loss: 0.7145 - val_accuracy: 0.7374 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1335 - accuracy: 0.9480 - val_loss: 0.8185 - val_accuracy: 0.7395 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1342 - accuracy: 0.9474 - val_loss: 0.8397 - val_accuracy: 0.7310 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1332 - accuracy: 0.9474 - val_loss: 0.8361 - val_accuracy: 0.7454 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1304 - accuracy: 0.9498 - val_loss: 1.1023 - val_accuracy: 0.7419 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1320 - accuracy: 0.9485 - val_loss: 0.8943 - val_accuracy: 0.7374 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.9481 - val_loss: 0.7807 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1225 - accuracy: 0.9516 - val_loss: 1.0115 - val_accuracy: 0.7374 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1209 - accuracy: 0.9516 - val_loss: 0.8452 - val_accuracy: 0.7400 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1196 - accuracy: 0.9532 - val_loss: 0.8038 - val_accuracy: 0.7383 - lr: 5.0000e-04\n",
            "Epoch 30/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1186 - accuracy: 0.9528 - val_loss: 0.9813 - val_accuracy: 0.7421 - lr: 5.0000e-04\n",
            "Epoch 31/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1179 - accuracy: 0.9539 - val_loss: 0.8997 - val_accuracy: 0.7487 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1145 - accuracy: 0.9550 - val_loss: 0.8239 - val_accuracy: 0.7368 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1163 - accuracy: 0.9542 - val_loss: 0.8872 - val_accuracy: 0.7441 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1146 - accuracy: 0.9564 - val_loss: 0.7428 - val_accuracy: 0.7265 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.9552 - val_loss: 1.0500 - val_accuracy: 0.7426 - lr: 5.0000e-04\n",
            "Epoch 36/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1134 - accuracy: 0.9568 - val_loss: 0.7811 - val_accuracy: 0.7463 - lr: 5.0000e-04\n",
            "Epoch 37/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1121 - accuracy: 0.9568 - val_loss: 0.7813 - val_accuracy: 0.7353 - lr: 5.0000e-04\n",
            "Epoch 38/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1113 - accuracy: 0.9566 - val_loss: 0.8178 - val_accuracy: 0.7400 - lr: 5.0000e-04\n",
            "Epoch 39/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1123 - accuracy: 0.9557 - val_loss: 0.8669 - val_accuracy: 0.7437 - lr: 5.0000e-04\n",
            "Epoch 40/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1121 - accuracy: 0.9569 - val_loss: 0.9001 - val_accuracy: 0.7435 - lr: 5.0000e-04\n",
            "Epoch 41/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1088 - accuracy: 0.9572 - val_loss: 0.7770 - val_accuracy: 0.7180 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1092 - accuracy: 0.9579 - val_loss: 1.0741 - val_accuracy: 0.7434 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1079 - accuracy: 0.9574 - val_loss: 0.9620 - val_accuracy: 0.7433 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1082 - accuracy: 0.9576 - val_loss: 0.8105 - val_accuracy: 0.7464 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1071 - accuracy: 0.9588 - val_loss: 1.0126 - val_accuracy: 0.7416 - lr: 5.0000e-04\n",
            "Epoch 46/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1081 - accuracy: 0.9580 - val_loss: 0.9191 - val_accuracy: 0.7425 - lr: 5.0000e-04\n",
            "Epoch 47/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1012 - accuracy: 0.9614 - val_loss: 0.9728 - val_accuracy: 0.7439 - lr: 2.5000e-04\n",
            "Epoch 48/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0997 - accuracy: 0.9622 - val_loss: 0.9122 - val_accuracy: 0.7468 - lr: 2.5000e-04\n",
            "Epoch 49/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1019 - accuracy: 0.9603 - val_loss: 0.8751 - val_accuracy: 0.7443 - lr: 2.5000e-04\n",
            "Epoch 50/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.1005 - accuracy: 0.9610 - val_loss: 0.8897 - val_accuracy: 0.7436 - lr: 2.5000e-04\n",
            "Epoch 51/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0982 - accuracy: 0.9621 - val_loss: 0.8848 - val_accuracy: 0.7487 - lr: 2.5000e-04\n",
            "Epoch 52/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0988 - accuracy: 0.9617 - val_loss: 0.9415 - val_accuracy: 0.7482 - lr: 2.5000e-04\n",
            "Epoch 53/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0979 - accuracy: 0.9624 - val_loss: 0.8522 - val_accuracy: 0.7377 - lr: 2.5000e-04\n",
            "Epoch 54/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0979 - accuracy: 0.9608 - val_loss: 0.9364 - val_accuracy: 0.7421 - lr: 2.5000e-04\n",
            "Epoch 55/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0990 - accuracy: 0.9614 - val_loss: 0.9315 - val_accuracy: 0.7441 - lr: 2.5000e-04\n",
            "Epoch 56/500\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0972 - accuracy: 0.9619 - val_loss: 1.0130 - val_accuracy: 0.7443 - lr: 2.5000e-04\n",
            "Epoch 56: early stopping\n",
            "280/280 [==============================] - 1s 2ms/step\n",
            "560/560 [==============================] - 1s 2ms/step\n",
            "93/93 [==============================] - 0s 2ms/step\n",
            "Training on fold 3/5\n",
            "Epoch 1/500\n",
            "840/840 [==============================] - 7s 5ms/step - loss: 0.3254 - accuracy: 0.8673 - val_loss: 0.9155 - val_accuracy: 0.4679 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.3067 - accuracy: 0.8709 - val_loss: 1.0794 - val_accuracy: 0.4379 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.3003 - accuracy: 0.8712 - val_loss: 0.8650 - val_accuracy: 0.4898 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2938 - accuracy: 0.8741 - val_loss: 0.7503 - val_accuracy: 0.5538 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2898 - accuracy: 0.8750 - val_loss: 0.8705 - val_accuracy: 0.4925 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2876 - accuracy: 0.8760 - val_loss: 0.9199 - val_accuracy: 0.4857 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2824 - accuracy: 0.8756 - val_loss: 0.8617 - val_accuracy: 0.5057 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2801 - accuracy: 0.8782 - val_loss: 0.8397 - val_accuracy: 0.5228 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2768 - accuracy: 0.8811 - val_loss: 0.8097 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2758 - accuracy: 0.8789 - val_loss: 0.7626 - val_accuracy: 0.5523 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2724 - accuracy: 0.8827 - val_loss: 0.7892 - val_accuracy: 0.5542 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2702 - accuracy: 0.8820 - val_loss: 0.8752 - val_accuracy: 0.5211 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2694 - accuracy: 0.8838 - val_loss: 0.9010 - val_accuracy: 0.5350 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2661 - accuracy: 0.8832 - val_loss: 0.8658 - val_accuracy: 0.5257 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2641 - accuracy: 0.8849 - val_loss: 0.8553 - val_accuracy: 0.5259 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2620 - accuracy: 0.8854 - val_loss: 0.8600 - val_accuracy: 0.5477 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2618 - accuracy: 0.8868 - val_loss: 1.0924 - val_accuracy: 0.4848 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2586 - accuracy: 0.8864 - val_loss: 0.7911 - val_accuracy: 0.5823 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2587 - accuracy: 0.8865 - val_loss: 0.7474 - val_accuracy: 0.5910 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2567 - accuracy: 0.8880 - val_loss: 0.8323 - val_accuracy: 0.5496 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2565 - accuracy: 0.8878 - val_loss: 0.7042 - val_accuracy: 0.6477 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2555 - accuracy: 0.8893 - val_loss: 0.8545 - val_accuracy: 0.5485 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2533 - accuracy: 0.8904 - val_loss: 0.8172 - val_accuracy: 0.5818 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2516 - accuracy: 0.8906 - val_loss: 0.7449 - val_accuracy: 0.6135 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2515 - accuracy: 0.8912 - val_loss: 1.0166 - val_accuracy: 0.5212 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2494 - accuracy: 0.8917 - val_loss: 1.1179 - val_accuracy: 0.5042 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2503 - accuracy: 0.8907 - val_loss: 0.8534 - val_accuracy: 0.5747 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2480 - accuracy: 0.8924 - val_loss: 0.7660 - val_accuracy: 0.5926 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2464 - accuracy: 0.8919 - val_loss: 0.8036 - val_accuracy: 0.5908 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2458 - accuracy: 0.8938 - val_loss: 0.9658 - val_accuracy: 0.5228 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2457 - accuracy: 0.8935 - val_loss: 1.1732 - val_accuracy: 0.5039 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2431 - accuracy: 0.8943 - val_loss: 0.8936 - val_accuracy: 0.5475 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2418 - accuracy: 0.8960 - val_loss: 0.9345 - val_accuracy: 0.5408 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2414 - accuracy: 0.8953 - val_loss: 0.8437 - val_accuracy: 0.5633 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2412 - accuracy: 0.8952 - val_loss: 0.7775 - val_accuracy: 0.6020 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2399 - accuracy: 0.8961 - val_loss: 0.8092 - val_accuracy: 0.5898 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2381 - accuracy: 0.8962 - val_loss: 0.7059 - val_accuracy: 0.6340 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2371 - accuracy: 0.8970 - val_loss: 0.7870 - val_accuracy: 0.6007 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2374 - accuracy: 0.8970 - val_loss: 0.7226 - val_accuracy: 0.6365 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2353 - accuracy: 0.8985 - val_loss: 0.7244 - val_accuracy: 0.6335 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2353 - accuracy: 0.8987 - val_loss: 1.0254 - val_accuracy: 0.5280 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2269 - accuracy: 0.9013 - val_loss: 0.7946 - val_accuracy: 0.5969 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2261 - accuracy: 0.9031 - val_loss: 0.9413 - val_accuracy: 0.5496 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2253 - accuracy: 0.9030 - val_loss: 1.0443 - val_accuracy: 0.5392 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2236 - accuracy: 0.9045 - val_loss: 0.7566 - val_accuracy: 0.6213 - lr: 5.0000e-04\n",
            "Epoch 46/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2241 - accuracy: 0.9025 - val_loss: 0.7987 - val_accuracy: 0.5948 - lr: 5.0000e-04\n",
            "Epoch 47/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2210 - accuracy: 0.9040 - val_loss: 0.7771 - val_accuracy: 0.6193 - lr: 5.0000e-04\n",
            "Epoch 48/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2201 - accuracy: 0.9054 - val_loss: 0.9557 - val_accuracy: 0.5545 - lr: 5.0000e-04\n",
            "Epoch 49/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2211 - accuracy: 0.9051 - val_loss: 1.1318 - val_accuracy: 0.5205 - lr: 5.0000e-04\n",
            "Epoch 50/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2198 - accuracy: 0.9039 - val_loss: 0.7407 - val_accuracy: 0.6619 - lr: 5.0000e-04\n",
            "Epoch 51/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2194 - accuracy: 0.9065 - val_loss: 1.0114 - val_accuracy: 0.5400 - lr: 5.0000e-04\n",
            "Epoch 52/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2192 - accuracy: 0.9049 - val_loss: 0.7792 - val_accuracy: 0.6282 - lr: 5.0000e-04\n",
            "Epoch 53/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2198 - accuracy: 0.9054 - val_loss: 0.8205 - val_accuracy: 0.6062 - lr: 5.0000e-04\n",
            "Epoch 54/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2167 - accuracy: 0.9075 - val_loss: 1.0516 - val_accuracy: 0.5421 - lr: 5.0000e-04\n",
            "Epoch 55/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2164 - accuracy: 0.9062 - val_loss: 0.7728 - val_accuracy: 0.6133 - lr: 5.0000e-04\n",
            "Epoch 56/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2169 - accuracy: 0.9067 - val_loss: 0.8671 - val_accuracy: 0.5863 - lr: 5.0000e-04\n",
            "Epoch 57/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2144 - accuracy: 0.9071 - val_loss: 0.7770 - val_accuracy: 0.6190 - lr: 5.0000e-04\n",
            "Epoch 58/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2174 - accuracy: 0.9065 - val_loss: 0.9654 - val_accuracy: 0.5559 - lr: 5.0000e-04\n",
            "Epoch 59/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2146 - accuracy: 0.9076 - val_loss: 0.8143 - val_accuracy: 0.6208 - lr: 5.0000e-04\n",
            "Epoch 60/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2132 - accuracy: 0.9076 - val_loss: 0.9180 - val_accuracy: 0.5789 - lr: 5.0000e-04\n",
            "Epoch 61/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2131 - accuracy: 0.9085 - val_loss: 0.8618 - val_accuracy: 0.5952 - lr: 5.0000e-04\n",
            "Epoch 62/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2080 - accuracy: 0.9122 - val_loss: 0.8954 - val_accuracy: 0.5857 - lr: 2.5000e-04\n",
            "Epoch 63/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2074 - accuracy: 0.9115 - val_loss: 0.9207 - val_accuracy: 0.5705 - lr: 2.5000e-04\n",
            "Epoch 64/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2068 - accuracy: 0.9102 - val_loss: 0.8821 - val_accuracy: 0.5939 - lr: 2.5000e-04\n",
            "Epoch 65/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2076 - accuracy: 0.9111 - val_loss: 0.8997 - val_accuracy: 0.5773 - lr: 2.5000e-04\n",
            "Epoch 66/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2047 - accuracy: 0.9136 - val_loss: 0.7942 - val_accuracy: 0.6133 - lr: 2.5000e-04\n",
            "Epoch 67/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2051 - accuracy: 0.9123 - val_loss: 0.8504 - val_accuracy: 0.5998 - lr: 2.5000e-04\n",
            "Epoch 68/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2066 - accuracy: 0.9114 - val_loss: 0.8508 - val_accuracy: 0.6011 - lr: 2.5000e-04\n",
            "Epoch 69/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2045 - accuracy: 0.9140 - val_loss: 0.8262 - val_accuracy: 0.6127 - lr: 2.5000e-04\n",
            "Epoch 70/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2047 - accuracy: 0.9131 - val_loss: 0.8725 - val_accuracy: 0.6037 - lr: 2.5000e-04\n",
            "Epoch 71/500\n",
            "840/840 [==============================] - 4s 5ms/step - loss: 0.2044 - accuracy: 0.9116 - val_loss: 0.8441 - val_accuracy: 0.6028 - lr: 2.5000e-04\n",
            "Epoch 71: early stopping\n",
            "280/280 [==============================] - 1s 2ms/step\n",
            "840/840 [==============================] - 1s 2ms/step\n",
            "93/93 [==============================] - 0s 2ms/step\n",
            "Training on fold 4/5\n",
            "Epoch 1/500\n",
            "1120/1120 [==============================] - 8s 5ms/step - loss: 0.4557 - accuracy: 0.7703 - val_loss: 1.5717 - val_accuracy: 0.1417 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.4255 - accuracy: 0.7915 - val_loss: 0.9359 - val_accuracy: 0.4583 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.4109 - accuracy: 0.7971 - val_loss: 0.6918 - val_accuracy: 0.6190 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.4020 - accuracy: 0.8040 - val_loss: 0.8030 - val_accuracy: 0.5502 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.3939 - accuracy: 0.8088 - val_loss: 0.6963 - val_accuracy: 0.6360 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3893 - accuracy: 0.8120 - val_loss: 0.7593 - val_accuracy: 0.6058 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.3845 - accuracy: 0.8148 - val_loss: 0.5128 - val_accuracy: 0.7441 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3790 - accuracy: 0.8179 - val_loss: 0.8654 - val_accuracy: 0.5445 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3732 - accuracy: 0.8227 - val_loss: 1.1051 - val_accuracy: 0.4050 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3699 - accuracy: 0.8238 - val_loss: 0.6639 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3673 - accuracy: 0.8246 - val_loss: 0.9534 - val_accuracy: 0.4634 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3655 - accuracy: 0.8263 - val_loss: 0.9574 - val_accuracy: 0.5016 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3610 - accuracy: 0.8302 - val_loss: 0.7151 - val_accuracy: 0.6056 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3587 - accuracy: 0.8302 - val_loss: 0.8295 - val_accuracy: 0.5607 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3549 - accuracy: 0.8324 - val_loss: 0.6266 - val_accuracy: 0.6805 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3526 - accuracy: 0.8350 - val_loss: 0.7306 - val_accuracy: 0.6002 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3512 - accuracy: 0.8330 - val_loss: 0.6092 - val_accuracy: 0.6834 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3488 - accuracy: 0.8348 - val_loss: 0.4592 - val_accuracy: 0.7904 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3439 - accuracy: 0.8383 - val_loss: 1.0563 - val_accuracy: 0.4460 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3445 - accuracy: 0.8381 - val_loss: 0.4318 - val_accuracy: 0.8123 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3434 - accuracy: 0.8375 - val_loss: 1.1174 - val_accuracy: 0.4104 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3403 - accuracy: 0.8398 - val_loss: 0.7668 - val_accuracy: 0.5791 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3372 - accuracy: 0.8431 - val_loss: 0.5337 - val_accuracy: 0.7359 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3380 - accuracy: 0.8416 - val_loss: 1.0272 - val_accuracy: 0.4658 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3351 - accuracy: 0.8428 - val_loss: 0.3424 - val_accuracy: 0.8538 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3318 - accuracy: 0.8443 - val_loss: 0.6164 - val_accuracy: 0.6919 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3313 - accuracy: 0.8449 - val_loss: 0.3663 - val_accuracy: 0.8461 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3290 - accuracy: 0.8459 - val_loss: 0.5983 - val_accuracy: 0.6892 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3275 - accuracy: 0.8494 - val_loss: 1.0204 - val_accuracy: 0.4581 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3266 - accuracy: 0.8474 - val_loss: 0.6670 - val_accuracy: 0.6603 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3236 - accuracy: 0.8496 - val_loss: 0.3215 - val_accuracy: 0.8777 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3240 - accuracy: 0.8486 - val_loss: 0.7448 - val_accuracy: 0.6051 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3209 - accuracy: 0.8516 - val_loss: 1.3089 - val_accuracy: 0.3317 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3210 - accuracy: 0.8494 - val_loss: 0.4326 - val_accuracy: 0.8036 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3179 - accuracy: 0.8535 - val_loss: 0.3230 - val_accuracy: 0.8778 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3155 - accuracy: 0.8541 - val_loss: 0.7363 - val_accuracy: 0.5981 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3145 - accuracy: 0.8544 - val_loss: 0.6483 - val_accuracy: 0.6599 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3142 - accuracy: 0.8551 - val_loss: 0.5176 - val_accuracy: 0.7411 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3118 - accuracy: 0.8568 - val_loss: 0.4464 - val_accuracy: 0.7933 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3124 - accuracy: 0.8571 - val_loss: 0.6741 - val_accuracy: 0.6531 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3096 - accuracy: 0.8569 - val_loss: 0.4504 - val_accuracy: 0.7911 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3070 - accuracy: 0.8591 - val_loss: 1.5353 - val_accuracy: 0.2693 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3067 - accuracy: 0.8578 - val_loss: 0.5172 - val_accuracy: 0.7507 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3063 - accuracy: 0.8597 - val_loss: 0.2847 - val_accuracy: 0.9013 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3045 - accuracy: 0.8578 - val_loss: 0.4477 - val_accuracy: 0.7868 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3034 - accuracy: 0.8617 - val_loss: 0.6398 - val_accuracy: 0.6573 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.3033 - accuracy: 0.8589 - val_loss: 0.6441 - val_accuracy: 0.6635 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2997 - accuracy: 0.8634 - val_loss: 0.6424 - val_accuracy: 0.6602 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2990 - accuracy: 0.8630 - val_loss: 0.9940 - val_accuracy: 0.4732 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2992 - accuracy: 0.8620 - val_loss: 0.5078 - val_accuracy: 0.7570 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2962 - accuracy: 0.8655 - val_loss: 0.6129 - val_accuracy: 0.6838 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2962 - accuracy: 0.8658 - val_loss: 0.7572 - val_accuracy: 0.6071 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2942 - accuracy: 0.8647 - val_loss: 0.4641 - val_accuracy: 0.7710 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2929 - accuracy: 0.8666 - val_loss: 0.7974 - val_accuracy: 0.5744 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2932 - accuracy: 0.8684 - val_loss: 0.7425 - val_accuracy: 0.6030 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2907 - accuracy: 0.8689 - val_loss: 0.2868 - val_accuracy: 0.8973 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2912 - accuracy: 0.8669 - val_loss: 0.5107 - val_accuracy: 0.7537 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2897 - accuracy: 0.8678 - val_loss: 0.5711 - val_accuracy: 0.7175 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2872 - accuracy: 0.8716 - val_loss: 0.7129 - val_accuracy: 0.6249 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2863 - accuracy: 0.8711 - val_loss: 0.5029 - val_accuracy: 0.7519 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2834 - accuracy: 0.8701 - val_loss: 1.3508 - val_accuracy: 0.3237 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2849 - accuracy: 0.8697 - val_loss: 0.7786 - val_accuracy: 0.5828 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2836 - accuracy: 0.8722 - val_loss: 0.9540 - val_accuracy: 0.4915 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2829 - accuracy: 0.8719 - val_loss: 0.2256 - val_accuracy: 0.9279 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2806 - accuracy: 0.8732 - val_loss: 0.5092 - val_accuracy: 0.7653 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2830 - accuracy: 0.8724 - val_loss: 0.7671 - val_accuracy: 0.5859 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2784 - accuracy: 0.8745 - val_loss: 0.9271 - val_accuracy: 0.4904 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2772 - accuracy: 0.8751 - val_loss: 0.6398 - val_accuracy: 0.6701 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2757 - accuracy: 0.8749 - val_loss: 1.4905 - val_accuracy: 0.2890 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2750 - accuracy: 0.8753 - val_loss: 0.3884 - val_accuracy: 0.8282 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2747 - accuracy: 0.8755 - val_loss: 0.2355 - val_accuracy: 0.9254 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2745 - accuracy: 0.8775 - val_loss: 0.4061 - val_accuracy: 0.8055 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2704 - accuracy: 0.8785 - val_loss: 0.3339 - val_accuracy: 0.8645 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2706 - accuracy: 0.8769 - val_loss: 0.2529 - val_accuracy: 0.9137 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2718 - accuracy: 0.8772 - val_loss: 0.3469 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2708 - accuracy: 0.8777 - val_loss: 0.3958 - val_accuracy: 0.8141 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2674 - accuracy: 0.8801 - val_loss: 0.2858 - val_accuracy: 0.8954 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2694 - accuracy: 0.8803 - val_loss: 0.9031 - val_accuracy: 0.5169 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2667 - accuracy: 0.8800 - val_loss: 0.5158 - val_accuracy: 0.7432 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2651 - accuracy: 0.8819 - val_loss: 0.2525 - val_accuracy: 0.9143 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2662 - accuracy: 0.8816 - val_loss: 0.5341 - val_accuracy: 0.7429 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2639 - accuracy: 0.8820 - val_loss: 0.5437 - val_accuracy: 0.7218 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2650 - accuracy: 0.8810 - val_loss: 0.4122 - val_accuracy: 0.8166 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2646 - accuracy: 0.8821 - val_loss: 0.7065 - val_accuracy: 0.6438 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2496 - accuracy: 0.8892 - val_loss: 0.3330 - val_accuracy: 0.8640 - lr: 5.0000e-04\n",
            "Epoch 86/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2474 - accuracy: 0.8920 - val_loss: 0.2508 - val_accuracy: 0.9165 - lr: 5.0000e-04\n",
            "Epoch 87/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2464 - accuracy: 0.8914 - val_loss: 0.6239 - val_accuracy: 0.6846 - lr: 5.0000e-04\n",
            "Epoch 88/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2468 - accuracy: 0.8906 - val_loss: 0.6702 - val_accuracy: 0.6531 - lr: 5.0000e-04\n",
            "Epoch 89/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2443 - accuracy: 0.8932 - val_loss: 0.5660 - val_accuracy: 0.7186 - lr: 5.0000e-04\n",
            "Epoch 90/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2464 - accuracy: 0.8923 - val_loss: 0.1597 - val_accuracy: 0.9570 - lr: 5.0000e-04\n",
            "Epoch 91/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2450 - accuracy: 0.8933 - val_loss: 0.2537 - val_accuracy: 0.9107 - lr: 5.0000e-04\n",
            "Epoch 92/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2420 - accuracy: 0.8950 - val_loss: 0.6313 - val_accuracy: 0.6771 - lr: 5.0000e-04\n",
            "Epoch 93/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2442 - accuracy: 0.8934 - val_loss: 0.1025 - val_accuracy: 0.9790 - lr: 5.0000e-04\n",
            "Epoch 94/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2428 - accuracy: 0.8948 - val_loss: 0.4442 - val_accuracy: 0.7960 - lr: 5.0000e-04\n",
            "Epoch 95/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2417 - accuracy: 0.8945 - val_loss: 0.3654 - val_accuracy: 0.8474 - lr: 5.0000e-04\n",
            "Epoch 96/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2422 - accuracy: 0.8943 - val_loss: 1.0221 - val_accuracy: 0.4533 - lr: 5.0000e-04\n",
            "Epoch 97/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2385 - accuracy: 0.8958 - val_loss: 0.5630 - val_accuracy: 0.7221 - lr: 5.0000e-04\n",
            "Epoch 98/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2372 - accuracy: 0.8977 - val_loss: 0.3849 - val_accuracy: 0.8364 - lr: 5.0000e-04\n",
            "Epoch 99/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2395 - accuracy: 0.8965 - val_loss: 0.2384 - val_accuracy: 0.9215 - lr: 5.0000e-04\n",
            "Epoch 100/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2362 - accuracy: 0.8967 - val_loss: 0.6389 - val_accuracy: 0.6820 - lr: 5.0000e-04\n",
            "Epoch 101/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2370 - accuracy: 0.8973 - val_loss: 0.2506 - val_accuracy: 0.9084 - lr: 5.0000e-04\n",
            "Epoch 102/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2372 - accuracy: 0.8981 - val_loss: 0.5079 - val_accuracy: 0.7528 - lr: 5.0000e-04\n",
            "Epoch 103/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2392 - accuracy: 0.8950 - val_loss: 0.4318 - val_accuracy: 0.8031 - lr: 5.0000e-04\n",
            "Epoch 104/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2341 - accuracy: 0.8977 - val_loss: 0.6164 - val_accuracy: 0.6944 - lr: 5.0000e-04\n",
            "Epoch 105/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2357 - accuracy: 0.8975 - val_loss: 1.1982 - val_accuracy: 0.3952 - lr: 5.0000e-04\n",
            "Epoch 106/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2353 - accuracy: 0.8988 - val_loss: 0.6092 - val_accuracy: 0.6939 - lr: 5.0000e-04\n",
            "Epoch 107/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2348 - accuracy: 0.8991 - val_loss: 0.3203 - val_accuracy: 0.8635 - lr: 5.0000e-04\n",
            "Epoch 108/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2330 - accuracy: 0.8995 - val_loss: 0.5798 - val_accuracy: 0.7174 - lr: 5.0000e-04\n",
            "Epoch 109/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2333 - accuracy: 0.8992 - val_loss: 0.6718 - val_accuracy: 0.6570 - lr: 5.0000e-04\n",
            "Epoch 110/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2320 - accuracy: 0.8973 - val_loss: 0.4174 - val_accuracy: 0.8165 - lr: 5.0000e-04\n",
            "Epoch 111/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2320 - accuracy: 0.8996 - val_loss: 0.6667 - val_accuracy: 0.6640 - lr: 5.0000e-04\n",
            "Epoch 112/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2297 - accuracy: 0.9021 - val_loss: 0.1905 - val_accuracy: 0.9432 - lr: 5.0000e-04\n",
            "Epoch 113/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2321 - accuracy: 0.8994 - val_loss: 0.2721 - val_accuracy: 0.8994 - lr: 5.0000e-04\n",
            "Epoch 114/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2205 - accuracy: 0.9060 - val_loss: 0.6651 - val_accuracy: 0.6638 - lr: 2.5000e-04\n",
            "Epoch 115/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2226 - accuracy: 0.9053 - val_loss: 0.7667 - val_accuracy: 0.6067 - lr: 2.5000e-04\n",
            "Epoch 116/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2209 - accuracy: 0.9073 - val_loss: 0.3729 - val_accuracy: 0.8453 - lr: 2.5000e-04\n",
            "Epoch 117/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2208 - accuracy: 0.9061 - val_loss: 0.3281 - val_accuracy: 0.8723 - lr: 2.5000e-04\n",
            "Epoch 118/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2184 - accuracy: 0.9068 - val_loss: 0.4216 - val_accuracy: 0.8075 - lr: 2.5000e-04\n",
            "Epoch 119/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2187 - accuracy: 0.9076 - val_loss: 0.2901 - val_accuracy: 0.8953 - lr: 2.5000e-04\n",
            "Epoch 120/500\n",
            "1120/1120 [==============================] - 6s 5ms/step - loss: 0.2165 - accuracy: 0.9092 - val_loss: 0.2447 - val_accuracy: 0.9218 - lr: 2.5000e-04\n",
            "Epoch 121/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2172 - accuracy: 0.9086 - val_loss: 0.5335 - val_accuracy: 0.7429 - lr: 2.5000e-04\n",
            "Epoch 122/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2183 - accuracy: 0.9076 - val_loss: 0.2434 - val_accuracy: 0.9146 - lr: 2.5000e-04\n",
            "Epoch 123/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2187 - accuracy: 0.9083 - val_loss: 0.3483 - val_accuracy: 0.8549 - lr: 2.5000e-04\n",
            "Epoch 124/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2190 - accuracy: 0.9066 - val_loss: 0.3731 - val_accuracy: 0.8453 - lr: 2.5000e-04\n",
            "Epoch 125/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2180 - accuracy: 0.9067 - val_loss: 0.4870 - val_accuracy: 0.7648 - lr: 2.5000e-04\n",
            "Epoch 126/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2162 - accuracy: 0.9103 - val_loss: 0.5134 - val_accuracy: 0.7542 - lr: 2.5000e-04\n",
            "Epoch 127/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2163 - accuracy: 0.9090 - val_loss: 0.3273 - val_accuracy: 0.8737 - lr: 2.5000e-04\n",
            "Epoch 128/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2161 - accuracy: 0.9105 - val_loss: 0.3374 - val_accuracy: 0.8645 - lr: 2.5000e-04\n",
            "Epoch 129/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2164 - accuracy: 0.9086 - val_loss: 0.2819 - val_accuracy: 0.8982 - lr: 2.5000e-04\n",
            "Epoch 130/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2158 - accuracy: 0.9088 - val_loss: 0.2372 - val_accuracy: 0.9223 - lr: 2.5000e-04\n",
            "Epoch 131/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2161 - accuracy: 0.9094 - val_loss: 0.2805 - val_accuracy: 0.8978 - lr: 2.5000e-04\n",
            "Epoch 132/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2129 - accuracy: 0.9103 - val_loss: 0.2410 - val_accuracy: 0.9221 - lr: 2.5000e-04\n",
            "Epoch 133/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2149 - accuracy: 0.9085 - val_loss: 0.4016 - val_accuracy: 0.8231 - lr: 2.5000e-04\n",
            "Epoch 134/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2099 - accuracy: 0.9113 - val_loss: 0.4244 - val_accuracy: 0.8094 - lr: 1.2500e-04\n",
            "Epoch 135/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2088 - accuracy: 0.9138 - val_loss: 0.3749 - val_accuracy: 0.8434 - lr: 1.2500e-04\n",
            "Epoch 136/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2094 - accuracy: 0.9128 - val_loss: 0.3529 - val_accuracy: 0.8565 - lr: 1.2500e-04\n",
            "Epoch 137/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2095 - accuracy: 0.9132 - val_loss: 0.3754 - val_accuracy: 0.8383 - lr: 1.2500e-04\n",
            "Epoch 138/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2083 - accuracy: 0.9126 - val_loss: 0.3199 - val_accuracy: 0.8737 - lr: 1.2500e-04\n",
            "Epoch 139/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2086 - accuracy: 0.9138 - val_loss: 0.3449 - val_accuracy: 0.8606 - lr: 1.2500e-04\n",
            "Epoch 140/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2087 - accuracy: 0.9134 - val_loss: 0.4584 - val_accuracy: 0.7862 - lr: 1.2500e-04\n",
            "Epoch 141/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2091 - accuracy: 0.9131 - val_loss: 0.6280 - val_accuracy: 0.6811 - lr: 1.2500e-04\n",
            "Epoch 142/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2074 - accuracy: 0.9138 - val_loss: 0.3737 - val_accuracy: 0.8427 - lr: 1.2500e-04\n",
            "Epoch 143/500\n",
            "1120/1120 [==============================] - 5s 5ms/step - loss: 0.2085 - accuracy: 0.9133 - val_loss: 0.3605 - val_accuracy: 0.8508 - lr: 1.2500e-04\n",
            "Epoch 143: early stopping\n",
            "280/280 [==============================] - 1s 2ms/step\n",
            "1120/1120 [==============================] - 2s 2ms/step\n",
            "93/93 [==============================] - 0s 2ms/step\n",
            "Training on fold 5/5\n",
            "Epoch 1/500\n",
            "1400/1400 [==============================] - 9s 5ms/step - loss: 0.5096 - accuracy: 0.7461 - val_loss: 0.5856 - val_accuracy: 0.7122 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.4737 - accuracy: 0.7690 - val_loss: 0.3788 - val_accuracy: 0.8633 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.4556 - accuracy: 0.7810 - val_loss: 0.5578 - val_accuracy: 0.7195 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.4411 - accuracy: 0.7890 - val_loss: 0.5284 - val_accuracy: 0.7570 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.4310 - accuracy: 0.7955 - val_loss: 0.5327 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.4216 - accuracy: 0.8005 - val_loss: 0.3897 - val_accuracy: 0.8412 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.4165 - accuracy: 0.8045 - val_loss: 0.4821 - val_accuracy: 0.7823 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.4092 - accuracy: 0.8086 - val_loss: 0.4084 - val_accuracy: 0.8324 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.4035 - accuracy: 0.8129 - val_loss: 0.6372 - val_accuracy: 0.6581 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3989 - accuracy: 0.8144 - val_loss: 0.3695 - val_accuracy: 0.8467 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3941 - accuracy: 0.8181 - val_loss: 0.3451 - val_accuracy: 0.8681 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3899 - accuracy: 0.8188 - val_loss: 0.5257 - val_accuracy: 0.7335 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3878 - accuracy: 0.8211 - val_loss: 0.4445 - val_accuracy: 0.8023 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3823 - accuracy: 0.8239 - val_loss: 0.4335 - val_accuracy: 0.8065 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3796 - accuracy: 0.8254 - val_loss: 0.3389 - val_accuracy: 0.8732 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3756 - accuracy: 0.8263 - val_loss: 0.5909 - val_accuracy: 0.6942 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3722 - accuracy: 0.8308 - val_loss: 0.4513 - val_accuracy: 0.7871 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3710 - accuracy: 0.8302 - val_loss: 0.2228 - val_accuracy: 0.9369 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3674 - accuracy: 0.8318 - val_loss: 0.5899 - val_accuracy: 0.7023 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3629 - accuracy: 0.8347 - val_loss: 0.3826 - val_accuracy: 0.8384 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3601 - accuracy: 0.8365 - val_loss: 0.2139 - val_accuracy: 0.9384 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3583 - accuracy: 0.8383 - val_loss: 0.4139 - val_accuracy: 0.8219 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3570 - accuracy: 0.8383 - val_loss: 0.9807 - val_accuracy: 0.4728 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3551 - accuracy: 0.8408 - val_loss: 0.7891 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3541 - accuracy: 0.8401 - val_loss: 0.1704 - val_accuracy: 0.9621 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3508 - accuracy: 0.8416 - val_loss: 0.6358 - val_accuracy: 0.6702 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3474 - accuracy: 0.8427 - val_loss: 0.3180 - val_accuracy: 0.8782 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3443 - accuracy: 0.8445 - val_loss: 0.4821 - val_accuracy: 0.7705 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3427 - accuracy: 0.8462 - val_loss: 0.3688 - val_accuracy: 0.8393 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3393 - accuracy: 0.8474 - val_loss: 0.3658 - val_accuracy: 0.8472 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3414 - accuracy: 0.8464 - val_loss: 0.3563 - val_accuracy: 0.8530 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3356 - accuracy: 0.8491 - val_loss: 0.4922 - val_accuracy: 0.7595 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3336 - accuracy: 0.8512 - val_loss: 0.6228 - val_accuracy: 0.6727 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3314 - accuracy: 0.8514 - val_loss: 0.2329 - val_accuracy: 0.9266 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3319 - accuracy: 0.8527 - val_loss: 0.3800 - val_accuracy: 0.8368 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3279 - accuracy: 0.8535 - val_loss: 0.3336 - val_accuracy: 0.8645 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3275 - accuracy: 0.8539 - val_loss: 0.1048 - val_accuracy: 0.9823 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3230 - accuracy: 0.8564 - val_loss: 0.5695 - val_accuracy: 0.7029 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.3235 - accuracy: 0.8581 - val_loss: 0.6161 - val_accuracy: 0.6720 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3215 - accuracy: 0.8564 - val_loss: 0.2877 - val_accuracy: 0.8902 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3176 - accuracy: 0.8590 - val_loss: 0.1759 - val_accuracy: 0.9485 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3177 - accuracy: 0.8607 - val_loss: 0.0820 - val_accuracy: 0.9857 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.3154 - accuracy: 0.8606 - val_loss: 0.1089 - val_accuracy: 0.9836 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3136 - accuracy: 0.8601 - val_loss: 0.2654 - val_accuracy: 0.9080 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3119 - accuracy: 0.8629 - val_loss: 0.4141 - val_accuracy: 0.8154 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3113 - accuracy: 0.8640 - val_loss: 0.1513 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3087 - accuracy: 0.8642 - val_loss: 0.2984 - val_accuracy: 0.8772 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3098 - accuracy: 0.8632 - val_loss: 0.7273 - val_accuracy: 0.6266 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3065 - accuracy: 0.8661 - val_loss: 0.1518 - val_accuracy: 0.9648 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.3051 - accuracy: 0.8681 - val_loss: 0.2195 - val_accuracy: 0.9355 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3043 - accuracy: 0.8659 - val_loss: 0.7563 - val_accuracy: 0.6180 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3035 - accuracy: 0.8661 - val_loss: 0.2826 - val_accuracy: 0.8992 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.3010 - accuracy: 0.8692 - val_loss: 0.1537 - val_accuracy: 0.9622 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2992 - accuracy: 0.8685 - val_loss: 0.4321 - val_accuracy: 0.7961 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2958 - accuracy: 0.8719 - val_loss: 1.4835 - val_accuracy: 0.2746 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2979 - accuracy: 0.8697 - val_loss: 0.2275 - val_accuracy: 0.9228 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2945 - accuracy: 0.8732 - val_loss: 0.4029 - val_accuracy: 0.8099 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2925 - accuracy: 0.8723 - val_loss: 0.2598 - val_accuracy: 0.9045 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2922 - accuracy: 0.8731 - val_loss: 1.0323 - val_accuracy: 0.4840 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2889 - accuracy: 0.8753 - val_loss: 0.3417 - val_accuracy: 0.8544 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2895 - accuracy: 0.8750 - val_loss: 0.2749 - val_accuracy: 0.9033 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2887 - accuracy: 0.8748 - val_loss: 0.1791 - val_accuracy: 0.9465 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2718 - accuracy: 0.8849 - val_loss: 0.1835 - val_accuracy: 0.9496 - lr: 5.0000e-04\n",
            "Epoch 64/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2712 - accuracy: 0.8870 - val_loss: 0.2440 - val_accuracy: 0.9181 - lr: 5.0000e-04\n",
            "Epoch 65/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2689 - accuracy: 0.8877 - val_loss: 0.1696 - val_accuracy: 0.9555 - lr: 5.0000e-04\n",
            "Epoch 66/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2656 - accuracy: 0.8894 - val_loss: 0.3929 - val_accuracy: 0.8291 - lr: 5.0000e-04\n",
            "Epoch 67/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2650 - accuracy: 0.8892 - val_loss: 0.2359 - val_accuracy: 0.9190 - lr: 5.0000e-04\n",
            "Epoch 68/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2658 - accuracy: 0.8877 - val_loss: 0.2139 - val_accuracy: 0.9317 - lr: 5.0000e-04\n",
            "Epoch 69/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2634 - accuracy: 0.8886 - val_loss: 0.4878 - val_accuracy: 0.7640 - lr: 5.0000e-04\n",
            "Epoch 70/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2639 - accuracy: 0.8888 - val_loss: 0.1303 - val_accuracy: 0.9724 - lr: 5.0000e-04\n",
            "Epoch 71/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2637 - accuracy: 0.8881 - val_loss: 0.1464 - val_accuracy: 0.9658 - lr: 5.0000e-04\n",
            "Epoch 72/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2602 - accuracy: 0.8920 - val_loss: 0.1042 - val_accuracy: 0.9807 - lr: 5.0000e-04\n",
            "Epoch 73/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2630 - accuracy: 0.8907 - val_loss: 0.1193 - val_accuracy: 0.9776 - lr: 5.0000e-04\n",
            "Epoch 74/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2586 - accuracy: 0.8931 - val_loss: 0.2789 - val_accuracy: 0.8970 - lr: 5.0000e-04\n",
            "Epoch 75/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2595 - accuracy: 0.8916 - val_loss: 0.2244 - val_accuracy: 0.9281 - lr: 5.0000e-04\n",
            "Epoch 76/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2577 - accuracy: 0.8924 - val_loss: 0.1782 - val_accuracy: 0.9500 - lr: 5.0000e-04\n",
            "Epoch 77/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2575 - accuracy: 0.8919 - val_loss: 0.1737 - val_accuracy: 0.9528 - lr: 5.0000e-04\n",
            "Epoch 78/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2569 - accuracy: 0.8934 - val_loss: 0.3007 - val_accuracy: 0.8810 - lr: 5.0000e-04\n",
            "Epoch 79/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2549 - accuracy: 0.8946 - val_loss: 0.2582 - val_accuracy: 0.9106 - lr: 5.0000e-04\n",
            "Epoch 80/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2532 - accuracy: 0.8955 - val_loss: 0.0716 - val_accuracy: 0.9930 - lr: 5.0000e-04\n",
            "Epoch 81/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2540 - accuracy: 0.8944 - val_loss: 0.2172 - val_accuracy: 0.9321 - lr: 5.0000e-04\n",
            "Epoch 82/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2539 - accuracy: 0.8957 - val_loss: 0.3249 - val_accuracy: 0.8717 - lr: 5.0000e-04\n",
            "Epoch 83/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2517 - accuracy: 0.8947 - val_loss: 0.1871 - val_accuracy: 0.9427 - lr: 5.0000e-04\n",
            "Epoch 84/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2506 - accuracy: 0.8929 - val_loss: 0.3759 - val_accuracy: 0.8366 - lr: 5.0000e-04\n",
            "Epoch 85/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2503 - accuracy: 0.8947 - val_loss: 0.1778 - val_accuracy: 0.9493 - lr: 5.0000e-04\n",
            "Epoch 86/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2486 - accuracy: 0.8975 - val_loss: 0.3585 - val_accuracy: 0.8433 - lr: 5.0000e-04\n",
            "Epoch 87/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2487 - accuracy: 0.8971 - val_loss: 0.1206 - val_accuracy: 0.9743 - lr: 5.0000e-04\n",
            "Epoch 88/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2495 - accuracy: 0.8956 - val_loss: 0.3771 - val_accuracy: 0.8281 - lr: 5.0000e-04\n",
            "Epoch 89/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2473 - accuracy: 0.8967 - val_loss: 0.1943 - val_accuracy: 0.9372 - lr: 5.0000e-04\n",
            "Epoch 90/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2451 - accuracy: 0.8987 - val_loss: 0.2660 - val_accuracy: 0.9012 - lr: 5.0000e-04\n",
            "Epoch 91/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2451 - accuracy: 0.8985 - val_loss: 0.2372 - val_accuracy: 0.9150 - lr: 5.0000e-04\n",
            "Epoch 92/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2451 - accuracy: 0.8973 - val_loss: 0.1878 - val_accuracy: 0.9461 - lr: 5.0000e-04\n",
            "Epoch 93/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2428 - accuracy: 0.8990 - val_loss: 0.1752 - val_accuracy: 0.9504 - lr: 5.0000e-04\n",
            "Epoch 94/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2433 - accuracy: 0.8996 - val_loss: 0.1387 - val_accuracy: 0.9657 - lr: 5.0000e-04\n",
            "Epoch 95/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2428 - accuracy: 0.8988 - val_loss: 0.3200 - val_accuracy: 0.8723 - lr: 5.0000e-04\n",
            "Epoch 96/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2419 - accuracy: 0.9012 - val_loss: 0.2503 - val_accuracy: 0.9080 - lr: 5.0000e-04\n",
            "Epoch 97/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2428 - accuracy: 0.9005 - val_loss: 0.3567 - val_accuracy: 0.8482 - lr: 5.0000e-04\n",
            "Epoch 98/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2416 - accuracy: 0.8994 - val_loss: 0.3731 - val_accuracy: 0.8352 - lr: 5.0000e-04\n",
            "Epoch 99/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2382 - accuracy: 0.9014 - val_loss: 0.1187 - val_accuracy: 0.9763 - lr: 5.0000e-04\n",
            "Epoch 100/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2391 - accuracy: 0.9005 - val_loss: 0.2578 - val_accuracy: 0.8999 - lr: 5.0000e-04\n",
            "Epoch 101/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2297 - accuracy: 0.9081 - val_loss: 0.3087 - val_accuracy: 0.8751 - lr: 2.5000e-04\n",
            "Epoch 102/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2276 - accuracy: 0.9089 - val_loss: 0.1938 - val_accuracy: 0.9450 - lr: 2.5000e-04\n",
            "Epoch 103/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2269 - accuracy: 0.9075 - val_loss: 0.1465 - val_accuracy: 0.9646 - lr: 2.5000e-04\n",
            "Epoch 104/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2282 - accuracy: 0.9071 - val_loss: 0.2094 - val_accuracy: 0.9347 - lr: 2.5000e-04\n",
            "Epoch 105/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2259 - accuracy: 0.9083 - val_loss: 0.1729 - val_accuracy: 0.9530 - lr: 2.5000e-04\n",
            "Epoch 106/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2253 - accuracy: 0.9103 - val_loss: 0.2665 - val_accuracy: 0.8987 - lr: 2.5000e-04\n",
            "Epoch 107/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2240 - accuracy: 0.9093 - val_loss: 0.2018 - val_accuracy: 0.9404 - lr: 2.5000e-04\n",
            "Epoch 108/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2250 - accuracy: 0.9095 - val_loss: 0.2453 - val_accuracy: 0.9134 - lr: 2.5000e-04\n",
            "Epoch 109/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2241 - accuracy: 0.9099 - val_loss: 0.2332 - val_accuracy: 0.9232 - lr: 2.5000e-04\n",
            "Epoch 110/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2244 - accuracy: 0.9093 - val_loss: 0.1673 - val_accuracy: 0.9536 - lr: 2.5000e-04\n",
            "Epoch 111/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2233 - accuracy: 0.9095 - val_loss: 0.1857 - val_accuracy: 0.9429 - lr: 2.5000e-04\n",
            "Epoch 112/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2207 - accuracy: 0.9116 - val_loss: 0.4376 - val_accuracy: 0.7922 - lr: 2.5000e-04\n",
            "Epoch 113/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2220 - accuracy: 0.9112 - val_loss: 0.1394 - val_accuracy: 0.9650 - lr: 2.5000e-04\n",
            "Epoch 114/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2228 - accuracy: 0.9107 - val_loss: 0.1918 - val_accuracy: 0.9414 - lr: 2.5000e-04\n",
            "Epoch 115/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2207 - accuracy: 0.9109 - val_loss: 0.2401 - val_accuracy: 0.9186 - lr: 2.5000e-04\n",
            "Epoch 116/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2211 - accuracy: 0.9118 - val_loss: 0.1807 - val_accuracy: 0.9465 - lr: 2.5000e-04\n",
            "Epoch 117/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2218 - accuracy: 0.9112 - val_loss: 0.2366 - val_accuracy: 0.9215 - lr: 2.5000e-04\n",
            "Epoch 118/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2187 - accuracy: 0.9114 - val_loss: 0.1992 - val_accuracy: 0.9378 - lr: 2.5000e-04\n",
            "Epoch 119/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2196 - accuracy: 0.9117 - val_loss: 0.2377 - val_accuracy: 0.9166 - lr: 2.5000e-04\n",
            "Epoch 120/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2194 - accuracy: 0.9132 - val_loss: 0.1167 - val_accuracy: 0.9758 - lr: 2.5000e-04\n",
            "Epoch 121/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2129 - accuracy: 0.9153 - val_loss: 0.1530 - val_accuracy: 0.9612 - lr: 1.2500e-04\n",
            "Epoch 122/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2163 - accuracy: 0.9149 - val_loss: 0.2104 - val_accuracy: 0.9307 - lr: 1.2500e-04\n",
            "Epoch 123/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2145 - accuracy: 0.9145 - val_loss: 0.1936 - val_accuracy: 0.9386 - lr: 1.2500e-04\n",
            "Epoch 124/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2126 - accuracy: 0.9156 - val_loss: 0.1266 - val_accuracy: 0.9711 - lr: 1.2500e-04\n",
            "Epoch 125/500\n",
            "1400/1400 [==============================] - 6s 5ms/step - loss: 0.2118 - accuracy: 0.9167 - val_loss: 0.2530 - val_accuracy: 0.9081 - lr: 1.2500e-04\n",
            "Epoch 126/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2133 - accuracy: 0.9154 - val_loss: 0.2314 - val_accuracy: 0.9193 - lr: 1.2500e-04\n",
            "Epoch 127/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2147 - accuracy: 0.9146 - val_loss: 0.1985 - val_accuracy: 0.9383 - lr: 1.2500e-04\n",
            "Epoch 128/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2105 - accuracy: 0.9175 - val_loss: 0.1197 - val_accuracy: 0.9748 - lr: 1.2500e-04\n",
            "Epoch 129/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2118 - accuracy: 0.9158 - val_loss: 0.1772 - val_accuracy: 0.9485 - lr: 1.2500e-04\n",
            "Epoch 130/500\n",
            "1400/1400 [==============================] - 7s 5ms/step - loss: 0.2114 - accuracy: 0.9173 - val_loss: 0.1629 - val_accuracy: 0.9545 - lr: 1.2500e-04\n",
            "Epoch 130: early stopping\n",
            "280/280 [==============================] - 1s 2ms/step\n",
            "1400/1400 [==============================] - 2s 2ms/step\n",
            "93/93 [==============================] - 0s 2ms/step\n",
            "Average F1 score (validation): 0.5139055496245906\n",
            "Average precision score (validation): 0.5676224211927732\n",
            "Average F1 score (train): 0.8904686146924996\n",
            "Average precision score (train): 0.9192308491863223\n",
            "Average F1 score (test): 0.4713117562956103\n",
            "Average precision score (test): 0.4897702695810827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN result\n",
        "#Average F1 score: 0.5076440234099121\n",
        "#Average precision score: 0.6114438993430864"
      ],
      "metadata": {
        "id": "n7cERDnyu2a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLvX29vdu2QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# is it overfitting?\n",
        "# Batchnormalization: method to make artificial NNs faster and more stable through re-centering and re-scaling layers inputs\n",
        "# Dropout: regularisation technique for reducing overfitting in ANNs by preventing complex co-adaptations on training data. Performing model averaging\n"
      ],
      "metadata": {
        "id": "kjdG7zP4aal6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## safe\n",
        "!mkdir -p saved_model\n",
        "large_model.save('saved_model/my_large_model')\n",
        "\n",
        "!zip -r saved_model.zip saved_model\n",
        "\n",
        "# push to GitHub see [3]\n",
        "\n",
        "## load\n",
        "# unzip files\n",
        "import zipfile\n",
        "with zipfile.ZipFile(‘./saved_model.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n",
        "\n",
        "# Load the saved model\n",
        "with tf.device('/device:GPU:0'):\n",
        "    new_large_model = tf.keras.models.load_model('saved_model/my_large_model')\n",
        "\n",
        "# Check its architecture\n",
        "new_large_model.summary()'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "voiBNpOfyZu9",
        "outputId": "6121a47d-5b18-4140-80e9-bf85ff84e1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n## safe \\n!mkdir -p saved_model\\nlarge_model.save('saved_model/my_large_model')\\n\\n!zip -r saved_model.zip saved_model\\n\\n# push to GitHub see [3]\\n\\n## load\\n# unzip files \\nimport zipfile\\nwith zipfile.ZipFile(‘./saved_model.zip', 'r') as zip_ref:\\n    zip_ref.extractall('./')\\n\\n# Load the saved model\\nwith tf.device('/device:GPU:0'):\\n    new_large_model = tf.keras.models.load_model('saved_model/my_large_model')\\n\\n# Check its architecture\\nnew_large_model.summary()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daily mean median and variance of redispatch"
      ],
      "metadata": {
        "id": "S_i1lgDdh8nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample data to different time intervals (e.g., daily, weekly, monthly)\n",
        "# Here, we calculate daily summary statistics\n",
        "daily_summary = df['redispatch'].resample('D').agg(['mean', 'median', 'var'])\n",
        "\n",
        "# Calculate autocorrelation\n",
        "autocorr = df['redispatch'].autocorr()\n",
        "\n",
        "# Plot summary statistics\n",
        "daily_summary.plot(title='Daily Summary Statistics', figsize=(10, 6))\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.legend(['Mean', 'Median', 'Variance'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Autocorrelation:\", autocorr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "hMFd4c_Hhjuv",
        "outputId": "3f48e939-d130-464e-9f54-19b759a4122f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autocorrelation: 0.960101247666363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weekly mean median and variance of redispatch"
      ],
      "metadata": {
        "id": "w8wNfXWqiD-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample data to different time intervals (e.g., daily, weekly, monthly)\n",
        "# Here, we calculate daily summary statistics\n",
        "weekly_summary = df['redispatch'].resample('W').agg(['mean', 'median', 'var'])\n",
        "\n",
        "# Calculate autocorrelation\n",
        "autocorr = df['redispatch'].autocorr()\n",
        "\n",
        "# Plot summary statistics\n",
        "weekly_summary.plot(title='Weekly Summary Statistics', figsize=(10, 6))\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.legend(['Mean', 'Median', 'Variance'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Autocorrelation:\", autocorr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "PmUfsCYLiGrN",
        "outputId": "f26995ac-f1ce-48b7-e415-73b08db071b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autocorrelation: 0.960101247666363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monthly mean median and variance of redispatch"
      ],
      "metadata": {
        "id": "ZSzjKaWMiWwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample data to different time intervals (e.g., daily, weekly, monthly)\n",
        "# Here, we calculate daily summary statistics\n",
        "monthly_summary = df['redispatch'].resample('M').agg(['mean', 'median', 'var'])\n",
        "\n",
        "# Calculate autocorrelation\n",
        "autocorr = df['redispatch'].autocorr()\n",
        "\n",
        "# Plot summary statistics\n",
        "monthly_summary.plot(title='Monthly Summary Statistics', figsize=(10, 6))\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.legend(['Mean', 'Median', 'Variance'])\n",
        "plt.show()\n",
        "\n",
        "print(\"Autocorrelation:\", autocorr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "-DcR6Y2riGj1",
        "outputId": "cf1b7281-1aa0-4e79-baab-1bdaef1b4163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autocorrelation: 0.960101247666363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for auto correlation of redispatch"
      ],
      "metadata": {
        "id": "XXMCfKkwkFjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate autocorrelation function (ACF)\n",
        "acf = pd.Series(data=df['redispatch']).autocorr()\n",
        "\n",
        "# Plot autocorrelation function (ACF)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_acf(df['redispatch'], lags=50, alpha=0.05)\n",
        "plt.title('Autocorrelation Function (ACF)')\n",
        "plt.xlabel('Lag')\n",
        "plt.ylabel('Autocorrelation')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Autocorrelation:\", acf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "_BHEy0w-id4J",
        "outputId": "42beaf56-b947-46e1-91ab-dba8235f61e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autocorrelation: 0.960101247666363\n"
          ]
        }
      ]
    }
  ]
}